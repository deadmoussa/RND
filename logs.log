2023-02-09 13:45:35,213:INFO:PyCaret Supervised Module
2023-02-09 13:45:35,213:INFO:ML Usecase: regression
2023-02-09 13:45:35,213:INFO:version 2.3.10
2023-02-09 13:45:35,213:INFO:Initializing setup()
2023-02-09 13:45:35,213:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'open', 'high', 'low', 'close', 'volume', 'volume_24HR', 'volume_24HR$', 'volume_$', 'closeChg', 'openChg', 'highChg', 'lowChg', 'volume_24HR$Chg', 'volume_24HRChg', 'volume_$'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-09 13:45:35,213:INFO:Checking environment
2023-02-09 13:45:35,213:INFO:python_version: 3.8.12
2023-02-09 13:45:35,213:INFO:python_build: ('default', 'Oct 12 2021 13:49:34')
2023-02-09 13:45:35,213:INFO:machine: x86_64
2023-02-09 13:45:35,213:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-09 13:45:35,213:INFO:Memory: svmem(total=134979592192, available=113095307264, percent=16.2, used=17959780352, free=88935157760, active=2859487232, inactive=41167663104, buffers=787968000, cached=27296686080, shared=2661179392, slab=1373425664)
2023-02-09 13:45:35,214:INFO:Physical Core: 16
2023-02-09 13:45:35,214:INFO:Logical Core: 32
2023-02-09 13:45:35,214:INFO:Checking libraries
2023-02-09 13:45:35,214:INFO:pd==1.4.1
2023-02-09 13:45:35,214:INFO:numpy==1.23.5
2023-02-09 13:45:35,214:INFO:sklearn==0.23.2
2023-02-09 13:45:35,214:INFO:lightgbm==3.3.5
2023-02-09 13:45:35,214:WARNING:catboost not found
2023-02-09 13:45:35,215:WARNING:xgboost not found
2023-02-09 13:45:35,215:INFO:mlflow==2.1.1
2023-02-09 13:45:35,215:INFO:Checking Exceptions
2023-02-09 13:45:35,215:INFO:Declaring global variables
2023-02-09 13:45:35,215:INFO:USI: 9ec4
2023-02-09 13:45:35,215:INFO:pycaret_globals: {'n_jobs_param', 'log_plots_param', '_gpu_n_jobs_param', 'logging_param', 'fix_imbalance_param', 'fold_generator', 'fold_groups_param_full', 'transform_target_param', 'pycaret_globals', 'experiment__', 'create_model_container', 'fold_shuffle_param', 'y_train', 'imputation_classifier', 'X', '_ml_usecase', 'iterative_imputation_iters_param', 'seed', 'prep_pipe', '_all_metrics', 'transform_target_method_param', '_internal_pipeline', '_all_models_internal', 'target_param', 'X_test', 'html_param', 'data_before_preprocess', 'dashboard_logger', 'exp_name_log', '_all_models', 'imputation_regressor', 'y', 'fold_groups_param', 'X_train', 'stratify_param', 'y_test', 'gpu_param', 'display_container', 'fix_imbalance_method_param', 'fold_param', '_available_plots', 'USI', 'master_model_container'}
2023-02-09 13:45:35,215:INFO:Preparing display monitor
2023-02-09 13:45:35,215:INFO:Preparing display monitor
2023-02-09 13:45:35,223:INFO:Importing libraries
2023-02-09 13:45:35,223:INFO:Copying data for preprocessing
2023-02-09 13:45:35,231:INFO:Declaring preprocessing parameters
2023-02-09 13:45:35,242:INFO:Creating preprocessing pipeline
2023-02-09 13:45:35,498:INFO:Preprocessing pipeline created successfully
2023-02-09 13:45:35,498:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-09 13:45:35,498:INFO:Creating global containers
2023-02-09 13:45:35,498:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-09 13:45:36,976:WARNING:Couldn't import xgboost.XGBRegressor
2023-02-09 13:45:36,977:WARNING:Couldn't import catboost.CatBoostRegressor
2023-02-09 13:45:37,044:WARNING:Couldn't import xgboost.XGBRegressor
2023-02-09 13:45:37,045:WARNING:Couldn't import catboost.CatBoostRegressor
2023-02-09 13:45:37,045:INFO:Creating grid variables
2023-02-09 13:45:37,059:INFO:create_model_container: 0
2023-02-09 13:45:37,059:INFO:master_model_container: 0
2023-02-09 13:45:37,059:INFO:display_container: 1
2023-02-09 13:45:37,061:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument', 'open',
                                                       'high', 'low', 'close',
                                                       'volume', 'volume_24HR',
                                                       'volume_24HR$',
                                                       'volume_$', 'closeChg',
                                                       'openChg', 'highChg',
                                                       'lowChg',
                                                       'volume_24HR$Chg',
                                                       'volume_24HRChg',
                                                       'volume_$'],
                                      id_columns=[], ml_usecase=...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-09 13:45:37,062:INFO:setup() succesfully completed......................................
2023-02-09 13:45:37,142:INFO:Initializing compare_models()
2023-02-09 13:45:37,142:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-02-09 13:45:37,142:INFO:Checking exceptions
2023-02-09 13:45:37,142:INFO:Preparing display monitor
2023-02-09 13:45:37,142:INFO:Preparing display monitor
2023-02-09 13:45:37,154:INFO:Initializing Linear Regression
2023-02-09 13:45:37,154:INFO:Total runtime is 1.4702479044596355e-06 minutes
2023-02-09 13:45:37,157:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:37,158:INFO:Initializing create_model()
2023-02-09 13:45:37,158:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:37,158:INFO:Checking exceptions
2023-02-09 13:45:37,158:INFO:Importing libraries
2023-02-09 13:45:37,158:INFO:Copying training dataset
2023-02-09 13:45:37,159:INFO:Defining folds
2023-02-09 13:45:37,159:INFO:Declaring metric variables
2023-02-09 13:45:37,162:INFO:Importing untrained model
2023-02-09 13:45:37,165:INFO:Linear Regression Imported succesfully
2023-02-09 13:45:37,171:INFO:Starting cross validation
2023-02-09 13:45:37,173:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:38,618:INFO:Calculating mean and std
2023-02-09 13:45:38,619:INFO:Creating metrics dataframe
2023-02-09 13:45:38,636:INFO:Uploading results into container
2023-02-09 13:45:38,636:INFO:Uploading model into container now
2023-02-09 13:45:38,636:INFO:create_model_container: 1
2023-02-09 13:45:38,636:INFO:master_model_container: 1
2023-02-09 13:45:38,636:INFO:display_container: 2
2023-02-09 13:45:38,636:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-09 13:45:38,636:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:38,719:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:38,719:INFO:Creating metrics dataframe
2023-02-09 13:45:38,728:INFO:Initializing Lasso Regression
2023-02-09 13:45:38,728:INFO:Total runtime is 0.026239426930745442 minutes
2023-02-09 13:45:38,732:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:38,732:INFO:Initializing create_model()
2023-02-09 13:45:38,732:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:38,732:INFO:Checking exceptions
2023-02-09 13:45:38,732:INFO:Importing libraries
2023-02-09 13:45:38,732:INFO:Copying training dataset
2023-02-09 13:45:38,733:INFO:Defining folds
2023-02-09 13:45:38,733:INFO:Declaring metric variables
2023-02-09 13:45:38,736:INFO:Importing untrained model
2023-02-09 13:45:38,739:INFO:Lasso Regression Imported succesfully
2023-02-09 13:45:38,745:INFO:Starting cross validation
2023-02-09 13:45:38,745:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:40,278:INFO:Calculating mean and std
2023-02-09 13:45:40,279:INFO:Creating metrics dataframe
2023-02-09 13:45:40,288:INFO:Uploading results into container
2023-02-09 13:45:40,288:INFO:Uploading model into container now
2023-02-09 13:45:40,288:INFO:create_model_container: 2
2023-02-09 13:45:40,288:INFO:master_model_container: 2
2023-02-09 13:45:40,288:INFO:display_container: 2
2023-02-09 13:45:40,288:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-09 13:45:40,288:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:40,372:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:40,372:INFO:Creating metrics dataframe
2023-02-09 13:45:40,382:INFO:Initializing Ridge Regression
2023-02-09 13:45:40,382:INFO:Total runtime is 0.0538089911142985 minutes
2023-02-09 13:45:40,386:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:40,386:INFO:Initializing create_model()
2023-02-09 13:45:40,386:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:40,386:INFO:Checking exceptions
2023-02-09 13:45:40,386:INFO:Importing libraries
2023-02-09 13:45:40,386:INFO:Copying training dataset
2023-02-09 13:45:40,387:INFO:Defining folds
2023-02-09 13:45:40,387:INFO:Declaring metric variables
2023-02-09 13:45:40,390:INFO:Importing untrained model
2023-02-09 13:45:40,393:INFO:Ridge Regression Imported succesfully
2023-02-09 13:45:40,399:INFO:Starting cross validation
2023-02-09 13:45:40,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:41,329:INFO:Calculating mean and std
2023-02-09 13:45:41,330:INFO:Creating metrics dataframe
2023-02-09 13:45:41,339:INFO:Uploading results into container
2023-02-09 13:45:41,339:INFO:Uploading model into container now
2023-02-09 13:45:41,339:INFO:create_model_container: 3
2023-02-09 13:45:41,339:INFO:master_model_container: 3
2023-02-09 13:45:41,339:INFO:display_container: 2
2023-02-09 13:45:41,339:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-09 13:45:41,340:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:41,424:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:41,424:INFO:Creating metrics dataframe
2023-02-09 13:45:41,435:INFO:Initializing Elastic Net
2023-02-09 13:45:41,435:INFO:Total runtime is 0.07134993076324463 minutes
2023-02-09 13:45:41,438:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:41,438:INFO:Initializing create_model()
2023-02-09 13:45:41,438:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:41,439:INFO:Checking exceptions
2023-02-09 13:45:41,439:INFO:Importing libraries
2023-02-09 13:45:41,439:INFO:Copying training dataset
2023-02-09 13:45:41,439:INFO:Defining folds
2023-02-09 13:45:41,439:INFO:Declaring metric variables
2023-02-09 13:45:41,442:INFO:Importing untrained model
2023-02-09 13:45:41,445:INFO:Elastic Net Imported succesfully
2023-02-09 13:45:41,451:INFO:Starting cross validation
2023-02-09 13:45:41,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:43,184:INFO:Calculating mean and std
2023-02-09 13:45:43,185:INFO:Creating metrics dataframe
2023-02-09 13:45:43,193:INFO:Uploading results into container
2023-02-09 13:45:43,193:INFO:Uploading model into container now
2023-02-09 13:45:43,193:INFO:create_model_container: 4
2023-02-09 13:45:43,193:INFO:master_model_container: 4
2023-02-09 13:45:43,193:INFO:display_container: 2
2023-02-09 13:45:43,193:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-09 13:45:43,193:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:43,271:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:43,271:INFO:Creating metrics dataframe
2023-02-09 13:45:43,282:INFO:Initializing Least Angle Regression
2023-02-09 13:45:43,282:INFO:Total runtime is 0.10213750998179118 minutes
2023-02-09 13:45:43,286:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:43,286:INFO:Initializing create_model()
2023-02-09 13:45:43,286:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:43,286:INFO:Checking exceptions
2023-02-09 13:45:43,286:INFO:Importing libraries
2023-02-09 13:45:43,286:INFO:Copying training dataset
2023-02-09 13:45:43,287:INFO:Defining folds
2023-02-09 13:45:43,287:INFO:Declaring metric variables
2023-02-09 13:45:43,290:INFO:Importing untrained model
2023-02-09 13:45:43,293:INFO:Least Angle Regression Imported succesfully
2023-02-09 13:45:43,299:INFO:Starting cross validation
2023-02-09 13:45:43,299:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:43,806:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-09 13:45:43,807:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 436, in _process_worker
    r = call_item()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 288, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 444, in result
    return self.__get_result()
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-09 13:45:43,807:INFO:Initializing create_model()
2023-02-09 13:45:43,807:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:43,807:INFO:Checking exceptions
2023-02-09 13:45:43,808:INFO:Importing libraries
2023-02-09 13:45:43,808:INFO:Copying training dataset
2023-02-09 13:45:43,809:INFO:Defining folds
2023-02-09 13:45:43,809:INFO:Declaring metric variables
2023-02-09 13:45:43,814:INFO:Importing untrained model
2023-02-09 13:45:43,818:INFO:Least Angle Regression Imported succesfully
2023-02-09 13:45:43,824:INFO:Starting cross validation
2023-02-09 13:45:43,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:45,393:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-02-09 13:45:45,393:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 436, in _process_worker
    r = call_item()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 288, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 444, in result
    return self.__get_result()
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-09 13:45:45,393:INFO:Initializing Lasso Least Angle Regression
2023-02-09 13:45:45,393:INFO:Total runtime is 0.1373206933339437 minutes
2023-02-09 13:45:45,400:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:45,400:INFO:Initializing create_model()
2023-02-09 13:45:45,400:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:45,400:INFO:Checking exceptions
2023-02-09 13:45:45,400:INFO:Importing libraries
2023-02-09 13:45:45,400:INFO:Copying training dataset
2023-02-09 13:45:45,401:INFO:Defining folds
2023-02-09 13:45:45,401:INFO:Declaring metric variables
2023-02-09 13:45:45,404:INFO:Importing untrained model
2023-02-09 13:45:45,408:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-09 13:45:45,414:INFO:Starting cross validation
2023-02-09 13:45:45,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:46,731:INFO:Calculating mean and std
2023-02-09 13:45:46,732:INFO:Creating metrics dataframe
2023-02-09 13:45:46,749:INFO:Uploading results into container
2023-02-09 13:45:46,749:INFO:Uploading model into container now
2023-02-09 13:45:46,750:INFO:create_model_container: 5
2023-02-09 13:45:46,750:INFO:master_model_container: 5
2023-02-09 13:45:46,750:INFO:display_container: 2
2023-02-09 13:45:46,750:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-09 13:45:46,750:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:46,846:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:46,846:INFO:Creating metrics dataframe
2023-02-09 13:45:46,856:INFO:Initializing Orthogonal Matching Pursuit
2023-02-09 13:45:46,856:INFO:Total runtime is 0.16169608036677044 minutes
2023-02-09 13:45:46,859:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:46,859:INFO:Initializing create_model()
2023-02-09 13:45:46,859:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:46,859:INFO:Checking exceptions
2023-02-09 13:45:46,859:INFO:Importing libraries
2023-02-09 13:45:46,859:INFO:Copying training dataset
2023-02-09 13:45:46,860:INFO:Defining folds
2023-02-09 13:45:46,860:INFO:Declaring metric variables
2023-02-09 13:45:46,863:INFO:Importing untrained model
2023-02-09 13:45:46,866:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-09 13:45:46,872:INFO:Starting cross validation
2023-02-09 13:45:46,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:47,813:INFO:Calculating mean and std
2023-02-09 13:45:47,814:INFO:Creating metrics dataframe
2023-02-09 13:45:47,825:INFO:Uploading results into container
2023-02-09 13:45:47,825:INFO:Uploading model into container now
2023-02-09 13:45:47,825:INFO:create_model_container: 6
2023-02-09 13:45:47,825:INFO:master_model_container: 6
2023-02-09 13:45:47,825:INFO:display_container: 2
2023-02-09 13:45:47,825:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-09 13:45:47,825:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:47,906:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:47,906:INFO:Creating metrics dataframe
2023-02-09 13:45:47,918:INFO:Initializing Bayesian Ridge
2023-02-09 13:45:47,918:INFO:Total runtime is 0.1794022838274638 minutes
2023-02-09 13:45:47,921:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:47,922:INFO:Initializing create_model()
2023-02-09 13:45:47,922:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:47,922:INFO:Checking exceptions
2023-02-09 13:45:47,922:INFO:Importing libraries
2023-02-09 13:45:47,922:INFO:Copying training dataset
2023-02-09 13:45:47,922:INFO:Defining folds
2023-02-09 13:45:47,923:INFO:Declaring metric variables
2023-02-09 13:45:47,926:INFO:Importing untrained model
2023-02-09 13:45:47,929:INFO:Bayesian Ridge Imported succesfully
2023-02-09 13:45:47,935:INFO:Starting cross validation
2023-02-09 13:45:47,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:49,074:INFO:Calculating mean and std
2023-02-09 13:45:49,074:INFO:Creating metrics dataframe
2023-02-09 13:45:49,084:INFO:Uploading results into container
2023-02-09 13:45:49,084:INFO:Uploading model into container now
2023-02-09 13:45:49,084:INFO:create_model_container: 7
2023-02-09 13:45:49,084:INFO:master_model_container: 7
2023-02-09 13:45:49,084:INFO:display_container: 2
2023-02-09 13:45:49,084:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-09 13:45:49,084:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:49,159:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:49,159:INFO:Creating metrics dataframe
2023-02-09 13:45:49,169:INFO:Initializing Passive Aggressive Regressor
2023-02-09 13:45:49,169:INFO:Total runtime is 0.20025487343470255 minutes
2023-02-09 13:45:49,173:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:49,173:INFO:Initializing create_model()
2023-02-09 13:45:49,173:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:49,173:INFO:Checking exceptions
2023-02-09 13:45:49,173:INFO:Importing libraries
2023-02-09 13:45:49,173:INFO:Copying training dataset
2023-02-09 13:45:49,174:INFO:Defining folds
2023-02-09 13:45:49,174:INFO:Declaring metric variables
2023-02-09 13:45:49,176:INFO:Importing untrained model
2023-02-09 13:45:49,180:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-09 13:45:49,186:INFO:Starting cross validation
2023-02-09 13:45:49,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:49,957:INFO:Calculating mean and std
2023-02-09 13:45:49,959:INFO:Creating metrics dataframe
2023-02-09 13:45:49,970:INFO:Uploading results into container
2023-02-09 13:45:49,970:INFO:Uploading model into container now
2023-02-09 13:45:49,970:INFO:create_model_container: 8
2023-02-09 13:45:49,971:INFO:master_model_container: 8
2023-02-09 13:45:49,971:INFO:display_container: 2
2023-02-09 13:45:49,971:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-09 13:45:49,971:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:50,047:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:50,047:INFO:Creating metrics dataframe
2023-02-09 13:45:50,058:INFO:Initializing Huber Regressor
2023-02-09 13:45:50,058:INFO:Total runtime is 0.2150668501853943 minutes
2023-02-09 13:45:50,061:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:50,062:INFO:Initializing create_model()
2023-02-09 13:45:50,062:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:50,062:INFO:Checking exceptions
2023-02-09 13:45:50,062:INFO:Importing libraries
2023-02-09 13:45:50,062:INFO:Copying training dataset
2023-02-09 13:45:50,062:INFO:Defining folds
2023-02-09 13:45:50,062:INFO:Declaring metric variables
2023-02-09 13:45:50,065:INFO:Importing untrained model
2023-02-09 13:45:50,068:INFO:Huber Regressor Imported succesfully
2023-02-09 13:45:50,074:INFO:Starting cross validation
2023-02-09 13:45:50,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:50,691:INFO:Calculating mean and std
2023-02-09 13:45:50,692:INFO:Creating metrics dataframe
2023-02-09 13:45:50,703:INFO:Uploading results into container
2023-02-09 13:45:50,703:INFO:Uploading model into container now
2023-02-09 13:45:50,703:INFO:create_model_container: 9
2023-02-09 13:45:50,703:INFO:master_model_container: 9
2023-02-09 13:45:50,703:INFO:display_container: 2
2023-02-09 13:45:50,704:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-09 13:45:50,704:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:50,779:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:50,780:INFO:Creating metrics dataframe
2023-02-09 13:45:50,791:INFO:Initializing K Neighbors Regressor
2023-02-09 13:45:50,791:INFO:Total runtime is 0.22727763652801514 minutes
2023-02-09 13:45:50,794:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:50,794:INFO:Initializing create_model()
2023-02-09 13:45:50,794:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:50,794:INFO:Checking exceptions
2023-02-09 13:45:50,794:INFO:Importing libraries
2023-02-09 13:45:50,794:INFO:Copying training dataset
2023-02-09 13:45:50,795:INFO:Defining folds
2023-02-09 13:45:50,795:INFO:Declaring metric variables
2023-02-09 13:45:50,798:INFO:Importing untrained model
2023-02-09 13:45:50,801:INFO:K Neighbors Regressor Imported succesfully
2023-02-09 13:45:50,807:INFO:Starting cross validation
2023-02-09 13:45:50,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:51,142:INFO:Calculating mean and std
2023-02-09 13:45:51,143:INFO:Creating metrics dataframe
2023-02-09 13:45:51,154:INFO:Uploading results into container
2023-02-09 13:45:51,154:INFO:Uploading model into container now
2023-02-09 13:45:51,154:INFO:create_model_container: 10
2023-02-09 13:45:51,154:INFO:master_model_container: 10
2023-02-09 13:45:51,154:INFO:display_container: 2
2023-02-09 13:45:51,154:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-09 13:45:51,154:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:51,234:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:51,234:INFO:Creating metrics dataframe
2023-02-09 13:45:51,247:INFO:Initializing Decision Tree Regressor
2023-02-09 13:45:51,247:INFO:Total runtime is 0.2348878542582194 minutes
2023-02-09 13:45:51,251:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:51,251:INFO:Initializing create_model()
2023-02-09 13:45:51,251:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:51,251:INFO:Checking exceptions
2023-02-09 13:45:51,251:INFO:Importing libraries
2023-02-09 13:45:51,251:INFO:Copying training dataset
2023-02-09 13:45:51,252:INFO:Defining folds
2023-02-09 13:45:51,252:INFO:Declaring metric variables
2023-02-09 13:45:51,255:INFO:Importing untrained model
2023-02-09 13:45:51,258:INFO:Decision Tree Regressor Imported succesfully
2023-02-09 13:45:51,264:INFO:Starting cross validation
2023-02-09 13:45:51,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:45:53,707:INFO:Calculating mean and std
2023-02-09 13:45:53,708:INFO:Creating metrics dataframe
2023-02-09 13:45:53,721:INFO:Uploading results into container
2023-02-09 13:45:53,721:INFO:Uploading model into container now
2023-02-09 13:45:53,721:INFO:create_model_container: 11
2023-02-09 13:45:53,721:INFO:master_model_container: 11
2023-02-09 13:45:53,721:INFO:display_container: 2
2023-02-09 13:45:53,721:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-09 13:45:53,721:INFO:create_model() succesfully completed......................................
2023-02-09 13:45:53,802:INFO:SubProcess create_model() end ==================================
2023-02-09 13:45:53,802:INFO:Creating metrics dataframe
2023-02-09 13:45:53,814:INFO:Initializing Random Forest Regressor
2023-02-09 13:45:53,814:INFO:Total runtime is 0.2776626229286194 minutes
2023-02-09 13:45:53,817:INFO:SubProcess create_model() called ==================================
2023-02-09 13:45:53,817:INFO:Initializing create_model()
2023-02-09 13:45:53,817:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:45:53,817:INFO:Checking exceptions
2023-02-09 13:45:53,817:INFO:Importing libraries
2023-02-09 13:45:53,817:INFO:Copying training dataset
2023-02-09 13:45:53,818:INFO:Defining folds
2023-02-09 13:45:53,818:INFO:Declaring metric variables
2023-02-09 13:45:53,821:INFO:Importing untrained model
2023-02-09 13:45:53,824:INFO:Random Forest Regressor Imported succesfully
2023-02-09 13:45:53,831:INFO:Starting cross validation
2023-02-09 13:45:53,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:46:54,383:INFO:Calculating mean and std
2023-02-09 13:46:54,384:INFO:Creating metrics dataframe
2023-02-09 13:46:54,394:INFO:Uploading results into container
2023-02-09 13:46:54,394:INFO:Uploading model into container now
2023-02-09 13:46:54,394:INFO:create_model_container: 12
2023-02-09 13:46:54,394:INFO:master_model_container: 12
2023-02-09 13:46:54,394:INFO:display_container: 2
2023-02-09 13:46:54,394:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-09 13:46:54,394:INFO:create_model() succesfully completed......................................
2023-02-09 13:46:54,470:INFO:SubProcess create_model() end ==================================
2023-02-09 13:46:54,470:INFO:Creating metrics dataframe
2023-02-09 13:46:54,481:INFO:Initializing Extra Trees Regressor
2023-02-09 13:46:54,481:INFO:Total runtime is 1.2887810309727987 minutes
2023-02-09 13:46:54,484:INFO:SubProcess create_model() called ==================================
2023-02-09 13:46:54,484:INFO:Initializing create_model()
2023-02-09 13:46:54,484:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:46:54,484:INFO:Checking exceptions
2023-02-09 13:46:54,485:INFO:Importing libraries
2023-02-09 13:46:54,485:INFO:Copying training dataset
2023-02-09 13:46:54,485:INFO:Defining folds
2023-02-09 13:46:54,485:INFO:Declaring metric variables
2023-02-09 13:46:54,488:INFO:Importing untrained model
2023-02-09 13:46:54,492:INFO:Extra Trees Regressor Imported succesfully
2023-02-09 13:46:54,498:INFO:Starting cross validation
2023-02-09 13:46:54,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:47:05,989:INFO:Calculating mean and std
2023-02-09 13:47:05,990:INFO:Creating metrics dataframe
2023-02-09 13:47:06,000:INFO:Uploading results into container
2023-02-09 13:47:06,000:INFO:Uploading model into container now
2023-02-09 13:47:06,000:INFO:create_model_container: 13
2023-02-09 13:47:06,000:INFO:master_model_container: 13
2023-02-09 13:47:06,000:INFO:display_container: 2
2023-02-09 13:47:06,000:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-09 13:47:06,000:INFO:create_model() succesfully completed......................................
2023-02-09 13:47:06,080:INFO:SubProcess create_model() end ==================================
2023-02-09 13:47:06,080:INFO:Creating metrics dataframe
2023-02-09 13:47:06,091:INFO:Initializing AdaBoost Regressor
2023-02-09 13:47:06,091:INFO:Total runtime is 1.4822811484336853 minutes
2023-02-09 13:47:06,094:INFO:SubProcess create_model() called ==================================
2023-02-09 13:47:06,095:INFO:Initializing create_model()
2023-02-09 13:47:06,095:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:47:06,095:INFO:Checking exceptions
2023-02-09 13:47:06,095:INFO:Importing libraries
2023-02-09 13:47:06,095:INFO:Copying training dataset
2023-02-09 13:47:06,095:INFO:Defining folds
2023-02-09 13:47:06,095:INFO:Declaring metric variables
2023-02-09 13:47:06,098:INFO:Importing untrained model
2023-02-09 13:47:06,102:INFO:AdaBoost Regressor Imported succesfully
2023-02-09 13:47:06,108:INFO:Starting cross validation
2023-02-09 13:47:06,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:47:14,120:INFO:Calculating mean and std
2023-02-09 13:47:14,121:INFO:Creating metrics dataframe
2023-02-09 13:47:14,128:INFO:Uploading results into container
2023-02-09 13:47:14,128:INFO:Uploading model into container now
2023-02-09 13:47:14,128:INFO:create_model_container: 14
2023-02-09 13:47:14,128:INFO:master_model_container: 14
2023-02-09 13:47:14,128:INFO:display_container: 2
2023-02-09 13:47:14,128:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-09 13:47:14,128:INFO:create_model() succesfully completed......................................
2023-02-09 13:47:14,206:INFO:SubProcess create_model() end ==================================
2023-02-09 13:47:14,206:INFO:Creating metrics dataframe
2023-02-09 13:47:14,218:INFO:Initializing Gradient Boosting Regressor
2023-02-09 13:47:14,218:INFO:Total runtime is 1.617742411295573 minutes
2023-02-09 13:47:14,222:INFO:SubProcess create_model() called ==================================
2023-02-09 13:47:14,222:INFO:Initializing create_model()
2023-02-09 13:47:14,222:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:47:14,222:INFO:Checking exceptions
2023-02-09 13:47:14,222:INFO:Importing libraries
2023-02-09 13:47:14,222:INFO:Copying training dataset
2023-02-09 13:47:14,223:INFO:Defining folds
2023-02-09 13:47:14,223:INFO:Declaring metric variables
2023-02-09 13:47:14,226:INFO:Importing untrained model
2023-02-09 13:47:14,231:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-09 13:47:14,238:INFO:Starting cross validation
2023-02-09 13:47:14,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:47:49,382:INFO:Calculating mean and std
2023-02-09 13:47:49,383:INFO:Creating metrics dataframe
2023-02-09 13:47:49,394:INFO:Uploading results into container
2023-02-09 13:47:49,394:INFO:Uploading model into container now
2023-02-09 13:47:49,394:INFO:create_model_container: 15
2023-02-09 13:47:49,394:INFO:master_model_container: 15
2023-02-09 13:47:49,394:INFO:display_container: 2
2023-02-09 13:47:49,395:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-09 13:47:49,395:INFO:create_model() succesfully completed......................................
2023-02-09 13:47:49,473:INFO:SubProcess create_model() end ==================================
2023-02-09 13:47:49,473:INFO:Creating metrics dataframe
2023-02-09 13:47:49,486:INFO:Initializing Light Gradient Boosting Machine
2023-02-09 13:47:49,486:INFO:Total runtime is 2.205527400970459 minutes
2023-02-09 13:47:49,489:INFO:SubProcess create_model() called ==================================
2023-02-09 13:47:49,489:INFO:Initializing create_model()
2023-02-09 13:47:49,489:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:47:49,489:INFO:Checking exceptions
2023-02-09 13:47:49,489:INFO:Importing libraries
2023-02-09 13:47:49,489:INFO:Copying training dataset
2023-02-09 13:47:49,490:INFO:Defining folds
2023-02-09 13:47:49,490:INFO:Declaring metric variables
2023-02-09 13:47:49,493:INFO:Importing untrained model
2023-02-09 13:47:49,496:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-09 13:47:49,503:INFO:Starting cross validation
2023-02-09 13:47:49,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:47:51,834:INFO:Calculating mean and std
2023-02-09 13:47:51,834:INFO:Creating metrics dataframe
2023-02-09 13:47:51,842:INFO:Uploading results into container
2023-02-09 13:47:51,842:INFO:Uploading model into container now
2023-02-09 13:47:51,842:INFO:create_model_container: 16
2023-02-09 13:47:51,842:INFO:master_model_container: 16
2023-02-09 13:47:51,842:INFO:display_container: 2
2023-02-09 13:47:51,842:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-09 13:47:51,843:INFO:create_model() succesfully completed......................................
2023-02-09 13:47:51,934:INFO:SubProcess create_model() end ==================================
2023-02-09 13:47:51,934:INFO:Creating metrics dataframe
2023-02-09 13:47:51,947:INFO:Initializing Dummy Regressor
2023-02-09 13:47:51,947:INFO:Total runtime is 2.246544325351715 minutes
2023-02-09 13:47:51,950:INFO:SubProcess create_model() called ==================================
2023-02-09 13:47:51,950:INFO:Initializing create_model()
2023-02-09 13:47:51,950:INFO:create_model(estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb4449752e0>, return_train_score=False, kwargs={})
2023-02-09 13:47:51,950:INFO:Checking exceptions
2023-02-09 13:47:51,950:INFO:Importing libraries
2023-02-09 13:47:51,950:INFO:Copying training dataset
2023-02-09 13:47:51,951:INFO:Defining folds
2023-02-09 13:47:51,951:INFO:Declaring metric variables
2023-02-09 13:47:51,955:INFO:Importing untrained model
2023-02-09 13:47:51,958:INFO:Dummy Regressor Imported succesfully
2023-02-09 13:47:51,964:INFO:Starting cross validation
2023-02-09 13:47:51,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:47:52,463:INFO:Calculating mean and std
2023-02-09 13:47:52,464:INFO:Creating metrics dataframe
2023-02-09 13:47:52,477:INFO:Uploading results into container
2023-02-09 13:47:52,477:INFO:Uploading model into container now
2023-02-09 13:47:52,477:INFO:create_model_container: 17
2023-02-09 13:47:52,477:INFO:master_model_container: 17
2023-02-09 13:47:52,477:INFO:display_container: 2
2023-02-09 13:47:52,478:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-02-09 13:47:52,478:INFO:create_model() succesfully completed......................................
2023-02-09 13:47:52,560:INFO:SubProcess create_model() end ==================================
2023-02-09 13:47:52,560:INFO:Creating metrics dataframe
2023-02-09 13:47:52,580:INFO:Initializing create_model()
2023-02-09 13:47:52,580:INFO:create_model(estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-09 13:47:52,580:INFO:Checking exceptions
2023-02-09 13:47:52,580:INFO:Importing libraries
2023-02-09 13:47:52,580:INFO:Copying training dataset
2023-02-09 13:47:52,581:INFO:Defining folds
2023-02-09 13:47:52,581:INFO:Declaring metric variables
2023-02-09 13:47:52,581:INFO:Importing untrained model
2023-02-09 13:47:52,581:INFO:Declaring custom model
2023-02-09 13:47:52,581:INFO:Extra Trees Regressor Imported succesfully
2023-02-09 13:47:52,582:INFO:Cross validation set to False
2023-02-09 13:47:52,582:INFO:Fitting Model
2023-02-09 13:47:53,989:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-09 13:47:53,990:INFO:create_models() succesfully completed......................................
2023-02-09 13:47:54,081:INFO:create_model_container: 17
2023-02-09 13:47:54,081:INFO:master_model_container: 17
2023-02-09 13:47:54,081:INFO:display_container: 2
2023-02-09 13:47:54,082:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-09 13:47:54,082:INFO:compare_models() succesfully completed......................................
2023-02-09 13:51:19,186:INFO:PyCaret Supervised Module
2023-02-09 13:51:19,186:INFO:ML Usecase: regression
2023-02-09 13:51:19,186:INFO:version 2.3.10
2023-02-09 13:51:19,186:INFO:Initializing setup()
2023-02-09 13:51:19,186:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'open', 'high', 'low', 'close', 'volume', 'volume_24HR', 'volume_24HR$', 'volume_$', 'closeChg', 'openChg', 'highChg', 'lowChg', 'volume_24HR$Chg', 'volume_24HRChg', 'volume_$'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-09 13:51:19,186:INFO:Checking environment
2023-02-09 13:51:19,186:INFO:python_version: 3.8.12
2023-02-09 13:51:19,186:INFO:python_build: ('default', 'Oct 12 2021 13:49:34')
2023-02-09 13:51:19,186:INFO:machine: x86_64
2023-02-09 13:51:19,186:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-09 13:51:19,186:INFO:Memory: svmem(total=134979592192, available=106182041600, percent=21.3, used=24855674880, free=82005995520, active=2914938880, inactive=47977103360, buffers=789250048, cached=27328671744, shared=2678550528, slab=1395204096)
2023-02-09 13:51:19,187:INFO:Physical Core: 16
2023-02-09 13:51:19,187:INFO:Logical Core: 32
2023-02-09 13:51:19,187:INFO:Checking libraries
2023-02-09 13:51:19,187:INFO:pd==1.4.1
2023-02-09 13:51:19,187:INFO:numpy==1.23.5
2023-02-09 13:51:19,187:INFO:sklearn==0.23.2
2023-02-09 13:51:19,187:INFO:lightgbm==3.3.5
2023-02-09 13:51:19,187:WARNING:catboost not found
2023-02-09 13:51:19,187:WARNING:xgboost not found
2023-02-09 13:51:19,187:INFO:mlflow==2.1.1
2023-02-09 13:51:19,187:INFO:Checking Exceptions
2023-02-09 13:51:19,187:INFO:Declaring global variables
2023-02-09 13:51:19,187:INFO:USI: 9b75
2023-02-09 13:51:19,187:INFO:pycaret_globals: {'n_jobs_param', 'log_plots_param', '_gpu_n_jobs_param', 'logging_param', 'fix_imbalance_param', 'fold_generator', 'fold_groups_param_full', 'transform_target_param', 'pycaret_globals', 'experiment__', 'create_model_container', 'fold_shuffle_param', 'y_train', 'imputation_classifier', 'X', '_ml_usecase', 'iterative_imputation_iters_param', 'seed', 'prep_pipe', '_all_metrics', 'transform_target_method_param', '_internal_pipeline', '_all_models_internal', 'target_param', 'X_test', 'html_param', 'data_before_preprocess', 'dashboard_logger', 'exp_name_log', '_all_models', 'imputation_regressor', 'y', 'fold_groups_param', 'X_train', 'stratify_param', 'y_test', 'gpu_param', 'display_container', 'fix_imbalance_method_param', 'fold_param', '_available_plots', 'USI', 'master_model_container'}
2023-02-09 13:51:19,187:INFO:Preparing display monitor
2023-02-09 13:51:19,187:INFO:Preparing display monitor
2023-02-09 13:51:19,193:INFO:Importing libraries
2023-02-09 13:51:19,193:INFO:Copying data for preprocessing
2023-02-09 13:51:19,202:INFO:Declaring preprocessing parameters
2023-02-09 13:51:19,211:INFO:Creating preprocessing pipeline
2023-02-09 13:51:19,462:INFO:Preprocessing pipeline created successfully
2023-02-09 13:51:19,462:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-09 13:51:19,462:INFO:Creating global containers
2023-02-09 13:51:19,462:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-09 13:51:20,809:WARNING:Couldn't import xgboost.XGBRegressor
2023-02-09 13:51:20,809:WARNING:Couldn't import catboost.CatBoostRegressor
2023-02-09 13:51:20,878:WARNING:Couldn't import xgboost.XGBRegressor
2023-02-09 13:51:20,878:WARNING:Couldn't import catboost.CatBoostRegressor
2023-02-09 13:51:20,878:INFO:Creating grid variables
2023-02-09 13:51:20,892:INFO:create_model_container: 0
2023-02-09 13:51:20,892:INFO:master_model_container: 0
2023-02-09 13:51:20,892:INFO:display_container: 1
2023-02-09 13:51:20,894:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument', 'open',
                                                       'high', 'low', 'close',
                                                       'volume', 'volume_24HR',
                                                       'volume_24HR$',
                                                       'volume_$', 'closeChg',
                                                       'openChg', 'highChg',
                                                       'lowChg',
                                                       'volume_24HR$Chg',
                                                       'volume_24HRChg',
                                                       'volume_$'],
                                      id_columns=[], ml_usecase=...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-09 13:51:20,894:INFO:setup() succesfully completed......................................
2023-02-09 13:51:20,975:INFO:Initializing compare_models()
2023-02-09 13:51:20,975:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-02-09 13:51:20,975:INFO:Checking exceptions
2023-02-09 13:51:20,975:INFO:Preparing display monitor
2023-02-09 13:51:20,975:INFO:Preparing display monitor
2023-02-09 13:51:20,988:INFO:Initializing Linear Regression
2023-02-09 13:51:20,988:INFO:Total runtime is 8.58306884765625e-07 minutes
2023-02-09 13:51:20,991:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:20,991:INFO:Initializing create_model()
2023-02-09 13:51:20,991:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:20,991:INFO:Checking exceptions
2023-02-09 13:51:20,991:INFO:Importing libraries
2023-02-09 13:51:20,991:INFO:Copying training dataset
2023-02-09 13:51:20,992:INFO:Defining folds
2023-02-09 13:51:20,992:INFO:Declaring metric variables
2023-02-09 13:51:20,995:INFO:Importing untrained model
2023-02-09 13:51:20,998:INFO:Linear Regression Imported succesfully
2023-02-09 13:51:21,004:INFO:Starting cross validation
2023-02-09 13:51:21,005:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:21,114:INFO:Calculating mean and std
2023-02-09 13:51:21,115:INFO:Creating metrics dataframe
2023-02-09 13:51:21,125:INFO:Uploading results into container
2023-02-09 13:51:21,125:INFO:Uploading model into container now
2023-02-09 13:51:21,125:INFO:create_model_container: 1
2023-02-09 13:51:21,125:INFO:master_model_container: 1
2023-02-09 13:51:21,125:INFO:display_container: 2
2023-02-09 13:51:21,125:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-09 13:51:21,125:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:21,208:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:21,209:INFO:Creating metrics dataframe
2023-02-09 13:51:21,219:INFO:Initializing Lasso Regression
2023-02-09 13:51:21,219:INFO:Total runtime is 0.0038568894068400066 minutes
2023-02-09 13:51:21,222:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:21,223:INFO:Initializing create_model()
2023-02-09 13:51:21,223:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:21,223:INFO:Checking exceptions
2023-02-09 13:51:21,223:INFO:Importing libraries
2023-02-09 13:51:21,223:INFO:Copying training dataset
2023-02-09 13:51:21,223:INFO:Defining folds
2023-02-09 13:51:21,224:INFO:Declaring metric variables
2023-02-09 13:51:21,227:INFO:Importing untrained model
2023-02-09 13:51:21,230:INFO:Lasso Regression Imported succesfully
2023-02-09 13:51:21,236:INFO:Starting cross validation
2023-02-09 13:51:21,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:22,367:INFO:Calculating mean and std
2023-02-09 13:51:22,368:INFO:Creating metrics dataframe
2023-02-09 13:51:22,379:INFO:Uploading results into container
2023-02-09 13:51:22,379:INFO:Uploading model into container now
2023-02-09 13:51:22,379:INFO:create_model_container: 2
2023-02-09 13:51:22,379:INFO:master_model_container: 2
2023-02-09 13:51:22,379:INFO:display_container: 2
2023-02-09 13:51:22,379:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-09 13:51:22,379:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:22,458:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:22,458:INFO:Creating metrics dataframe
2023-02-09 13:51:22,468:INFO:Initializing Ridge Regression
2023-02-09 13:51:22,468:INFO:Total runtime is 0.02467712163925171 minutes
2023-02-09 13:51:22,472:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:22,472:INFO:Initializing create_model()
2023-02-09 13:51:22,472:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:22,472:INFO:Checking exceptions
2023-02-09 13:51:22,472:INFO:Importing libraries
2023-02-09 13:51:22,472:INFO:Copying training dataset
2023-02-09 13:51:22,473:INFO:Defining folds
2023-02-09 13:51:22,473:INFO:Declaring metric variables
2023-02-09 13:51:22,476:INFO:Importing untrained model
2023-02-09 13:51:22,479:INFO:Ridge Regression Imported succesfully
2023-02-09 13:51:22,486:INFO:Starting cross validation
2023-02-09 13:51:22,486:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:23,305:INFO:Calculating mean and std
2023-02-09 13:51:23,306:INFO:Creating metrics dataframe
2023-02-09 13:51:23,316:INFO:Uploading results into container
2023-02-09 13:51:23,316:INFO:Uploading model into container now
2023-02-09 13:51:23,316:INFO:create_model_container: 3
2023-02-09 13:51:23,316:INFO:master_model_container: 3
2023-02-09 13:51:23,316:INFO:display_container: 2
2023-02-09 13:51:23,317:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-09 13:51:23,317:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:23,395:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:23,396:INFO:Creating metrics dataframe
2023-02-09 13:51:23,405:INFO:Initializing Elastic Net
2023-02-09 13:51:23,405:INFO:Total runtime is 0.040287836392720544 minutes
2023-02-09 13:51:23,408:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:23,408:INFO:Initializing create_model()
2023-02-09 13:51:23,408:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:23,409:INFO:Checking exceptions
2023-02-09 13:51:23,409:INFO:Importing libraries
2023-02-09 13:51:23,409:INFO:Copying training dataset
2023-02-09 13:51:23,409:INFO:Defining folds
2023-02-09 13:51:23,409:INFO:Declaring metric variables
2023-02-09 13:51:23,412:INFO:Importing untrained model
2023-02-09 13:51:23,416:INFO:Elastic Net Imported succesfully
2023-02-09 13:51:23,422:INFO:Starting cross validation
2023-02-09 13:51:23,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:25,250:INFO:Calculating mean and std
2023-02-09 13:51:25,251:INFO:Creating metrics dataframe
2023-02-09 13:51:25,261:INFO:Uploading results into container
2023-02-09 13:51:25,261:INFO:Uploading model into container now
2023-02-09 13:51:25,261:INFO:create_model_container: 4
2023-02-09 13:51:25,261:INFO:master_model_container: 4
2023-02-09 13:51:25,261:INFO:display_container: 2
2023-02-09 13:51:25,261:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-09 13:51:25,261:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:25,340:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:25,340:INFO:Creating metrics dataframe
2023-02-09 13:51:25,349:INFO:Initializing Least Angle Regression
2023-02-09 13:51:25,349:INFO:Total runtime is 0.07269763946533203 minutes
2023-02-09 13:51:25,353:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:25,353:INFO:Initializing create_model()
2023-02-09 13:51:25,353:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:25,353:INFO:Checking exceptions
2023-02-09 13:51:25,353:INFO:Importing libraries
2023-02-09 13:51:25,353:INFO:Copying training dataset
2023-02-09 13:51:25,354:INFO:Defining folds
2023-02-09 13:51:25,354:INFO:Declaring metric variables
2023-02-09 13:51:25,357:INFO:Importing untrained model
2023-02-09 13:51:25,361:INFO:Least Angle Regression Imported succesfully
2023-02-09 13:51:25,367:INFO:Starting cross validation
2023-02-09 13:51:25,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:26,542:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-09 13:51:26,542:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 436, in _process_worker
    r = call_item()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 288, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-09 13:51:26,542:INFO:Initializing create_model()
2023-02-09 13:51:26,542:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:26,542:INFO:Checking exceptions
2023-02-09 13:51:26,542:INFO:Importing libraries
2023-02-09 13:51:26,542:INFO:Copying training dataset
2023-02-09 13:51:26,544:INFO:Defining folds
2023-02-09 13:51:26,544:INFO:Declaring metric variables
2023-02-09 13:51:26,549:INFO:Importing untrained model
2023-02-09 13:51:26,553:INFO:Least Angle Regression Imported succesfully
2023-02-09 13:51:26,559:INFO:Starting cross validation
2023-02-09 13:51:26,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:28,361:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-02-09 13:51:28,362:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 436, in _process_worker
    r = call_item()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 288, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 444, in result
    return self.__get_result()
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-09 13:51:28,362:INFO:Initializing Lasso Least Angle Regression
2023-02-09 13:51:28,362:INFO:Total runtime is 0.12290397087732952 minutes
2023-02-09 13:51:28,368:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:28,368:INFO:Initializing create_model()
2023-02-09 13:51:28,368:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:28,368:INFO:Checking exceptions
2023-02-09 13:51:28,368:INFO:Importing libraries
2023-02-09 13:51:28,368:INFO:Copying training dataset
2023-02-09 13:51:28,369:INFO:Defining folds
2023-02-09 13:51:28,369:INFO:Declaring metric variables
2023-02-09 13:51:28,372:INFO:Importing untrained model
2023-02-09 13:51:28,377:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-09 13:51:28,383:INFO:Starting cross validation
2023-02-09 13:51:28,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:29,879:INFO:Calculating mean and std
2023-02-09 13:51:29,880:INFO:Creating metrics dataframe
2023-02-09 13:51:29,892:INFO:Uploading results into container
2023-02-09 13:51:29,892:INFO:Uploading model into container now
2023-02-09 13:51:29,892:INFO:create_model_container: 5
2023-02-09 13:51:29,892:INFO:master_model_container: 5
2023-02-09 13:51:29,892:INFO:display_container: 2
2023-02-09 13:51:29,893:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-09 13:51:29,893:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:29,982:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:29,982:INFO:Creating metrics dataframe
2023-02-09 13:51:29,997:INFO:Initializing Orthogonal Matching Pursuit
2023-02-09 13:51:29,997:INFO:Total runtime is 0.15015157461166384 minutes
2023-02-09 13:51:30,000:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:30,000:INFO:Initializing create_model()
2023-02-09 13:51:30,000:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:30,000:INFO:Checking exceptions
2023-02-09 13:51:30,000:INFO:Importing libraries
2023-02-09 13:51:30,000:INFO:Copying training dataset
2023-02-09 13:51:30,001:INFO:Defining folds
2023-02-09 13:51:30,001:INFO:Declaring metric variables
2023-02-09 13:51:30,005:INFO:Importing untrained model
2023-02-09 13:51:30,008:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-09 13:51:30,014:INFO:Starting cross validation
2023-02-09 13:51:30,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:30,974:INFO:Calculating mean and std
2023-02-09 13:51:30,975:INFO:Creating metrics dataframe
2023-02-09 13:51:30,987:INFO:Uploading results into container
2023-02-09 13:51:30,987:INFO:Uploading model into container now
2023-02-09 13:51:30,987:INFO:create_model_container: 6
2023-02-09 13:51:30,987:INFO:master_model_container: 6
2023-02-09 13:51:30,987:INFO:display_container: 2
2023-02-09 13:51:30,987:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-09 13:51:30,987:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:31,067:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:31,067:INFO:Creating metrics dataframe
2023-02-09 13:51:31,078:INFO:Initializing Bayesian Ridge
2023-02-09 13:51:31,078:INFO:Total runtime is 0.1681731700897217 minutes
2023-02-09 13:51:31,081:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:31,082:INFO:Initializing create_model()
2023-02-09 13:51:31,082:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:31,082:INFO:Checking exceptions
2023-02-09 13:51:31,082:INFO:Importing libraries
2023-02-09 13:51:31,082:INFO:Copying training dataset
2023-02-09 13:51:31,082:INFO:Defining folds
2023-02-09 13:51:31,082:INFO:Declaring metric variables
2023-02-09 13:51:31,085:INFO:Importing untrained model
2023-02-09 13:51:31,089:INFO:Bayesian Ridge Imported succesfully
2023-02-09 13:51:31,095:INFO:Starting cross validation
2023-02-09 13:51:31,095:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:32,147:INFO:Calculating mean and std
2023-02-09 13:51:32,148:INFO:Creating metrics dataframe
2023-02-09 13:51:32,157:INFO:Uploading results into container
2023-02-09 13:51:32,157:INFO:Uploading model into container now
2023-02-09 13:51:32,157:INFO:create_model_container: 7
2023-02-09 13:51:32,157:INFO:master_model_container: 7
2023-02-09 13:51:32,157:INFO:display_container: 2
2023-02-09 13:51:32,157:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-09 13:51:32,157:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:32,237:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:32,237:INFO:Creating metrics dataframe
2023-02-09 13:51:32,249:INFO:Initializing Passive Aggressive Regressor
2023-02-09 13:51:32,249:INFO:Total runtime is 0.18768762350082402 minutes
2023-02-09 13:51:32,252:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:32,253:INFO:Initializing create_model()
2023-02-09 13:51:32,253:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:32,253:INFO:Checking exceptions
2023-02-09 13:51:32,253:INFO:Importing libraries
2023-02-09 13:51:32,253:INFO:Copying training dataset
2023-02-09 13:51:32,253:INFO:Defining folds
2023-02-09 13:51:32,253:INFO:Declaring metric variables
2023-02-09 13:51:32,256:INFO:Importing untrained model
2023-02-09 13:51:32,260:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-09 13:51:32,266:INFO:Starting cross validation
2023-02-09 13:51:32,266:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:33,026:INFO:Calculating mean and std
2023-02-09 13:51:33,027:INFO:Creating metrics dataframe
2023-02-09 13:51:33,039:INFO:Uploading results into container
2023-02-09 13:51:33,039:INFO:Uploading model into container now
2023-02-09 13:51:33,039:INFO:create_model_container: 8
2023-02-09 13:51:33,039:INFO:master_model_container: 8
2023-02-09 13:51:33,039:INFO:display_container: 2
2023-02-09 13:51:33,039:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-09 13:51:33,039:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:33,119:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:33,120:INFO:Creating metrics dataframe
2023-02-09 13:51:33,131:INFO:Initializing Huber Regressor
2023-02-09 13:51:33,131:INFO:Total runtime is 0.20238532622655236 minutes
2023-02-09 13:51:33,134:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:33,134:INFO:Initializing create_model()
2023-02-09 13:51:33,134:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:33,134:INFO:Checking exceptions
2023-02-09 13:51:33,134:INFO:Importing libraries
2023-02-09 13:51:33,134:INFO:Copying training dataset
2023-02-09 13:51:33,135:INFO:Defining folds
2023-02-09 13:51:33,135:INFO:Declaring metric variables
2023-02-09 13:51:33,138:INFO:Importing untrained model
2023-02-09 13:51:33,141:INFO:Huber Regressor Imported succesfully
2023-02-09 13:51:33,147:INFO:Starting cross validation
2023-02-09 13:51:33,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:33,689:INFO:Calculating mean and std
2023-02-09 13:51:33,690:INFO:Creating metrics dataframe
2023-02-09 13:51:33,700:INFO:Uploading results into container
2023-02-09 13:51:33,700:INFO:Uploading model into container now
2023-02-09 13:51:33,700:INFO:create_model_container: 9
2023-02-09 13:51:33,700:INFO:master_model_container: 9
2023-02-09 13:51:33,700:INFO:display_container: 2
2023-02-09 13:51:33,700:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-09 13:51:33,700:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:33,781:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:33,781:INFO:Creating metrics dataframe
2023-02-09 13:51:33,792:INFO:Initializing K Neighbors Regressor
2023-02-09 13:51:33,792:INFO:Total runtime is 0.21340630849202477 minutes
2023-02-09 13:51:33,796:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:33,796:INFO:Initializing create_model()
2023-02-09 13:51:33,796:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:33,796:INFO:Checking exceptions
2023-02-09 13:51:33,796:INFO:Importing libraries
2023-02-09 13:51:33,796:INFO:Copying training dataset
2023-02-09 13:51:33,797:INFO:Defining folds
2023-02-09 13:51:33,797:INFO:Declaring metric variables
2023-02-09 13:51:33,800:INFO:Importing untrained model
2023-02-09 13:51:33,803:INFO:K Neighbors Regressor Imported succesfully
2023-02-09 13:51:33,809:INFO:Starting cross validation
2023-02-09 13:51:33,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:34,146:INFO:Calculating mean and std
2023-02-09 13:51:34,147:INFO:Creating metrics dataframe
2023-02-09 13:51:34,159:INFO:Uploading results into container
2023-02-09 13:51:34,159:INFO:Uploading model into container now
2023-02-09 13:51:34,159:INFO:create_model_container: 10
2023-02-09 13:51:34,159:INFO:master_model_container: 10
2023-02-09 13:51:34,159:INFO:display_container: 2
2023-02-09 13:51:34,159:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-09 13:51:34,159:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:34,239:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:34,239:INFO:Creating metrics dataframe
2023-02-09 13:51:34,250:INFO:Initializing Decision Tree Regressor
2023-02-09 13:51:34,250:INFO:Total runtime is 0.22103758255640668 minutes
2023-02-09 13:51:34,253:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:34,254:INFO:Initializing create_model()
2023-02-09 13:51:34,254:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:34,254:INFO:Checking exceptions
2023-02-09 13:51:34,254:INFO:Importing libraries
2023-02-09 13:51:34,254:INFO:Copying training dataset
2023-02-09 13:51:34,254:INFO:Defining folds
2023-02-09 13:51:34,254:INFO:Declaring metric variables
2023-02-09 13:51:34,258:INFO:Importing untrained model
2023-02-09 13:51:34,261:INFO:Decision Tree Regressor Imported succesfully
2023-02-09 13:51:34,267:INFO:Starting cross validation
2023-02-09 13:51:34,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:51:36,668:INFO:Calculating mean and std
2023-02-09 13:51:36,669:INFO:Creating metrics dataframe
2023-02-09 13:51:36,678:INFO:Uploading results into container
2023-02-09 13:51:36,678:INFO:Uploading model into container now
2023-02-09 13:51:36,678:INFO:create_model_container: 11
2023-02-09 13:51:36,678:INFO:master_model_container: 11
2023-02-09 13:51:36,678:INFO:display_container: 2
2023-02-09 13:51:36,678:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-09 13:51:36,678:INFO:create_model() succesfully completed......................................
2023-02-09 13:51:36,781:INFO:SubProcess create_model() end ==================================
2023-02-09 13:51:36,782:INFO:Creating metrics dataframe
2023-02-09 13:51:36,794:INFO:Initializing Random Forest Regressor
2023-02-09 13:51:36,795:INFO:Total runtime is 0.26345084905624394 minutes
2023-02-09 13:51:36,798:INFO:SubProcess create_model() called ==================================
2023-02-09 13:51:36,798:INFO:Initializing create_model()
2023-02-09 13:51:36,798:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:51:36,798:INFO:Checking exceptions
2023-02-09 13:51:36,798:INFO:Importing libraries
2023-02-09 13:51:36,798:INFO:Copying training dataset
2023-02-09 13:51:36,799:INFO:Defining folds
2023-02-09 13:51:36,799:INFO:Declaring metric variables
2023-02-09 13:51:36,802:INFO:Importing untrained model
2023-02-09 13:51:36,805:INFO:Random Forest Regressor Imported succesfully
2023-02-09 13:51:36,812:INFO:Starting cross validation
2023-02-09 13:51:36,812:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:52:38,014:INFO:Calculating mean and std
2023-02-09 13:52:38,015:INFO:Creating metrics dataframe
2023-02-09 13:52:38,024:INFO:Uploading results into container
2023-02-09 13:52:38,025:INFO:Uploading model into container now
2023-02-09 13:52:38,025:INFO:create_model_container: 12
2023-02-09 13:52:38,025:INFO:master_model_container: 12
2023-02-09 13:52:38,025:INFO:display_container: 2
2023-02-09 13:52:38,025:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-09 13:52:38,025:INFO:create_model() succesfully completed......................................
2023-02-09 13:52:38,109:INFO:SubProcess create_model() end ==================================
2023-02-09 13:52:38,109:INFO:Creating metrics dataframe
2023-02-09 13:52:38,121:INFO:Initializing Extra Trees Regressor
2023-02-09 13:52:38,121:INFO:Total runtime is 1.285557742913564 minutes
2023-02-09 13:52:38,125:INFO:SubProcess create_model() called ==================================
2023-02-09 13:52:38,125:INFO:Initializing create_model()
2023-02-09 13:52:38,125:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:52:38,125:INFO:Checking exceptions
2023-02-09 13:52:38,125:INFO:Importing libraries
2023-02-09 13:52:38,125:INFO:Copying training dataset
2023-02-09 13:52:38,126:INFO:Defining folds
2023-02-09 13:52:38,126:INFO:Declaring metric variables
2023-02-09 13:52:38,129:INFO:Importing untrained model
2023-02-09 13:52:38,133:INFO:Extra Trees Regressor Imported succesfully
2023-02-09 13:52:38,139:INFO:Starting cross validation
2023-02-09 13:52:38,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:52:50,149:INFO:Calculating mean and std
2023-02-09 13:52:50,150:INFO:Creating metrics dataframe
2023-02-09 13:52:50,161:INFO:Uploading results into container
2023-02-09 13:52:50,161:INFO:Uploading model into container now
2023-02-09 13:52:50,161:INFO:create_model_container: 13
2023-02-09 13:52:50,161:INFO:master_model_container: 13
2023-02-09 13:52:50,161:INFO:display_container: 2
2023-02-09 13:52:50,161:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-09 13:52:50,161:INFO:create_model() succesfully completed......................................
2023-02-09 13:52:50,251:INFO:SubProcess create_model() end ==================================
2023-02-09 13:52:50,251:INFO:Creating metrics dataframe
2023-02-09 13:52:50,265:INFO:Initializing AdaBoost Regressor
2023-02-09 13:52:50,265:INFO:Total runtime is 1.487954890727997 minutes
2023-02-09 13:52:50,269:INFO:SubProcess create_model() called ==================================
2023-02-09 13:52:50,269:INFO:Initializing create_model()
2023-02-09 13:52:50,269:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:52:50,269:INFO:Checking exceptions
2023-02-09 13:52:50,269:INFO:Importing libraries
2023-02-09 13:52:50,269:INFO:Copying training dataset
2023-02-09 13:52:50,270:INFO:Defining folds
2023-02-09 13:52:50,270:INFO:Declaring metric variables
2023-02-09 13:52:50,273:INFO:Importing untrained model
2023-02-09 13:52:50,276:INFO:AdaBoost Regressor Imported succesfully
2023-02-09 13:52:50,283:INFO:Starting cross validation
2023-02-09 13:52:50,283:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:52:58,307:INFO:Calculating mean and std
2023-02-09 13:52:58,308:INFO:Creating metrics dataframe
2023-02-09 13:52:58,317:INFO:Uploading results into container
2023-02-09 13:52:58,317:INFO:Uploading model into container now
2023-02-09 13:52:58,317:INFO:create_model_container: 14
2023-02-09 13:52:58,317:INFO:master_model_container: 14
2023-02-09 13:52:58,317:INFO:display_container: 2
2023-02-09 13:52:58,317:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-09 13:52:58,317:INFO:create_model() succesfully completed......................................
2023-02-09 13:52:58,397:INFO:SubProcess create_model() end ==================================
2023-02-09 13:52:58,397:INFO:Creating metrics dataframe
2023-02-09 13:52:58,408:INFO:Initializing Gradient Boosting Regressor
2023-02-09 13:52:58,409:INFO:Total runtime is 1.623683508237203 minutes
2023-02-09 13:52:58,412:INFO:SubProcess create_model() called ==================================
2023-02-09 13:52:58,412:INFO:Initializing create_model()
2023-02-09 13:52:58,412:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:52:58,412:INFO:Checking exceptions
2023-02-09 13:52:58,412:INFO:Importing libraries
2023-02-09 13:52:58,412:INFO:Copying training dataset
2023-02-09 13:52:58,413:INFO:Defining folds
2023-02-09 13:52:58,413:INFO:Declaring metric variables
2023-02-09 13:52:58,416:INFO:Importing untrained model
2023-02-09 13:52:58,419:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-09 13:52:58,426:INFO:Starting cross validation
2023-02-09 13:52:58,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:53:14,962:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-09 13:53:14,963:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 439, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 302, in wait
    waiter.acquire()
KeyboardInterrupt

2023-02-09 13:53:14,963:INFO:Initializing create_model()
2023-02-09 13:53:14,963:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:53:14,963:INFO:Checking exceptions
2023-02-09 13:53:14,963:INFO:Importing libraries
2023-02-09 13:53:14,963:INFO:Copying training dataset
2023-02-09 13:53:14,964:INFO:Defining folds
2023-02-09 13:53:14,964:INFO:Declaring metric variables
2023-02-09 13:53:14,969:INFO:Importing untrained model
2023-02-09 13:53:14,974:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-09 13:53:14,980:INFO:Starting cross validation
2023-02-09 13:53:14,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:53:18,390:ERROR:create_model() for gbr raised an exception or returned all 0.0:
2023-02-09 13:53:18,396:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 439, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 302, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 439, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 302, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 957, in retrieve
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 561, in abort_everything
    self._workers.terminate(kill_workers=True)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/executor.py", line 74, in terminate
    self.shutdown(kill_workers=kill_workers)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 1185, in shutdown
    executor_manager_thread.join()
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 1011, in join
    self._wait_for_tstate_lock()
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 1027, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt

2023-02-09 13:53:18,396:INFO:Initializing Light Gradient Boosting Machine
2023-02-09 13:53:18,396:INFO:Total runtime is 1.9568104108174642 minutes
2023-02-09 13:53:18,402:INFO:SubProcess create_model() called ==================================
2023-02-09 13:53:18,402:INFO:Initializing create_model()
2023-02-09 13:53:18,402:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb3d032fa90>, return_train_score=False, kwargs={})
2023-02-09 13:53:18,402:INFO:Checking exceptions
2023-02-09 13:53:18,402:INFO:Importing libraries
2023-02-09 13:53:18,402:INFO:Copying training dataset
2023-02-09 13:53:18,403:INFO:Defining folds
2023-02-09 13:53:18,403:INFO:Declaring metric variables
2023-02-09 13:53:18,406:INFO:Importing untrained model
2023-02-09 13:53:18,410:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-09 13:53:18,416:INFO:Starting cross validation
2023-02-09 13:53:18,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:13,189:INFO:PyCaret Supervised Module
2023-02-09 13:54:13,189:INFO:ML Usecase: regression
2023-02-09 13:54:13,189:INFO:version 2.3.10
2023-02-09 13:54:13,189:INFO:Initializing setup()
2023-02-09 13:54:13,189:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'open', 'high', 'low', 'close', 'volume', 'volume_24HR', 'volume_24HR$', 'volume_$', 'closeChg', 'openChg', 'highChg', 'lowChg', 'volume_24HR$Chg', 'volume_24HRChg', 'volume_$'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-09 13:54:13,189:INFO:Checking environment
2023-02-09 13:54:13,189:INFO:python_version: 3.8.12
2023-02-09 13:54:13,189:INFO:python_build: ('default', 'Oct 12 2021 13:49:34')
2023-02-09 13:54:13,189:INFO:machine: x86_64
2023-02-09 13:54:13,189:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-09 13:54:13,190:INFO:Memory: svmem(total=134979592192, available=110315642880, percent=18.3, used=20692373504, free=86123937792, active=2943807488, inactive=43858493440, buffers=790188032, cached=27373092864, shared=2708250624, slab=1392533504)
2023-02-09 13:54:13,190:INFO:Physical Core: 16
2023-02-09 13:54:13,190:INFO:Logical Core: 32
2023-02-09 13:54:13,190:INFO:Checking libraries
2023-02-09 13:54:13,190:INFO:pd==1.4.1
2023-02-09 13:54:13,190:INFO:numpy==1.23.5
2023-02-09 13:54:13,190:INFO:sklearn==0.23.2
2023-02-09 13:54:13,190:INFO:lightgbm==3.3.5
2023-02-09 13:54:13,190:WARNING:catboost not found
2023-02-09 13:54:13,191:WARNING:xgboost not found
2023-02-09 13:54:13,191:INFO:mlflow==2.1.1
2023-02-09 13:54:13,191:INFO:Checking Exceptions
2023-02-09 13:54:13,191:INFO:Declaring global variables
2023-02-09 13:54:13,191:INFO:USI: ad2a
2023-02-09 13:54:13,191:INFO:pycaret_globals: {'_ml_usecase', 'n_jobs_param', 'X_train', 'USI', 'data_before_preprocess', 'imputation_classifier', 'seed', '_all_models_internal', 'create_model_container', '_all_metrics', '_available_plots', 'fold_param', 'logging_param', 'fold_generator', 'y_train', 'X', 'target_param', 'log_plots_param', 'fold_shuffle_param', 'fold_groups_param_full', 'y_test', '_all_models', 'prep_pipe', 'master_model_container', 'iterative_imputation_iters_param', 'fold_groups_param', 'transform_target_method_param', 'stratify_param', 'fix_imbalance_param', 'pycaret_globals', 'exp_name_log', 'html_param', '_gpu_n_jobs_param', 'fix_imbalance_method_param', 'y', 'gpu_param', 'transform_target_param', 'dashboard_logger', '_internal_pipeline', 'experiment__', 'imputation_regressor', 'X_test', 'display_container'}
2023-02-09 13:54:13,191:INFO:Preparing display monitor
2023-02-09 13:54:13,191:INFO:Preparing display monitor
2023-02-09 13:54:13,198:INFO:Importing libraries
2023-02-09 13:54:13,198:INFO:Copying data for preprocessing
2023-02-09 13:54:13,207:INFO:Declaring preprocessing parameters
2023-02-09 13:54:13,216:INFO:Creating preprocessing pipeline
2023-02-09 13:54:13,462:INFO:Preprocessing pipeline created successfully
2023-02-09 13:54:13,463:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-09 13:54:13,463:INFO:Creating global containers
2023-02-09 13:54:13,463:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-09 13:54:14,860:WARNING:Couldn't import xgboost.XGBRegressor
2023-02-09 13:54:14,861:WARNING:Couldn't import catboost.CatBoostRegressor
2023-02-09 13:54:14,927:WARNING:Couldn't import xgboost.XGBRegressor
2023-02-09 13:54:14,927:WARNING:Couldn't import catboost.CatBoostRegressor
2023-02-09 13:54:14,927:INFO:Creating grid variables
2023-02-09 13:54:14,941:INFO:create_model_container: 0
2023-02-09 13:54:14,941:INFO:master_model_container: 0
2023-02-09 13:54:14,941:INFO:display_container: 1
2023-02-09 13:54:14,944:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument', 'open',
                                                       'high', 'low', 'close',
                                                       'volume', 'volume_24HR',
                                                       'volume_24HR$',
                                                       'volume_$', 'closeChg',
                                                       'openChg', 'highChg',
                                                       'lowChg',
                                                       'volume_24HR$Chg',
                                                       'volume_24HRChg',
                                                       'volume_$'],
                                      id_columns=[], ml_usecase=...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-09 13:54:14,944:INFO:setup() succesfully completed......................................
2023-02-09 13:54:15,018:INFO:Initializing compare_models()
2023-02-09 13:54:15,018:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-02-09 13:54:15,018:INFO:Checking exceptions
2023-02-09 13:54:15,018:INFO:Preparing display monitor
2023-02-09 13:54:15,018:INFO:Preparing display monitor
2023-02-09 13:54:15,030:INFO:Initializing Linear Regression
2023-02-09 13:54:15,030:INFO:Total runtime is 1.1245409647623698e-06 minutes
2023-02-09 13:54:15,033:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:15,033:INFO:Initializing create_model()
2023-02-09 13:54:15,033:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:15,033:INFO:Checking exceptions
2023-02-09 13:54:15,033:INFO:Importing libraries
2023-02-09 13:54:15,033:INFO:Copying training dataset
2023-02-09 13:54:15,035:INFO:Defining folds
2023-02-09 13:54:15,035:INFO:Declaring metric variables
2023-02-09 13:54:15,038:INFO:Importing untrained model
2023-02-09 13:54:15,041:INFO:Linear Regression Imported succesfully
2023-02-09 13:54:15,047:INFO:Starting cross validation
2023-02-09 13:54:15,048:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:16,367:INFO:Calculating mean and std
2023-02-09 13:54:16,368:INFO:Creating metrics dataframe
2023-02-09 13:54:16,383:INFO:Uploading results into container
2023-02-09 13:54:16,384:INFO:Uploading model into container now
2023-02-09 13:54:16,384:INFO:create_model_container: 1
2023-02-09 13:54:16,384:INFO:master_model_container: 1
2023-02-09 13:54:16,384:INFO:display_container: 2
2023-02-09 13:54:16,384:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-09 13:54:16,384:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:16,470:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:16,470:INFO:Creating metrics dataframe
2023-02-09 13:54:16,479:INFO:Initializing Lasso Regression
2023-02-09 13:54:16,479:INFO:Total runtime is 0.02415120204289754 minutes
2023-02-09 13:54:16,482:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:16,482:INFO:Initializing create_model()
2023-02-09 13:54:16,482:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:16,482:INFO:Checking exceptions
2023-02-09 13:54:16,482:INFO:Importing libraries
2023-02-09 13:54:16,482:INFO:Copying training dataset
2023-02-09 13:54:16,484:INFO:Defining folds
2023-02-09 13:54:16,484:INFO:Declaring metric variables
2023-02-09 13:54:16,487:INFO:Importing untrained model
2023-02-09 13:54:16,490:INFO:Lasso Regression Imported succesfully
2023-02-09 13:54:16,495:INFO:Starting cross validation
2023-02-09 13:54:16,496:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:18,030:INFO:Calculating mean and std
2023-02-09 13:54:18,031:INFO:Creating metrics dataframe
2023-02-09 13:54:18,043:INFO:Uploading results into container
2023-02-09 13:54:18,043:INFO:Uploading model into container now
2023-02-09 13:54:18,043:INFO:create_model_container: 2
2023-02-09 13:54:18,043:INFO:master_model_container: 2
2023-02-09 13:54:18,043:INFO:display_container: 2
2023-02-09 13:54:18,044:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-09 13:54:18,044:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:18,117:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:18,117:INFO:Creating metrics dataframe
2023-02-09 13:54:18,126:INFO:Initializing Ridge Regression
2023-02-09 13:54:18,126:INFO:Total runtime is 0.051604958375294996 minutes
2023-02-09 13:54:18,129:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:18,130:INFO:Initializing create_model()
2023-02-09 13:54:18,130:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:18,130:INFO:Checking exceptions
2023-02-09 13:54:18,130:INFO:Importing libraries
2023-02-09 13:54:18,130:INFO:Copying training dataset
2023-02-09 13:54:18,130:INFO:Defining folds
2023-02-09 13:54:18,130:INFO:Declaring metric variables
2023-02-09 13:54:18,133:INFO:Importing untrained model
2023-02-09 13:54:18,136:INFO:Ridge Regression Imported succesfully
2023-02-09 13:54:18,142:INFO:Starting cross validation
2023-02-09 13:54:18,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:19,092:INFO:Calculating mean and std
2023-02-09 13:54:19,093:INFO:Creating metrics dataframe
2023-02-09 13:54:19,104:INFO:Uploading results into container
2023-02-09 13:54:19,104:INFO:Uploading model into container now
2023-02-09 13:54:19,105:INFO:create_model_container: 3
2023-02-09 13:54:19,105:INFO:master_model_container: 3
2023-02-09 13:54:19,105:INFO:display_container: 2
2023-02-09 13:54:19,105:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-09 13:54:19,105:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:19,180:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:19,180:INFO:Creating metrics dataframe
2023-02-09 13:54:19,189:INFO:Initializing Elastic Net
2023-02-09 13:54:19,189:INFO:Total runtime is 0.06932279268900553 minutes
2023-02-09 13:54:19,193:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:19,193:INFO:Initializing create_model()
2023-02-09 13:54:19,193:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:19,193:INFO:Checking exceptions
2023-02-09 13:54:19,193:INFO:Importing libraries
2023-02-09 13:54:19,193:INFO:Copying training dataset
2023-02-09 13:54:19,194:INFO:Defining folds
2023-02-09 13:54:19,194:INFO:Declaring metric variables
2023-02-09 13:54:19,196:INFO:Importing untrained model
2023-02-09 13:54:19,199:INFO:Elastic Net Imported succesfully
2023-02-09 13:54:19,205:INFO:Starting cross validation
2023-02-09 13:54:19,205:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:20,707:INFO:Calculating mean and std
2023-02-09 13:54:20,708:INFO:Creating metrics dataframe
2023-02-09 13:54:20,718:INFO:Uploading results into container
2023-02-09 13:54:20,718:INFO:Uploading model into container now
2023-02-09 13:54:20,718:INFO:create_model_container: 4
2023-02-09 13:54:20,718:INFO:master_model_container: 4
2023-02-09 13:54:20,718:INFO:display_container: 2
2023-02-09 13:54:20,719:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-09 13:54:20,719:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:20,793:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:20,793:INFO:Creating metrics dataframe
2023-02-09 13:54:20,803:INFO:Initializing Least Angle Regression
2023-02-09 13:54:20,803:INFO:Total runtime is 0.09622655709584553 minutes
2023-02-09 13:54:20,807:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:20,807:INFO:Initializing create_model()
2023-02-09 13:54:20,807:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:20,807:INFO:Checking exceptions
2023-02-09 13:54:20,807:INFO:Importing libraries
2023-02-09 13:54:20,807:INFO:Copying training dataset
2023-02-09 13:54:20,808:INFO:Defining folds
2023-02-09 13:54:20,808:INFO:Declaring metric variables
2023-02-09 13:54:20,811:INFO:Importing untrained model
2023-02-09 13:54:20,814:INFO:Least Angle Regression Imported succesfully
2023-02-09 13:54:20,820:INFO:Starting cross validation
2023-02-09 13:54:20,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:21,303:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-09 13:54:21,304:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 436, in _process_worker
    r = call_item()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 288, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 444, in result
    return self.__get_result()
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-09 13:54:21,304:INFO:Initializing create_model()
2023-02-09 13:54:21,304:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:21,304:INFO:Checking exceptions
2023-02-09 13:54:21,304:INFO:Importing libraries
2023-02-09 13:54:21,304:INFO:Copying training dataset
2023-02-09 13:54:21,306:INFO:Defining folds
2023-02-09 13:54:21,306:INFO:Declaring metric variables
2023-02-09 13:54:21,312:INFO:Importing untrained model
2023-02-09 13:54:21,315:INFO:Least Angle Regression Imported succesfully
2023-02-09 13:54:21,321:INFO:Starting cross validation
2023-02-09 13:54:21,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:22,917:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-02-09 13:54:22,917:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 436, in _process_worker
    r = call_item()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 288, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 444, in result
    return self.__get_result()
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-09 13:54:22,917:INFO:Initializing Lasso Least Angle Regression
2023-02-09 13:54:22,917:INFO:Total runtime is 0.13145934343338012 minutes
2023-02-09 13:54:22,923:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:22,923:INFO:Initializing create_model()
2023-02-09 13:54:22,923:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:22,923:INFO:Checking exceptions
2023-02-09 13:54:22,923:INFO:Importing libraries
2023-02-09 13:54:22,923:INFO:Copying training dataset
2023-02-09 13:54:22,925:INFO:Defining folds
2023-02-09 13:54:22,925:INFO:Declaring metric variables
2023-02-09 13:54:22,927:INFO:Importing untrained model
2023-02-09 13:54:22,930:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-09 13:54:22,936:INFO:Starting cross validation
2023-02-09 13:54:22,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:24,285:INFO:Calculating mean and std
2023-02-09 13:54:24,286:INFO:Creating metrics dataframe
2023-02-09 13:54:24,299:INFO:Uploading results into container
2023-02-09 13:54:24,299:INFO:Uploading model into container now
2023-02-09 13:54:24,299:INFO:create_model_container: 5
2023-02-09 13:54:24,299:INFO:master_model_container: 5
2023-02-09 13:54:24,299:INFO:display_container: 2
2023-02-09 13:54:24,299:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-09 13:54:24,299:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:24,377:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:24,377:INFO:Creating metrics dataframe
2023-02-09 13:54:24,388:INFO:Initializing Orthogonal Matching Pursuit
2023-02-09 13:54:24,388:INFO:Total runtime is 0.15596662362416586 minutes
2023-02-09 13:54:24,392:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:24,392:INFO:Initializing create_model()
2023-02-09 13:54:24,392:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:24,392:INFO:Checking exceptions
2023-02-09 13:54:24,392:INFO:Importing libraries
2023-02-09 13:54:24,392:INFO:Copying training dataset
2023-02-09 13:54:24,393:INFO:Defining folds
2023-02-09 13:54:24,393:INFO:Declaring metric variables
2023-02-09 13:54:24,397:INFO:Importing untrained model
2023-02-09 13:54:24,400:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-09 13:54:24,407:INFO:Starting cross validation
2023-02-09 13:54:24,407:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:25,398:INFO:Calculating mean and std
2023-02-09 13:54:25,399:INFO:Creating metrics dataframe
2023-02-09 13:54:25,411:INFO:Uploading results into container
2023-02-09 13:54:25,411:INFO:Uploading model into container now
2023-02-09 13:54:25,411:INFO:create_model_container: 6
2023-02-09 13:54:25,411:INFO:master_model_container: 6
2023-02-09 13:54:25,411:INFO:display_container: 2
2023-02-09 13:54:25,411:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-09 13:54:25,411:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:25,485:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:25,486:INFO:Creating metrics dataframe
2023-02-09 13:54:25,496:INFO:Initializing Bayesian Ridge
2023-02-09 13:54:25,496:INFO:Total runtime is 0.17443475723266602 minutes
2023-02-09 13:54:25,499:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:25,500:INFO:Initializing create_model()
2023-02-09 13:54:25,500:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:25,500:INFO:Checking exceptions
2023-02-09 13:54:25,500:INFO:Importing libraries
2023-02-09 13:54:25,500:INFO:Copying training dataset
2023-02-09 13:54:25,500:INFO:Defining folds
2023-02-09 13:54:25,501:INFO:Declaring metric variables
2023-02-09 13:54:25,504:INFO:Importing untrained model
2023-02-09 13:54:25,507:INFO:Bayesian Ridge Imported succesfully
2023-02-09 13:54:25,513:INFO:Starting cross validation
2023-02-09 13:54:25,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:26,588:INFO:Calculating mean and std
2023-02-09 13:54:26,589:INFO:Creating metrics dataframe
2023-02-09 13:54:26,599:INFO:Uploading results into container
2023-02-09 13:54:26,599:INFO:Uploading model into container now
2023-02-09 13:54:26,599:INFO:create_model_container: 7
2023-02-09 13:54:26,599:INFO:master_model_container: 7
2023-02-09 13:54:26,599:INFO:display_container: 2
2023-02-09 13:54:26,600:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-09 13:54:26,600:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:26,673:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:26,674:INFO:Creating metrics dataframe
2023-02-09 13:54:26,684:INFO:Initializing Passive Aggressive Regressor
2023-02-09 13:54:26,684:INFO:Total runtime is 0.19424107869466145 minutes
2023-02-09 13:54:26,688:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:26,689:INFO:Initializing create_model()
2023-02-09 13:54:26,689:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:26,689:INFO:Checking exceptions
2023-02-09 13:54:26,689:INFO:Importing libraries
2023-02-09 13:54:26,689:INFO:Copying training dataset
2023-02-09 13:54:26,689:INFO:Defining folds
2023-02-09 13:54:26,689:INFO:Declaring metric variables
2023-02-09 13:54:26,693:INFO:Importing untrained model
2023-02-09 13:54:26,696:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-09 13:54:26,703:INFO:Starting cross validation
2023-02-09 13:54:26,703:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:27,486:INFO:Calculating mean and std
2023-02-09 13:54:27,487:INFO:Creating metrics dataframe
2023-02-09 13:54:27,496:INFO:Uploading results into container
2023-02-09 13:54:27,497:INFO:Uploading model into container now
2023-02-09 13:54:27,497:INFO:create_model_container: 8
2023-02-09 13:54:27,497:INFO:master_model_container: 8
2023-02-09 13:54:27,497:INFO:display_container: 2
2023-02-09 13:54:27,497:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-09 13:54:27,497:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:27,572:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:27,573:INFO:Creating metrics dataframe
2023-02-09 13:54:27,583:INFO:Initializing Huber Regressor
2023-02-09 13:54:27,583:INFO:Total runtime is 0.2092244744300842 minutes
2023-02-09 13:54:27,587:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:27,587:INFO:Initializing create_model()
2023-02-09 13:54:27,587:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:27,587:INFO:Checking exceptions
2023-02-09 13:54:27,588:INFO:Importing libraries
2023-02-09 13:54:27,588:INFO:Copying training dataset
2023-02-09 13:54:27,588:INFO:Defining folds
2023-02-09 13:54:27,588:INFO:Declaring metric variables
2023-02-09 13:54:27,592:INFO:Importing untrained model
2023-02-09 13:54:27,595:INFO:Huber Regressor Imported succesfully
2023-02-09 13:54:27,602:INFO:Starting cross validation
2023-02-09 13:54:27,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:28,252:INFO:Calculating mean and std
2023-02-09 13:54:28,253:INFO:Creating metrics dataframe
2023-02-09 13:54:28,263:INFO:Uploading results into container
2023-02-09 13:54:28,263:INFO:Uploading model into container now
2023-02-09 13:54:28,263:INFO:create_model_container: 9
2023-02-09 13:54:28,263:INFO:master_model_container: 9
2023-02-09 13:54:28,263:INFO:display_container: 2
2023-02-09 13:54:28,263:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-09 13:54:28,263:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:28,335:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:28,335:INFO:Creating metrics dataframe
2023-02-09 13:54:28,346:INFO:Initializing K Neighbors Regressor
2023-02-09 13:54:28,346:INFO:Total runtime is 0.22193961540857948 minutes
2023-02-09 13:54:28,350:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:28,350:INFO:Initializing create_model()
2023-02-09 13:54:28,350:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:28,350:INFO:Checking exceptions
2023-02-09 13:54:28,350:INFO:Importing libraries
2023-02-09 13:54:28,350:INFO:Copying training dataset
2023-02-09 13:54:28,351:INFO:Defining folds
2023-02-09 13:54:28,351:INFO:Declaring metric variables
2023-02-09 13:54:28,355:INFO:Importing untrained model
2023-02-09 13:54:28,358:INFO:K Neighbors Regressor Imported succesfully
2023-02-09 13:54:28,365:INFO:Starting cross validation
2023-02-09 13:54:28,365:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:28,699:INFO:Calculating mean and std
2023-02-09 13:54:28,700:INFO:Creating metrics dataframe
2023-02-09 13:54:28,711:INFO:Uploading results into container
2023-02-09 13:54:28,711:INFO:Uploading model into container now
2023-02-09 13:54:28,711:INFO:create_model_container: 10
2023-02-09 13:54:28,711:INFO:master_model_container: 10
2023-02-09 13:54:28,711:INFO:display_container: 2
2023-02-09 13:54:28,711:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-09 13:54:28,711:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:28,784:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:28,784:INFO:Creating metrics dataframe
2023-02-09 13:54:28,795:INFO:Initializing Decision Tree Regressor
2023-02-09 13:54:28,795:INFO:Total runtime is 0.2294135014216105 minutes
2023-02-09 13:54:28,798:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:28,798:INFO:Initializing create_model()
2023-02-09 13:54:28,798:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:28,798:INFO:Checking exceptions
2023-02-09 13:54:28,798:INFO:Importing libraries
2023-02-09 13:54:28,798:INFO:Copying training dataset
2023-02-09 13:54:28,799:INFO:Defining folds
2023-02-09 13:54:28,799:INFO:Declaring metric variables
2023-02-09 13:54:28,802:INFO:Importing untrained model
2023-02-09 13:54:28,805:INFO:Decision Tree Regressor Imported succesfully
2023-02-09 13:54:28,811:INFO:Starting cross validation
2023-02-09 13:54:28,811:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:54:31,259:INFO:Calculating mean and std
2023-02-09 13:54:31,260:INFO:Creating metrics dataframe
2023-02-09 13:54:31,272:INFO:Uploading results into container
2023-02-09 13:54:31,272:INFO:Uploading model into container now
2023-02-09 13:54:31,272:INFO:create_model_container: 11
2023-02-09 13:54:31,272:INFO:master_model_container: 11
2023-02-09 13:54:31,273:INFO:display_container: 2
2023-02-09 13:54:31,273:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-09 13:54:31,273:INFO:create_model() succesfully completed......................................
2023-02-09 13:54:31,346:INFO:SubProcess create_model() end ==================================
2023-02-09 13:54:31,346:INFO:Creating metrics dataframe
2023-02-09 13:54:31,356:INFO:Initializing Random Forest Regressor
2023-02-09 13:54:31,356:INFO:Total runtime is 0.27210938135782875 minutes
2023-02-09 13:54:31,360:INFO:SubProcess create_model() called ==================================
2023-02-09 13:54:31,360:INFO:Initializing create_model()
2023-02-09 13:54:31,360:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:54:31,360:INFO:Checking exceptions
2023-02-09 13:54:31,360:INFO:Importing libraries
2023-02-09 13:54:31,360:INFO:Copying training dataset
2023-02-09 13:54:31,361:INFO:Defining folds
2023-02-09 13:54:31,361:INFO:Declaring metric variables
2023-02-09 13:54:31,364:INFO:Importing untrained model
2023-02-09 13:54:31,367:INFO:Random Forest Regressor Imported succesfully
2023-02-09 13:54:31,375:INFO:Starting cross validation
2023-02-09 13:54:31,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:55:32,742:INFO:Calculating mean and std
2023-02-09 13:55:32,743:INFO:Creating metrics dataframe
2023-02-09 13:55:32,752:INFO:Uploading results into container
2023-02-09 13:55:32,752:INFO:Uploading model into container now
2023-02-09 13:55:32,752:INFO:create_model_container: 12
2023-02-09 13:55:32,752:INFO:master_model_container: 12
2023-02-09 13:55:32,752:INFO:display_container: 2
2023-02-09 13:55:32,753:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-09 13:55:32,753:INFO:create_model() succesfully completed......................................
2023-02-09 13:55:32,827:INFO:SubProcess create_model() end ==================================
2023-02-09 13:55:32,827:INFO:Creating metrics dataframe
2023-02-09 13:55:32,838:INFO:Initializing Extra Trees Regressor
2023-02-09 13:55:32,839:INFO:Total runtime is 1.2968109091122946 minutes
2023-02-09 13:55:32,842:INFO:SubProcess create_model() called ==================================
2023-02-09 13:55:32,842:INFO:Initializing create_model()
2023-02-09 13:55:32,842:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:55:32,842:INFO:Checking exceptions
2023-02-09 13:55:32,842:INFO:Importing libraries
2023-02-09 13:55:32,842:INFO:Copying training dataset
2023-02-09 13:55:32,843:INFO:Defining folds
2023-02-09 13:55:32,843:INFO:Declaring metric variables
2023-02-09 13:55:32,846:INFO:Importing untrained model
2023-02-09 13:55:32,849:INFO:Extra Trees Regressor Imported succesfully
2023-02-09 13:55:32,855:INFO:Starting cross validation
2023-02-09 13:55:32,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:55:44,617:INFO:Calculating mean and std
2023-02-09 13:55:44,618:INFO:Creating metrics dataframe
2023-02-09 13:55:44,627:INFO:Uploading results into container
2023-02-09 13:55:44,627:INFO:Uploading model into container now
2023-02-09 13:55:44,627:INFO:create_model_container: 13
2023-02-09 13:55:44,627:INFO:master_model_container: 13
2023-02-09 13:55:44,627:INFO:display_container: 2
2023-02-09 13:55:44,628:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-09 13:55:44,628:INFO:create_model() succesfully completed......................................
2023-02-09 13:55:44,702:INFO:SubProcess create_model() end ==================================
2023-02-09 13:55:44,702:INFO:Creating metrics dataframe
2023-02-09 13:55:44,717:INFO:Initializing AdaBoost Regressor
2023-02-09 13:55:44,717:INFO:Total runtime is 1.4947779496510825 minutes
2023-02-09 13:55:44,720:INFO:SubProcess create_model() called ==================================
2023-02-09 13:55:44,720:INFO:Initializing create_model()
2023-02-09 13:55:44,720:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:55:44,720:INFO:Checking exceptions
2023-02-09 13:55:44,720:INFO:Importing libraries
2023-02-09 13:55:44,720:INFO:Copying training dataset
2023-02-09 13:55:44,721:INFO:Defining folds
2023-02-09 13:55:44,721:INFO:Declaring metric variables
2023-02-09 13:55:44,724:INFO:Importing untrained model
2023-02-09 13:55:44,727:INFO:AdaBoost Regressor Imported succesfully
2023-02-09 13:55:44,733:INFO:Starting cross validation
2023-02-09 13:55:44,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:55:52,665:INFO:Calculating mean and std
2023-02-09 13:55:52,666:INFO:Creating metrics dataframe
2023-02-09 13:55:52,674:INFO:Uploading results into container
2023-02-09 13:55:52,675:INFO:Uploading model into container now
2023-02-09 13:55:52,675:INFO:create_model_container: 14
2023-02-09 13:55:52,675:INFO:master_model_container: 14
2023-02-09 13:55:52,675:INFO:display_container: 2
2023-02-09 13:55:52,675:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-09 13:55:52,675:INFO:create_model() succesfully completed......................................
2023-02-09 13:55:52,750:INFO:SubProcess create_model() end ==================================
2023-02-09 13:55:52,750:INFO:Creating metrics dataframe
2023-02-09 13:55:52,761:INFO:Initializing Gradient Boosting Regressor
2023-02-09 13:55:52,761:INFO:Total runtime is 1.6288534522056581 minutes
2023-02-09 13:55:52,764:INFO:SubProcess create_model() called ==================================
2023-02-09 13:55:52,765:INFO:Initializing create_model()
2023-02-09 13:55:52,765:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:55:52,765:INFO:Checking exceptions
2023-02-09 13:55:52,765:INFO:Importing libraries
2023-02-09 13:55:52,765:INFO:Copying training dataset
2023-02-09 13:55:52,765:INFO:Defining folds
2023-02-09 13:55:52,765:INFO:Declaring metric variables
2023-02-09 13:55:52,768:INFO:Importing untrained model
2023-02-09 13:55:52,771:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-09 13:55:52,777:INFO:Starting cross validation
2023-02-09 13:55:52,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:55:54,172:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-09 13:55:54,172:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 439, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 302, in wait
    waiter.acquire()
KeyboardInterrupt

2023-02-09 13:55:54,172:INFO:Initializing create_model()
2023-02-09 13:55:54,172:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:55:54,173:INFO:Checking exceptions
2023-02-09 13:55:54,173:INFO:Importing libraries
2023-02-09 13:55:54,173:INFO:Copying training dataset
2023-02-09 13:55:54,174:INFO:Defining folds
2023-02-09 13:55:54,174:INFO:Declaring metric variables
2023-02-09 13:55:54,180:INFO:Importing untrained model
2023-02-09 13:55:54,183:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-09 13:55:54,190:INFO:Starting cross validation
2023-02-09 13:55:54,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:56:01,502:ERROR:create_model() for gbr raised an exception or returned all 0.0:
2023-02-09 13:56:01,503:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 439, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 302, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 439, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 302, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 957, in retrieve
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 561, in abort_everything
    self._workers.terminate(kill_workers=True)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/executor.py", line 74, in terminate
    self.shutdown(kill_workers=kill_workers)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 1185, in shutdown
    executor_manager_thread.join()
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 1011, in join
    self._wait_for_tstate_lock()
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 1027, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt

2023-02-09 13:56:01,503:INFO:Initializing Light Gradient Boosting Machine
2023-02-09 13:56:01,503:INFO:Total runtime is 1.7745497941970827 minutes
2023-02-09 13:56:01,507:INFO:SubProcess create_model() called ==================================
2023-02-09 13:56:01,508:INFO:Initializing create_model()
2023-02-09 13:56:01,508:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f97d8363e80>, return_train_score=False, kwargs={})
2023-02-09 13:56:01,508:INFO:Checking exceptions
2023-02-09 13:56:01,508:INFO:Importing libraries
2023-02-09 13:56:01,508:INFO:Copying training dataset
2023-02-09 13:56:01,509:INFO:Defining folds
2023-02-09 13:56:01,509:INFO:Declaring metric variables
2023-02-09 13:56:01,512:INFO:Importing untrained model
2023-02-09 13:56:01,516:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-09 13:56:01,522:INFO:Starting cross validation
2023-02-09 13:56:01,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:06,939:INFO:PyCaret Supervised Module
2023-02-09 13:57:06,939:INFO:ML Usecase: regression
2023-02-09 13:57:06,939:INFO:version 2.3.10
2023-02-09 13:57:06,939:INFO:Initializing setup()
2023-02-09 13:57:06,939:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'open', 'high', 'low', 'close', 'volume', 'volume_24HR', 'volume_24HR$', 'volume_$', 'closeChg', 'openChg', 'highChg', 'lowChg', 'volume_24HR$Chg', 'volume_24HRChg', 'volume_$'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-09 13:57:06,939:INFO:Checking environment
2023-02-09 13:57:06,939:INFO:python_version: 3.8.12
2023-02-09 13:57:06,939:INFO:python_build: ('default', 'Oct 12 2021 13:49:34')
2023-02-09 13:57:06,939:INFO:machine: x86_64
2023-02-09 13:57:06,939:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-09 13:57:06,939:INFO:Memory: svmem(total=134979592192, available=107606274048, percent=20.3, used=23383535616, free=83404918784, active=3011321856, inactive=46478491648, buffers=790933504, cached=27400204288, shared=2726457344, slab=1406648320)
2023-02-09 13:57:06,940:INFO:Physical Core: 16
2023-02-09 13:57:06,940:INFO:Logical Core: 32
2023-02-09 13:57:06,940:INFO:Checking libraries
2023-02-09 13:57:06,940:INFO:pd==1.4.1
2023-02-09 13:57:06,940:INFO:numpy==1.23.5
2023-02-09 13:57:06,940:INFO:sklearn==0.23.2
2023-02-09 13:57:06,940:INFO:lightgbm==3.3.5
2023-02-09 13:57:06,940:WARNING:catboost not found
2023-02-09 13:57:06,940:WARNING:xgboost not found
2023-02-09 13:57:06,940:INFO:mlflow==2.1.1
2023-02-09 13:57:06,940:INFO:Checking Exceptions
2023-02-09 13:57:06,940:INFO:Declaring global variables
2023-02-09 13:57:06,941:INFO:USI: 333f
2023-02-09 13:57:06,941:INFO:pycaret_globals: {'imputation_regressor', 'y', '_all_models', '_ml_usecase', 'X_train', 'y_train', 'master_model_container', 'create_model_container', 'fold_groups_param_full', 'display_container', 'fold_generator', 'data_before_preprocess', 'prep_pipe', 'html_param', 'log_plots_param', 'n_jobs_param', 'USI', '_all_models_internal', 'pycaret_globals', 'X_test', 'dashboard_logger', 'fix_imbalance_method_param', 'transform_target_method_param', 'imputation_classifier', 'experiment__', 'transform_target_param', '_all_metrics', 'fix_imbalance_param', 'seed', 'iterative_imputation_iters_param', '_internal_pipeline', '_gpu_n_jobs_param', 'fold_shuffle_param', 'X', 'gpu_param', 'y_test', 'target_param', 'fold_groups_param', 'logging_param', 'exp_name_log', 'fold_param', 'stratify_param', '_available_plots'}
2023-02-09 13:57:06,941:INFO:Preparing display monitor
2023-02-09 13:57:06,941:INFO:Preparing display monitor
2023-02-09 13:57:06,947:INFO:Importing libraries
2023-02-09 13:57:06,947:INFO:Copying data for preprocessing
2023-02-09 13:57:06,956:INFO:Declaring preprocessing parameters
2023-02-09 13:57:06,965:INFO:Creating preprocessing pipeline
2023-02-09 13:57:07,209:INFO:Preprocessing pipeline created successfully
2023-02-09 13:57:07,209:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-09 13:57:07,209:INFO:Creating global containers
2023-02-09 13:57:07,210:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-09 13:57:08,600:WARNING:Couldn't import xgboost.XGBRegressor
2023-02-09 13:57:08,600:WARNING:Couldn't import catboost.CatBoostRegressor
2023-02-09 13:57:08,665:WARNING:Couldn't import xgboost.XGBRegressor
2023-02-09 13:57:08,666:WARNING:Couldn't import catboost.CatBoostRegressor
2023-02-09 13:57:08,666:INFO:Creating grid variables
2023-02-09 13:57:08,679:INFO:create_model_container: 0
2023-02-09 13:57:08,679:INFO:master_model_container: 0
2023-02-09 13:57:08,679:INFO:display_container: 1
2023-02-09 13:57:08,681:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument', 'open',
                                                       'high', 'low', 'close',
                                                       'volume', 'volume_24HR',
                                                       'volume_24HR$',
                                                       'volume_$', 'closeChg',
                                                       'openChg', 'highChg',
                                                       'lowChg',
                                                       'volume_24HR$Chg',
                                                       'volume_24HRChg',
                                                       'volume_$'],
                                      id_columns=[], ml_usecase=...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-09 13:57:08,681:INFO:setup() succesfully completed......................................
2023-02-09 13:57:08,759:INFO:Initializing compare_models()
2023-02-09 13:57:08,759:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-02-09 13:57:08,759:INFO:Checking exceptions
2023-02-09 13:57:08,759:INFO:Preparing display monitor
2023-02-09 13:57:08,759:INFO:Preparing display monitor
2023-02-09 13:57:08,770:INFO:Initializing Linear Regression
2023-02-09 13:57:08,770:INFO:Total runtime is 1.1682510375976563e-06 minutes
2023-02-09 13:57:08,773:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:08,774:INFO:Initializing create_model()
2023-02-09 13:57:08,774:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:08,774:INFO:Checking exceptions
2023-02-09 13:57:08,774:INFO:Importing libraries
2023-02-09 13:57:08,774:INFO:Copying training dataset
2023-02-09 13:57:08,774:INFO:Defining folds
2023-02-09 13:57:08,774:INFO:Declaring metric variables
2023-02-09 13:57:08,779:INFO:Importing untrained model
2023-02-09 13:57:08,782:INFO:Linear Regression Imported succesfully
2023-02-09 13:57:08,788:INFO:Starting cross validation
2023-02-09 13:57:08,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:10,158:INFO:Calculating mean and std
2023-02-09 13:57:10,159:INFO:Creating metrics dataframe
2023-02-09 13:57:10,179:INFO:Uploading results into container
2023-02-09 13:57:10,179:INFO:Uploading model into container now
2023-02-09 13:57:10,179:INFO:create_model_container: 1
2023-02-09 13:57:10,179:INFO:master_model_container: 1
2023-02-09 13:57:10,179:INFO:display_container: 2
2023-02-09 13:57:10,179:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-09 13:57:10,179:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:10,268:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:10,268:INFO:Creating metrics dataframe
2023-02-09 13:57:10,278:INFO:Initializing Lasso Regression
2023-02-09 13:57:10,278:INFO:Total runtime is 0.025124287605285643 minutes
2023-02-09 13:57:10,281:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:10,281:INFO:Initializing create_model()
2023-02-09 13:57:10,281:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:10,281:INFO:Checking exceptions
2023-02-09 13:57:10,281:INFO:Importing libraries
2023-02-09 13:57:10,281:INFO:Copying training dataset
2023-02-09 13:57:10,282:INFO:Defining folds
2023-02-09 13:57:10,282:INFO:Declaring metric variables
2023-02-09 13:57:10,285:INFO:Importing untrained model
2023-02-09 13:57:10,288:INFO:Lasso Regression Imported succesfully
2023-02-09 13:57:10,294:INFO:Starting cross validation
2023-02-09 13:57:10,294:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:11,837:INFO:Calculating mean and std
2023-02-09 13:57:11,838:INFO:Creating metrics dataframe
2023-02-09 13:57:11,851:INFO:Uploading results into container
2023-02-09 13:57:11,851:INFO:Uploading model into container now
2023-02-09 13:57:11,851:INFO:create_model_container: 2
2023-02-09 13:57:11,851:INFO:master_model_container: 2
2023-02-09 13:57:11,851:INFO:display_container: 2
2023-02-09 13:57:11,852:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-09 13:57:11,852:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:11,926:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:11,926:INFO:Creating metrics dataframe
2023-02-09 13:57:11,935:INFO:Initializing Ridge Regression
2023-02-09 13:57:11,935:INFO:Total runtime is 0.05275266170501709 minutes
2023-02-09 13:57:11,939:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:11,939:INFO:Initializing create_model()
2023-02-09 13:57:11,939:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:11,939:INFO:Checking exceptions
2023-02-09 13:57:11,939:INFO:Importing libraries
2023-02-09 13:57:11,939:INFO:Copying training dataset
2023-02-09 13:57:11,940:INFO:Defining folds
2023-02-09 13:57:11,940:INFO:Declaring metric variables
2023-02-09 13:57:11,943:INFO:Importing untrained model
2023-02-09 13:57:11,946:INFO:Ridge Regression Imported succesfully
2023-02-09 13:57:11,951:INFO:Starting cross validation
2023-02-09 13:57:11,952:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:12,886:INFO:Calculating mean and std
2023-02-09 13:57:12,886:INFO:Creating metrics dataframe
2023-02-09 13:57:12,898:INFO:Uploading results into container
2023-02-09 13:57:12,898:INFO:Uploading model into container now
2023-02-09 13:57:12,898:INFO:create_model_container: 3
2023-02-09 13:57:12,898:INFO:master_model_container: 3
2023-02-09 13:57:12,898:INFO:display_container: 2
2023-02-09 13:57:12,898:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-09 13:57:12,898:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:12,971:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:12,971:INFO:Creating metrics dataframe
2023-02-09 13:57:12,980:INFO:Initializing Elastic Net
2023-02-09 13:57:12,981:INFO:Total runtime is 0.0701717734336853 minutes
2023-02-09 13:57:12,984:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:12,984:INFO:Initializing create_model()
2023-02-09 13:57:12,984:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:12,984:INFO:Checking exceptions
2023-02-09 13:57:12,984:INFO:Importing libraries
2023-02-09 13:57:12,984:INFO:Copying training dataset
2023-02-09 13:57:12,985:INFO:Defining folds
2023-02-09 13:57:12,985:INFO:Declaring metric variables
2023-02-09 13:57:12,988:INFO:Importing untrained model
2023-02-09 13:57:12,991:INFO:Elastic Net Imported succesfully
2023-02-09 13:57:12,996:INFO:Starting cross validation
2023-02-09 13:57:12,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:14,664:INFO:Calculating mean and std
2023-02-09 13:57:14,665:INFO:Creating metrics dataframe
2023-02-09 13:57:14,674:INFO:Uploading results into container
2023-02-09 13:57:14,674:INFO:Uploading model into container now
2023-02-09 13:57:14,674:INFO:create_model_container: 4
2023-02-09 13:57:14,674:INFO:master_model_container: 4
2023-02-09 13:57:14,674:INFO:display_container: 2
2023-02-09 13:57:14,674:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-09 13:57:14,674:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:14,757:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:14,757:INFO:Creating metrics dataframe
2023-02-09 13:57:14,767:INFO:Initializing Least Angle Regression
2023-02-09 13:57:14,767:INFO:Total runtime is 0.09995335340499878 minutes
2023-02-09 13:57:14,771:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:14,771:INFO:Initializing create_model()
2023-02-09 13:57:14,771:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:14,771:INFO:Checking exceptions
2023-02-09 13:57:14,771:INFO:Importing libraries
2023-02-09 13:57:14,771:INFO:Copying training dataset
2023-02-09 13:57:14,772:INFO:Defining folds
2023-02-09 13:57:14,772:INFO:Declaring metric variables
2023-02-09 13:57:14,775:INFO:Importing untrained model
2023-02-09 13:57:14,778:INFO:Least Angle Regression Imported succesfully
2023-02-09 13:57:14,784:INFO:Starting cross validation
2023-02-09 13:57:14,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:15,292:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-09 13:57:15,292:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 436, in _process_worker
    r = call_item()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 288, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 444, in result
    return self.__get_result()
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-09 13:57:15,293:INFO:Initializing create_model()
2023-02-09 13:57:15,293:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:15,293:INFO:Checking exceptions
2023-02-09 13:57:15,293:INFO:Importing libraries
2023-02-09 13:57:15,293:INFO:Copying training dataset
2023-02-09 13:57:15,295:INFO:Defining folds
2023-02-09 13:57:15,295:INFO:Declaring metric variables
2023-02-09 13:57:15,300:INFO:Importing untrained model
2023-02-09 13:57:15,304:INFO:Least Angle Regression Imported succesfully
2023-02-09 13:57:15,310:INFO:Starting cross validation
2023-02-09 13:57:15,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:16,878:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-02-09 13:57:16,879:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 436, in _process_worker
    r = call_item()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py", line 288, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 262, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-09 13:57:16,879:INFO:Initializing Lasso Least Angle Regression
2023-02-09 13:57:16,879:INFO:Total runtime is 0.135141388575236 minutes
2023-02-09 13:57:16,885:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:16,885:INFO:Initializing create_model()
2023-02-09 13:57:16,886:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:16,886:INFO:Checking exceptions
2023-02-09 13:57:16,886:INFO:Importing libraries
2023-02-09 13:57:16,886:INFO:Copying training dataset
2023-02-09 13:57:16,888:INFO:Defining folds
2023-02-09 13:57:16,888:INFO:Declaring metric variables
2023-02-09 13:57:16,891:INFO:Importing untrained model
2023-02-09 13:57:16,896:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-09 13:57:16,904:INFO:Starting cross validation
2023-02-09 13:57:16,904:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:18,255:INFO:Calculating mean and std
2023-02-09 13:57:18,257:INFO:Creating metrics dataframe
2023-02-09 13:57:18,271:INFO:Uploading results into container
2023-02-09 13:57:18,271:INFO:Uploading model into container now
2023-02-09 13:57:18,271:INFO:create_model_container: 5
2023-02-09 13:57:18,271:INFO:master_model_container: 5
2023-02-09 13:57:18,271:INFO:display_container: 2
2023-02-09 13:57:18,271:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-09 13:57:18,271:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:18,349:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:18,349:INFO:Creating metrics dataframe
2023-02-09 13:57:18,360:INFO:Initializing Orthogonal Matching Pursuit
2023-02-09 13:57:18,360:INFO:Total runtime is 0.15982791980107625 minutes
2023-02-09 13:57:18,364:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:18,364:INFO:Initializing create_model()
2023-02-09 13:57:18,364:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:18,364:INFO:Checking exceptions
2023-02-09 13:57:18,364:INFO:Importing libraries
2023-02-09 13:57:18,364:INFO:Copying training dataset
2023-02-09 13:57:18,365:INFO:Defining folds
2023-02-09 13:57:18,366:INFO:Declaring metric variables
2023-02-09 13:57:18,369:INFO:Importing untrained model
2023-02-09 13:57:18,372:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-09 13:57:18,381:INFO:Starting cross validation
2023-02-09 13:57:18,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:19,327:INFO:Calculating mean and std
2023-02-09 13:57:19,328:INFO:Creating metrics dataframe
2023-02-09 13:57:19,340:INFO:Uploading results into container
2023-02-09 13:57:19,340:INFO:Uploading model into container now
2023-02-09 13:57:19,341:INFO:create_model_container: 6
2023-02-09 13:57:19,341:INFO:master_model_container: 6
2023-02-09 13:57:19,341:INFO:display_container: 2
2023-02-09 13:57:19,341:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-09 13:57:19,341:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:19,419:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:19,419:INFO:Creating metrics dataframe
2023-02-09 13:57:19,429:INFO:Initializing Bayesian Ridge
2023-02-09 13:57:19,429:INFO:Total runtime is 0.17764663298924763 minutes
2023-02-09 13:57:19,432:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:19,433:INFO:Initializing create_model()
2023-02-09 13:57:19,433:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:19,433:INFO:Checking exceptions
2023-02-09 13:57:19,433:INFO:Importing libraries
2023-02-09 13:57:19,433:INFO:Copying training dataset
2023-02-09 13:57:19,433:INFO:Defining folds
2023-02-09 13:57:19,433:INFO:Declaring metric variables
2023-02-09 13:57:19,436:INFO:Importing untrained model
2023-02-09 13:57:19,439:INFO:Bayesian Ridge Imported succesfully
2023-02-09 13:57:19,445:INFO:Starting cross validation
2023-02-09 13:57:19,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:20,504:INFO:Calculating mean and std
2023-02-09 13:57:20,505:INFO:Creating metrics dataframe
2023-02-09 13:57:20,515:INFO:Uploading results into container
2023-02-09 13:57:20,515:INFO:Uploading model into container now
2023-02-09 13:57:20,515:INFO:create_model_container: 7
2023-02-09 13:57:20,515:INFO:master_model_container: 7
2023-02-09 13:57:20,515:INFO:display_container: 2
2023-02-09 13:57:20,515:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-09 13:57:20,515:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:20,606:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:20,606:INFO:Creating metrics dataframe
2023-02-09 13:57:20,618:INFO:Initializing Passive Aggressive Regressor
2023-02-09 13:57:20,618:INFO:Total runtime is 0.19747034311294553 minutes
2023-02-09 13:57:20,622:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:20,622:INFO:Initializing create_model()
2023-02-09 13:57:20,622:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:20,622:INFO:Checking exceptions
2023-02-09 13:57:20,622:INFO:Importing libraries
2023-02-09 13:57:20,622:INFO:Copying training dataset
2023-02-09 13:57:20,623:INFO:Defining folds
2023-02-09 13:57:20,623:INFO:Declaring metric variables
2023-02-09 13:57:20,627:INFO:Importing untrained model
2023-02-09 13:57:20,630:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-09 13:57:20,636:INFO:Starting cross validation
2023-02-09 13:57:20,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:21,407:INFO:Calculating mean and std
2023-02-09 13:57:21,408:INFO:Creating metrics dataframe
2023-02-09 13:57:21,419:INFO:Uploading results into container
2023-02-09 13:57:21,419:INFO:Uploading model into container now
2023-02-09 13:57:21,419:INFO:create_model_container: 8
2023-02-09 13:57:21,419:INFO:master_model_container: 8
2023-02-09 13:57:21,419:INFO:display_container: 2
2023-02-09 13:57:21,419:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-09 13:57:21,419:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:21,522:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:21,522:INFO:Creating metrics dataframe
2023-02-09 13:57:21,533:INFO:Initializing Huber Regressor
2023-02-09 13:57:21,533:INFO:Total runtime is 0.21271476348241167 minutes
2023-02-09 13:57:21,537:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:21,537:INFO:Initializing create_model()
2023-02-09 13:57:21,537:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:21,537:INFO:Checking exceptions
2023-02-09 13:57:21,537:INFO:Importing libraries
2023-02-09 13:57:21,537:INFO:Copying training dataset
2023-02-09 13:57:21,538:INFO:Defining folds
2023-02-09 13:57:21,538:INFO:Declaring metric variables
2023-02-09 13:57:21,541:INFO:Importing untrained model
2023-02-09 13:57:21,545:INFO:Huber Regressor Imported succesfully
2023-02-09 13:57:21,551:INFO:Starting cross validation
2023-02-09 13:57:21,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:22,153:INFO:Calculating mean and std
2023-02-09 13:57:22,154:INFO:Creating metrics dataframe
2023-02-09 13:57:22,164:INFO:Uploading results into container
2023-02-09 13:57:22,165:INFO:Uploading model into container now
2023-02-09 13:57:22,165:INFO:create_model_container: 9
2023-02-09 13:57:22,165:INFO:master_model_container: 9
2023-02-09 13:57:22,165:INFO:display_container: 2
2023-02-09 13:57:22,165:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-09 13:57:22,165:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:22,247:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:22,247:INFO:Creating metrics dataframe
2023-02-09 13:57:22,260:INFO:Initializing K Neighbors Regressor
2023-02-09 13:57:22,260:INFO:Total runtime is 0.22483201821645096 minutes
2023-02-09 13:57:22,264:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:22,264:INFO:Initializing create_model()
2023-02-09 13:57:22,264:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:22,264:INFO:Checking exceptions
2023-02-09 13:57:22,264:INFO:Importing libraries
2023-02-09 13:57:22,264:INFO:Copying training dataset
2023-02-09 13:57:22,266:INFO:Defining folds
2023-02-09 13:57:22,266:INFO:Declaring metric variables
2023-02-09 13:57:22,270:INFO:Importing untrained model
2023-02-09 13:57:22,275:INFO:K Neighbors Regressor Imported succesfully
2023-02-09 13:57:22,284:INFO:Starting cross validation
2023-02-09 13:57:22,284:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:22,619:INFO:Calculating mean and std
2023-02-09 13:57:22,620:INFO:Creating metrics dataframe
2023-02-09 13:57:22,630:INFO:Uploading results into container
2023-02-09 13:57:22,630:INFO:Uploading model into container now
2023-02-09 13:57:22,630:INFO:create_model_container: 10
2023-02-09 13:57:22,630:INFO:master_model_container: 10
2023-02-09 13:57:22,630:INFO:display_container: 2
2023-02-09 13:57:22,631:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-09 13:57:22,631:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:22,711:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:22,711:INFO:Creating metrics dataframe
2023-02-09 13:57:22,723:INFO:Initializing Decision Tree Regressor
2023-02-09 13:57:22,723:INFO:Total runtime is 0.2325541019439697 minutes
2023-02-09 13:57:22,727:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:22,728:INFO:Initializing create_model()
2023-02-09 13:57:22,728:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:22,728:INFO:Checking exceptions
2023-02-09 13:57:22,728:INFO:Importing libraries
2023-02-09 13:57:22,728:INFO:Copying training dataset
2023-02-09 13:57:22,728:INFO:Defining folds
2023-02-09 13:57:22,728:INFO:Declaring metric variables
2023-02-09 13:57:22,732:INFO:Importing untrained model
2023-02-09 13:57:22,735:INFO:Decision Tree Regressor Imported succesfully
2023-02-09 13:57:22,742:INFO:Starting cross validation
2023-02-09 13:57:22,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:57:25,179:INFO:Calculating mean and std
2023-02-09 13:57:25,179:INFO:Creating metrics dataframe
2023-02-09 13:57:25,189:INFO:Uploading results into container
2023-02-09 13:57:25,189:INFO:Uploading model into container now
2023-02-09 13:57:25,189:INFO:create_model_container: 11
2023-02-09 13:57:25,189:INFO:master_model_container: 11
2023-02-09 13:57:25,189:INFO:display_container: 2
2023-02-09 13:57:25,190:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-09 13:57:25,190:INFO:create_model() succesfully completed......................................
2023-02-09 13:57:25,265:INFO:SubProcess create_model() end ==================================
2023-02-09 13:57:25,265:INFO:Creating metrics dataframe
2023-02-09 13:57:25,275:INFO:Initializing Random Forest Regressor
2023-02-09 13:57:25,275:INFO:Total runtime is 0.27508394718170165 minutes
2023-02-09 13:57:25,279:INFO:SubProcess create_model() called ==================================
2023-02-09 13:57:25,279:INFO:Initializing create_model()
2023-02-09 13:57:25,279:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:57:25,279:INFO:Checking exceptions
2023-02-09 13:57:25,279:INFO:Importing libraries
2023-02-09 13:57:25,279:INFO:Copying training dataset
2023-02-09 13:57:25,280:INFO:Defining folds
2023-02-09 13:57:25,280:INFO:Declaring metric variables
2023-02-09 13:57:25,283:INFO:Importing untrained model
2023-02-09 13:57:25,287:INFO:Random Forest Regressor Imported succesfully
2023-02-09 13:57:25,293:INFO:Starting cross validation
2023-02-09 13:57:25,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:58:26,527:INFO:Calculating mean and std
2023-02-09 13:58:26,528:INFO:Creating metrics dataframe
2023-02-09 13:58:26,539:INFO:Uploading results into container
2023-02-09 13:58:26,539:INFO:Uploading model into container now
2023-02-09 13:58:26,539:INFO:create_model_container: 12
2023-02-09 13:58:26,539:INFO:master_model_container: 12
2023-02-09 13:58:26,539:INFO:display_container: 2
2023-02-09 13:58:26,539:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-09 13:58:26,539:INFO:create_model() succesfully completed......................................
2023-02-09 13:58:26,620:INFO:SubProcess create_model() end ==================================
2023-02-09 13:58:26,620:INFO:Creating metrics dataframe
2023-02-09 13:58:26,632:INFO:Initializing Extra Trees Regressor
2023-02-09 13:58:26,632:INFO:Total runtime is 1.2976996858914693 minutes
2023-02-09 13:58:26,636:INFO:SubProcess create_model() called ==================================
2023-02-09 13:58:26,636:INFO:Initializing create_model()
2023-02-09 13:58:26,636:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:58:26,636:INFO:Checking exceptions
2023-02-09 13:58:26,636:INFO:Importing libraries
2023-02-09 13:58:26,636:INFO:Copying training dataset
2023-02-09 13:58:26,637:INFO:Defining folds
2023-02-09 13:58:26,637:INFO:Declaring metric variables
2023-02-09 13:58:26,640:INFO:Importing untrained model
2023-02-09 13:58:26,644:INFO:Extra Trees Regressor Imported succesfully
2023-02-09 13:58:26,650:INFO:Starting cross validation
2023-02-09 13:58:26,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:58:38,419:INFO:Calculating mean and std
2023-02-09 13:58:38,420:INFO:Creating metrics dataframe
2023-02-09 13:58:38,431:INFO:Uploading results into container
2023-02-09 13:58:38,431:INFO:Uploading model into container now
2023-02-09 13:58:38,431:INFO:create_model_container: 13
2023-02-09 13:58:38,431:INFO:master_model_container: 13
2023-02-09 13:58:38,431:INFO:display_container: 2
2023-02-09 13:58:38,431:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-09 13:58:38,431:INFO:create_model() succesfully completed......................................
2023-02-09 13:58:38,507:INFO:SubProcess create_model() end ==================================
2023-02-09 13:58:38,507:INFO:Creating metrics dataframe
2023-02-09 13:58:38,518:INFO:Initializing AdaBoost Regressor
2023-02-09 13:58:38,518:INFO:Total runtime is 1.4958022832870483 minutes
2023-02-09 13:58:38,522:INFO:SubProcess create_model() called ==================================
2023-02-09 13:58:38,522:INFO:Initializing create_model()
2023-02-09 13:58:38,522:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:58:38,522:INFO:Checking exceptions
2023-02-09 13:58:38,522:INFO:Importing libraries
2023-02-09 13:58:38,522:INFO:Copying training dataset
2023-02-09 13:58:38,523:INFO:Defining folds
2023-02-09 13:58:38,523:INFO:Declaring metric variables
2023-02-09 13:58:38,527:INFO:Importing untrained model
2023-02-09 13:58:38,530:INFO:AdaBoost Regressor Imported succesfully
2023-02-09 13:58:38,536:INFO:Starting cross validation
2023-02-09 13:58:38,537:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:58:46,586:INFO:Calculating mean and std
2023-02-09 13:58:46,587:INFO:Creating metrics dataframe
2023-02-09 13:58:46,597:INFO:Uploading results into container
2023-02-09 13:58:46,597:INFO:Uploading model into container now
2023-02-09 13:58:46,597:INFO:create_model_container: 14
2023-02-09 13:58:46,597:INFO:master_model_container: 14
2023-02-09 13:58:46,597:INFO:display_container: 2
2023-02-09 13:58:46,597:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-09 13:58:46,597:INFO:create_model() succesfully completed......................................
2023-02-09 13:58:46,676:INFO:SubProcess create_model() end ==================================
2023-02-09 13:58:46,676:INFO:Creating metrics dataframe
2023-02-09 13:58:46,688:INFO:Initializing Gradient Boosting Regressor
2023-02-09 13:58:46,688:INFO:Total runtime is 1.6319613218307496 minutes
2023-02-09 13:58:46,691:INFO:SubProcess create_model() called ==================================
2023-02-09 13:58:46,692:INFO:Initializing create_model()
2023-02-09 13:58:46,692:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:58:46,692:INFO:Checking exceptions
2023-02-09 13:58:46,692:INFO:Importing libraries
2023-02-09 13:58:46,692:INFO:Copying training dataset
2023-02-09 13:58:46,692:INFO:Defining folds
2023-02-09 13:58:46,692:INFO:Declaring metric variables
2023-02-09 13:58:46,695:INFO:Importing untrained model
2023-02-09 13:58:46,699:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-09 13:58:46,705:INFO:Starting cross validation
2023-02-09 13:58:46,705:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:58:54,142:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-09 13:58:54,143:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 1056, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/lib/python3.8/concurrent/futures/_base.py", line 439, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/lib/python3.8/threading.py", line 302, in wait
    waiter.acquire()
KeyboardInterrupt

2023-02-09 13:58:54,143:INFO:Initializing create_model()
2023-02-09 13:58:54,143:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:58:54,143:INFO:Checking exceptions
2023-02-09 13:58:54,143:INFO:Importing libraries
2023-02-09 13:58:54,143:INFO:Copying training dataset
2023-02-09 13:58:54,145:INFO:Defining folds
2023-02-09 13:58:54,145:INFO:Declaring metric variables
2023-02-09 13:58:54,149:INFO:Importing untrained model
2023-02-09 13:58:54,152:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-09 13:58:54,158:INFO:Starting cross validation
2023-02-09 13:58:54,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:59:33,900:INFO:Calculating mean and std
2023-02-09 13:59:33,901:INFO:Creating metrics dataframe
2023-02-09 13:59:33,914:INFO:Uploading results into container
2023-02-09 13:59:33,914:INFO:Uploading model into container now
2023-02-09 13:59:33,914:INFO:create_model_container: 15
2023-02-09 13:59:33,914:INFO:master_model_container: 15
2023-02-09 13:59:33,914:INFO:display_container: 2
2023-02-09 13:59:33,914:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-09 13:59:33,914:INFO:create_model() succesfully completed......................................
2023-02-09 13:59:33,995:INFO:SubProcess create_model() end ==================================
2023-02-09 13:59:33,995:INFO:Creating metrics dataframe
2023-02-09 13:59:34,007:INFO:Initializing Light Gradient Boosting Machine
2023-02-09 13:59:34,007:INFO:Total runtime is 2.4206138451894126 minutes
2023-02-09 13:59:34,010:INFO:SubProcess create_model() called ==================================
2023-02-09 13:59:34,011:INFO:Initializing create_model()
2023-02-09 13:59:34,011:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:59:34,011:INFO:Checking exceptions
2023-02-09 13:59:34,011:INFO:Importing libraries
2023-02-09 13:59:34,011:INFO:Copying training dataset
2023-02-09 13:59:34,012:INFO:Defining folds
2023-02-09 13:59:34,012:INFO:Declaring metric variables
2023-02-09 13:59:34,015:INFO:Importing untrained model
2023-02-09 13:59:34,018:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-09 13:59:34,024:INFO:Starting cross validation
2023-02-09 13:59:34,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:59:36,035:INFO:Calculating mean and std
2023-02-09 13:59:36,036:INFO:Creating metrics dataframe
2023-02-09 13:59:36,047:INFO:Uploading results into container
2023-02-09 13:59:36,047:INFO:Uploading model into container now
2023-02-09 13:59:36,047:INFO:create_model_container: 16
2023-02-09 13:59:36,047:INFO:master_model_container: 16
2023-02-09 13:59:36,047:INFO:display_container: 2
2023-02-09 13:59:36,048:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-09 13:59:36,048:INFO:create_model() succesfully completed......................................
2023-02-09 13:59:36,124:INFO:SubProcess create_model() end ==================================
2023-02-09 13:59:36,124:INFO:Creating metrics dataframe
2023-02-09 13:59:36,135:INFO:Initializing Dummy Regressor
2023-02-09 13:59:36,135:INFO:Total runtime is 2.4560808738072715 minutes
2023-02-09 13:59:36,138:INFO:SubProcess create_model() called ==================================
2023-02-09 13:59:36,139:INFO:Initializing create_model()
2023-02-09 13:59:36,139:INFO:create_model(estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fd60df687f0>, return_train_score=False, kwargs={})
2023-02-09 13:59:36,139:INFO:Checking exceptions
2023-02-09 13:59:36,139:INFO:Importing libraries
2023-02-09 13:59:36,139:INFO:Copying training dataset
2023-02-09 13:59:36,139:INFO:Defining folds
2023-02-09 13:59:36,139:INFO:Declaring metric variables
2023-02-09 13:59:36,142:INFO:Importing untrained model
2023-02-09 13:59:36,145:INFO:Dummy Regressor Imported succesfully
2023-02-09 13:59:36,151:INFO:Starting cross validation
2023-02-09 13:59:36,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-09 13:59:37,151:INFO:Calculating mean and std
2023-02-09 13:59:37,152:INFO:Creating metrics dataframe
2023-02-09 13:59:37,161:INFO:Uploading results into container
2023-02-09 13:59:37,162:INFO:Uploading model into container now
2023-02-09 13:59:37,162:INFO:create_model_container: 17
2023-02-09 13:59:37,162:INFO:master_model_container: 17
2023-02-09 13:59:37,162:INFO:display_container: 2
2023-02-09 13:59:37,162:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-02-09 13:59:37,162:INFO:create_model() succesfully completed......................................
2023-02-09 13:59:37,238:INFO:SubProcess create_model() end ==================================
2023-02-09 13:59:37,238:INFO:Creating metrics dataframe
2023-02-09 13:59:37,256:INFO:Initializing create_model()
2023-02-09 13:59:37,256:INFO:create_model(estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-09 13:59:37,256:INFO:Checking exceptions
2023-02-09 13:59:37,256:INFO:Importing libraries
2023-02-09 13:59:37,256:INFO:Copying training dataset
2023-02-09 13:59:37,257:INFO:Defining folds
2023-02-09 13:59:37,257:INFO:Declaring metric variables
2023-02-09 13:59:37,257:INFO:Importing untrained model
2023-02-09 13:59:37,257:INFO:Declaring custom model
2023-02-09 13:59:37,257:INFO:Extra Trees Regressor Imported succesfully
2023-02-09 13:59:37,257:INFO:Cross validation set to False
2023-02-09 13:59:37,257:INFO:Fitting Model
2023-02-09 13:59:38,698:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-09 13:59:38,698:INFO:create_models() succesfully completed......................................
2023-02-09 13:59:38,786:INFO:create_model_container: 17
2023-02-09 13:59:38,787:INFO:master_model_container: 17
2023-02-09 13:59:38,787:INFO:display_container: 2
2023-02-09 13:59:38,787:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-09 13:59:38,787:INFO:compare_models() succesfully completed......................................
2023-02-09 15:02:23,699:INFO:Soft dependency imported: cuml: 22.12.0
2023-02-09 15:07:00,470:INFO:Soft dependency imported: cuml: 22.12.0
2023-02-09 15:07:06,128:INFO:Soft dependency imported: cuml: 22.12.0
2023-02-09 15:07:13,376:INFO:Soft dependency imported: cuml: 22.12.0
2023-02-09 15:10:26,793:INFO:Soft dependency imported: cuml: 22.12.0
2023-02-10 10:11:09,400:INFO:PyCaret Supervised Module
2023-02-10 10:11:09,400:INFO:ML Usecase: regression
2023-02-10 10:11:09,400:INFO:version 2.3.10
2023-02-10 10:11:09,400:INFO:Initializing setup()
2023-02-10 10:11:09,400:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['exchange', 'timestamp', 'open', 'high', 'low', 'close', 'volume', 'instrument', 'dt', 'volume_24HR', 'volume_24HR$', 'volume_$', 'closeChg24HR', 'openChg24HR', 'highChg24HR', 'lowChg24HR', 'volume_24HRChg24HR', 'volume_24HR$Chg24HR', 'volumeChg24HR', 'volume_$Chg24HR', 'closeChg1HR', 'openChg1HR', 'highChg1HR', 'lowChg1HR', 'volume_24HRChg1HR', 'volume_24HR$Chg1HR', 'volumeChg1HR', 'volume_$Chg1HR', 'closeChg3HR', 'openChg3HR', 'highChg3HR', 'lowChg3HR', 'volume_24HRChg3HR', 'volume_24HR$Chg3HR', 'volumeChg3HR', 'volume_$Chg3HR', 'closeChg6HR', 'openChg6HR', 'highChg6HR', 'lowChg6HR', 'volume_24HRChg6HR', 'volume_24HR$Chg6HR', 'volumeChg6HR', 'volume_$Chg6HR', 'closeChg12HR', 'openChg12HR', 'highChg12HR', 'lowChg12HR', 'volume_24HRChg12HR', 'volume_24HR$Chg12HR', 'volumeChg12HR', 'volume_$Chg12HR', 'close_ewm7D', 'open_ewm7D', 'high_ewm7D', 'low_ewm7D', 'volume_ewm7D', 'volume_24HR_ewm7D', 'volume_$_ewm7D', 'volume_24HR$_ewm7D', 'close_ewm21D', 'open_ewm21D', 'high_ewm21D', 'low_ewm21D', 'volume_ewm21D', 'volume_24HR_ewm21D', 'volume_$_ewm21D', 'volume_24HR$_ewm21D', 'close_ewm7DChg1HR', 'close_ewm7DChg3HR', 'close_ewm7DChg6HR', 'close_ewm7DChg12HR', 'close_ewm7DChg24HR', 'open_ewm7DChg1HR', 'open_ewm7DChg3HR', 'open_ewm7DChg6HR', 'open_ewm7DChg12HR', 'open_ewm7DChg24HR', 'high_ewm7DChg1HR', 'high_ewm7DChg3HR', 'high_ewm7DChg6HR', 'high_ewm7DChg12HR', 'high_ewm7DChg24HR', 'low_ewm7DChg1HR', 'low_ewm7DChg3HR', 'low_ewm7DChg6HR', 'low_ewm7DChg12HR', 'low_ewm7DChg24HR', 'volume_ewm7DChg1HR', 'volume_ewm7DChg3HR', 'volume_ewm7DChg6HR', 'volume_ewm7DChg12HR', 'volume_ewm7DChg24HR', 'volume_24HR_ewm7DChg1HR', 'volume_24HR_ewm7DChg3HR', 'volume_24HR_ewm7DChg6HR', 'volume_24HR_ewm7DChg12HR', 'volume_24HR_ewm7DChg24HR', 'volume_$_ewm7DChg1HR', 'volume_$_ewm7DChg3HR', 'volume_$_ewm7DChg6HR', 'volume_$_ewm7DChg12HR', 'volume_$_ewm7DChg24HR', 'volume_24HR$_ewm7DChg1HR', 'volume_24HR$_ewm7DChg3HR', 'volume_24HR$_ewm7DChg6HR', 'volume_24HR$_ewm7DChg12HR', 'volume_24HR$_ewm7DChg24HR', 'close_ewm21DChg1HR', 'close_ewm21DChg3HR', 'close_ewm21DChg6HR', 'close_ewm21DChg12HR', 'close_ewm21DChg24HR', 'open_ewm21DChg1HR', 'open_ewm21DChg3HR', 'open_ewm21DChg6HR', 'open_ewm21DChg12HR', 'open_ewm21DChg24HR', 'high_ewm21DChg1HR', 'high_ewm21DChg3HR', 'high_ewm21DChg6HR', 'high_ewm21DChg12HR', 'high_ewm21DChg24HR', 'low_ewm21DChg1HR', 'low_ewm21DChg3HR', 'low_ewm21DChg6HR', 'low_ewm21DChg12HR', 'low_ewm21DChg24HR', 'volume_ewm21DChg1HR', 'volume_ewm21DChg3HR', 'volume_ewm21DChg6HR', 'volume_ewm21DChg12HR', 'volume_ewm21DChg24HR', 'volume_24HR_ewm21DChg1HR', 'volume_24HR_ewm21DChg3HR', 'volume_24HR_ewm21DChg6HR', 'volume_24HR_ewm21DChg12HR', 'volume_24HR_ewm21DChg24HR', 'volume_$_ewm21DChg1HR', 'volume_$_ewm21DChg3HR', 'volume_$_ewm21DChg6HR', 'volume_$_ewm21DChg12HR', 'volume_$_ewm21DChg24HR', 'volume_24HR$_ewm21DChg1HR', 'volume_24HR$_ewm21DChg3HR', 'volume_24HR$_ewm21DChg6HR', 'volume_24HR$_ewm21DChg12HR', 'volume_24HR$_ewm21DChg24HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 10:11:09,400:INFO:Checking environment
2023-02-10 10:11:09,400:INFO:python_version: 3.9.16
2023-02-10 10:11:09,400:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 10:11:09,400:INFO:machine: x86_64
2023-02-10 10:11:09,400:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 10:11:09,400:INFO:Memory: svmem(total=134979592192, available=98485239808, percent=27.0, used=32168054784, free=54889455616, active=5367296000, inactive=71442817024, buffers=1362321408, cached=46559760384, shared=3062960128, slab=2558447616)
2023-02-10 10:11:09,401:INFO:Physical Core: 16
2023-02-10 10:11:09,401:INFO:Logical Core: 32
2023-02-10 10:11:09,401:INFO:Checking libraries
2023-02-10 10:11:09,401:INFO:pd==1.5.2
2023-02-10 10:11:09,401:INFO:numpy==1.20.3
2023-02-10 10:11:09,401:INFO:sklearn==0.23.2
2023-02-10 10:11:09,401:INFO:lightgbm==3.3.5
2023-02-10 10:11:09,418:INFO:catboost==1.1.1
2023-02-10 10:11:09,418:INFO:xgboost==1.7.3
2023-02-10 10:11:09,419:INFO:mlflow==2.1.1
2023-02-10 10:11:09,419:INFO:Checking Exceptions
2023-02-10 10:11:09,419:INFO:Declaring global variables
2023-02-10 10:11:09,419:INFO:USI: 6bfb
2023-02-10 10:11:09,419:INFO:pycaret_globals: {'fold_groups_param_full', 'prep_pipe', 'y', 'fold_generator', 'experiment__', 'display_container', 'pycaret_globals', 'stratify_param', 'X_test', '_available_plots', 'data_before_preprocess', '_internal_pipeline', 'fold_shuffle_param', 'target_param', '_all_metrics', 'y_test', '_all_models_internal', '_gpu_n_jobs_param', 'log_plots_param', '_all_models', 'imputation_classifier', 'html_param', 'fold_groups_param', 'X', 'create_model_container', 'gpu_param', 'n_jobs_param', 'seed', 'transform_target_method_param', 'y_train', 'exp_name_log', 'fix_imbalance_param', 'USI', 'master_model_container', 'dashboard_logger', 'X_train', 'imputation_regressor', 'fold_param', 'fix_imbalance_method_param', 'transform_target_param', '_ml_usecase', 'logging_param', 'iterative_imputation_iters_param'}
2023-02-10 10:11:09,419:INFO:Preparing display monitor
2023-02-10 10:11:09,419:INFO:Preparing display monitor
2023-02-10 10:11:09,426:INFO:Importing libraries
2023-02-10 10:11:09,426:INFO:Copying data for preprocessing
2023-02-10 10:11:09,470:INFO:Declaring preprocessing parameters
2023-02-10 10:11:09,546:INFO:Creating preprocessing pipeline
2023-02-10 10:11:11,318:INFO:Preprocessing pipeline created successfully
2023-02-10 10:11:11,318:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 10:11:11,318:INFO:Creating global containers
2023-02-10 10:11:11,319:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 10:11:56,572:INFO:Creating grid variables
2023-02-10 10:11:56,612:INFO:create_model_container: 0
2023-02-10 10:11:56,613:INFO:master_model_container: 0
2023-02-10 10:11:56,613:INFO:display_container: 1
2023-02-10 10:11:56,615:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['exchange', 'timestamp',
                                                       'open', 'high', 'low',
                                                       'close', 'volume',
                                                       'instrument', 'dt',
                                                       'volume_24HR',
                                                       'volume_24HR$',
                                                       'volume_$',
                                                       'closeChg24HR',
                                                       'openChg24HR',
                                                       'highChg24HR',
                                                       'lowChg24HR',
                                                       'volume_24HRChg24HR',
                                                       'volume_24HR$Chg24HR',
                                                       'volumeChg24H...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-10 10:11:56,616:INFO:setup() succesfully completed......................................
2023-02-10 10:12:29,225:INFO:PyCaret Supervised Module
2023-02-10 10:12:29,225:INFO:ML Usecase: regression
2023-02-10 10:12:29,225:INFO:version 2.3.10
2023-02-10 10:12:29,225:INFO:Initializing setup()
2023-02-10 10:12:29,225:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['exchange', 'timestamp', 'open', 'high', 'low', 'close', 'volume', 'instrument', 'dt', 'volume_24HR', 'volume_24HR$', 'volume_$', 'closeChg24HR', 'openChg24HR', 'highChg24HR', 'lowChg24HR', 'volume_24HRChg24HR', 'volume_24HR$Chg24HR', 'volumeChg24HR', 'volume_$Chg24HR', 'closeChg1HR', 'openChg1HR', 'highChg1HR', 'lowChg1HR', 'volume_24HRChg1HR', 'volume_24HR$Chg1HR', 'volumeChg1HR', 'volume_$Chg1HR', 'closeChg3HR', 'openChg3HR', 'highChg3HR', 'lowChg3HR', 'volume_24HRChg3HR', 'volume_24HR$Chg3HR', 'volumeChg3HR', 'volume_$Chg3HR', 'closeChg6HR', 'openChg6HR', 'highChg6HR', 'lowChg6HR', 'volume_24HRChg6HR', 'volume_24HR$Chg6HR', 'volumeChg6HR', 'volume_$Chg6HR', 'closeChg12HR', 'openChg12HR', 'highChg12HR', 'lowChg12HR', 'volume_24HRChg12HR', 'volume_24HR$Chg12HR', 'volumeChg12HR', 'volume_$Chg12HR', 'close_ewm7D', 'open_ewm7D', 'high_ewm7D', 'low_ewm7D', 'volume_ewm7D', 'volume_24HR_ewm7D', 'volume_$_ewm7D', 'volume_24HR$_ewm7D', 'close_ewm21D', 'open_ewm21D', 'high_ewm21D', 'low_ewm21D', 'volume_ewm21D', 'volume_24HR_ewm21D', 'volume_$_ewm21D', 'volume_24HR$_ewm21D', 'close_ewm7DChg1HR', 'close_ewm7DChg3HR', 'close_ewm7DChg6HR', 'close_ewm7DChg12HR', 'close_ewm7DChg24HR', 'open_ewm7DChg1HR', 'open_ewm7DChg3HR', 'open_ewm7DChg6HR', 'open_ewm7DChg12HR', 'open_ewm7DChg24HR', 'high_ewm7DChg1HR', 'high_ewm7DChg3HR', 'high_ewm7DChg6HR', 'high_ewm7DChg12HR', 'high_ewm7DChg24HR', 'low_ewm7DChg1HR', 'low_ewm7DChg3HR', 'low_ewm7DChg6HR', 'low_ewm7DChg12HR', 'low_ewm7DChg24HR', 'volume_ewm7DChg1HR', 'volume_ewm7DChg3HR', 'volume_ewm7DChg6HR', 'volume_ewm7DChg12HR', 'volume_ewm7DChg24HR', 'volume_24HR_ewm7DChg1HR', 'volume_24HR_ewm7DChg3HR', 'volume_24HR_ewm7DChg6HR', 'volume_24HR_ewm7DChg12HR', 'volume_24HR_ewm7DChg24HR', 'volume_$_ewm7DChg1HR', 'volume_$_ewm7DChg3HR', 'volume_$_ewm7DChg6HR', 'volume_$_ewm7DChg12HR', 'volume_$_ewm7DChg24HR', 'volume_24HR$_ewm7DChg1HR', 'volume_24HR$_ewm7DChg3HR', 'volume_24HR$_ewm7DChg6HR', 'volume_24HR$_ewm7DChg12HR', 'volume_24HR$_ewm7DChg24HR', 'close_ewm21DChg1HR', 'close_ewm21DChg3HR', 'close_ewm21DChg6HR', 'close_ewm21DChg12HR', 'close_ewm21DChg24HR', 'open_ewm21DChg1HR', 'open_ewm21DChg3HR', 'open_ewm21DChg6HR', 'open_ewm21DChg12HR', 'open_ewm21DChg24HR', 'high_ewm21DChg1HR', 'high_ewm21DChg3HR', 'high_ewm21DChg6HR', 'high_ewm21DChg12HR', 'high_ewm21DChg24HR', 'low_ewm21DChg1HR', 'low_ewm21DChg3HR', 'low_ewm21DChg6HR', 'low_ewm21DChg12HR', 'low_ewm21DChg24HR', 'volume_ewm21DChg1HR', 'volume_ewm21DChg3HR', 'volume_ewm21DChg6HR', 'volume_ewm21DChg12HR', 'volume_ewm21DChg24HR', 'volume_24HR_ewm21DChg1HR', 'volume_24HR_ewm21DChg3HR', 'volume_24HR_ewm21DChg6HR', 'volume_24HR_ewm21DChg12HR', 'volume_24HR_ewm21DChg24HR', 'volume_$_ewm21DChg1HR', 'volume_$_ewm21DChg3HR', 'volume_$_ewm21DChg6HR', 'volume_$_ewm21DChg12HR', 'volume_$_ewm21DChg24HR', 'volume_24HR$_ewm21DChg1HR', 'volume_24HR$_ewm21DChg3HR', 'volume_24HR$_ewm21DChg6HR', 'volume_24HR$_ewm21DChg12HR', 'volume_24HR$_ewm21DChg24HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 10:12:29,225:INFO:Checking environment
2023-02-10 10:12:29,225:INFO:python_version: 3.9.16
2023-02-10 10:12:29,225:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 10:12:29,225:INFO:machine: x86_64
2023-02-10 10:12:29,225:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 10:12:29,226:INFO:Memory: svmem(total=134979592192, available=98266808320, percent=27.2, used=32480980992, free=54657331200, active=5368328192, inactive=71673126912, buffers=1362644992, cached=46478635008, shared=2968461312, slab=2559000576)
2023-02-10 10:12:29,226:INFO:Physical Core: 16
2023-02-10 10:12:29,226:INFO:Logical Core: 32
2023-02-10 10:12:29,226:INFO:Checking libraries
2023-02-10 10:12:29,226:INFO:pd==1.5.2
2023-02-10 10:12:29,226:INFO:numpy==1.20.3
2023-02-10 10:12:29,226:INFO:sklearn==0.23.2
2023-02-10 10:12:29,227:INFO:lightgbm==3.3.5
2023-02-10 10:12:29,227:INFO:catboost==1.1.1
2023-02-10 10:12:29,227:INFO:xgboost==1.7.3
2023-02-10 10:12:29,227:INFO:mlflow==2.1.1
2023-02-10 10:12:29,227:INFO:Checking Exceptions
2023-02-10 10:12:29,227:INFO:Declaring global variables
2023-02-10 10:12:29,227:INFO:USI: d7d8
2023-02-10 10:12:29,227:INFO:pycaret_globals: {'fold_groups_param_full', 'prep_pipe', 'y', 'fold_generator', 'experiment__', 'display_container', 'pycaret_globals', 'stratify_param', 'X_test', '_available_plots', 'data_before_preprocess', '_internal_pipeline', 'fold_shuffle_param', 'target_param', '_all_metrics', 'y_test', '_all_models_internal', '_gpu_n_jobs_param', 'log_plots_param', '_all_models', 'imputation_classifier', 'html_param', 'fold_groups_param', 'X', 'create_model_container', 'gpu_param', 'n_jobs_param', 'seed', 'transform_target_method_param', 'y_train', 'exp_name_log', 'fix_imbalance_param', 'USI', 'master_model_container', 'dashboard_logger', 'X_train', 'imputation_regressor', 'fold_param', 'fix_imbalance_method_param', 'transform_target_param', '_ml_usecase', 'logging_param', 'iterative_imputation_iters_param'}
2023-02-10 10:12:29,227:INFO:Preparing display monitor
2023-02-10 10:12:29,227:INFO:Preparing display monitor
2023-02-10 10:12:29,233:INFO:Importing libraries
2023-02-10 10:12:29,233:INFO:Copying data for preprocessing
2023-02-10 10:12:29,273:INFO:Declaring preprocessing parameters
2023-02-10 10:12:29,342:INFO:Creating preprocessing pipeline
2023-02-10 10:12:31,015:INFO:Preprocessing pipeline created successfully
2023-02-10 10:12:31,015:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 10:12:31,016:INFO:Creating global containers
2023-02-10 10:12:31,016:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 10:13:16,946:INFO:Creating grid variables
2023-02-10 10:13:16,987:INFO:create_model_container: 0
2023-02-10 10:13:16,988:INFO:master_model_container: 0
2023-02-10 10:13:16,988:INFO:display_container: 1
2023-02-10 10:13:16,990:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['exchange', 'timestamp',
                                                       'open', 'high', 'low',
                                                       'close', 'volume',
                                                       'instrument', 'dt',
                                                       'volume_24HR',
                                                       'volume_24HR$',
                                                       'volume_$',
                                                       'closeChg24HR',
                                                       'openChg24HR',
                                                       'highChg24HR',
                                                       'lowChg24HR',
                                                       'volume_24HRChg24HR',
                                                       'volume_24HR$Chg24HR',
                                                       'volumeChg24H...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-10 10:13:16,990:INFO:setup() succesfully completed......................................
2023-02-10 10:13:17,093:INFO:Initializing compare_models()
2023-02-10 10:13:17,093:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-02-10 10:13:17,093:INFO:Checking exceptions
2023-02-10 10:13:17,093:INFO:Preparing display monitor
2023-02-10 10:13:17,093:INFO:Preparing display monitor
2023-02-10 10:13:17,103:INFO:Initializing Linear Regression
2023-02-10 10:13:17,103:INFO:Total runtime is 1.712640126546224e-06 minutes
2023-02-10 10:13:17,107:INFO:SubProcess create_model() called ==================================
2023-02-10 10:13:17,107:INFO:Initializing create_model()
2023-02-10 10:13:17,107:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:13:17,107:INFO:Checking exceptions
2023-02-10 10:13:17,107:INFO:Importing libraries
2023-02-10 10:13:17,107:INFO:Copying training dataset
2023-02-10 10:13:17,110:INFO:Defining folds
2023-02-10 10:13:17,110:INFO:Declaring metric variables
2023-02-10 10:13:17,113:INFO:Importing untrained model
2023-02-10 10:13:17,116:INFO:Linear Regression Imported succesfully
2023-02-10 10:13:17,123:INFO:Starting cross validation
2023-02-10 10:13:17,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:13:19,628:INFO:Calculating mean and std
2023-02-10 10:13:19,629:INFO:Creating metrics dataframe
2023-02-10 10:13:19,634:INFO:Uploading results into container
2023-02-10 10:13:19,634:INFO:Uploading model into container now
2023-02-10 10:13:19,634:INFO:create_model_container: 1
2023-02-10 10:13:19,634:INFO:master_model_container: 1
2023-02-10 10:13:19,634:INFO:display_container: 2
2023-02-10 10:13:19,635:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-10 10:13:19,635:INFO:create_model() succesfully completed......................................
2023-02-10 10:13:19,748:INFO:SubProcess create_model() end ==================================
2023-02-10 10:13:19,748:INFO:Creating metrics dataframe
2023-02-10 10:13:19,754:INFO:Initializing Lasso Regression
2023-02-10 10:13:19,754:INFO:Total runtime is 0.044173006216684976 minutes
2023-02-10 10:13:19,757:INFO:SubProcess create_model() called ==================================
2023-02-10 10:13:19,757:INFO:Initializing create_model()
2023-02-10 10:13:19,757:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:13:19,757:INFO:Checking exceptions
2023-02-10 10:13:19,757:INFO:Importing libraries
2023-02-10 10:13:19,757:INFO:Copying training dataset
2023-02-10 10:13:19,766:INFO:Defining folds
2023-02-10 10:13:19,766:INFO:Declaring metric variables
2023-02-10 10:13:19,769:INFO:Importing untrained model
2023-02-10 10:13:19,773:INFO:Lasso Regression Imported succesfully
2023-02-10 10:13:19,782:INFO:Starting cross validation
2023-02-10 10:13:19,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:13:21,043:INFO:Calculating mean and std
2023-02-10 10:13:21,044:INFO:Creating metrics dataframe
2023-02-10 10:13:21,047:INFO:Uploading results into container
2023-02-10 10:13:21,047:INFO:Uploading model into container now
2023-02-10 10:13:21,047:INFO:create_model_container: 2
2023-02-10 10:13:21,047:INFO:master_model_container: 2
2023-02-10 10:13:21,047:INFO:display_container: 2
2023-02-10 10:13:21,047:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 10:13:21,047:INFO:create_model() succesfully completed......................................
2023-02-10 10:13:21,157:INFO:SubProcess create_model() end ==================================
2023-02-10 10:13:21,157:INFO:Creating metrics dataframe
2023-02-10 10:13:21,163:INFO:Initializing Ridge Regression
2023-02-10 10:13:21,163:INFO:Total runtime is 0.06766251722971597 minutes
2023-02-10 10:13:21,166:INFO:SubProcess create_model() called ==================================
2023-02-10 10:13:21,167:INFO:Initializing create_model()
2023-02-10 10:13:21,167:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:13:21,167:INFO:Checking exceptions
2023-02-10 10:13:21,167:INFO:Importing libraries
2023-02-10 10:13:21,167:INFO:Copying training dataset
2023-02-10 10:13:21,170:INFO:Defining folds
2023-02-10 10:13:21,170:INFO:Declaring metric variables
2023-02-10 10:13:21,173:INFO:Importing untrained model
2023-02-10 10:13:21,176:INFO:Ridge Regression Imported succesfully
2023-02-10 10:13:21,182:INFO:Starting cross validation
2023-02-10 10:13:21,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:13:22,454:INFO:Calculating mean and std
2023-02-10 10:13:22,454:INFO:Creating metrics dataframe
2023-02-10 10:13:22,458:INFO:Uploading results into container
2023-02-10 10:13:22,458:INFO:Uploading model into container now
2023-02-10 10:13:22,458:INFO:create_model_container: 3
2023-02-10 10:13:22,458:INFO:master_model_container: 3
2023-02-10 10:13:22,458:INFO:display_container: 2
2023-02-10 10:13:22,459:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-10 10:13:22,459:INFO:create_model() succesfully completed......................................
2023-02-10 10:13:22,551:INFO:SubProcess create_model() end ==================================
2023-02-10 10:13:22,551:INFO:Creating metrics dataframe
2023-02-10 10:13:22,557:INFO:Initializing Elastic Net
2023-02-10 10:13:22,557:INFO:Total runtime is 0.09090246756871541 minutes
2023-02-10 10:13:22,561:INFO:SubProcess create_model() called ==================================
2023-02-10 10:13:22,561:INFO:Initializing create_model()
2023-02-10 10:13:22,561:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:13:22,561:INFO:Checking exceptions
2023-02-10 10:13:22,561:INFO:Importing libraries
2023-02-10 10:13:22,561:INFO:Copying training dataset
2023-02-10 10:13:22,564:INFO:Defining folds
2023-02-10 10:13:22,564:INFO:Declaring metric variables
2023-02-10 10:13:22,567:INFO:Importing untrained model
2023-02-10 10:13:22,570:INFO:Elastic Net Imported succesfully
2023-02-10 10:13:22,576:INFO:Starting cross validation
2023-02-10 10:13:22,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:13:23,638:INFO:Calculating mean and std
2023-02-10 10:13:23,639:INFO:Creating metrics dataframe
2023-02-10 10:13:23,642:INFO:Uploading results into container
2023-02-10 10:13:23,642:INFO:Uploading model into container now
2023-02-10 10:13:23,642:INFO:create_model_container: 4
2023-02-10 10:13:23,642:INFO:master_model_container: 4
2023-02-10 10:13:23,642:INFO:display_container: 2
2023-02-10 10:13:23,643:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 10:13:23,643:INFO:create_model() succesfully completed......................................
2023-02-10 10:13:23,733:INFO:SubProcess create_model() end ==================================
2023-02-10 10:13:23,734:INFO:Creating metrics dataframe
2023-02-10 10:13:23,739:INFO:Initializing Least Angle Regression
2023-02-10 10:13:23,740:INFO:Total runtime is 0.110604989528656 minutes
2023-02-10 10:13:23,743:INFO:SubProcess create_model() called ==================================
2023-02-10 10:13:23,743:INFO:Initializing create_model()
2023-02-10 10:13:23,743:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:13:23,743:INFO:Checking exceptions
2023-02-10 10:13:23,743:INFO:Importing libraries
2023-02-10 10:13:23,743:INFO:Copying training dataset
2023-02-10 10:13:23,746:INFO:Defining folds
2023-02-10 10:13:23,746:INFO:Declaring metric variables
2023-02-10 10:13:23,749:INFO:Importing untrained model
2023-02-10 10:13:23,752:INFO:Least Angle Regression Imported succesfully
2023-02-10 10:13:23,758:INFO:Starting cross validation
2023-02-10 10:13:23,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:13:24,336:INFO:Calculating mean and std
2023-02-10 10:13:24,337:INFO:Creating metrics dataframe
2023-02-10 10:13:24,340:INFO:Uploading results into container
2023-02-10 10:13:24,340:INFO:Uploading model into container now
2023-02-10 10:13:24,340:INFO:create_model_container: 5
2023-02-10 10:13:24,340:INFO:master_model_container: 5
2023-02-10 10:13:24,340:INFO:display_container: 2
2023-02-10 10:13:24,341:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize=True, precompute='auto',
     random_state=11, verbose=False)
2023-02-10 10:13:24,341:INFO:create_model() succesfully completed......................................
2023-02-10 10:13:24,435:INFO:SubProcess create_model() end ==================================
2023-02-10 10:13:24,435:INFO:Creating metrics dataframe
2023-02-10 10:13:24,441:INFO:Initializing Lasso Least Angle Regression
2023-02-10 10:13:24,441:INFO:Total runtime is 0.12229345242182413 minutes
2023-02-10 10:13:24,444:INFO:SubProcess create_model() called ==================================
2023-02-10 10:13:24,444:INFO:Initializing create_model()
2023-02-10 10:13:24,444:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:13:24,444:INFO:Checking exceptions
2023-02-10 10:13:24,444:INFO:Importing libraries
2023-02-10 10:13:24,444:INFO:Copying training dataset
2023-02-10 10:13:24,447:INFO:Defining folds
2023-02-10 10:13:24,447:INFO:Declaring metric variables
2023-02-10 10:13:24,450:INFO:Importing untrained model
2023-02-10 10:13:24,453:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-10 10:13:24,459:INFO:Starting cross validation
2023-02-10 10:13:24,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:13:24,958:INFO:Calculating mean and std
2023-02-10 10:13:24,959:INFO:Creating metrics dataframe
2023-02-10 10:13:24,961:INFO:Uploading results into container
2023-02-10 10:13:24,961:INFO:Uploading model into container now
2023-02-10 10:13:24,961:INFO:create_model_container: 6
2023-02-10 10:13:24,961:INFO:master_model_container: 6
2023-02-10 10:13:24,961:INFO:display_container: 2
2023-02-10 10:13:24,962:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-10 10:13:24,962:INFO:create_model() succesfully completed......................................
2023-02-10 10:13:25,054:INFO:SubProcess create_model() end ==================================
2023-02-10 10:13:25,054:INFO:Creating metrics dataframe
2023-02-10 10:13:25,060:INFO:Initializing Orthogonal Matching Pursuit
2023-02-10 10:13:25,060:INFO:Total runtime is 0.1326147198677063 minutes
2023-02-10 10:13:25,063:INFO:SubProcess create_model() called ==================================
2023-02-10 10:13:25,064:INFO:Initializing create_model()
2023-02-10 10:13:25,064:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:13:25,064:INFO:Checking exceptions
2023-02-10 10:13:25,064:INFO:Importing libraries
2023-02-10 10:13:25,064:INFO:Copying training dataset
2023-02-10 10:13:25,067:INFO:Defining folds
2023-02-10 10:13:25,067:INFO:Declaring metric variables
2023-02-10 10:13:25,070:INFO:Importing untrained model
2023-02-10 10:13:25,073:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 10:13:25,080:INFO:Starting cross validation
2023-02-10 10:13:25,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:13:25,551:INFO:Calculating mean and std
2023-02-10 10:13:25,552:INFO:Creating metrics dataframe
2023-02-10 10:13:25,555:INFO:Uploading results into container
2023-02-10 10:13:25,555:INFO:Uploading model into container now
2023-02-10 10:13:25,555:INFO:create_model_container: 7
2023-02-10 10:13:25,555:INFO:master_model_container: 7
2023-02-10 10:13:25,555:INFO:display_container: 2
2023-02-10 10:13:25,555:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 10:13:25,555:INFO:create_model() succesfully completed......................................
2023-02-10 10:13:25,650:INFO:SubProcess create_model() end ==================================
2023-02-10 10:13:25,650:INFO:Creating metrics dataframe
2023-02-10 10:13:25,657:INFO:Initializing Bayesian Ridge
2023-02-10 10:13:25,657:INFO:Total runtime is 0.1425587018330892 minutes
2023-02-10 10:13:25,660:INFO:SubProcess create_model() called ==================================
2023-02-10 10:13:25,660:INFO:Initializing create_model()
2023-02-10 10:13:25,660:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:13:25,660:INFO:Checking exceptions
2023-02-10 10:13:25,660:INFO:Importing libraries
2023-02-10 10:13:25,660:INFO:Copying training dataset
2023-02-10 10:13:25,663:INFO:Defining folds
2023-02-10 10:13:25,664:INFO:Declaring metric variables
2023-02-10 10:13:25,666:INFO:Importing untrained model
2023-02-10 10:13:25,670:INFO:Bayesian Ridge Imported succesfully
2023-02-10 10:13:25,675:INFO:Starting cross validation
2023-02-10 10:13:25,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:13:32,431:INFO:Calculating mean and std
2023-02-10 10:13:32,432:INFO:Creating metrics dataframe
2023-02-10 10:13:32,435:INFO:Uploading results into container
2023-02-10 10:13:32,436:INFO:Uploading model into container now
2023-02-10 10:13:32,436:INFO:create_model_container: 8
2023-02-10 10:13:32,436:INFO:master_model_container: 8
2023-02-10 10:13:32,436:INFO:display_container: 2
2023-02-10 10:13:32,436:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-10 10:13:32,436:INFO:create_model() succesfully completed......................................
2023-02-10 10:13:32,530:INFO:SubProcess create_model() end ==================================
2023-02-10 10:13:32,531:INFO:Creating metrics dataframe
2023-02-10 10:13:32,537:INFO:Initializing Passive Aggressive Regressor
2023-02-10 10:13:32,537:INFO:Total runtime is 0.2572255293528239 minutes
2023-02-10 10:13:32,540:INFO:SubProcess create_model() called ==================================
2023-02-10 10:13:32,540:INFO:Initializing create_model()
2023-02-10 10:13:32,540:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:13:32,540:INFO:Checking exceptions
2023-02-10 10:13:32,540:INFO:Importing libraries
2023-02-10 10:13:32,540:INFO:Copying training dataset
2023-02-10 10:13:32,543:INFO:Defining folds
2023-02-10 10:13:32,544:INFO:Declaring metric variables
2023-02-10 10:13:32,546:INFO:Importing untrained model
2023-02-10 10:13:32,549:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-10 10:13:32,555:INFO:Starting cross validation
2023-02-10 10:13:32,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:13:33,232:INFO:Calculating mean and std
2023-02-10 10:13:33,232:INFO:Creating metrics dataframe
2023-02-10 10:13:33,235:INFO:Uploading results into container
2023-02-10 10:13:33,235:INFO:Uploading model into container now
2023-02-10 10:13:33,235:INFO:create_model_container: 9
2023-02-10 10:13:33,235:INFO:master_model_container: 9
2023-02-10 10:13:33,235:INFO:display_container: 2
2023-02-10 10:13:33,235:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-10 10:13:33,235:INFO:create_model() succesfully completed......................................
2023-02-10 10:13:33,327:INFO:SubProcess create_model() end ==================================
2023-02-10 10:13:33,327:INFO:Creating metrics dataframe
2023-02-10 10:13:33,334:INFO:Initializing Huber Regressor
2023-02-10 10:13:33,334:INFO:Total runtime is 0.2705063343048096 minutes
2023-02-10 10:13:33,337:INFO:SubProcess create_model() called ==================================
2023-02-10 10:13:33,337:INFO:Initializing create_model()
2023-02-10 10:13:33,337:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:13:33,337:INFO:Checking exceptions
2023-02-10 10:13:33,337:INFO:Importing libraries
2023-02-10 10:13:33,337:INFO:Copying training dataset
2023-02-10 10:13:33,340:INFO:Defining folds
2023-02-10 10:13:33,340:INFO:Declaring metric variables
2023-02-10 10:13:33,343:INFO:Importing untrained model
2023-02-10 10:13:33,346:INFO:Huber Regressor Imported succesfully
2023-02-10 10:13:33,351:INFO:Starting cross validation
2023-02-10 10:13:33,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:14:10,105:INFO:Calculating mean and std
2023-02-10 10:14:10,106:INFO:Creating metrics dataframe
2023-02-10 10:14:10,110:INFO:Uploading results into container
2023-02-10 10:14:10,111:INFO:Uploading model into container now
2023-02-10 10:14:10,111:INFO:create_model_container: 10
2023-02-10 10:14:10,111:INFO:master_model_container: 10
2023-02-10 10:14:10,111:INFO:display_container: 2
2023-02-10 10:14:10,111:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-10 10:14:10,111:INFO:create_model() succesfully completed......................................
2023-02-10 10:14:10,220:INFO:SubProcess create_model() end ==================================
2023-02-10 10:14:10,220:INFO:Creating metrics dataframe
2023-02-10 10:14:10,227:INFO:Initializing K Neighbors Regressor
2023-02-10 10:14:10,227:INFO:Total runtime is 0.8853916724522908 minutes
2023-02-10 10:14:10,230:INFO:SubProcess create_model() called ==================================
2023-02-10 10:14:10,230:INFO:Initializing create_model()
2023-02-10 10:14:10,230:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:14:10,230:INFO:Checking exceptions
2023-02-10 10:14:10,230:INFO:Importing libraries
2023-02-10 10:14:10,230:INFO:Copying training dataset
2023-02-10 10:14:10,233:INFO:Defining folds
2023-02-10 10:14:10,233:INFO:Declaring metric variables
2023-02-10 10:14:10,236:INFO:Importing untrained model
2023-02-10 10:14:10,239:INFO:K Neighbors Regressor Imported succesfully
2023-02-10 10:14:10,244:INFO:Starting cross validation
2023-02-10 10:14:10,245:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:14:20,040:INFO:Calculating mean and std
2023-02-10 10:14:20,040:INFO:Creating metrics dataframe
2023-02-10 10:14:20,043:INFO:Uploading results into container
2023-02-10 10:14:20,043:INFO:Uploading model into container now
2023-02-10 10:14:20,043:INFO:create_model_container: 11
2023-02-10 10:14:20,043:INFO:master_model_container: 11
2023-02-10 10:14:20,043:INFO:display_container: 2
2023-02-10 10:14:20,043:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-10 10:14:20,043:INFO:create_model() succesfully completed......................................
2023-02-10 10:14:20,148:INFO:SubProcess create_model() end ==================================
2023-02-10 10:14:20,148:INFO:Creating metrics dataframe
2023-02-10 10:14:20,155:INFO:Initializing Decision Tree Regressor
2023-02-10 10:14:20,155:INFO:Total runtime is 1.0508626222610473 minutes
2023-02-10 10:14:20,158:INFO:SubProcess create_model() called ==================================
2023-02-10 10:14:20,159:INFO:Initializing create_model()
2023-02-10 10:14:20,159:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:14:20,159:INFO:Checking exceptions
2023-02-10 10:14:20,159:INFO:Importing libraries
2023-02-10 10:14:20,159:INFO:Copying training dataset
2023-02-10 10:14:20,162:INFO:Defining folds
2023-02-10 10:14:20,162:INFO:Declaring metric variables
2023-02-10 10:14:20,165:INFO:Importing untrained model
2023-02-10 10:14:20,168:INFO:Decision Tree Regressor Imported succesfully
2023-02-10 10:14:20,174:INFO:Starting cross validation
2023-02-10 10:14:20,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:14:37,956:INFO:Calculating mean and std
2023-02-10 10:14:37,957:INFO:Creating metrics dataframe
2023-02-10 10:14:37,960:INFO:Uploading results into container
2023-02-10 10:14:37,960:INFO:Uploading model into container now
2023-02-10 10:14:37,960:INFO:create_model_container: 12
2023-02-10 10:14:37,960:INFO:master_model_container: 12
2023-02-10 10:14:37,960:INFO:display_container: 2
2023-02-10 10:14:37,961:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-10 10:14:37,961:INFO:create_model() succesfully completed......................................
2023-02-10 10:14:38,053:INFO:SubProcess create_model() end ==================================
2023-02-10 10:14:38,053:INFO:Creating metrics dataframe
2023-02-10 10:14:38,060:INFO:Initializing Random Forest Regressor
2023-02-10 10:14:38,060:INFO:Total runtime is 1.3492839217185972 minutes
2023-02-10 10:14:38,064:INFO:SubProcess create_model() called ==================================
2023-02-10 10:14:38,064:INFO:Initializing create_model()
2023-02-10 10:14:38,064:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:14:38,064:INFO:Checking exceptions
2023-02-10 10:14:38,064:INFO:Importing libraries
2023-02-10 10:14:38,064:INFO:Copying training dataset
2023-02-10 10:14:38,067:INFO:Defining folds
2023-02-10 10:14:38,067:INFO:Declaring metric variables
2023-02-10 10:14:38,070:INFO:Importing untrained model
2023-02-10 10:14:38,073:INFO:Random Forest Regressor Imported succesfully
2023-02-10 10:14:38,079:INFO:Starting cross validation
2023-02-10 10:14:38,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:22:45,807:INFO:Calculating mean and std
2023-02-10 10:22:45,808:INFO:Creating metrics dataframe
2023-02-10 10:22:45,812:INFO:Uploading results into container
2023-02-10 10:22:45,813:INFO:Uploading model into container now
2023-02-10 10:22:45,813:INFO:create_model_container: 13
2023-02-10 10:22:45,813:INFO:master_model_container: 13
2023-02-10 10:22:45,813:INFO:display_container: 2
2023-02-10 10:22:45,813:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-10 10:22:45,813:INFO:create_model() succesfully completed......................................
2023-02-10 10:22:45,905:INFO:SubProcess create_model() end ==================================
2023-02-10 10:22:45,905:INFO:Creating metrics dataframe
2023-02-10 10:22:45,912:INFO:Initializing Extra Trees Regressor
2023-02-10 10:22:45,913:INFO:Total runtime is 9.480155579249065 minutes
2023-02-10 10:22:45,916:INFO:SubProcess create_model() called ==================================
2023-02-10 10:22:45,916:INFO:Initializing create_model()
2023-02-10 10:22:45,916:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:22:45,916:INFO:Checking exceptions
2023-02-10 10:22:45,916:INFO:Importing libraries
2023-02-10 10:22:45,916:INFO:Copying training dataset
2023-02-10 10:22:45,919:INFO:Defining folds
2023-02-10 10:22:45,919:INFO:Declaring metric variables
2023-02-10 10:22:45,922:INFO:Importing untrained model
2023-02-10 10:22:45,925:INFO:Extra Trees Regressor Imported succesfully
2023-02-10 10:22:45,931:INFO:Starting cross validation
2023-02-10 10:22:45,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:26:21,926:INFO:Calculating mean and std
2023-02-10 10:26:21,927:INFO:Creating metrics dataframe
2023-02-10 10:26:21,931:INFO:Uploading results into container
2023-02-10 10:26:21,931:INFO:Uploading model into container now
2023-02-10 10:26:21,931:INFO:create_model_container: 14
2023-02-10 10:26:21,931:INFO:master_model_container: 14
2023-02-10 10:26:21,931:INFO:display_container: 2
2023-02-10 10:26:21,931:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-10 10:26:21,931:INFO:create_model() succesfully completed......................................
2023-02-10 10:26:22,048:INFO:SubProcess create_model() end ==================================
2023-02-10 10:26:22,048:INFO:Creating metrics dataframe
2023-02-10 10:26:22,055:INFO:Initializing AdaBoost Regressor
2023-02-10 10:26:22,055:INFO:Total runtime is 13.082538175582886 minutes
2023-02-10 10:26:22,059:INFO:SubProcess create_model() called ==================================
2023-02-10 10:26:22,059:INFO:Initializing create_model()
2023-02-10 10:26:22,059:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:26:22,059:INFO:Checking exceptions
2023-02-10 10:26:22,059:INFO:Importing libraries
2023-02-10 10:26:22,059:INFO:Copying training dataset
2023-02-10 10:26:22,063:INFO:Defining folds
2023-02-10 10:26:22,063:INFO:Declaring metric variables
2023-02-10 10:26:22,066:INFO:Importing untrained model
2023-02-10 10:26:22,069:INFO:AdaBoost Regressor Imported succesfully
2023-02-10 10:26:22,074:INFO:Starting cross validation
2023-02-10 10:26:22,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:27:30,357:INFO:Calculating mean and std
2023-02-10 10:27:30,358:INFO:Creating metrics dataframe
2023-02-10 10:27:30,364:INFO:Uploading results into container
2023-02-10 10:27:30,364:INFO:Uploading model into container now
2023-02-10 10:27:30,364:INFO:create_model_container: 15
2023-02-10 10:27:30,364:INFO:master_model_container: 15
2023-02-10 10:27:30,364:INFO:display_container: 2
2023-02-10 10:27:30,365:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-10 10:27:30,365:INFO:create_model() succesfully completed......................................
2023-02-10 10:27:30,475:INFO:SubProcess create_model() end ==================================
2023-02-10 10:27:30,475:INFO:Creating metrics dataframe
2023-02-10 10:27:30,483:INFO:Initializing Gradient Boosting Regressor
2023-02-10 10:27:30,483:INFO:Total runtime is 14.222994542121889 minutes
2023-02-10 10:27:30,486:INFO:SubProcess create_model() called ==================================
2023-02-10 10:27:30,487:INFO:Initializing create_model()
2023-02-10 10:27:30,487:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:27:30,487:INFO:Checking exceptions
2023-02-10 10:27:30,487:INFO:Importing libraries
2023-02-10 10:27:30,487:INFO:Copying training dataset
2023-02-10 10:27:30,490:INFO:Defining folds
2023-02-10 10:27:30,490:INFO:Declaring metric variables
2023-02-10 10:27:30,493:INFO:Importing untrained model
2023-02-10 10:27:30,497:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-10 10:27:30,503:INFO:Starting cross validation
2023-02-10 10:27:30,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:31:54,118:INFO:Calculating mean and std
2023-02-10 10:31:54,119:INFO:Creating metrics dataframe
2023-02-10 10:31:54,123:INFO:Uploading results into container
2023-02-10 10:31:54,123:INFO:Uploading model into container now
2023-02-10 10:31:54,123:INFO:create_model_container: 16
2023-02-10 10:31:54,123:INFO:master_model_container: 16
2023-02-10 10:31:54,123:INFO:display_container: 2
2023-02-10 10:31:54,124:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-10 10:31:54,124:INFO:create_model() succesfully completed......................................
2023-02-10 10:31:54,228:INFO:SubProcess create_model() end ==================================
2023-02-10 10:31:54,228:INFO:Creating metrics dataframe
2023-02-10 10:31:54,236:INFO:Initializing Extreme Gradient Boosting
2023-02-10 10:31:54,236:INFO:Total runtime is 18.618878412246705 minutes
2023-02-10 10:31:54,239:INFO:SubProcess create_model() called ==================================
2023-02-10 10:31:54,240:INFO:Initializing create_model()
2023-02-10 10:31:54,240:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:31:54,240:INFO:Checking exceptions
2023-02-10 10:31:54,240:INFO:Importing libraries
2023-02-10 10:31:54,240:INFO:Copying training dataset
2023-02-10 10:31:54,243:INFO:Defining folds
2023-02-10 10:31:54,243:INFO:Declaring metric variables
2023-02-10 10:31:54,246:INFO:Importing untrained model
2023-02-10 10:31:54,249:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-10 10:31:54,255:INFO:Starting cross validation
2023-02-10 10:31:54,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:33:56,517:INFO:Calculating mean and std
2023-02-10 10:33:56,518:INFO:Creating metrics dataframe
2023-02-10 10:33:56,523:INFO:Uploading results into container
2023-02-10 10:33:56,523:INFO:Uploading model into container now
2023-02-10 10:33:56,523:INFO:create_model_container: 17
2023-02-10 10:33:56,523:INFO:master_model_container: 17
2023-02-10 10:33:56,523:INFO:display_container: 2
2023-02-10 10:33:56,523:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-10 10:33:56,524:INFO:create_model() succesfully completed......................................
2023-02-10 10:33:56,635:INFO:SubProcess create_model() end ==================================
2023-02-10 10:33:56,635:INFO:Creating metrics dataframe
2023-02-10 10:33:56,643:INFO:Initializing Light Gradient Boosting Machine
2023-02-10 10:33:56,643:INFO:Total runtime is 20.659004016717276 minutes
2023-02-10 10:33:56,647:INFO:SubProcess create_model() called ==================================
2023-02-10 10:33:56,647:INFO:Initializing create_model()
2023-02-10 10:33:56,647:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:33:56,647:INFO:Checking exceptions
2023-02-10 10:33:56,647:INFO:Importing libraries
2023-02-10 10:33:56,647:INFO:Copying training dataset
2023-02-10 10:33:56,650:INFO:Defining folds
2023-02-10 10:33:56,650:INFO:Declaring metric variables
2023-02-10 10:33:56,653:INFO:Importing untrained model
2023-02-10 10:33:56,657:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-10 10:33:56,663:INFO:Starting cross validation
2023-02-10 10:33:56,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:34:15,380:INFO:Calculating mean and std
2023-02-10 10:34:15,381:INFO:Creating metrics dataframe
2023-02-10 10:34:15,385:INFO:Uploading results into container
2023-02-10 10:34:15,385:INFO:Uploading model into container now
2023-02-10 10:34:15,385:INFO:create_model_container: 18
2023-02-10 10:34:15,385:INFO:master_model_container: 18
2023-02-10 10:34:15,385:INFO:display_container: 2
2023-02-10 10:34:15,386:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-10 10:34:15,386:INFO:create_model() succesfully completed......................................
2023-02-10 10:34:15,489:INFO:SubProcess create_model() end ==================================
2023-02-10 10:34:15,489:INFO:Creating metrics dataframe
2023-02-10 10:34:15,496:INFO:Initializing CatBoost Regressor
2023-02-10 10:34:15,496:INFO:Total runtime is 20.973219537734987 minutes
2023-02-10 10:34:15,500:INFO:SubProcess create_model() called ==================================
2023-02-10 10:34:15,500:INFO:Initializing create_model()
2023-02-10 10:34:15,500:INFO:create_model(estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:34:15,500:INFO:Checking exceptions
2023-02-10 10:34:15,501:INFO:Importing libraries
2023-02-10 10:34:15,501:INFO:Copying training dataset
2023-02-10 10:34:15,503:INFO:Defining folds
2023-02-10 10:34:15,504:INFO:Declaring metric variables
2023-02-10 10:34:15,507:INFO:Importing untrained model
2023-02-10 10:34:15,510:INFO:CatBoost Regressor Imported succesfully
2023-02-10 10:34:15,517:INFO:Starting cross validation
2023-02-10 10:34:15,517:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:39:24,292:INFO:Calculating mean and std
2023-02-10 10:39:24,293:INFO:Creating metrics dataframe
2023-02-10 10:39:24,296:INFO:Uploading results into container
2023-02-10 10:39:24,296:INFO:Uploading model into container now
2023-02-10 10:39:24,296:INFO:create_model_container: 19
2023-02-10 10:39:24,296:INFO:master_model_container: 19
2023-02-10 10:39:24,296:INFO:display_container: 2
2023-02-10 10:39:24,296:INFO:<catboost.core.CatBoostRegressor object at 0x7f64b8965f70>
2023-02-10 10:39:24,296:INFO:create_model() succesfully completed......................................
2023-02-10 10:39:24,411:INFO:SubProcess create_model() end ==================================
2023-02-10 10:39:24,411:INFO:Creating metrics dataframe
2023-02-10 10:39:24,419:INFO:Initializing Dummy Regressor
2023-02-10 10:39:24,419:INFO:Total runtime is 26.12193820079168 minutes
2023-02-10 10:39:24,423:INFO:SubProcess create_model() called ==================================
2023-02-10 10:39:24,423:INFO:Initializing create_model()
2023-02-10 10:39:24,423:INFO:create_model(estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f650ed4a2e0>, return_train_score=False, kwargs={})
2023-02-10 10:39:24,423:INFO:Checking exceptions
2023-02-10 10:39:24,423:INFO:Importing libraries
2023-02-10 10:39:24,423:INFO:Copying training dataset
2023-02-10 10:39:24,426:INFO:Defining folds
2023-02-10 10:39:24,426:INFO:Declaring metric variables
2023-02-10 10:39:24,429:INFO:Importing untrained model
2023-02-10 10:39:24,433:INFO:Dummy Regressor Imported succesfully
2023-02-10 10:39:24,439:INFO:Starting cross validation
2023-02-10 10:39:24,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:39:24,869:INFO:Calculating mean and std
2023-02-10 10:39:24,870:INFO:Creating metrics dataframe
2023-02-10 10:39:24,875:INFO:Uploading results into container
2023-02-10 10:39:24,875:INFO:Uploading model into container now
2023-02-10 10:39:24,875:INFO:create_model_container: 20
2023-02-10 10:39:24,875:INFO:master_model_container: 20
2023-02-10 10:39:24,875:INFO:display_container: 2
2023-02-10 10:39:24,875:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-02-10 10:39:24,875:INFO:create_model() succesfully completed......................................
2023-02-10 10:39:25,043:INFO:SubProcess create_model() end ==================================
2023-02-10 10:39:25,043:INFO:Creating metrics dataframe
2023-02-10 10:39:25,059:INFO:Initializing create_model()
2023-02-10 10:39:25,059:INFO:create_model(estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 10:39:25,059:INFO:Checking exceptions
2023-02-10 10:39:25,059:INFO:Importing libraries
2023-02-10 10:39:25,060:INFO:Copying training dataset
2023-02-10 10:39:25,063:INFO:Defining folds
2023-02-10 10:39:25,063:INFO:Declaring metric variables
2023-02-10 10:39:25,063:INFO:Importing untrained model
2023-02-10 10:39:25,063:INFO:Declaring custom model
2023-02-10 10:39:25,064:INFO:Extra Trees Regressor Imported succesfully
2023-02-10 10:39:25,064:INFO:Cross validation set to False
2023-02-10 10:39:25,064:INFO:Fitting Model
2023-02-10 10:39:38,942:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-10 10:39:38,942:INFO:create_models() succesfully completed......................................
2023-02-10 10:39:39,088:INFO:create_model_container: 20
2023-02-10 10:39:39,088:INFO:master_model_container: 20
2023-02-10 10:39:39,088:INFO:display_container: 2
2023-02-10 10:39:39,088:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-10 10:39:39,088:INFO:compare_models() succesfully completed......................................
2023-02-10 10:44:14,561:INFO:PyCaret Supervised Module
2023-02-10 10:44:14,561:INFO:ML Usecase: regression
2023-02-10 10:44:14,561:INFO:version 2.3.10
2023-02-10 10:44:14,561:INFO:Initializing setup()
2023-02-10 10:44:14,561:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['exchange', 'timestamp', 'open', 'high', 'low', 'close', 'volume', 'instrument', 'dt', 'volume_24HR', 'volume_24HR$', 'volume_$', 'close_ewm7D', 'open_ewm7D', 'high_ewm7D', 'low_ewm7D', 'volume_ewm7D', 'volume_24HR_ewm7D', 'volume_$_ewm7D', 'volume_24HR$_ewm7D', 'close_ewm21D', 'open_ewm21D', 'high_ewm21D', 'low_ewm21D', 'volume_ewm21D', 'volume_24HR_ewm21D', 'volume_$_ewm21D', 'volume_24HR$_ewm21D'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 10:44:14,561:INFO:Checking environment
2023-02-10 10:44:14,561:INFO:python_version: 3.9.16
2023-02-10 10:44:14,561:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 10:44:14,561:INFO:machine: x86_64
2023-02-10 10:44:14,561:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 10:44:14,561:INFO:Memory: svmem(total=134979592192, available=94085320704, percent=30.3, used=36708728832, free=50332844032, active=5388566528, inactive=75932467200, buffers=1369919488, cached=46568099840, shared=3031785472, slab=2577154048)
2023-02-10 10:44:14,562:INFO:Physical Core: 16
2023-02-10 10:44:14,562:INFO:Logical Core: 32
2023-02-10 10:44:14,562:INFO:Checking libraries
2023-02-10 10:44:14,562:INFO:pd==1.5.2
2023-02-10 10:44:14,562:INFO:numpy==1.20.3
2023-02-10 10:44:14,562:INFO:sklearn==0.23.2
2023-02-10 10:44:14,562:INFO:lightgbm==3.3.5
2023-02-10 10:44:14,562:INFO:catboost==1.1.1
2023-02-10 10:44:14,562:INFO:xgboost==1.7.3
2023-02-10 10:44:14,562:INFO:mlflow==2.1.1
2023-02-10 10:44:14,562:INFO:Checking Exceptions
2023-02-10 10:44:14,563:INFO:Declaring global variables
2023-02-10 10:44:14,563:INFO:USI: 0c2c
2023-02-10 10:44:14,563:INFO:pycaret_globals: {'fold_groups_param_full', 'prep_pipe', 'y', 'fold_generator', 'experiment__', 'display_container', 'pycaret_globals', 'stratify_param', 'X_test', '_available_plots', 'data_before_preprocess', '_internal_pipeline', 'fold_shuffle_param', 'target_param', '_all_metrics', 'y_test', '_all_models_internal', '_gpu_n_jobs_param', 'log_plots_param', '_all_models', 'imputation_classifier', 'html_param', 'fold_groups_param', 'X', 'create_model_container', 'gpu_param', 'n_jobs_param', 'seed', 'transform_target_method_param', 'y_train', 'exp_name_log', 'fix_imbalance_param', 'USI', 'master_model_container', 'dashboard_logger', 'X_train', 'imputation_regressor', 'fold_param', 'fix_imbalance_method_param', 'transform_target_param', '_ml_usecase', 'logging_param', 'iterative_imputation_iters_param'}
2023-02-10 10:44:14,563:INFO:Preparing display monitor
2023-02-10 10:44:14,563:INFO:Preparing display monitor
2023-02-10 10:44:14,568:INFO:Importing libraries
2023-02-10 10:44:14,568:INFO:Copying data for preprocessing
2023-02-10 10:44:14,608:INFO:Declaring preprocessing parameters
2023-02-10 10:44:14,680:INFO:Creating preprocessing pipeline
2023-02-10 10:44:16,385:INFO:Preprocessing pipeline created successfully
2023-02-10 10:44:16,386:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 10:44:16,386:INFO:Creating global containers
2023-02-10 10:44:16,386:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 10:45:11,428:INFO:Creating grid variables
2023-02-10 10:45:11,471:INFO:create_model_container: 0
2023-02-10 10:45:11,471:INFO:master_model_container: 0
2023-02-10 10:45:11,471:INFO:display_container: 1
2023-02-10 10:45:11,474:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['exchange', 'timestamp',
                                                       'open', 'high', 'low',
                                                       'close', 'volume',
                                                       'instrument', 'dt',
                                                       'volume_24HR',
                                                       'volume_24HR$',
                                                       'volume_$',
                                                       'close_ewm7D',
                                                       'open_ewm7D',
                                                       'high_ewm7D',
                                                       'low_ewm7D',
                                                       'volume_ewm7D',
                                                       'volume_24HR_ewm7D',
                                                       'volume_$_ewm7D',
                                                       'volume_...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-10 10:45:11,474:INFO:setup() succesfully completed......................................
2023-02-10 10:45:11,582:INFO:Initializing compare_models()
2023-02-10 10:45:11,582:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-02-10 10:45:11,582:INFO:Checking exceptions
2023-02-10 10:45:11,582:INFO:Preparing display monitor
2023-02-10 10:45:11,582:INFO:Preparing display monitor
2023-02-10 10:45:11,592:INFO:Initializing Linear Regression
2023-02-10 10:45:11,592:INFO:Total runtime is 1.629193623860677e-06 minutes
2023-02-10 10:45:11,595:INFO:SubProcess create_model() called ==================================
2023-02-10 10:45:11,596:INFO:Initializing create_model()
2023-02-10 10:45:11,596:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:45:11,596:INFO:Checking exceptions
2023-02-10 10:45:11,596:INFO:Importing libraries
2023-02-10 10:45:11,596:INFO:Copying training dataset
2023-02-10 10:45:11,599:INFO:Defining folds
2023-02-10 10:45:11,600:INFO:Declaring metric variables
2023-02-10 10:45:11,603:INFO:Importing untrained model
2023-02-10 10:45:11,606:INFO:Linear Regression Imported succesfully
2023-02-10 10:45:11,612:INFO:Starting cross validation
2023-02-10 10:45:11,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:45:14,498:INFO:Calculating mean and std
2023-02-10 10:45:14,499:INFO:Creating metrics dataframe
2023-02-10 10:45:14,503:INFO:Uploading results into container
2023-02-10 10:45:14,503:INFO:Uploading model into container now
2023-02-10 10:45:14,503:INFO:create_model_container: 1
2023-02-10 10:45:14,503:INFO:master_model_container: 1
2023-02-10 10:45:14,503:INFO:display_container: 2
2023-02-10 10:45:14,504:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-10 10:45:14,504:INFO:create_model() succesfully completed......................................
2023-02-10 10:45:14,623:INFO:SubProcess create_model() end ==================================
2023-02-10 10:45:14,624:INFO:Creating metrics dataframe
2023-02-10 10:45:14,631:INFO:Initializing Lasso Regression
2023-02-10 10:45:14,631:INFO:Total runtime is 0.050643670558929446 minutes
2023-02-10 10:45:14,634:INFO:SubProcess create_model() called ==================================
2023-02-10 10:45:14,634:INFO:Initializing create_model()
2023-02-10 10:45:14,634:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:45:14,634:INFO:Checking exceptions
2023-02-10 10:45:14,634:INFO:Importing libraries
2023-02-10 10:45:14,635:INFO:Copying training dataset
2023-02-10 10:45:14,642:INFO:Defining folds
2023-02-10 10:45:14,642:INFO:Declaring metric variables
2023-02-10 10:45:14,646:INFO:Importing untrained model
2023-02-10 10:45:14,649:INFO:Lasso Regression Imported succesfully
2023-02-10 10:45:14,655:INFO:Starting cross validation
2023-02-10 10:45:14,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:45:30,611:INFO:Calculating mean and std
2023-02-10 10:45:30,612:INFO:Creating metrics dataframe
2023-02-10 10:45:30,615:INFO:Uploading results into container
2023-02-10 10:45:30,615:INFO:Uploading model into container now
2023-02-10 10:45:30,615:INFO:create_model_container: 2
2023-02-10 10:45:30,615:INFO:master_model_container: 2
2023-02-10 10:45:30,615:INFO:display_container: 2
2023-02-10 10:45:30,616:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 10:45:30,616:INFO:create_model() succesfully completed......................................
2023-02-10 10:45:30,733:INFO:SubProcess create_model() end ==================================
2023-02-10 10:45:30,733:INFO:Creating metrics dataframe
2023-02-10 10:45:30,739:INFO:Initializing Ridge Regression
2023-02-10 10:45:30,739:INFO:Total runtime is 0.31911399761835735 minutes
2023-02-10 10:45:30,743:INFO:SubProcess create_model() called ==================================
2023-02-10 10:45:30,743:INFO:Initializing create_model()
2023-02-10 10:45:30,744:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:45:30,744:INFO:Checking exceptions
2023-02-10 10:45:30,744:INFO:Importing libraries
2023-02-10 10:45:30,744:INFO:Copying training dataset
2023-02-10 10:45:30,748:INFO:Defining folds
2023-02-10 10:45:30,748:INFO:Declaring metric variables
2023-02-10 10:45:30,754:INFO:Importing untrained model
2023-02-10 10:45:30,759:INFO:Ridge Regression Imported succesfully
2023-02-10 10:45:30,767:INFO:Starting cross validation
2023-02-10 10:45:30,767:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:45:34,166:INFO:Calculating mean and std
2023-02-10 10:45:34,167:INFO:Creating metrics dataframe
2023-02-10 10:45:34,170:INFO:Uploading results into container
2023-02-10 10:45:34,170:INFO:Uploading model into container now
2023-02-10 10:45:34,170:INFO:create_model_container: 3
2023-02-10 10:45:34,170:INFO:master_model_container: 3
2023-02-10 10:45:34,170:INFO:display_container: 2
2023-02-10 10:45:34,170:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-10 10:45:34,170:INFO:create_model() succesfully completed......................................
2023-02-10 10:45:34,276:INFO:SubProcess create_model() end ==================================
2023-02-10 10:45:34,277:INFO:Creating metrics dataframe
2023-02-10 10:45:34,283:INFO:Initializing Elastic Net
2023-02-10 10:45:34,283:INFO:Total runtime is 0.3781764705975851 minutes
2023-02-10 10:45:34,286:INFO:SubProcess create_model() called ==================================
2023-02-10 10:45:34,286:INFO:Initializing create_model()
2023-02-10 10:45:34,286:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:45:34,286:INFO:Checking exceptions
2023-02-10 10:45:34,286:INFO:Importing libraries
2023-02-10 10:45:34,286:INFO:Copying training dataset
2023-02-10 10:45:34,290:INFO:Defining folds
2023-02-10 10:45:34,290:INFO:Declaring metric variables
2023-02-10 10:45:34,293:INFO:Importing untrained model
2023-02-10 10:45:34,296:INFO:Elastic Net Imported succesfully
2023-02-10 10:45:34,301:INFO:Starting cross validation
2023-02-10 10:45:34,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:45:49,976:INFO:Calculating mean and std
2023-02-10 10:45:49,977:INFO:Creating metrics dataframe
2023-02-10 10:45:49,980:INFO:Uploading results into container
2023-02-10 10:45:49,980:INFO:Uploading model into container now
2023-02-10 10:45:49,980:INFO:create_model_container: 4
2023-02-10 10:45:49,980:INFO:master_model_container: 4
2023-02-10 10:45:49,980:INFO:display_container: 2
2023-02-10 10:45:49,980:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 10:45:49,980:INFO:create_model() succesfully completed......................................
2023-02-10 10:45:50,077:INFO:SubProcess create_model() end ==================================
2023-02-10 10:45:50,077:INFO:Creating metrics dataframe
2023-02-10 10:45:50,083:INFO:Initializing Least Angle Regression
2023-02-10 10:45:50,083:INFO:Total runtime is 0.6415190855662029 minutes
2023-02-10 10:45:50,087:INFO:SubProcess create_model() called ==================================
2023-02-10 10:45:50,087:INFO:Initializing create_model()
2023-02-10 10:45:50,087:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:45:50,087:INFO:Checking exceptions
2023-02-10 10:45:50,087:INFO:Importing libraries
2023-02-10 10:45:50,087:INFO:Copying training dataset
2023-02-10 10:45:50,090:INFO:Defining folds
2023-02-10 10:45:50,090:INFO:Declaring metric variables
2023-02-10 10:45:50,093:INFO:Importing untrained model
2023-02-10 10:45:50,096:INFO:Least Angle Regression Imported succesfully
2023-02-10 10:45:50,103:INFO:Starting cross validation
2023-02-10 10:45:50,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:45:50,705:INFO:Calculating mean and std
2023-02-10 10:45:50,706:INFO:Creating metrics dataframe
2023-02-10 10:45:50,709:INFO:Uploading results into container
2023-02-10 10:45:50,709:INFO:Uploading model into container now
2023-02-10 10:45:50,709:INFO:create_model_container: 5
2023-02-10 10:45:50,709:INFO:master_model_container: 5
2023-02-10 10:45:50,709:INFO:display_container: 2
2023-02-10 10:45:50,709:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize=True, precompute='auto',
     random_state=11, verbose=False)
2023-02-10 10:45:50,709:INFO:create_model() succesfully completed......................................
2023-02-10 10:45:50,822:INFO:SubProcess create_model() end ==================================
2023-02-10 10:45:50,822:INFO:Creating metrics dataframe
2023-02-10 10:45:50,828:INFO:Initializing Lasso Least Angle Regression
2023-02-10 10:45:50,828:INFO:Total runtime is 0.6539311329523723 minutes
2023-02-10 10:45:50,831:INFO:SubProcess create_model() called ==================================
2023-02-10 10:45:50,832:INFO:Initializing create_model()
2023-02-10 10:45:50,832:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:45:50,832:INFO:Checking exceptions
2023-02-10 10:45:50,832:INFO:Importing libraries
2023-02-10 10:45:50,832:INFO:Copying training dataset
2023-02-10 10:45:50,835:INFO:Defining folds
2023-02-10 10:45:50,836:INFO:Declaring metric variables
2023-02-10 10:45:50,839:INFO:Importing untrained model
2023-02-10 10:45:50,842:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-10 10:45:50,848:INFO:Starting cross validation
2023-02-10 10:45:50,848:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:45:51,407:INFO:Calculating mean and std
2023-02-10 10:45:51,408:INFO:Creating metrics dataframe
2023-02-10 10:45:51,412:INFO:Uploading results into container
2023-02-10 10:45:51,412:INFO:Uploading model into container now
2023-02-10 10:45:51,413:INFO:create_model_container: 6
2023-02-10 10:45:51,413:INFO:master_model_container: 6
2023-02-10 10:45:51,413:INFO:display_container: 2
2023-02-10 10:45:51,413:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-10 10:45:51,413:INFO:create_model() succesfully completed......................................
2023-02-10 10:45:51,538:INFO:SubProcess create_model() end ==================================
2023-02-10 10:45:51,538:INFO:Creating metrics dataframe
2023-02-10 10:45:51,545:INFO:Initializing Orthogonal Matching Pursuit
2023-02-10 10:45:51,545:INFO:Total runtime is 0.665876034895579 minutes
2023-02-10 10:45:51,548:INFO:SubProcess create_model() called ==================================
2023-02-10 10:45:51,548:INFO:Initializing create_model()
2023-02-10 10:45:51,548:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:45:51,548:INFO:Checking exceptions
2023-02-10 10:45:51,548:INFO:Importing libraries
2023-02-10 10:45:51,548:INFO:Copying training dataset
2023-02-10 10:45:51,552:INFO:Defining folds
2023-02-10 10:45:51,552:INFO:Declaring metric variables
2023-02-10 10:45:51,555:INFO:Importing untrained model
2023-02-10 10:45:51,558:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 10:45:51,565:INFO:Starting cross validation
2023-02-10 10:45:51,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:45:52,137:INFO:Calculating mean and std
2023-02-10 10:45:52,137:INFO:Creating metrics dataframe
2023-02-10 10:45:52,140:INFO:Uploading results into container
2023-02-10 10:45:52,140:INFO:Uploading model into container now
2023-02-10 10:45:52,140:INFO:create_model_container: 7
2023-02-10 10:45:52,140:INFO:master_model_container: 7
2023-02-10 10:45:52,140:INFO:display_container: 2
2023-02-10 10:45:52,141:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 10:45:52,141:INFO:create_model() succesfully completed......................................
2023-02-10 10:45:52,272:INFO:SubProcess create_model() end ==================================
2023-02-10 10:45:52,272:INFO:Creating metrics dataframe
2023-02-10 10:45:52,279:INFO:Initializing Bayesian Ridge
2023-02-10 10:45:52,279:INFO:Total runtime is 0.6781214992205302 minutes
2023-02-10 10:45:52,283:INFO:SubProcess create_model() called ==================================
2023-02-10 10:45:52,283:INFO:Initializing create_model()
2023-02-10 10:45:52,283:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:45:52,283:INFO:Checking exceptions
2023-02-10 10:45:52,283:INFO:Importing libraries
2023-02-10 10:45:52,283:INFO:Copying training dataset
2023-02-10 10:45:52,287:INFO:Defining folds
2023-02-10 10:45:52,287:INFO:Declaring metric variables
2023-02-10 10:45:52,290:INFO:Importing untrained model
2023-02-10 10:45:52,293:INFO:Bayesian Ridge Imported succesfully
2023-02-10 10:45:52,299:INFO:Starting cross validation
2023-02-10 10:45:52,300:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:45:59,124:INFO:Calculating mean and std
2023-02-10 10:45:59,124:INFO:Creating metrics dataframe
2023-02-10 10:45:59,127:INFO:Uploading results into container
2023-02-10 10:45:59,127:INFO:Uploading model into container now
2023-02-10 10:45:59,127:INFO:create_model_container: 8
2023-02-10 10:45:59,127:INFO:master_model_container: 8
2023-02-10 10:45:59,127:INFO:display_container: 2
2023-02-10 10:45:59,128:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-10 10:45:59,128:INFO:create_model() succesfully completed......................................
2023-02-10 10:45:59,249:INFO:SubProcess create_model() end ==================================
2023-02-10 10:45:59,249:INFO:Creating metrics dataframe
2023-02-10 10:45:59,256:INFO:Initializing Passive Aggressive Regressor
2023-02-10 10:45:59,256:INFO:Total runtime is 0.7943944334983826 minutes
2023-02-10 10:45:59,259:INFO:SubProcess create_model() called ==================================
2023-02-10 10:45:59,259:INFO:Initializing create_model()
2023-02-10 10:45:59,259:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:45:59,259:INFO:Checking exceptions
2023-02-10 10:45:59,259:INFO:Importing libraries
2023-02-10 10:45:59,259:INFO:Copying training dataset
2023-02-10 10:45:59,263:INFO:Defining folds
2023-02-10 10:45:59,263:INFO:Declaring metric variables
2023-02-10 10:45:59,266:INFO:Importing untrained model
2023-02-10 10:45:59,269:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-10 10:45:59,276:INFO:Starting cross validation
2023-02-10 10:45:59,276:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:46:00,053:INFO:Calculating mean and std
2023-02-10 10:46:00,054:INFO:Creating metrics dataframe
2023-02-10 10:46:00,057:INFO:Uploading results into container
2023-02-10 10:46:00,057:INFO:Uploading model into container now
2023-02-10 10:46:00,057:INFO:create_model_container: 9
2023-02-10 10:46:00,057:INFO:master_model_container: 9
2023-02-10 10:46:00,057:INFO:display_container: 2
2023-02-10 10:46:00,057:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-10 10:46:00,057:INFO:create_model() succesfully completed......................................
2023-02-10 10:46:00,169:INFO:SubProcess create_model() end ==================================
2023-02-10 10:46:00,170:INFO:Creating metrics dataframe
2023-02-10 10:46:00,177:INFO:Initializing Huber Regressor
2023-02-10 10:46:00,177:INFO:Total runtime is 0.8097476442654927 minutes
2023-02-10 10:46:00,180:INFO:SubProcess create_model() called ==================================
2023-02-10 10:46:00,181:INFO:Initializing create_model()
2023-02-10 10:46:00,181:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:46:00,181:INFO:Checking exceptions
2023-02-10 10:46:00,181:INFO:Importing libraries
2023-02-10 10:46:00,181:INFO:Copying training dataset
2023-02-10 10:46:00,184:INFO:Defining folds
2023-02-10 10:46:00,184:INFO:Declaring metric variables
2023-02-10 10:46:00,187:INFO:Importing untrained model
2023-02-10 10:46:00,190:INFO:Huber Regressor Imported succesfully
2023-02-10 10:46:00,196:INFO:Starting cross validation
2023-02-10 10:46:00,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:46:11,112:INFO:Calculating mean and std
2023-02-10 10:46:11,113:INFO:Creating metrics dataframe
2023-02-10 10:46:11,116:INFO:Uploading results into container
2023-02-10 10:46:11,116:INFO:Uploading model into container now
2023-02-10 10:46:11,116:INFO:create_model_container: 10
2023-02-10 10:46:11,116:INFO:master_model_container: 10
2023-02-10 10:46:11,116:INFO:display_container: 2
2023-02-10 10:46:11,116:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-10 10:46:11,116:INFO:create_model() succesfully completed......................................
2023-02-10 10:46:11,234:INFO:SubProcess create_model() end ==================================
2023-02-10 10:46:11,235:INFO:Creating metrics dataframe
2023-02-10 10:46:11,242:INFO:Initializing K Neighbors Regressor
2023-02-10 10:46:11,242:INFO:Total runtime is 0.994161581993103 minutes
2023-02-10 10:46:11,245:INFO:SubProcess create_model() called ==================================
2023-02-10 10:46:11,245:INFO:Initializing create_model()
2023-02-10 10:46:11,245:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:46:11,245:INFO:Checking exceptions
2023-02-10 10:46:11,245:INFO:Importing libraries
2023-02-10 10:46:11,245:INFO:Copying training dataset
2023-02-10 10:46:11,249:INFO:Defining folds
2023-02-10 10:46:11,249:INFO:Declaring metric variables
2023-02-10 10:46:11,252:INFO:Importing untrained model
2023-02-10 10:46:11,255:INFO:K Neighbors Regressor Imported succesfully
2023-02-10 10:46:11,261:INFO:Starting cross validation
2023-02-10 10:46:11,261:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:46:14,118:INFO:Calculating mean and std
2023-02-10 10:46:14,119:INFO:Creating metrics dataframe
2023-02-10 10:46:14,122:INFO:Uploading results into container
2023-02-10 10:46:14,123:INFO:Uploading model into container now
2023-02-10 10:46:14,123:INFO:create_model_container: 11
2023-02-10 10:46:14,123:INFO:master_model_container: 11
2023-02-10 10:46:14,123:INFO:display_container: 2
2023-02-10 10:46:14,123:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-10 10:46:14,123:INFO:create_model() succesfully completed......................................
2023-02-10 10:46:14,240:INFO:SubProcess create_model() end ==================================
2023-02-10 10:46:14,240:INFO:Creating metrics dataframe
2023-02-10 10:46:14,247:INFO:Initializing Decision Tree Regressor
2023-02-10 10:46:14,247:INFO:Total runtime is 1.0442512512207032 minutes
2023-02-10 10:46:14,251:INFO:SubProcess create_model() called ==================================
2023-02-10 10:46:14,251:INFO:Initializing create_model()
2023-02-10 10:46:14,251:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:46:14,251:INFO:Checking exceptions
2023-02-10 10:46:14,251:INFO:Importing libraries
2023-02-10 10:46:14,251:INFO:Copying training dataset
2023-02-10 10:46:14,254:INFO:Defining folds
2023-02-10 10:46:14,254:INFO:Declaring metric variables
2023-02-10 10:46:14,257:INFO:Importing untrained model
2023-02-10 10:46:14,260:INFO:Decision Tree Regressor Imported succesfully
2023-02-10 10:46:14,267:INFO:Starting cross validation
2023-02-10 10:46:14,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:46:33,709:INFO:Calculating mean and std
2023-02-10 10:46:33,710:INFO:Creating metrics dataframe
2023-02-10 10:46:33,713:INFO:Uploading results into container
2023-02-10 10:46:33,714:INFO:Uploading model into container now
2023-02-10 10:46:33,714:INFO:create_model_container: 12
2023-02-10 10:46:33,714:INFO:master_model_container: 12
2023-02-10 10:46:33,714:INFO:display_container: 2
2023-02-10 10:46:33,714:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-10 10:46:33,714:INFO:create_model() succesfully completed......................................
2023-02-10 10:46:33,813:INFO:SubProcess create_model() end ==================================
2023-02-10 10:46:33,813:INFO:Creating metrics dataframe
2023-02-10 10:46:33,821:INFO:Initializing Random Forest Regressor
2023-02-10 10:46:33,821:INFO:Total runtime is 1.3704830328623454 minutes
2023-02-10 10:46:33,825:INFO:SubProcess create_model() called ==================================
2023-02-10 10:46:33,825:INFO:Initializing create_model()
2023-02-10 10:46:33,825:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:46:33,825:INFO:Checking exceptions
2023-02-10 10:46:33,825:INFO:Importing libraries
2023-02-10 10:46:33,825:INFO:Copying training dataset
2023-02-10 10:46:33,829:INFO:Defining folds
2023-02-10 10:46:33,829:INFO:Declaring metric variables
2023-02-10 10:46:33,832:INFO:Importing untrained model
2023-02-10 10:46:33,835:INFO:Random Forest Regressor Imported succesfully
2023-02-10 10:46:33,841:INFO:Starting cross validation
2023-02-10 10:46:33,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:55:35,051:INFO:Calculating mean and std
2023-02-10 10:55:35,052:INFO:Creating metrics dataframe
2023-02-10 10:55:35,057:INFO:Uploading results into container
2023-02-10 10:55:35,057:INFO:Uploading model into container now
2023-02-10 10:55:35,057:INFO:create_model_container: 13
2023-02-10 10:55:35,057:INFO:master_model_container: 13
2023-02-10 10:55:35,057:INFO:display_container: 2
2023-02-10 10:55:35,057:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-10 10:55:35,057:INFO:create_model() succesfully completed......................................
2023-02-10 10:55:35,161:INFO:SubProcess create_model() end ==================================
2023-02-10 10:55:35,161:INFO:Creating metrics dataframe
2023-02-10 10:55:35,168:INFO:Initializing Extra Trees Regressor
2023-02-10 10:55:35,168:INFO:Total runtime is 10.392931207021078 minutes
2023-02-10 10:55:35,171:INFO:SubProcess create_model() called ==================================
2023-02-10 10:55:35,171:INFO:Initializing create_model()
2023-02-10 10:55:35,172:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:55:35,172:INFO:Checking exceptions
2023-02-10 10:55:35,172:INFO:Importing libraries
2023-02-10 10:55:35,172:INFO:Copying training dataset
2023-02-10 10:55:35,175:INFO:Defining folds
2023-02-10 10:55:35,175:INFO:Declaring metric variables
2023-02-10 10:55:35,178:INFO:Importing untrained model
2023-02-10 10:55:35,181:INFO:Extra Trees Regressor Imported succesfully
2023-02-10 10:55:35,187:INFO:Starting cross validation
2023-02-10 10:55:35,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 10:59:47,767:INFO:Calculating mean and std
2023-02-10 10:59:47,768:INFO:Creating metrics dataframe
2023-02-10 10:59:47,771:INFO:Uploading results into container
2023-02-10 10:59:47,771:INFO:Uploading model into container now
2023-02-10 10:59:47,771:INFO:create_model_container: 14
2023-02-10 10:59:47,771:INFO:master_model_container: 14
2023-02-10 10:59:47,771:INFO:display_container: 2
2023-02-10 10:59:47,772:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-10 10:59:47,772:INFO:create_model() succesfully completed......................................
2023-02-10 10:59:47,888:INFO:SubProcess create_model() end ==================================
2023-02-10 10:59:47,888:INFO:Creating metrics dataframe
2023-02-10 10:59:47,897:INFO:Initializing AdaBoost Regressor
2023-02-10 10:59:47,897:INFO:Total runtime is 14.605076678593955 minutes
2023-02-10 10:59:47,900:INFO:SubProcess create_model() called ==================================
2023-02-10 10:59:47,900:INFO:Initializing create_model()
2023-02-10 10:59:47,900:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 10:59:47,900:INFO:Checking exceptions
2023-02-10 10:59:47,900:INFO:Importing libraries
2023-02-10 10:59:47,900:INFO:Copying training dataset
2023-02-10 10:59:47,904:INFO:Defining folds
2023-02-10 10:59:47,904:INFO:Declaring metric variables
2023-02-10 10:59:47,907:INFO:Importing untrained model
2023-02-10 10:59:47,910:INFO:AdaBoost Regressor Imported succesfully
2023-02-10 10:59:47,916:INFO:Starting cross validation
2023-02-10 10:59:47,917:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:01:04,695:INFO:Calculating mean and std
2023-02-10 11:01:04,696:INFO:Creating metrics dataframe
2023-02-10 11:01:04,702:INFO:Uploading results into container
2023-02-10 11:01:04,702:INFO:Uploading model into container now
2023-02-10 11:01:04,702:INFO:create_model_container: 15
2023-02-10 11:01:04,702:INFO:master_model_container: 15
2023-02-10 11:01:04,702:INFO:display_container: 2
2023-02-10 11:01:04,702:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-10 11:01:04,702:INFO:create_model() succesfully completed......................................
2023-02-10 11:01:04,809:INFO:SubProcess create_model() end ==================================
2023-02-10 11:01:04,809:INFO:Creating metrics dataframe
2023-02-10 11:01:04,817:INFO:Initializing Gradient Boosting Regressor
2023-02-10 11:01:04,817:INFO:Total runtime is 15.887079974015554 minutes
2023-02-10 11:01:04,821:INFO:SubProcess create_model() called ==================================
2023-02-10 11:01:04,821:INFO:Initializing create_model()
2023-02-10 11:01:04,821:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 11:01:04,821:INFO:Checking exceptions
2023-02-10 11:01:04,821:INFO:Importing libraries
2023-02-10 11:01:04,821:INFO:Copying training dataset
2023-02-10 11:01:04,824:INFO:Defining folds
2023-02-10 11:01:04,824:INFO:Declaring metric variables
2023-02-10 11:01:04,828:INFO:Importing untrained model
2023-02-10 11:01:04,831:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-10 11:01:04,837:INFO:Starting cross validation
2023-02-10 11:01:04,837:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:05:58,852:INFO:Calculating mean and std
2023-02-10 11:05:58,854:INFO:Creating metrics dataframe
2023-02-10 11:05:58,859:INFO:Uploading results into container
2023-02-10 11:05:58,859:INFO:Uploading model into container now
2023-02-10 11:05:58,859:INFO:create_model_container: 16
2023-02-10 11:05:58,859:INFO:master_model_container: 16
2023-02-10 11:05:58,859:INFO:display_container: 2
2023-02-10 11:05:58,860:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-10 11:05:58,860:INFO:create_model() succesfully completed......................................
2023-02-10 11:05:58,962:INFO:SubProcess create_model() end ==================================
2023-02-10 11:05:58,962:INFO:Creating metrics dataframe
2023-02-10 11:05:58,970:INFO:Initializing Extreme Gradient Boosting
2023-02-10 11:05:58,970:INFO:Total runtime is 20.789630154768627 minutes
2023-02-10 11:05:58,973:INFO:SubProcess create_model() called ==================================
2023-02-10 11:05:58,973:INFO:Initializing create_model()
2023-02-10 11:05:58,974:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 11:05:58,974:INFO:Checking exceptions
2023-02-10 11:05:58,974:INFO:Importing libraries
2023-02-10 11:05:58,974:INFO:Copying training dataset
2023-02-10 11:05:58,977:INFO:Defining folds
2023-02-10 11:05:58,977:INFO:Declaring metric variables
2023-02-10 11:05:58,980:INFO:Importing untrained model
2023-02-10 11:05:58,983:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-10 11:05:58,989:INFO:Starting cross validation
2023-02-10 11:05:58,990:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:08:13,632:INFO:Calculating mean and std
2023-02-10 11:08:13,633:INFO:Creating metrics dataframe
2023-02-10 11:08:13,638:INFO:Uploading results into container
2023-02-10 11:08:13,638:INFO:Uploading model into container now
2023-02-10 11:08:13,638:INFO:create_model_container: 17
2023-02-10 11:08:13,638:INFO:master_model_container: 17
2023-02-10 11:08:13,638:INFO:display_container: 2
2023-02-10 11:08:13,639:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-10 11:08:13,639:INFO:create_model() succesfully completed......................................
2023-02-10 11:08:13,738:INFO:SubProcess create_model() end ==================================
2023-02-10 11:08:13,738:INFO:Creating metrics dataframe
2023-02-10 11:08:13,746:INFO:Initializing Light Gradient Boosting Machine
2023-02-10 11:08:13,746:INFO:Total runtime is 23.035892693201703 minutes
2023-02-10 11:08:13,749:INFO:SubProcess create_model() called ==================================
2023-02-10 11:08:13,749:INFO:Initializing create_model()
2023-02-10 11:08:13,749:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 11:08:13,749:INFO:Checking exceptions
2023-02-10 11:08:13,749:INFO:Importing libraries
2023-02-10 11:08:13,749:INFO:Copying training dataset
2023-02-10 11:08:13,753:INFO:Defining folds
2023-02-10 11:08:13,753:INFO:Declaring metric variables
2023-02-10 11:08:13,756:INFO:Importing untrained model
2023-02-10 11:08:13,759:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-10 11:08:13,765:INFO:Starting cross validation
2023-02-10 11:08:13,765:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:08:35,181:INFO:Calculating mean and std
2023-02-10 11:08:35,182:INFO:Creating metrics dataframe
2023-02-10 11:08:35,187:INFO:Uploading results into container
2023-02-10 11:08:35,187:INFO:Uploading model into container now
2023-02-10 11:08:35,187:INFO:create_model_container: 18
2023-02-10 11:08:35,187:INFO:master_model_container: 18
2023-02-10 11:08:35,187:INFO:display_container: 2
2023-02-10 11:08:35,187:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-10 11:08:35,187:INFO:create_model() succesfully completed......................................
2023-02-10 11:08:35,299:INFO:SubProcess create_model() end ==================================
2023-02-10 11:08:35,299:INFO:Creating metrics dataframe
2023-02-10 11:08:35,307:INFO:Initializing CatBoost Regressor
2023-02-10 11:08:35,307:INFO:Total runtime is 23.395245651404064 minutes
2023-02-10 11:08:35,310:INFO:SubProcess create_model() called ==================================
2023-02-10 11:08:35,310:INFO:Initializing create_model()
2023-02-10 11:08:35,310:INFO:create_model(estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 11:08:35,310:INFO:Checking exceptions
2023-02-10 11:08:35,310:INFO:Importing libraries
2023-02-10 11:08:35,310:INFO:Copying training dataset
2023-02-10 11:08:35,314:INFO:Defining folds
2023-02-10 11:08:35,314:INFO:Declaring metric variables
2023-02-10 11:08:35,317:INFO:Importing untrained model
2023-02-10 11:08:35,320:INFO:CatBoost Regressor Imported succesfully
2023-02-10 11:08:35,326:INFO:Starting cross validation
2023-02-10 11:08:35,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:14:13,254:INFO:Calculating mean and std
2023-02-10 11:14:13,254:INFO:Creating metrics dataframe
2023-02-10 11:14:13,258:INFO:Uploading results into container
2023-02-10 11:14:13,258:INFO:Uploading model into container now
2023-02-10 11:14:13,258:INFO:create_model_container: 19
2023-02-10 11:14:13,258:INFO:master_model_container: 19
2023-02-10 11:14:13,258:INFO:display_container: 2
2023-02-10 11:14:13,259:INFO:<catboost.core.CatBoostRegressor object at 0x7f64b8952190>
2023-02-10 11:14:13,259:INFO:create_model() succesfully completed......................................
2023-02-10 11:14:13,360:INFO:SubProcess create_model() end ==================================
2023-02-10 11:14:13,361:INFO:Creating metrics dataframe
2023-02-10 11:14:13,368:INFO:Initializing Dummy Regressor
2023-02-10 11:14:13,368:INFO:Total runtime is 29.029603481292725 minutes
2023-02-10 11:14:13,372:INFO:SubProcess create_model() called ==================================
2023-02-10 11:14:13,372:INFO:Initializing create_model()
2023-02-10 11:14:13,372:INFO:create_model(estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f64b89a50d0>, return_train_score=False, kwargs={})
2023-02-10 11:14:13,372:INFO:Checking exceptions
2023-02-10 11:14:13,372:INFO:Importing libraries
2023-02-10 11:14:13,372:INFO:Copying training dataset
2023-02-10 11:14:13,375:INFO:Defining folds
2023-02-10 11:14:13,375:INFO:Declaring metric variables
2023-02-10 11:14:13,378:INFO:Importing untrained model
2023-02-10 11:14:13,381:INFO:Dummy Regressor Imported succesfully
2023-02-10 11:14:13,387:INFO:Starting cross validation
2023-02-10 11:14:13,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:14:13,981:INFO:Calculating mean and std
2023-02-10 11:14:13,983:INFO:Creating metrics dataframe
2023-02-10 11:14:13,987:INFO:Uploading results into container
2023-02-10 11:14:13,987:INFO:Uploading model into container now
2023-02-10 11:14:13,987:INFO:create_model_container: 20
2023-02-10 11:14:13,987:INFO:master_model_container: 20
2023-02-10 11:14:13,987:INFO:display_container: 2
2023-02-10 11:14:13,987:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-02-10 11:14:13,987:INFO:create_model() succesfully completed......................................
2023-02-10 11:14:14,108:INFO:SubProcess create_model() end ==================================
2023-02-10 11:14:14,108:INFO:Creating metrics dataframe
2023-02-10 11:14:14,123:INFO:Initializing create_model()
2023-02-10 11:14:14,123:INFO:create_model(estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 11:14:14,123:INFO:Checking exceptions
2023-02-10 11:14:14,123:INFO:Importing libraries
2023-02-10 11:14:14,123:INFO:Copying training dataset
2023-02-10 11:14:14,127:INFO:Defining folds
2023-02-10 11:14:14,127:INFO:Declaring metric variables
2023-02-10 11:14:14,127:INFO:Importing untrained model
2023-02-10 11:14:14,127:INFO:Declaring custom model
2023-02-10 11:14:14,127:INFO:Extra Trees Regressor Imported succesfully
2023-02-10 11:14:14,127:INFO:Cross validation set to False
2023-02-10 11:14:14,127:INFO:Fitting Model
2023-02-10 11:14:30,813:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-10 11:14:30,813:INFO:create_models() succesfully completed......................................
2023-02-10 11:14:30,935:INFO:create_model_container: 20
2023-02-10 11:14:30,936:INFO:master_model_container: 20
2023-02-10 11:14:30,936:INFO:display_container: 2
2023-02-10 11:14:30,936:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-10 11:14:30,936:INFO:compare_models() succesfully completed......................................
2023-02-10 11:16:14,286:INFO:PyCaret Supervised Module
2023-02-10 11:16:14,286:INFO:ML Usecase: regression
2023-02-10 11:16:14,286:INFO:version 2.3.10
2023-02-10 11:16:14,286:INFO:Initializing setup()
2023-02-10 11:16:14,286:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 11:16:14,286:INFO:Checking environment
2023-02-10 11:16:14,286:INFO:python_version: 3.9.16
2023-02-10 11:16:14,286:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 11:16:14,286:INFO:machine: x86_64
2023-02-10 11:16:14,286:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 11:16:14,286:INFO:Memory: svmem(total=134979592192, available=93452099584, percent=30.8, used=37332615168, free=49646821376, active=5399846912, inactive=76563431424, buffers=1377665024, cached=46622490624, shared=3056533504, slab=2586906624)
2023-02-10 11:16:14,287:INFO:Physical Core: 16
2023-02-10 11:16:14,287:INFO:Logical Core: 32
2023-02-10 11:16:14,287:INFO:Checking libraries
2023-02-10 11:16:14,287:INFO:pd==1.5.2
2023-02-10 11:16:14,287:INFO:numpy==1.20.3
2023-02-10 11:16:14,287:INFO:sklearn==0.23.2
2023-02-10 11:16:14,287:INFO:lightgbm==3.3.5
2023-02-10 11:16:14,287:INFO:catboost==1.1.1
2023-02-10 11:16:14,287:INFO:xgboost==1.7.3
2023-02-10 11:16:14,287:INFO:mlflow==2.1.1
2023-02-10 11:16:14,287:INFO:Checking Exceptions
2023-02-10 11:16:14,287:INFO:Declaring global variables
2023-02-10 11:16:14,287:INFO:USI: c16c
2023-02-10 11:16:14,287:INFO:pycaret_globals: {'fold_groups_param_full', 'prep_pipe', 'y', 'fold_generator', 'experiment__', 'display_container', 'pycaret_globals', 'stratify_param', 'X_test', '_available_plots', 'data_before_preprocess', '_internal_pipeline', 'fold_shuffle_param', 'target_param', '_all_metrics', 'y_test', '_all_models_internal', '_gpu_n_jobs_param', 'log_plots_param', '_all_models', 'imputation_classifier', 'html_param', 'fold_groups_param', 'X', 'create_model_container', 'gpu_param', 'n_jobs_param', 'seed', 'transform_target_method_param', 'y_train', 'exp_name_log', 'fix_imbalance_param', 'USI', 'master_model_container', 'dashboard_logger', 'X_train', 'imputation_regressor', 'fold_param', 'fix_imbalance_method_param', 'transform_target_param', '_ml_usecase', 'logging_param', 'iterative_imputation_iters_param'}
2023-02-10 11:16:14,287:INFO:Preparing display monitor
2023-02-10 11:16:14,287:INFO:Preparing display monitor
2023-02-10 11:16:14,293:INFO:Importing libraries
2023-02-10 11:16:14,293:INFO:Copying data for preprocessing
2023-02-10 11:16:14,335:INFO:Declaring preprocessing parameters
2023-02-10 11:16:14,407:INFO:Creating preprocessing pipeline
2023-02-10 11:16:16,088:INFO:Preprocessing pipeline created successfully
2023-02-10 11:16:16,088:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 11:16:16,088:INFO:Creating global containers
2023-02-10 11:16:16,088:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 11:17:11,736:INFO:Creating grid variables
2023-02-10 11:17:11,776:INFO:create_model_container: 0
2023-02-10 11:17:11,776:INFO:master_model_container: 0
2023-02-10 11:17:11,776:INFO:display_container: 1
2023-02-10 11:17:11,778:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_available',
                                fill_value_cate...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-10 11:17:11,778:INFO:setup() succesfully completed......................................
2023-02-10 11:17:56,445:INFO:PyCaret Supervised Module
2023-02-10 11:17:56,445:INFO:ML Usecase: regression
2023-02-10 11:17:56,445:INFO:version 2.3.10
2023-02-10 11:17:56,445:INFO:Initializing setup()
2023-02-10 11:17:56,445:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 11:17:56,445:INFO:Checking environment
2023-02-10 11:17:56,445:INFO:python_version: 3.9.16
2023-02-10 11:17:56,445:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 11:17:56,445:INFO:machine: x86_64
2023-02-10 11:17:56,445:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 11:17:56,445:INFO:Memory: svmem(total=134979592192, available=93307830272, percent=30.9, used=37482266624, free=49500106752, active=5400887296, inactive=76698021888, buffers=1378000896, cached=46619217920, shared=3051155456, slab=2586443776)
2023-02-10 11:17:56,446:INFO:Physical Core: 16
2023-02-10 11:17:56,446:INFO:Logical Core: 32
2023-02-10 11:17:56,446:INFO:Checking libraries
2023-02-10 11:17:56,446:INFO:pd==1.5.2
2023-02-10 11:17:56,446:INFO:numpy==1.20.3
2023-02-10 11:17:56,446:INFO:sklearn==0.23.2
2023-02-10 11:17:56,446:INFO:lightgbm==3.3.5
2023-02-10 11:17:56,446:INFO:catboost==1.1.1
2023-02-10 11:17:56,446:INFO:xgboost==1.7.3
2023-02-10 11:17:56,446:INFO:mlflow==2.1.1
2023-02-10 11:17:56,446:INFO:Checking Exceptions
2023-02-10 11:17:56,446:INFO:Declaring global variables
2023-02-10 11:17:56,446:INFO:USI: 2d31
2023-02-10 11:17:56,446:INFO:pycaret_globals: {'fold_groups_param_full', 'prep_pipe', 'y', 'fold_generator', 'experiment__', 'display_container', 'pycaret_globals', 'stratify_param', 'X_test', '_available_plots', 'data_before_preprocess', '_internal_pipeline', 'fold_shuffle_param', 'target_param', '_all_metrics', 'y_test', '_all_models_internal', '_gpu_n_jobs_param', 'log_plots_param', '_all_models', 'imputation_classifier', 'html_param', 'fold_groups_param', 'X', 'create_model_container', 'gpu_param', 'n_jobs_param', 'seed', 'transform_target_method_param', 'y_train', 'exp_name_log', 'fix_imbalance_param', 'USI', 'master_model_container', 'dashboard_logger', 'X_train', 'imputation_regressor', 'fold_param', 'fix_imbalance_method_param', 'transform_target_param', '_ml_usecase', 'logging_param', 'iterative_imputation_iters_param'}
2023-02-10 11:17:56,446:INFO:Preparing display monitor
2023-02-10 11:17:56,446:INFO:Preparing display monitor
2023-02-10 11:17:56,451:INFO:Importing libraries
2023-02-10 11:17:56,451:INFO:Copying data for preprocessing
2023-02-10 11:17:56,491:INFO:Declaring preprocessing parameters
2023-02-10 11:17:56,561:INFO:Creating preprocessing pipeline
2023-02-10 11:17:58,264:INFO:Preprocessing pipeline created successfully
2023-02-10 11:17:58,264:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 11:17:58,265:INFO:Creating global containers
2023-02-10 11:17:58,265:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 11:18:54,461:INFO:Creating grid variables
2023-02-10 11:18:54,507:INFO:create_model_container: 0
2023-02-10 11:18:54,507:INFO:master_model_container: 0
2023-02-10 11:18:54,507:INFO:display_container: 1
2023-02-10 11:18:54,509:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_available',
                                fill_value_cate...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-10 11:18:54,509:INFO:setup() succesfully completed......................................
2023-02-10 11:18:54,623:INFO:Initializing compare_models()
2023-02-10 11:18:54,623:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-02-10 11:18:54,623:INFO:Checking exceptions
2023-02-10 11:18:54,623:INFO:Preparing display monitor
2023-02-10 11:18:54,623:INFO:Preparing display monitor
2023-02-10 11:18:54,635:INFO:Initializing Linear Regression
2023-02-10 11:18:54,635:INFO:Total runtime is 1.6848246256510416e-06 minutes
2023-02-10 11:18:54,638:INFO:SubProcess create_model() called ==================================
2023-02-10 11:18:54,639:INFO:Initializing create_model()
2023-02-10 11:18:54,639:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:18:54,639:INFO:Checking exceptions
2023-02-10 11:18:54,639:INFO:Importing libraries
2023-02-10 11:18:54,639:INFO:Copying training dataset
2023-02-10 11:18:54,647:INFO:Defining folds
2023-02-10 11:18:54,647:INFO:Declaring metric variables
2023-02-10 11:18:54,652:INFO:Importing untrained model
2023-02-10 11:18:54,655:INFO:Linear Regression Imported succesfully
2023-02-10 11:18:54,661:INFO:Starting cross validation
2023-02-10 11:18:54,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:18:56,639:INFO:Calculating mean and std
2023-02-10 11:18:56,640:INFO:Creating metrics dataframe
2023-02-10 11:18:56,644:INFO:Uploading results into container
2023-02-10 11:18:56,644:INFO:Uploading model into container now
2023-02-10 11:18:56,644:INFO:create_model_container: 1
2023-02-10 11:18:56,644:INFO:master_model_container: 1
2023-02-10 11:18:56,644:INFO:display_container: 2
2023-02-10 11:18:56,644:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-10 11:18:56,644:INFO:create_model() succesfully completed......................................
2023-02-10 11:18:56,743:INFO:SubProcess create_model() end ==================================
2023-02-10 11:18:56,743:INFO:Creating metrics dataframe
2023-02-10 11:18:56,748:INFO:Initializing Lasso Regression
2023-02-10 11:18:56,748:INFO:Total runtime is 0.03521782159805298 minutes
2023-02-10 11:18:56,752:INFO:SubProcess create_model() called ==================================
2023-02-10 11:18:56,752:INFO:Initializing create_model()
2023-02-10 11:18:56,752:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:18:56,752:INFO:Checking exceptions
2023-02-10 11:18:56,752:INFO:Importing libraries
2023-02-10 11:18:56,752:INFO:Copying training dataset
2023-02-10 11:18:56,759:INFO:Defining folds
2023-02-10 11:18:56,760:INFO:Declaring metric variables
2023-02-10 11:18:56,763:INFO:Importing untrained model
2023-02-10 11:18:56,766:INFO:Lasso Regression Imported succesfully
2023-02-10 11:18:56,772:INFO:Starting cross validation
2023-02-10 11:18:56,773:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:19:22,637:INFO:Calculating mean and std
2023-02-10 11:19:22,638:INFO:Creating metrics dataframe
2023-02-10 11:19:22,641:INFO:Uploading results into container
2023-02-10 11:19:22,641:INFO:Uploading model into container now
2023-02-10 11:19:22,641:INFO:create_model_container: 2
2023-02-10 11:19:22,641:INFO:master_model_container: 2
2023-02-10 11:19:22,641:INFO:display_container: 2
2023-02-10 11:19:22,642:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 11:19:22,642:INFO:create_model() succesfully completed......................................
2023-02-10 11:19:22,751:INFO:SubProcess create_model() end ==================================
2023-02-10 11:19:22,751:INFO:Creating metrics dataframe
2023-02-10 11:19:22,757:INFO:Initializing Ridge Regression
2023-02-10 11:19:22,757:INFO:Total runtime is 0.4687004804611206 minutes
2023-02-10 11:19:22,760:INFO:SubProcess create_model() called ==================================
2023-02-10 11:19:22,761:INFO:Initializing create_model()
2023-02-10 11:19:22,761:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:19:22,761:INFO:Checking exceptions
2023-02-10 11:19:22,761:INFO:Importing libraries
2023-02-10 11:19:22,761:INFO:Copying training dataset
2023-02-10 11:19:22,767:INFO:Defining folds
2023-02-10 11:19:22,767:INFO:Declaring metric variables
2023-02-10 11:19:22,770:INFO:Importing untrained model
2023-02-10 11:19:22,773:INFO:Ridge Regression Imported succesfully
2023-02-10 11:19:22,779:INFO:Starting cross validation
2023-02-10 11:19:22,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:19:25,584:INFO:Calculating mean and std
2023-02-10 11:19:25,585:INFO:Creating metrics dataframe
2023-02-10 11:19:25,589:INFO:Uploading results into container
2023-02-10 11:19:25,589:INFO:Uploading model into container now
2023-02-10 11:19:25,590:INFO:create_model_container: 3
2023-02-10 11:19:25,590:INFO:master_model_container: 3
2023-02-10 11:19:25,590:INFO:display_container: 2
2023-02-10 11:19:25,590:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-10 11:19:25,590:INFO:create_model() succesfully completed......................................
2023-02-10 11:19:25,699:INFO:SubProcess create_model() end ==================================
2023-02-10 11:19:25,699:INFO:Creating metrics dataframe
2023-02-10 11:19:25,705:INFO:Initializing Elastic Net
2023-02-10 11:19:25,705:INFO:Total runtime is 0.5178377628326416 minutes
2023-02-10 11:19:25,709:INFO:SubProcess create_model() called ==================================
2023-02-10 11:19:25,709:INFO:Initializing create_model()
2023-02-10 11:19:25,709:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:19:25,709:INFO:Checking exceptions
2023-02-10 11:19:25,709:INFO:Importing libraries
2023-02-10 11:19:25,709:INFO:Copying training dataset
2023-02-10 11:19:25,717:INFO:Defining folds
2023-02-10 11:19:25,717:INFO:Declaring metric variables
2023-02-10 11:19:25,720:INFO:Importing untrained model
2023-02-10 11:19:25,723:INFO:Elastic Net Imported succesfully
2023-02-10 11:19:25,729:INFO:Starting cross validation
2023-02-10 11:19:25,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:19:40,693:INFO:Calculating mean and std
2023-02-10 11:19:40,694:INFO:Creating metrics dataframe
2023-02-10 11:19:40,697:INFO:Uploading results into container
2023-02-10 11:19:40,697:INFO:Uploading model into container now
2023-02-10 11:19:40,697:INFO:create_model_container: 4
2023-02-10 11:19:40,697:INFO:master_model_container: 4
2023-02-10 11:19:40,697:INFO:display_container: 2
2023-02-10 11:19:40,698:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 11:19:40,698:INFO:create_model() succesfully completed......................................
2023-02-10 11:19:40,803:INFO:SubProcess create_model() end ==================================
2023-02-10 11:19:40,803:INFO:Creating metrics dataframe
2023-02-10 11:19:40,809:INFO:Initializing Least Angle Regression
2023-02-10 11:19:40,809:INFO:Total runtime is 0.7695713400840759 minutes
2023-02-10 11:19:40,813:INFO:SubProcess create_model() called ==================================
2023-02-10 11:19:40,813:INFO:Initializing create_model()
2023-02-10 11:19:40,813:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:19:40,813:INFO:Checking exceptions
2023-02-10 11:19:40,813:INFO:Importing libraries
2023-02-10 11:19:40,813:INFO:Copying training dataset
2023-02-10 11:19:40,820:INFO:Defining folds
2023-02-10 11:19:40,820:INFO:Declaring metric variables
2023-02-10 11:19:40,823:INFO:Importing untrained model
2023-02-10 11:19:40,826:INFO:Least Angle Regression Imported succesfully
2023-02-10 11:19:40,832:INFO:Starting cross validation
2023-02-10 11:19:40,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:19:42,296:INFO:Calculating mean and std
2023-02-10 11:19:42,297:INFO:Creating metrics dataframe
2023-02-10 11:19:42,300:INFO:Uploading results into container
2023-02-10 11:19:42,301:INFO:Uploading model into container now
2023-02-10 11:19:42,301:INFO:create_model_container: 5
2023-02-10 11:19:42,301:INFO:master_model_container: 5
2023-02-10 11:19:42,301:INFO:display_container: 2
2023-02-10 11:19:42,301:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize=True, precompute='auto',
     random_state=11, verbose=False)
2023-02-10 11:19:42,301:INFO:create_model() succesfully completed......................................
2023-02-10 11:19:42,410:INFO:SubProcess create_model() end ==================================
2023-02-10 11:19:42,410:INFO:Creating metrics dataframe
2023-02-10 11:19:42,416:INFO:Initializing Lasso Least Angle Regression
2023-02-10 11:19:42,417:INFO:Total runtime is 0.7963570475578308 minutes
2023-02-10 11:19:42,420:INFO:SubProcess create_model() called ==================================
2023-02-10 11:19:42,420:INFO:Initializing create_model()
2023-02-10 11:19:42,420:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:19:42,420:INFO:Checking exceptions
2023-02-10 11:19:42,420:INFO:Importing libraries
2023-02-10 11:19:42,420:INFO:Copying training dataset
2023-02-10 11:19:42,427:INFO:Defining folds
2023-02-10 11:19:42,427:INFO:Declaring metric variables
2023-02-10 11:19:42,430:INFO:Importing untrained model
2023-02-10 11:19:42,433:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-10 11:19:42,439:INFO:Starting cross validation
2023-02-10 11:19:42,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:19:43,551:INFO:Calculating mean and std
2023-02-10 11:19:43,552:INFO:Creating metrics dataframe
2023-02-10 11:19:43,555:INFO:Uploading results into container
2023-02-10 11:19:43,555:INFO:Uploading model into container now
2023-02-10 11:19:43,555:INFO:create_model_container: 6
2023-02-10 11:19:43,555:INFO:master_model_container: 6
2023-02-10 11:19:43,555:INFO:display_container: 2
2023-02-10 11:19:43,555:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-10 11:19:43,555:INFO:create_model() succesfully completed......................................
2023-02-10 11:19:43,668:INFO:SubProcess create_model() end ==================================
2023-02-10 11:19:43,668:INFO:Creating metrics dataframe
2023-02-10 11:19:43,675:INFO:Initializing Orthogonal Matching Pursuit
2023-02-10 11:19:43,675:INFO:Total runtime is 0.8173281073570251 minutes
2023-02-10 11:19:43,678:INFO:SubProcess create_model() called ==================================
2023-02-10 11:19:43,678:INFO:Initializing create_model()
2023-02-10 11:19:43,678:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:19:43,678:INFO:Checking exceptions
2023-02-10 11:19:43,679:INFO:Importing libraries
2023-02-10 11:19:43,679:INFO:Copying training dataset
2023-02-10 11:19:43,686:INFO:Defining folds
2023-02-10 11:19:43,686:INFO:Declaring metric variables
2023-02-10 11:19:43,690:INFO:Importing untrained model
2023-02-10 11:19:43,693:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 11:19:43,698:INFO:Starting cross validation
2023-02-10 11:19:43,699:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:19:44,206:INFO:Calculating mean and std
2023-02-10 11:19:44,207:INFO:Creating metrics dataframe
2023-02-10 11:19:44,211:INFO:Uploading results into container
2023-02-10 11:19:44,211:INFO:Uploading model into container now
2023-02-10 11:19:44,211:INFO:create_model_container: 7
2023-02-10 11:19:44,211:INFO:master_model_container: 7
2023-02-10 11:19:44,212:INFO:display_container: 2
2023-02-10 11:19:44,212:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 11:19:44,212:INFO:create_model() succesfully completed......................................
2023-02-10 11:19:44,308:INFO:SubProcess create_model() end ==================================
2023-02-10 11:19:44,308:INFO:Creating metrics dataframe
2023-02-10 11:19:44,314:INFO:Initializing Bayesian Ridge
2023-02-10 11:19:44,315:INFO:Total runtime is 0.8279903133710225 minutes
2023-02-10 11:19:44,318:INFO:SubProcess create_model() called ==================================
2023-02-10 11:19:44,318:INFO:Initializing create_model()
2023-02-10 11:19:44,318:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:19:44,318:INFO:Checking exceptions
2023-02-10 11:19:44,318:INFO:Importing libraries
2023-02-10 11:19:44,318:INFO:Copying training dataset
2023-02-10 11:19:44,325:INFO:Defining folds
2023-02-10 11:19:44,325:INFO:Declaring metric variables
2023-02-10 11:19:44,328:INFO:Importing untrained model
2023-02-10 11:19:44,331:INFO:Bayesian Ridge Imported succesfully
2023-02-10 11:19:44,337:INFO:Starting cross validation
2023-02-10 11:19:44,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:19:50,802:INFO:Calculating mean and std
2023-02-10 11:19:50,802:INFO:Creating metrics dataframe
2023-02-10 11:19:50,806:INFO:Uploading results into container
2023-02-10 11:19:50,806:INFO:Uploading model into container now
2023-02-10 11:19:50,806:INFO:create_model_container: 8
2023-02-10 11:19:50,806:INFO:master_model_container: 8
2023-02-10 11:19:50,806:INFO:display_container: 2
2023-02-10 11:19:50,807:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-10 11:19:50,807:INFO:create_model() succesfully completed......................................
2023-02-10 11:19:50,899:INFO:SubProcess create_model() end ==================================
2023-02-10 11:19:50,899:INFO:Creating metrics dataframe
2023-02-10 11:19:50,905:INFO:Initializing Passive Aggressive Regressor
2023-02-10 11:19:50,905:INFO:Total runtime is 0.9378378431002299 minutes
2023-02-10 11:19:50,909:INFO:SubProcess create_model() called ==================================
2023-02-10 11:19:50,909:INFO:Initializing create_model()
2023-02-10 11:19:50,909:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:19:50,909:INFO:Checking exceptions
2023-02-10 11:19:50,909:INFO:Importing libraries
2023-02-10 11:19:50,909:INFO:Copying training dataset
2023-02-10 11:19:50,916:INFO:Defining folds
2023-02-10 11:19:50,916:INFO:Declaring metric variables
2023-02-10 11:19:50,919:INFO:Importing untrained model
2023-02-10 11:19:50,922:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-10 11:19:50,927:INFO:Starting cross validation
2023-02-10 11:19:50,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:19:51,603:INFO:Calculating mean and std
2023-02-10 11:19:51,604:INFO:Creating metrics dataframe
2023-02-10 11:19:51,607:INFO:Uploading results into container
2023-02-10 11:19:51,607:INFO:Uploading model into container now
2023-02-10 11:19:51,607:INFO:create_model_container: 9
2023-02-10 11:19:51,607:INFO:master_model_container: 9
2023-02-10 11:19:51,607:INFO:display_container: 2
2023-02-10 11:19:51,608:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-10 11:19:51,608:INFO:create_model() succesfully completed......................................
2023-02-10 11:19:51,704:INFO:SubProcess create_model() end ==================================
2023-02-10 11:19:51,704:INFO:Creating metrics dataframe
2023-02-10 11:19:51,710:INFO:Initializing Huber Regressor
2023-02-10 11:19:51,710:INFO:Total runtime is 0.9512550791104635 minutes
2023-02-10 11:19:51,714:INFO:SubProcess create_model() called ==================================
2023-02-10 11:19:51,714:INFO:Initializing create_model()
2023-02-10 11:19:51,714:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:19:51,714:INFO:Checking exceptions
2023-02-10 11:19:51,714:INFO:Importing libraries
2023-02-10 11:19:51,714:INFO:Copying training dataset
2023-02-10 11:19:51,721:INFO:Defining folds
2023-02-10 11:19:51,721:INFO:Declaring metric variables
2023-02-10 11:19:51,724:INFO:Importing untrained model
2023-02-10 11:19:51,727:INFO:Huber Regressor Imported succesfully
2023-02-10 11:19:51,733:INFO:Starting cross validation
2023-02-10 11:19:51,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:20:02,757:INFO:Calculating mean and std
2023-02-10 11:20:02,758:INFO:Creating metrics dataframe
2023-02-10 11:20:02,761:INFO:Uploading results into container
2023-02-10 11:20:02,761:INFO:Uploading model into container now
2023-02-10 11:20:02,761:INFO:create_model_container: 10
2023-02-10 11:20:02,761:INFO:master_model_container: 10
2023-02-10 11:20:02,761:INFO:display_container: 2
2023-02-10 11:20:02,761:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-10 11:20:02,761:INFO:create_model() succesfully completed......................................
2023-02-10 11:20:02,865:INFO:SubProcess create_model() end ==================================
2023-02-10 11:20:02,865:INFO:Creating metrics dataframe
2023-02-10 11:20:02,875:INFO:Initializing K Neighbors Regressor
2023-02-10 11:20:02,875:INFO:Total runtime is 1.1373297174771626 minutes
2023-02-10 11:20:02,878:INFO:SubProcess create_model() called ==================================
2023-02-10 11:20:02,878:INFO:Initializing create_model()
2023-02-10 11:20:02,878:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:20:02,878:INFO:Checking exceptions
2023-02-10 11:20:02,878:INFO:Importing libraries
2023-02-10 11:20:02,878:INFO:Copying training dataset
2023-02-10 11:20:02,885:INFO:Defining folds
2023-02-10 11:20:02,885:INFO:Declaring metric variables
2023-02-10 11:20:02,889:INFO:Importing untrained model
2023-02-10 11:20:02,892:INFO:K Neighbors Regressor Imported succesfully
2023-02-10 11:20:02,897:INFO:Starting cross validation
2023-02-10 11:20:02,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:20:05,143:INFO:Calculating mean and std
2023-02-10 11:20:05,143:INFO:Creating metrics dataframe
2023-02-10 11:20:05,151:INFO:Uploading results into container
2023-02-10 11:20:05,151:INFO:Uploading model into container now
2023-02-10 11:20:05,151:INFO:create_model_container: 11
2023-02-10 11:20:05,151:INFO:master_model_container: 11
2023-02-10 11:20:05,151:INFO:display_container: 2
2023-02-10 11:20:05,151:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-10 11:20:05,151:INFO:create_model() succesfully completed......................................
2023-02-10 11:20:05,253:INFO:SubProcess create_model() end ==================================
2023-02-10 11:20:05,253:INFO:Creating metrics dataframe
2023-02-10 11:20:05,260:INFO:Initializing Decision Tree Regressor
2023-02-10 11:20:05,260:INFO:Total runtime is 1.177082864443461 minutes
2023-02-10 11:20:05,264:INFO:SubProcess create_model() called ==================================
2023-02-10 11:20:05,264:INFO:Initializing create_model()
2023-02-10 11:20:05,264:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:20:05,264:INFO:Checking exceptions
2023-02-10 11:20:05,264:INFO:Importing libraries
2023-02-10 11:20:05,264:INFO:Copying training dataset
2023-02-10 11:20:05,270:INFO:Defining folds
2023-02-10 11:20:05,271:INFO:Declaring metric variables
2023-02-10 11:20:05,274:INFO:Importing untrained model
2023-02-10 11:20:05,277:INFO:Decision Tree Regressor Imported succesfully
2023-02-10 11:20:05,284:INFO:Starting cross validation
2023-02-10 11:20:05,284:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:20:25,287:INFO:Calculating mean and std
2023-02-10 11:20:25,288:INFO:Creating metrics dataframe
2023-02-10 11:20:25,291:INFO:Uploading results into container
2023-02-10 11:20:25,291:INFO:Uploading model into container now
2023-02-10 11:20:25,291:INFO:create_model_container: 12
2023-02-10 11:20:25,291:INFO:master_model_container: 12
2023-02-10 11:20:25,291:INFO:display_container: 2
2023-02-10 11:20:25,291:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-10 11:20:25,291:INFO:create_model() succesfully completed......................................
2023-02-10 11:20:25,401:INFO:SubProcess create_model() end ==================================
2023-02-10 11:20:25,401:INFO:Creating metrics dataframe
2023-02-10 11:20:25,408:INFO:Initializing Random Forest Regressor
2023-02-10 11:20:25,408:INFO:Total runtime is 1.512878429889679 minutes
2023-02-10 11:20:25,411:INFO:SubProcess create_model() called ==================================
2023-02-10 11:20:25,411:INFO:Initializing create_model()
2023-02-10 11:20:25,411:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:20:25,411:INFO:Checking exceptions
2023-02-10 11:20:25,412:INFO:Importing libraries
2023-02-10 11:20:25,412:INFO:Copying training dataset
2023-02-10 11:20:25,418:INFO:Defining folds
2023-02-10 11:20:25,418:INFO:Declaring metric variables
2023-02-10 11:20:25,422:INFO:Importing untrained model
2023-02-10 11:20:25,425:INFO:Random Forest Regressor Imported succesfully
2023-02-10 11:20:25,431:INFO:Starting cross validation
2023-02-10 11:20:25,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:29:56,329:INFO:Calculating mean and std
2023-02-10 11:29:56,330:INFO:Creating metrics dataframe
2023-02-10 11:29:56,333:INFO:Uploading results into container
2023-02-10 11:29:56,333:INFO:Uploading model into container now
2023-02-10 11:29:56,333:INFO:create_model_container: 13
2023-02-10 11:29:56,333:INFO:master_model_container: 13
2023-02-10 11:29:56,333:INFO:display_container: 2
2023-02-10 11:29:56,333:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-10 11:29:56,333:INFO:create_model() succesfully completed......................................
2023-02-10 11:29:56,478:INFO:SubProcess create_model() end ==================================
2023-02-10 11:29:56,479:INFO:Creating metrics dataframe
2023-02-10 11:29:56,486:INFO:Initializing Extra Trees Regressor
2023-02-10 11:29:56,486:INFO:Total runtime is 11.030842161178589 minutes
2023-02-10 11:29:56,489:INFO:SubProcess create_model() called ==================================
2023-02-10 11:29:56,489:INFO:Initializing create_model()
2023-02-10 11:29:56,489:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:29:56,489:INFO:Checking exceptions
2023-02-10 11:29:56,489:INFO:Importing libraries
2023-02-10 11:29:56,489:INFO:Copying training dataset
2023-02-10 11:29:56,496:INFO:Defining folds
2023-02-10 11:29:56,496:INFO:Declaring metric variables
2023-02-10 11:29:56,499:INFO:Importing untrained model
2023-02-10 11:29:56,502:INFO:Extra Trees Regressor Imported succesfully
2023-02-10 11:29:56,508:INFO:Starting cross validation
2023-02-10 11:29:56,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:34:16,709:INFO:Calculating mean and std
2023-02-10 11:34:16,710:INFO:Creating metrics dataframe
2023-02-10 11:34:16,715:INFO:Uploading results into container
2023-02-10 11:34:16,715:INFO:Uploading model into container now
2023-02-10 11:34:16,715:INFO:create_model_container: 14
2023-02-10 11:34:16,715:INFO:master_model_container: 14
2023-02-10 11:34:16,715:INFO:display_container: 2
2023-02-10 11:34:16,716:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-10 11:34:16,716:INFO:create_model() succesfully completed......................................
2023-02-10 11:34:16,819:INFO:SubProcess create_model() end ==================================
2023-02-10 11:34:16,819:INFO:Creating metrics dataframe
2023-02-10 11:34:16,827:INFO:Initializing AdaBoost Regressor
2023-02-10 11:34:16,827:INFO:Total runtime is 15.369862230618795 minutes
2023-02-10 11:34:16,831:INFO:SubProcess create_model() called ==================================
2023-02-10 11:34:16,831:INFO:Initializing create_model()
2023-02-10 11:34:16,831:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:34:16,831:INFO:Checking exceptions
2023-02-10 11:34:16,831:INFO:Importing libraries
2023-02-10 11:34:16,831:INFO:Copying training dataset
2023-02-10 11:34:16,838:INFO:Defining folds
2023-02-10 11:34:16,838:INFO:Declaring metric variables
2023-02-10 11:34:16,841:INFO:Importing untrained model
2023-02-10 11:34:16,844:INFO:AdaBoost Regressor Imported succesfully
2023-02-10 11:34:16,850:INFO:Starting cross validation
2023-02-10 11:34:16,850:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:35:36,646:INFO:Calculating mean and std
2023-02-10 11:35:36,647:INFO:Creating metrics dataframe
2023-02-10 11:35:36,653:INFO:Uploading results into container
2023-02-10 11:35:36,653:INFO:Uploading model into container now
2023-02-10 11:35:36,653:INFO:create_model_container: 15
2023-02-10 11:35:36,653:INFO:master_model_container: 15
2023-02-10 11:35:36,653:INFO:display_container: 2
2023-02-10 11:35:36,653:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-10 11:35:36,654:INFO:create_model() succesfully completed......................................
2023-02-10 11:35:36,760:INFO:SubProcess create_model() end ==================================
2023-02-10 11:35:36,760:INFO:Creating metrics dataframe
2023-02-10 11:35:36,768:INFO:Initializing Gradient Boosting Regressor
2023-02-10 11:35:36,768:INFO:Total runtime is 16.702212433020275 minutes
2023-02-10 11:35:36,771:INFO:SubProcess create_model() called ==================================
2023-02-10 11:35:36,771:INFO:Initializing create_model()
2023-02-10 11:35:36,771:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:35:36,771:INFO:Checking exceptions
2023-02-10 11:35:36,772:INFO:Importing libraries
2023-02-10 11:35:36,772:INFO:Copying training dataset
2023-02-10 11:35:36,779:INFO:Defining folds
2023-02-10 11:35:36,779:INFO:Declaring metric variables
2023-02-10 11:35:36,782:INFO:Importing untrained model
2023-02-10 11:35:36,786:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-10 11:35:36,792:INFO:Starting cross validation
2023-02-10 11:35:36,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:40:35,930:INFO:Calculating mean and std
2023-02-10 11:40:35,931:INFO:Creating metrics dataframe
2023-02-10 11:40:35,935:INFO:Uploading results into container
2023-02-10 11:40:35,935:INFO:Uploading model into container now
2023-02-10 11:40:35,935:INFO:create_model_container: 16
2023-02-10 11:40:35,935:INFO:master_model_container: 16
2023-02-10 11:40:35,935:INFO:display_container: 2
2023-02-10 11:40:35,935:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-10 11:40:35,935:INFO:create_model() succesfully completed......................................
2023-02-10 11:40:36,062:INFO:SubProcess create_model() end ==================================
2023-02-10 11:40:36,062:INFO:Creating metrics dataframe
2023-02-10 11:40:36,070:INFO:Initializing Extreme Gradient Boosting
2023-02-10 11:40:36,070:INFO:Total runtime is 21.6905845006307 minutes
2023-02-10 11:40:36,074:INFO:SubProcess create_model() called ==================================
2023-02-10 11:40:36,074:INFO:Initializing create_model()
2023-02-10 11:40:36,074:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:40:36,074:INFO:Checking exceptions
2023-02-10 11:40:36,074:INFO:Importing libraries
2023-02-10 11:40:36,074:INFO:Copying training dataset
2023-02-10 11:40:36,081:INFO:Defining folds
2023-02-10 11:40:36,082:INFO:Declaring metric variables
2023-02-10 11:40:36,085:INFO:Importing untrained model
2023-02-10 11:40:36,088:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-10 11:40:36,094:INFO:Starting cross validation
2023-02-10 11:40:36,095:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:42:50,948:INFO:Calculating mean and std
2023-02-10 11:42:50,949:INFO:Creating metrics dataframe
2023-02-10 11:42:50,954:INFO:Uploading results into container
2023-02-10 11:42:50,954:INFO:Uploading model into container now
2023-02-10 11:42:50,954:INFO:create_model_container: 17
2023-02-10 11:42:50,954:INFO:master_model_container: 17
2023-02-10 11:42:50,954:INFO:display_container: 2
2023-02-10 11:42:50,955:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-10 11:42:50,955:INFO:create_model() succesfully completed......................................
2023-02-10 11:42:51,059:INFO:SubProcess create_model() end ==================================
2023-02-10 11:42:51,059:INFO:Creating metrics dataframe
2023-02-10 11:42:51,067:INFO:Initializing Light Gradient Boosting Machine
2023-02-10 11:42:51,067:INFO:Total runtime is 23.94053455591202 minutes
2023-02-10 11:42:51,071:INFO:SubProcess create_model() called ==================================
2023-02-10 11:42:51,071:INFO:Initializing create_model()
2023-02-10 11:42:51,071:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:42:51,071:INFO:Checking exceptions
2023-02-10 11:42:51,071:INFO:Importing libraries
2023-02-10 11:42:51,071:INFO:Copying training dataset
2023-02-10 11:42:51,077:INFO:Defining folds
2023-02-10 11:42:51,077:INFO:Declaring metric variables
2023-02-10 11:42:51,080:INFO:Importing untrained model
2023-02-10 11:42:51,083:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-10 11:42:51,089:INFO:Starting cross validation
2023-02-10 11:42:51,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:42:59,836:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-10 11:42:59,838:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/concurrent/futures/_base.py", line 441, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1098, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 997, in retrieve
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 586, in abort_everything
    self._workers.terminate(kill_workers=True)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/executor.py", line 74, in terminate
    self.shutdown(kill_workers=kill_workers)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 1199, in shutdown
    executor_manager_thread.join()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 1060, in join
    self._wait_for_tstate_lock()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt

2023-02-10 11:42:59,838:INFO:Initializing create_model()
2023-02-10 11:42:59,838:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:42:59,838:INFO:Checking exceptions
2023-02-10 11:42:59,838:INFO:Importing libraries
2023-02-10 11:42:59,838:INFO:Copying training dataset
2023-02-10 11:42:59,847:INFO:Defining folds
2023-02-10 11:42:59,847:INFO:Declaring metric variables
2023-02-10 11:42:59,851:INFO:Importing untrained model
2023-02-10 11:42:59,856:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-10 11:42:59,864:INFO:Starting cross validation
2023-02-10 11:42:59,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:43:00,759:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-02-10 11:43:00,759:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/concurrent/futures/_base.py", line 441, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1098, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 997, in retrieve
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 586, in abort_everything
    self._workers.terminate(kill_workers=True)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/executor.py", line 74, in terminate
    self.shutdown(kill_workers=kill_workers)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 1199, in shutdown
    executor_manager_thread.join()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 1060, in join
    self._wait_for_tstate_lock()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1098, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/concurrent/futures/_base.py", line 446, in result
    return self.__get_result()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGTERM(-15)}

2023-02-10 11:43:00,759:INFO:Initializing CatBoost Regressor
2023-02-10 11:43:00,759:INFO:Total runtime is 24.10206953684489 minutes
2023-02-10 11:43:00,766:INFO:SubProcess create_model() called ==================================
2023-02-10 11:43:00,766:INFO:Initializing create_model()
2023-02-10 11:43:00,766:INFO:create_model(estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f65f78bf550>, return_train_score=False, kwargs={})
2023-02-10 11:43:00,766:INFO:Checking exceptions
2023-02-10 11:43:00,766:INFO:Importing libraries
2023-02-10 11:43:00,766:INFO:Copying training dataset
2023-02-10 11:43:00,773:INFO:Defining folds
2023-02-10 11:43:00,773:INFO:Declaring metric variables
2023-02-10 11:43:00,776:INFO:Importing untrained model
2023-02-10 11:43:00,779:INFO:CatBoost Regressor Imported succesfully
2023-02-10 11:43:00,785:INFO:Starting cross validation
2023-02-10 11:43:00,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 11:49:40,172:INFO:PyCaret Supervised Module
2023-02-10 11:49:40,173:INFO:ML Usecase: regression
2023-02-10 11:49:40,173:INFO:version 2.3.10
2023-02-10 11:49:40,173:INFO:Initializing setup()
2023-02-10 11:49:40,173:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 11:49:40,173:INFO:Checking environment
2023-02-10 11:49:40,173:INFO:python_version: 3.9.16
2023-02-10 11:49:40,173:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 11:49:40,173:INFO:machine: x86_64
2023-02-10 11:49:40,173:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 11:49:40,173:INFO:Memory: svmem(total=134979592192, available=95722553344, percent=29.1, used=34955128832, free=52023025664, active=5415038976, inactive=74223407104, buffers=1383395328, cached=46618042368, shared=3038568448, slab=2584002560)
2023-02-10 11:49:40,174:INFO:Physical Core: 16
2023-02-10 11:49:40,174:INFO:Logical Core: 32
2023-02-10 11:49:40,174:INFO:Checking libraries
2023-02-10 11:49:40,174:INFO:pd==1.5.2
2023-02-10 11:49:40,174:INFO:numpy==1.20.3
2023-02-10 11:49:40,174:INFO:sklearn==0.23.2
2023-02-10 11:49:40,174:INFO:lightgbm==3.3.5
2023-02-10 11:49:40,190:INFO:catboost==1.1.1
2023-02-10 11:49:40,190:INFO:xgboost==1.7.3
2023-02-10 11:49:40,190:INFO:mlflow==2.1.1
2023-02-10 11:49:40,190:INFO:Checking Exceptions
2023-02-10 11:49:40,191:INFO:Declaring global variables
2023-02-10 11:49:40,191:INFO:USI: e49f
2023-02-10 11:49:40,191:INFO:pycaret_globals: {'_ml_usecase', '_all_metrics', 'stratify_param', '_all_models', 'imputation_regressor', 'fold_shuffle_param', '_available_plots', 'fold_param', 'experiment__', 'create_model_container', 'gpu_param', 'pycaret_globals', 'data_before_preprocess', 'seed', 'fix_imbalance_param', 'X_train', 'target_param', 'X', 'prep_pipe', 'y_test', 'exp_name_log', '_internal_pipeline', 'n_jobs_param', 'master_model_container', 'fix_imbalance_method_param', 'dashboard_logger', 'transform_target_param', 'fold_groups_param_full', '_all_models_internal', 'logging_param', '_gpu_n_jobs_param', 'imputation_classifier', 'X_test', 'transform_target_method_param', 'y', 'display_container', 'fold_generator', 'fold_groups_param', 'USI', 'iterative_imputation_iters_param', 'y_train', 'log_plots_param', 'html_param'}
2023-02-10 11:49:40,191:INFO:Preparing display monitor
2023-02-10 11:49:40,191:INFO:Preparing display monitor
2023-02-10 11:49:40,197:INFO:Importing libraries
2023-02-10 11:49:40,197:INFO:Copying data for preprocessing
2023-02-10 11:49:40,955:INFO:Declaring preprocessing parameters
2023-02-10 11:49:41,292:INFO:Creating preprocessing pipeline
2023-02-10 11:49:48,433:INFO:Preprocessing pipeline created successfully
2023-02-10 11:49:48,433:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 11:49:48,433:INFO:Creating global containers
2023-02-10 11:49:48,434:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 12:02:31,311:INFO:PyCaret Supervised Module
2023-02-10 12:02:31,311:INFO:ML Usecase: regression
2023-02-10 12:02:31,311:INFO:version 2.3.10
2023-02-10 12:02:31,311:INFO:Initializing setup()
2023-02-10 12:02:31,311:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 12:02:31,311:INFO:Checking environment
2023-02-10 12:02:31,311:INFO:python_version: 3.9.16
2023-02-10 12:02:31,311:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 12:02:31,311:INFO:machine: x86_64
2023-02-10 12:02:31,311:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 12:02:31,311:INFO:Memory: svmem(total=134979592192, available=83857678336, percent=37.9, used=46828077056, free=40153030656, active=5419335680, inactive=86068244480, buffers=1385406464, cached=46613078016, shared=3030499328, slab=2583965696)
2023-02-10 12:02:31,311:INFO:Physical Core: 16
2023-02-10 12:02:31,312:INFO:Logical Core: 32
2023-02-10 12:02:31,312:INFO:Checking libraries
2023-02-10 12:02:31,312:INFO:pd==1.5.2
2023-02-10 12:02:31,312:INFO:numpy==1.20.3
2023-02-10 12:02:31,312:INFO:sklearn==0.23.2
2023-02-10 12:02:31,312:INFO:lightgbm==3.3.5
2023-02-10 12:02:31,312:INFO:catboost==1.1.1
2023-02-10 12:02:31,312:INFO:xgboost==1.7.3
2023-02-10 12:02:31,312:INFO:mlflow==2.1.1
2023-02-10 12:02:31,312:INFO:Checking Exceptions
2023-02-10 12:02:31,312:INFO:Declaring global variables
2023-02-10 12:02:31,312:INFO:USI: 0075
2023-02-10 12:02:31,312:INFO:pycaret_globals: {'_ml_usecase', '_all_metrics', 'stratify_param', '_all_models', 'imputation_regressor', 'fold_shuffle_param', '_available_plots', 'fold_param', 'experiment__', 'create_model_container', 'gpu_param', 'pycaret_globals', 'data_before_preprocess', 'seed', 'fix_imbalance_param', 'X_train', 'target_param', 'X', 'prep_pipe', 'y_test', 'exp_name_log', '_internal_pipeline', 'n_jobs_param', 'master_model_container', 'fix_imbalance_method_param', 'dashboard_logger', 'transform_target_param', 'fold_groups_param_full', '_all_models_internal', 'logging_param', '_gpu_n_jobs_param', 'imputation_classifier', 'X_test', 'transform_target_method_param', 'y', 'display_container', 'fold_generator', 'fold_groups_param', 'USI', 'iterative_imputation_iters_param', 'y_train', 'log_plots_param', 'html_param'}
2023-02-10 12:02:31,312:INFO:Preparing display monitor
2023-02-10 12:02:31,313:INFO:Preparing display monitor
2023-02-10 12:02:31,318:INFO:Importing libraries
2023-02-10 12:02:31,318:INFO:Copying data for preprocessing
2023-02-10 12:02:31,822:INFO:Declaring preprocessing parameters
2023-02-10 12:02:32,160:INFO:Creating preprocessing pipeline
2023-02-10 12:02:40,887:INFO:Preprocessing pipeline created successfully
2023-02-10 12:02:40,888:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 12:02:40,888:INFO:Creating global containers
2023-02-10 12:02:40,888:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 12:07:52,089:INFO:PyCaret Supervised Module
2023-02-10 12:07:52,089:INFO:ML Usecase: regression
2023-02-10 12:07:52,090:INFO:version 2.3.10
2023-02-10 12:07:52,090:INFO:Initializing setup()
2023-02-10 12:07:52,090:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 12:07:52,090:INFO:Checking environment
2023-02-10 12:07:52,090:INFO:python_version: 3.9.16
2023-02-10 12:07:52,090:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 12:07:52,090:INFO:machine: x86_64
2023-02-10 12:07:52,090:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 12:07:52,090:INFO:Memory: svmem(total=134979592192, available=83732897792, percent=38.0, used=46955536384, free=40026058752, active=5421002752, inactive=86190100480, buffers=1386102784, cached=46611894272, shared=3027832832, slab=2583687168)
2023-02-10 12:07:52,090:INFO:Physical Core: 16
2023-02-10 12:07:52,091:INFO:Logical Core: 32
2023-02-10 12:07:52,091:INFO:Checking libraries
2023-02-10 12:07:52,091:INFO:pd==1.5.2
2023-02-10 12:07:52,091:INFO:numpy==1.20.3
2023-02-10 12:07:52,091:INFO:sklearn==0.23.2
2023-02-10 12:07:52,091:INFO:lightgbm==3.3.5
2023-02-10 12:07:52,091:INFO:catboost==1.1.1
2023-02-10 12:07:52,091:INFO:xgboost==1.7.3
2023-02-10 12:07:52,091:INFO:mlflow==2.1.1
2023-02-10 12:07:52,091:INFO:Checking Exceptions
2023-02-10 12:07:52,092:INFO:Declaring global variables
2023-02-10 12:07:52,092:INFO:USI: 9d5c
2023-02-10 12:07:52,092:INFO:pycaret_globals: {'_ml_usecase', '_all_metrics', 'stratify_param', '_all_models', 'imputation_regressor', 'fold_shuffle_param', '_available_plots', 'fold_param', 'experiment__', 'create_model_container', 'gpu_param', 'pycaret_globals', 'data_before_preprocess', 'seed', 'fix_imbalance_param', 'X_train', 'target_param', 'X', 'prep_pipe', 'y_test', 'exp_name_log', '_internal_pipeline', 'n_jobs_param', 'master_model_container', 'fix_imbalance_method_param', 'dashboard_logger', 'transform_target_param', 'fold_groups_param_full', '_all_models_internal', 'logging_param', '_gpu_n_jobs_param', 'imputation_classifier', 'X_test', 'transform_target_method_param', 'y', 'display_container', 'fold_generator', 'fold_groups_param', 'USI', 'iterative_imputation_iters_param', 'y_train', 'log_plots_param', 'html_param'}
2023-02-10 12:07:52,092:INFO:Preparing display monitor
2023-02-10 12:07:52,092:INFO:Preparing display monitor
2023-02-10 12:07:52,096:INFO:Importing libraries
2023-02-10 12:07:52,096:INFO:Copying data for preprocessing
2023-02-10 12:07:52,266:INFO:Declaring preprocessing parameters
2023-02-10 12:07:52,593:INFO:Creating preprocessing pipeline
2023-02-10 12:08:00,998:INFO:Preprocessing pipeline created successfully
2023-02-10 12:08:00,998:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 12:08:00,998:INFO:Creating global containers
2023-02-10 12:08:00,998:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 12:12:57,257:INFO:PyCaret Supervised Module
2023-02-10 12:12:57,258:INFO:ML Usecase: regression
2023-02-10 12:12:57,258:INFO:version 2.3.10
2023-02-10 12:12:57,258:INFO:Initializing setup()
2023-02-10 12:12:57,258:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 12:12:57,258:INFO:Checking environment
2023-02-10 12:12:57,258:INFO:python_version: 3.9.16
2023-02-10 12:12:57,258:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 12:12:57,258:INFO:machine: x86_64
2023-02-10 12:12:57,258:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 12:12:57,258:INFO:Memory: svmem(total=134979592192, available=83553480704, percent=38.1, used=47120400384, free=39844675584, active=5421850624, inactive=86373048320, buffers=1386602496, cached=46627913728, shared=3042381824, slab=2583732224)
2023-02-10 12:12:57,259:INFO:Physical Core: 16
2023-02-10 12:12:57,259:INFO:Logical Core: 32
2023-02-10 12:12:57,259:INFO:Checking libraries
2023-02-10 12:12:57,259:INFO:pd==1.5.2
2023-02-10 12:12:57,259:INFO:numpy==1.20.3
2023-02-10 12:12:57,259:INFO:sklearn==0.23.2
2023-02-10 12:12:57,259:INFO:lightgbm==3.3.5
2023-02-10 12:12:57,259:INFO:catboost==1.1.1
2023-02-10 12:12:57,259:INFO:xgboost==1.7.3
2023-02-10 12:12:57,259:INFO:mlflow==2.1.1
2023-02-10 12:12:57,259:INFO:Checking Exceptions
2023-02-10 12:12:57,260:INFO:Declaring global variables
2023-02-10 12:12:57,260:INFO:USI: 1f51
2023-02-10 12:12:57,260:INFO:pycaret_globals: {'_ml_usecase', '_all_metrics', 'stratify_param', '_all_models', 'imputation_regressor', 'fold_shuffle_param', '_available_plots', 'fold_param', 'experiment__', 'create_model_container', 'gpu_param', 'pycaret_globals', 'data_before_preprocess', 'seed', 'fix_imbalance_param', 'X_train', 'target_param', 'X', 'prep_pipe', 'y_test', 'exp_name_log', '_internal_pipeline', 'n_jobs_param', 'master_model_container', 'fix_imbalance_method_param', 'dashboard_logger', 'transform_target_param', 'fold_groups_param_full', '_all_models_internal', 'logging_param', '_gpu_n_jobs_param', 'imputation_classifier', 'X_test', 'transform_target_method_param', 'y', 'display_container', 'fold_generator', 'fold_groups_param', 'USI', 'iterative_imputation_iters_param', 'y_train', 'log_plots_param', 'html_param'}
2023-02-10 12:12:57,260:INFO:Preparing display monitor
2023-02-10 12:12:57,260:INFO:Preparing display monitor
2023-02-10 12:12:57,265:INFO:Importing libraries
2023-02-10 12:12:57,265:INFO:Copying data for preprocessing
2023-02-10 12:12:57,436:INFO:Declaring preprocessing parameters
2023-02-10 12:12:57,764:INFO:Creating preprocessing pipeline
2023-02-10 12:13:06,147:INFO:Preprocessing pipeline created successfully
2023-02-10 12:13:06,147:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 12:13:06,147:INFO:Creating global containers
2023-02-10 12:13:06,147:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 12:31:59,262:INFO:Creating grid variables
2023-02-10 12:31:59,437:INFO:create_model_container: 0
2023-02-10 12:31:59,437:INFO:master_model_container: 0
2023-02-10 12:31:59,437:INFO:display_container: 1
2023-02-10 12:31:59,440:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-10 12:31:59,440:INFO:setup() succesfully completed......................................
2023-02-10 12:31:59,553:INFO:Initializing compare_models()
2023-02-10 12:31:59,553:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-02-10 12:31:59,553:INFO:Checking exceptions
2023-02-10 12:31:59,553:INFO:Preparing display monitor
2023-02-10 12:31:59,553:INFO:Preparing display monitor
2023-02-10 12:31:59,564:INFO:Initializing Linear Regression
2023-02-10 12:31:59,564:INFO:Total runtime is 2.586841583251953e-06 minutes
2023-02-10 12:31:59,567:INFO:SubProcess create_model() called ==================================
2023-02-10 12:31:59,567:INFO:Initializing create_model()
2023-02-10 12:31:59,567:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:31:59,567:INFO:Checking exceptions
2023-02-10 12:31:59,567:INFO:Importing libraries
2023-02-10 12:31:59,567:INFO:Copying training dataset
2023-02-10 12:31:59,594:INFO:Defining folds
2023-02-10 12:31:59,594:INFO:Declaring metric variables
2023-02-10 12:31:59,598:INFO:Importing untrained model
2023-02-10 12:31:59,601:INFO:Linear Regression Imported succesfully
2023-02-10 12:31:59,607:INFO:Starting cross validation
2023-02-10 12:31:59,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:32:26,156:INFO:Calculating mean and std
2023-02-10 12:32:26,157:INFO:Creating metrics dataframe
2023-02-10 12:32:26,162:INFO:Uploading results into container
2023-02-10 12:32:26,162:INFO:Uploading model into container now
2023-02-10 12:32:26,162:INFO:create_model_container: 1
2023-02-10 12:32:26,162:INFO:master_model_container: 1
2023-02-10 12:32:26,162:INFO:display_container: 2
2023-02-10 12:32:26,163:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-10 12:32:26,163:INFO:create_model() succesfully completed......................................
2023-02-10 12:32:26,273:INFO:SubProcess create_model() end ==================================
2023-02-10 12:32:26,273:INFO:Creating metrics dataframe
2023-02-10 12:32:26,279:INFO:Initializing Lasso Regression
2023-02-10 12:32:26,279:INFO:Total runtime is 0.44525869290033976 minutes
2023-02-10 12:32:26,283:INFO:SubProcess create_model() called ==================================
2023-02-10 12:32:26,283:INFO:Initializing create_model()
2023-02-10 12:32:26,283:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:32:26,283:INFO:Checking exceptions
2023-02-10 12:32:26,283:INFO:Importing libraries
2023-02-10 12:32:26,283:INFO:Copying training dataset
2023-02-10 12:32:26,309:INFO:Defining folds
2023-02-10 12:32:26,309:INFO:Declaring metric variables
2023-02-10 12:32:26,312:INFO:Importing untrained model
2023-02-10 12:32:26,315:INFO:Lasso Regression Imported succesfully
2023-02-10 12:32:26,321:INFO:Starting cross validation
2023-02-10 12:32:26,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:33:21,642:INFO:Calculating mean and std
2023-02-10 12:33:21,642:INFO:Creating metrics dataframe
2023-02-10 12:33:21,646:INFO:Uploading results into container
2023-02-10 12:33:21,646:INFO:Uploading model into container now
2023-02-10 12:33:21,646:INFO:create_model_container: 2
2023-02-10 12:33:21,646:INFO:master_model_container: 2
2023-02-10 12:33:21,646:INFO:display_container: 2
2023-02-10 12:33:21,647:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 12:33:21,647:INFO:create_model() succesfully completed......................................
2023-02-10 12:33:21,749:INFO:SubProcess create_model() end ==================================
2023-02-10 12:33:21,749:INFO:Creating metrics dataframe
2023-02-10 12:33:21,756:INFO:Initializing Ridge Regression
2023-02-10 12:33:21,756:INFO:Total runtime is 1.3698646545410156 minutes
2023-02-10 12:33:21,760:INFO:SubProcess create_model() called ==================================
2023-02-10 12:33:21,760:INFO:Initializing create_model()
2023-02-10 12:33:21,760:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:33:21,760:INFO:Checking exceptions
2023-02-10 12:33:21,760:INFO:Importing libraries
2023-02-10 12:33:21,760:INFO:Copying training dataset
2023-02-10 12:33:21,785:INFO:Defining folds
2023-02-10 12:33:21,785:INFO:Declaring metric variables
2023-02-10 12:33:21,789:INFO:Importing untrained model
2023-02-10 12:33:21,793:INFO:Ridge Regression Imported succesfully
2023-02-10 12:33:21,799:INFO:Starting cross validation
2023-02-10 12:33:21,799:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:34:07,061:INFO:Calculating mean and std
2023-02-10 12:34:07,061:INFO:Creating metrics dataframe
2023-02-10 12:34:07,066:INFO:Uploading results into container
2023-02-10 12:34:07,066:INFO:Uploading model into container now
2023-02-10 12:34:07,066:INFO:create_model_container: 3
2023-02-10 12:34:07,066:INFO:master_model_container: 3
2023-02-10 12:34:07,066:INFO:display_container: 2
2023-02-10 12:34:07,066:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-10 12:34:07,066:INFO:create_model() succesfully completed......................................
2023-02-10 12:34:07,165:INFO:SubProcess create_model() end ==================================
2023-02-10 12:34:07,165:INFO:Creating metrics dataframe
2023-02-10 12:34:07,170:INFO:Initializing Elastic Net
2023-02-10 12:34:07,171:INFO:Total runtime is 2.1267807046572367 minutes
2023-02-10 12:34:07,174:INFO:SubProcess create_model() called ==================================
2023-02-10 12:34:07,174:INFO:Initializing create_model()
2023-02-10 12:34:07,174:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:34:07,174:INFO:Checking exceptions
2023-02-10 12:34:07,174:INFO:Importing libraries
2023-02-10 12:34:07,174:INFO:Copying training dataset
2023-02-10 12:34:07,200:INFO:Defining folds
2023-02-10 12:34:07,200:INFO:Declaring metric variables
2023-02-10 12:34:07,203:INFO:Importing untrained model
2023-02-10 12:34:07,207:INFO:Elastic Net Imported succesfully
2023-02-10 12:34:07,213:INFO:Starting cross validation
2023-02-10 12:34:07,213:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:35:01,785:INFO:Calculating mean and std
2023-02-10 12:35:01,785:INFO:Creating metrics dataframe
2023-02-10 12:35:01,789:INFO:Uploading results into container
2023-02-10 12:35:01,789:INFO:Uploading model into container now
2023-02-10 12:35:01,789:INFO:create_model_container: 4
2023-02-10 12:35:01,789:INFO:master_model_container: 4
2023-02-10 12:35:01,789:INFO:display_container: 2
2023-02-10 12:35:01,790:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 12:35:01,790:INFO:create_model() succesfully completed......................................
2023-02-10 12:35:01,888:INFO:SubProcess create_model() end ==================================
2023-02-10 12:35:01,888:INFO:Creating metrics dataframe
2023-02-10 12:35:01,895:INFO:Initializing Least Angle Regression
2023-02-10 12:35:01,895:INFO:Total runtime is 3.0388574878374737 minutes
2023-02-10 12:35:01,899:INFO:SubProcess create_model() called ==================================
2023-02-10 12:35:01,899:INFO:Initializing create_model()
2023-02-10 12:35:01,899:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:35:01,899:INFO:Checking exceptions
2023-02-10 12:35:01,899:INFO:Importing libraries
2023-02-10 12:35:01,899:INFO:Copying training dataset
2023-02-10 12:35:01,925:INFO:Defining folds
2023-02-10 12:35:01,925:INFO:Declaring metric variables
2023-02-10 12:35:01,929:INFO:Importing untrained model
2023-02-10 12:35:01,932:INFO:Least Angle Regression Imported succesfully
2023-02-10 12:35:01,938:INFO:Starting cross validation
2023-02-10 12:35:01,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:35:04,842:INFO:Calculating mean and std
2023-02-10 12:35:04,842:INFO:Creating metrics dataframe
2023-02-10 12:35:04,846:INFO:Uploading results into container
2023-02-10 12:35:04,846:INFO:Uploading model into container now
2023-02-10 12:35:04,846:INFO:create_model_container: 5
2023-02-10 12:35:04,846:INFO:master_model_container: 5
2023-02-10 12:35:04,846:INFO:display_container: 2
2023-02-10 12:35:04,846:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize=True, precompute='auto',
     random_state=11, verbose=False)
2023-02-10 12:35:04,847:INFO:create_model() succesfully completed......................................
2023-02-10 12:35:04,944:INFO:SubProcess create_model() end ==================================
2023-02-10 12:35:04,944:INFO:Creating metrics dataframe
2023-02-10 12:35:04,951:INFO:Initializing Lasso Least Angle Regression
2023-02-10 12:35:04,951:INFO:Total runtime is 3.0897871454556785 minutes
2023-02-10 12:35:04,955:INFO:SubProcess create_model() called ==================================
2023-02-10 12:35:04,955:INFO:Initializing create_model()
2023-02-10 12:35:04,955:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:35:04,955:INFO:Checking exceptions
2023-02-10 12:35:04,955:INFO:Importing libraries
2023-02-10 12:35:04,955:INFO:Copying training dataset
2023-02-10 12:35:04,980:INFO:Defining folds
2023-02-10 12:35:04,980:INFO:Declaring metric variables
2023-02-10 12:35:04,984:INFO:Importing untrained model
2023-02-10 12:35:04,988:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-10 12:35:04,995:INFO:Starting cross validation
2023-02-10 12:35:04,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:35:07,568:INFO:Calculating mean and std
2023-02-10 12:35:07,569:INFO:Creating metrics dataframe
2023-02-10 12:35:07,573:INFO:Uploading results into container
2023-02-10 12:35:07,574:INFO:Uploading model into container now
2023-02-10 12:35:07,574:INFO:create_model_container: 6
2023-02-10 12:35:07,574:INFO:master_model_container: 6
2023-02-10 12:35:07,574:INFO:display_container: 2
2023-02-10 12:35:07,574:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-10 12:35:07,574:INFO:create_model() succesfully completed......................................
2023-02-10 12:35:07,670:INFO:SubProcess create_model() end ==================================
2023-02-10 12:35:07,670:INFO:Creating metrics dataframe
2023-02-10 12:35:07,677:INFO:Initializing Orthogonal Matching Pursuit
2023-02-10 12:35:07,677:INFO:Total runtime is 3.1352161169052124 minutes
2023-02-10 12:35:07,680:INFO:SubProcess create_model() called ==================================
2023-02-10 12:35:07,681:INFO:Initializing create_model()
2023-02-10 12:35:07,681:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:35:07,681:INFO:Checking exceptions
2023-02-10 12:35:07,681:INFO:Importing libraries
2023-02-10 12:35:07,681:INFO:Copying training dataset
2023-02-10 12:35:07,707:INFO:Defining folds
2023-02-10 12:35:07,707:INFO:Declaring metric variables
2023-02-10 12:35:07,711:INFO:Importing untrained model
2023-02-10 12:35:07,714:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 12:35:07,721:INFO:Starting cross validation
2023-02-10 12:35:07,721:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:35:10,338:INFO:Calculating mean and std
2023-02-10 12:35:10,338:INFO:Creating metrics dataframe
2023-02-10 12:35:10,342:INFO:Uploading results into container
2023-02-10 12:35:10,342:INFO:Uploading model into container now
2023-02-10 12:35:10,342:INFO:create_model_container: 7
2023-02-10 12:35:10,342:INFO:master_model_container: 7
2023-02-10 12:35:10,342:INFO:display_container: 2
2023-02-10 12:35:10,342:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 12:35:10,342:INFO:create_model() succesfully completed......................................
2023-02-10 12:35:10,438:INFO:SubProcess create_model() end ==================================
2023-02-10 12:35:10,439:INFO:Creating metrics dataframe
2023-02-10 12:35:10,445:INFO:Initializing Bayesian Ridge
2023-02-10 12:35:10,445:INFO:Total runtime is 3.1813621600468953 minutes
2023-02-10 12:35:10,449:INFO:SubProcess create_model() called ==================================
2023-02-10 12:35:10,449:INFO:Initializing create_model()
2023-02-10 12:35:10,449:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:35:10,449:INFO:Checking exceptions
2023-02-10 12:35:10,449:INFO:Importing libraries
2023-02-10 12:35:10,450:INFO:Copying training dataset
2023-02-10 12:35:10,474:INFO:Defining folds
2023-02-10 12:35:10,475:INFO:Declaring metric variables
2023-02-10 12:35:10,478:INFO:Importing untrained model
2023-02-10 12:35:10,482:INFO:Bayesian Ridge Imported succesfully
2023-02-10 12:35:10,488:INFO:Starting cross validation
2023-02-10 12:35:10,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:41:18,454:INFO:Calculating mean and std
2023-02-10 12:41:18,455:INFO:Creating metrics dataframe
2023-02-10 12:41:18,459:INFO:Uploading results into container
2023-02-10 12:41:18,460:INFO:Uploading model into container now
2023-02-10 12:41:18,460:INFO:create_model_container: 8
2023-02-10 12:41:18,460:INFO:master_model_container: 8
2023-02-10 12:41:18,460:INFO:display_container: 2
2023-02-10 12:41:18,460:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-10 12:41:18,460:INFO:create_model() succesfully completed......................................
2023-02-10 12:41:18,556:INFO:SubProcess create_model() end ==================================
2023-02-10 12:41:18,556:INFO:Creating metrics dataframe
2023-02-10 12:41:18,563:INFO:Initializing Passive Aggressive Regressor
2023-02-10 12:41:18,563:INFO:Total runtime is 9.316656033198038 minutes
2023-02-10 12:41:18,566:INFO:SubProcess create_model() called ==================================
2023-02-10 12:41:18,566:INFO:Initializing create_model()
2023-02-10 12:41:18,567:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:41:18,567:INFO:Checking exceptions
2023-02-10 12:41:18,567:INFO:Importing libraries
2023-02-10 12:41:18,567:INFO:Copying training dataset
2023-02-10 12:41:18,592:INFO:Defining folds
2023-02-10 12:41:18,592:INFO:Declaring metric variables
2023-02-10 12:41:18,595:INFO:Importing untrained model
2023-02-10 12:41:18,598:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-10 12:41:18,606:INFO:Starting cross validation
2023-02-10 12:41:18,606:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:41:21,420:INFO:Calculating mean and std
2023-02-10 12:41:21,420:INFO:Creating metrics dataframe
2023-02-10 12:41:21,424:INFO:Uploading results into container
2023-02-10 12:41:21,424:INFO:Uploading model into container now
2023-02-10 12:41:21,424:INFO:create_model_container: 9
2023-02-10 12:41:21,424:INFO:master_model_container: 9
2023-02-10 12:41:21,424:INFO:display_container: 2
2023-02-10 12:41:21,424:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-10 12:41:21,425:INFO:create_model() succesfully completed......................................
2023-02-10 12:41:21,532:INFO:SubProcess create_model() end ==================================
2023-02-10 12:41:21,533:INFO:Creating metrics dataframe
2023-02-10 12:41:21,540:INFO:Initializing Huber Regressor
2023-02-10 12:41:21,540:INFO:Total runtime is 9.366269143422445 minutes
2023-02-10 12:41:21,543:INFO:SubProcess create_model() called ==================================
2023-02-10 12:41:21,543:INFO:Initializing create_model()
2023-02-10 12:41:21,543:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:41:21,543:INFO:Checking exceptions
2023-02-10 12:41:21,543:INFO:Importing libraries
2023-02-10 12:41:21,543:INFO:Copying training dataset
2023-02-10 12:41:21,570:INFO:Defining folds
2023-02-10 12:41:21,570:INFO:Declaring metric variables
2023-02-10 12:41:21,573:INFO:Importing untrained model
2023-02-10 12:41:21,576:INFO:Huber Regressor Imported succesfully
2023-02-10 12:41:21,582:INFO:Starting cross validation
2023-02-10 12:41:21,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:42:56,863:INFO:Calculating mean and std
2023-02-10 12:42:56,864:INFO:Creating metrics dataframe
2023-02-10 12:42:56,868:INFO:Uploading results into container
2023-02-10 12:42:56,868:INFO:Uploading model into container now
2023-02-10 12:42:56,868:INFO:create_model_container: 10
2023-02-10 12:42:56,868:INFO:master_model_container: 10
2023-02-10 12:42:56,868:INFO:display_container: 2
2023-02-10 12:42:56,869:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-10 12:42:56,869:INFO:create_model() succesfully completed......................................
2023-02-10 12:42:56,964:INFO:SubProcess create_model() end ==================================
2023-02-10 12:42:56,964:INFO:Creating metrics dataframe
2023-02-10 12:42:56,971:INFO:Initializing K Neighbors Regressor
2023-02-10 12:42:56,971:INFO:Total runtime is 10.956781299908956 minutes
2023-02-10 12:42:56,974:INFO:SubProcess create_model() called ==================================
2023-02-10 12:42:56,974:INFO:Initializing create_model()
2023-02-10 12:42:56,974:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:42:56,974:INFO:Checking exceptions
2023-02-10 12:42:56,974:INFO:Importing libraries
2023-02-10 12:42:56,974:INFO:Copying training dataset
2023-02-10 12:42:56,999:INFO:Defining folds
2023-02-10 12:42:56,999:INFO:Declaring metric variables
2023-02-10 12:42:57,002:INFO:Importing untrained model
2023-02-10 12:42:57,005:INFO:K Neighbors Regressor Imported succesfully
2023-02-10 12:42:57,010:INFO:Starting cross validation
2023-02-10 12:42:57,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:43:09,014:INFO:Calculating mean and std
2023-02-10 12:43:09,015:INFO:Creating metrics dataframe
2023-02-10 12:43:09,018:INFO:Uploading results into container
2023-02-10 12:43:09,019:INFO:Uploading model into container now
2023-02-10 12:43:09,019:INFO:create_model_container: 11
2023-02-10 12:43:09,019:INFO:master_model_container: 11
2023-02-10 12:43:09,019:INFO:display_container: 2
2023-02-10 12:43:09,019:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-10 12:43:09,019:INFO:create_model() succesfully completed......................................
2023-02-10 12:43:09,118:INFO:SubProcess create_model() end ==================================
2023-02-10 12:43:09,118:INFO:Creating metrics dataframe
2023-02-10 12:43:09,125:INFO:Initializing Decision Tree Regressor
2023-02-10 12:43:09,126:INFO:Total runtime is 11.159363702932993 minutes
2023-02-10 12:43:09,129:INFO:SubProcess create_model() called ==================================
2023-02-10 12:43:09,129:INFO:Initializing create_model()
2023-02-10 12:43:09,129:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:43:09,129:INFO:Checking exceptions
2023-02-10 12:43:09,129:INFO:Importing libraries
2023-02-10 12:43:09,129:INFO:Copying training dataset
2023-02-10 12:43:09,154:INFO:Defining folds
2023-02-10 12:43:09,155:INFO:Declaring metric variables
2023-02-10 12:43:09,158:INFO:Importing untrained model
2023-02-10 12:43:09,161:INFO:Decision Tree Regressor Imported succesfully
2023-02-10 12:43:09,167:INFO:Starting cross validation
2023-02-10 12:43:09,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 12:44:02,687:INFO:Calculating mean and std
2023-02-10 12:44:02,688:INFO:Creating metrics dataframe
2023-02-10 12:44:02,692:INFO:Uploading results into container
2023-02-10 12:44:02,692:INFO:Uploading model into container now
2023-02-10 12:44:02,693:INFO:create_model_container: 12
2023-02-10 12:44:02,693:INFO:master_model_container: 12
2023-02-10 12:44:02,693:INFO:display_container: 2
2023-02-10 12:44:02,693:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-10 12:44:02,693:INFO:create_model() succesfully completed......................................
2023-02-10 12:44:02,792:INFO:SubProcess create_model() end ==================================
2023-02-10 12:44:02,793:INFO:Creating metrics dataframe
2023-02-10 12:44:02,800:INFO:Initializing Random Forest Regressor
2023-02-10 12:44:02,800:INFO:Total runtime is 12.053936147689818 minutes
2023-02-10 12:44:02,803:INFO:SubProcess create_model() called ==================================
2023-02-10 12:44:02,803:INFO:Initializing create_model()
2023-02-10 12:44:02,803:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 12:44:02,803:INFO:Checking exceptions
2023-02-10 12:44:02,804:INFO:Importing libraries
2023-02-10 12:44:02,804:INFO:Copying training dataset
2023-02-10 12:44:02,829:INFO:Defining folds
2023-02-10 12:44:02,829:INFO:Declaring metric variables
2023-02-10 12:44:02,833:INFO:Importing untrained model
2023-02-10 12:44:02,836:INFO:Random Forest Regressor Imported succesfully
2023-02-10 12:44:02,842:INFO:Starting cross validation
2023-02-10 12:44:02,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 13:08:11,834:INFO:Calculating mean and std
2023-02-10 13:08:11,835:INFO:Creating metrics dataframe
2023-02-10 13:08:11,839:INFO:Uploading results into container
2023-02-10 13:08:11,839:INFO:Uploading model into container now
2023-02-10 13:08:11,839:INFO:create_model_container: 13
2023-02-10 13:08:11,840:INFO:master_model_container: 13
2023-02-10 13:08:11,840:INFO:display_container: 2
2023-02-10 13:08:11,840:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-10 13:08:11,840:INFO:create_model() succesfully completed......................................
2023-02-10 13:08:11,968:INFO:SubProcess create_model() end ==================================
2023-02-10 13:08:11,968:INFO:Creating metrics dataframe
2023-02-10 13:08:11,976:INFO:Initializing Extra Trees Regressor
2023-02-10 13:08:11,976:INFO:Total runtime is 36.20686686038971 minutes
2023-02-10 13:08:11,979:INFO:SubProcess create_model() called ==================================
2023-02-10 13:08:11,979:INFO:Initializing create_model()
2023-02-10 13:08:11,979:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 13:08:11,979:INFO:Checking exceptions
2023-02-10 13:08:11,979:INFO:Importing libraries
2023-02-10 13:08:11,980:INFO:Copying training dataset
2023-02-10 13:08:12,008:INFO:Defining folds
2023-02-10 13:08:12,009:INFO:Declaring metric variables
2023-02-10 13:08:12,012:INFO:Importing untrained model
2023-02-10 13:08:12,016:INFO:Extra Trees Regressor Imported succesfully
2023-02-10 13:08:12,022:INFO:Starting cross validation
2023-02-10 13:08:12,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 13:31:20,374:INFO:Calculating mean and std
2023-02-10 13:31:20,375:INFO:Creating metrics dataframe
2023-02-10 13:31:20,379:INFO:Uploading results into container
2023-02-10 13:31:20,379:INFO:Uploading model into container now
2023-02-10 13:31:20,379:INFO:create_model_container: 14
2023-02-10 13:31:20,379:INFO:master_model_container: 14
2023-02-10 13:31:20,379:INFO:display_container: 2
2023-02-10 13:31:20,379:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-10 13:31:20,379:INFO:create_model() succesfully completed......................................
2023-02-10 13:31:20,484:INFO:SubProcess create_model() end ==================================
2023-02-10 13:31:20,484:INFO:Creating metrics dataframe
2023-02-10 13:31:20,492:INFO:Initializing AdaBoost Regressor
2023-02-10 13:31:20,492:INFO:Total runtime is 59.34880038499832 minutes
2023-02-10 13:31:20,495:INFO:SubProcess create_model() called ==================================
2023-02-10 13:31:20,495:INFO:Initializing create_model()
2023-02-10 13:31:20,495:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 13:31:20,495:INFO:Checking exceptions
2023-02-10 13:31:20,495:INFO:Importing libraries
2023-02-10 13:31:20,495:INFO:Copying training dataset
2023-02-10 13:31:20,522:INFO:Defining folds
2023-02-10 13:31:20,522:INFO:Declaring metric variables
2023-02-10 13:31:20,526:INFO:Importing untrained model
2023-02-10 13:31:20,529:INFO:AdaBoost Regressor Imported succesfully
2023-02-10 13:31:20,535:INFO:Starting cross validation
2023-02-10 13:31:20,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 13:36:43,539:INFO:Calculating mean and std
2023-02-10 13:36:43,540:INFO:Creating metrics dataframe
2023-02-10 13:36:43,546:INFO:Uploading results into container
2023-02-10 13:36:43,546:INFO:Uploading model into container now
2023-02-10 13:36:43,546:INFO:create_model_container: 15
2023-02-10 13:36:43,546:INFO:master_model_container: 15
2023-02-10 13:36:43,546:INFO:display_container: 2
2023-02-10 13:36:43,547:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-10 13:36:43,547:INFO:create_model() succesfully completed......................................
2023-02-10 13:36:43,649:INFO:SubProcess create_model() end ==================================
2023-02-10 13:36:43,649:INFO:Creating metrics dataframe
2023-02-10 13:36:43,657:INFO:Initializing Gradient Boosting Regressor
2023-02-10 13:36:43,657:INFO:Total runtime is 64.73489014307658 minutes
2023-02-10 13:36:43,661:INFO:SubProcess create_model() called ==================================
2023-02-10 13:36:43,661:INFO:Initializing create_model()
2023-02-10 13:36:43,661:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 13:36:43,661:INFO:Checking exceptions
2023-02-10 13:36:43,661:INFO:Importing libraries
2023-02-10 13:36:43,661:INFO:Copying training dataset
2023-02-10 13:36:43,686:INFO:Defining folds
2023-02-10 13:36:43,686:INFO:Declaring metric variables
2023-02-10 13:36:43,691:INFO:Importing untrained model
2023-02-10 13:36:43,694:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-10 13:36:43,700:INFO:Starting cross validation
2023-02-10 13:36:43,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 13:55:52,580:INFO:Calculating mean and std
2023-02-10 13:55:52,581:INFO:Creating metrics dataframe
2023-02-10 13:55:52,586:INFO:Uploading results into container
2023-02-10 13:55:52,586:INFO:Uploading model into container now
2023-02-10 13:55:52,586:INFO:create_model_container: 16
2023-02-10 13:55:52,587:INFO:master_model_container: 16
2023-02-10 13:55:52,587:INFO:display_container: 2
2023-02-10 13:55:52,587:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-10 13:55:52,587:INFO:create_model() succesfully completed......................................
2023-02-10 13:55:52,690:INFO:SubProcess create_model() end ==================================
2023-02-10 13:55:52,691:INFO:Creating metrics dataframe
2023-02-10 13:55:52,698:INFO:Initializing Extreme Gradient Boosting
2023-02-10 13:55:52,698:INFO:Total runtime is 83.88557781775793 minutes
2023-02-10 13:55:52,702:INFO:SubProcess create_model() called ==================================
2023-02-10 13:55:52,702:INFO:Initializing create_model()
2023-02-10 13:55:52,702:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 13:55:52,702:INFO:Checking exceptions
2023-02-10 13:55:52,702:INFO:Importing libraries
2023-02-10 13:55:52,702:INFO:Copying training dataset
2023-02-10 13:55:52,727:INFO:Defining folds
2023-02-10 13:55:52,727:INFO:Declaring metric variables
2023-02-10 13:55:52,730:INFO:Importing untrained model
2023-02-10 13:55:52,734:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-10 13:55:52,739:INFO:Starting cross validation
2023-02-10 13:55:52,740:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 14:04:05,097:INFO:Calculating mean and std
2023-02-10 14:04:05,098:INFO:Creating metrics dataframe
2023-02-10 14:04:05,103:INFO:Uploading results into container
2023-02-10 14:04:05,103:INFO:Uploading model into container now
2023-02-10 14:04:05,103:INFO:create_model_container: 17
2023-02-10 14:04:05,104:INFO:master_model_container: 17
2023-02-10 14:04:05,104:INFO:display_container: 2
2023-02-10 14:04:05,104:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-10 14:04:05,104:INFO:create_model() succesfully completed......................................
2023-02-10 14:04:05,205:INFO:SubProcess create_model() end ==================================
2023-02-10 14:04:05,205:INFO:Creating metrics dataframe
2023-02-10 14:04:05,213:INFO:Initializing Light Gradient Boosting Machine
2023-02-10 14:04:05,213:INFO:Total runtime is 92.09415848255159 minutes
2023-02-10 14:04:05,217:INFO:SubProcess create_model() called ==================================
2023-02-10 14:04:05,217:INFO:Initializing create_model()
2023-02-10 14:04:05,217:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 14:04:05,217:INFO:Checking exceptions
2023-02-10 14:04:05,217:INFO:Importing libraries
2023-02-10 14:04:05,217:INFO:Copying training dataset
2023-02-10 14:04:05,242:INFO:Defining folds
2023-02-10 14:04:05,242:INFO:Declaring metric variables
2023-02-10 14:04:05,245:INFO:Importing untrained model
2023-02-10 14:04:05,248:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-10 14:04:05,254:INFO:Starting cross validation
2023-02-10 14:04:05,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 14:05:23,981:INFO:Calculating mean and std
2023-02-10 14:05:23,982:INFO:Creating metrics dataframe
2023-02-10 14:05:23,986:INFO:Uploading results into container
2023-02-10 14:05:23,986:INFO:Uploading model into container now
2023-02-10 14:05:23,986:INFO:create_model_container: 18
2023-02-10 14:05:23,986:INFO:master_model_container: 18
2023-02-10 14:05:23,986:INFO:display_container: 2
2023-02-10 14:05:23,987:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-10 14:05:23,987:INFO:create_model() succesfully completed......................................
2023-02-10 14:05:24,091:INFO:SubProcess create_model() end ==================================
2023-02-10 14:05:24,092:INFO:Creating metrics dataframe
2023-02-10 14:05:24,100:INFO:Initializing CatBoost Regressor
2023-02-10 14:05:24,100:INFO:Total runtime is 93.40893661181134 minutes
2023-02-10 14:05:24,104:INFO:SubProcess create_model() called ==================================
2023-02-10 14:05:24,104:INFO:Initializing create_model()
2023-02-10 14:05:24,104:INFO:create_model(estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 14:05:24,104:INFO:Checking exceptions
2023-02-10 14:05:24,104:INFO:Importing libraries
2023-02-10 14:05:24,104:INFO:Copying training dataset
2023-02-10 14:05:24,132:INFO:Defining folds
2023-02-10 14:05:24,132:INFO:Declaring metric variables
2023-02-10 14:05:24,136:INFO:Importing untrained model
2023-02-10 14:05:24,139:INFO:CatBoost Regressor Imported succesfully
2023-02-10 14:05:24,146:INFO:Starting cross validation
2023-02-10 14:05:24,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 14:23:33,361:INFO:Calculating mean and std
2023-02-10 14:23:33,362:INFO:Creating metrics dataframe
2023-02-10 14:23:33,366:INFO:Uploading results into container
2023-02-10 14:23:33,366:INFO:Uploading model into container now
2023-02-10 14:23:33,366:INFO:create_model_container: 19
2023-02-10 14:23:33,366:INFO:master_model_container: 19
2023-02-10 14:23:33,367:INFO:display_container: 2
2023-02-10 14:23:33,367:INFO:<catboost.core.CatBoostRegressor object at 0x7f4bc6b9c040>
2023-02-10 14:23:33,367:INFO:create_model() succesfully completed......................................
2023-02-10 14:23:33,469:INFO:SubProcess create_model() end ==================================
2023-02-10 14:23:33,469:INFO:Creating metrics dataframe
2023-02-10 14:23:33,477:INFO:Initializing Dummy Regressor
2023-02-10 14:23:33,477:INFO:Total runtime is 111.56522243022921 minutes
2023-02-10 14:23:33,481:INFO:SubProcess create_model() called ==================================
2023-02-10 14:23:33,481:INFO:Initializing create_model()
2023-02-10 14:23:33,481:INFO:create_model(estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb5fee0>, return_train_score=False, kwargs={})
2023-02-10 14:23:33,481:INFO:Checking exceptions
2023-02-10 14:23:33,481:INFO:Importing libraries
2023-02-10 14:23:33,481:INFO:Copying training dataset
2023-02-10 14:23:33,507:INFO:Defining folds
2023-02-10 14:23:33,507:INFO:Declaring metric variables
2023-02-10 14:23:33,510:INFO:Importing untrained model
2023-02-10 14:23:33,513:INFO:Dummy Regressor Imported succesfully
2023-02-10 14:23:33,520:INFO:Starting cross validation
2023-02-10 14:23:33,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 14:23:34,470:INFO:Calculating mean and std
2023-02-10 14:23:34,471:INFO:Creating metrics dataframe
2023-02-10 14:23:34,474:INFO:Uploading results into container
2023-02-10 14:23:34,474:INFO:Uploading model into container now
2023-02-10 14:23:34,474:INFO:create_model_container: 20
2023-02-10 14:23:34,474:INFO:master_model_container: 20
2023-02-10 14:23:34,474:INFO:display_container: 2
2023-02-10 14:23:34,475:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-02-10 14:23:34,475:INFO:create_model() succesfully completed......................................
2023-02-10 14:23:34,593:INFO:SubProcess create_model() end ==================================
2023-02-10 14:23:34,593:INFO:Creating metrics dataframe
2023-02-10 14:23:34,609:INFO:Initializing create_model()
2023-02-10 14:23:34,609:INFO:create_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 14:23:34,609:INFO:Checking exceptions
2023-02-10 14:23:34,609:INFO:Importing libraries
2023-02-10 14:23:34,609:INFO:Copying training dataset
2023-02-10 14:23:34,635:INFO:Defining folds
2023-02-10 14:23:34,635:INFO:Declaring metric variables
2023-02-10 14:23:34,635:INFO:Importing untrained model
2023-02-10 14:23:34,635:INFO:Declaring custom model
2023-02-10 14:23:34,635:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 14:23:34,635:INFO:Cross validation set to False
2023-02-10 14:23:34,635:INFO:Fitting Model
2023-02-10 14:23:35,088:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 14:23:35,088:INFO:create_models() succesfully completed......................................
2023-02-10 14:23:35,220:INFO:create_model_container: 20
2023-02-10 14:23:35,220:INFO:master_model_container: 20
2023-02-10 14:23:35,220:INFO:display_container: 2
2023-02-10 14:23:35,220:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 14:23:35,220:INFO:compare_models() succesfully completed......................................
2023-02-10 16:18:27,451:INFO:PyCaret Supervised Module
2023-02-10 16:18:27,451:INFO:ML Usecase: regression
2023-02-10 16:18:27,451:INFO:version 2.3.10
2023-02-10 16:18:27,451:INFO:Initializing setup()
2023-02-10 16:18:27,451:INFO:setup(target=closeChg%_forward1HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward24HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 16:18:27,451:INFO:Checking environment
2023-02-10 16:18:27,451:INFO:python_version: 3.9.16
2023-02-10 16:18:27,451:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 16:18:27,451:INFO:machine: x86_64
2023-02-10 16:18:27,451:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 16:18:27,451:INFO:Memory: svmem(total=134979592192, available=82726645760, percent=38.7, used=47799328768, free=38802522112, active=5561921536, inactive=87214862336, buffers=1430138880, cached=46947602432, shared=3190284288, slab=2610831360)
2023-02-10 16:18:27,452:INFO:Physical Core: 16
2023-02-10 16:18:27,452:INFO:Logical Core: 32
2023-02-10 16:18:27,452:INFO:Checking libraries
2023-02-10 16:18:27,452:INFO:pd==1.5.2
2023-02-10 16:18:27,452:INFO:numpy==1.20.3
2023-02-10 16:18:27,452:INFO:sklearn==0.23.2
2023-02-10 16:18:27,452:INFO:lightgbm==3.3.5
2023-02-10 16:18:27,452:INFO:catboost==1.1.1
2023-02-10 16:18:27,452:INFO:xgboost==1.7.3
2023-02-10 16:18:27,452:INFO:mlflow==2.1.1
2023-02-10 16:18:27,452:INFO:Checking Exceptions
2023-02-10 16:18:27,453:INFO:Declaring global variables
2023-02-10 16:18:27,453:INFO:USI: 3502
2023-02-10 16:18:27,453:INFO:pycaret_globals: {'_ml_usecase', '_all_metrics', 'stratify_param', '_all_models', 'imputation_regressor', 'fold_shuffle_param', '_available_plots', 'fold_param', 'experiment__', 'create_model_container', 'gpu_param', 'pycaret_globals', 'data_before_preprocess', 'seed', 'fix_imbalance_param', 'X_train', 'target_param', 'X', 'prep_pipe', 'y_test', 'exp_name_log', '_internal_pipeline', 'n_jobs_param', 'master_model_container', 'fix_imbalance_method_param', 'dashboard_logger', 'transform_target_param', 'fold_groups_param_full', '_all_models_internal', 'logging_param', '_gpu_n_jobs_param', 'imputation_classifier', 'X_test', 'transform_target_method_param', 'y', 'display_container', 'fold_generator', 'fold_groups_param', 'USI', 'iterative_imputation_iters_param', 'y_train', 'log_plots_param', 'html_param'}
2023-02-10 16:18:27,453:INFO:Preparing display monitor
2023-02-10 16:18:27,453:INFO:Preparing display monitor
2023-02-10 16:18:27,460:INFO:Importing libraries
2023-02-10 16:18:27,460:INFO:Copying data for preprocessing
2023-02-10 16:18:27,634:INFO:Declaring preprocessing parameters
2023-02-10 16:18:27,986:INFO:Creating preprocessing pipeline
2023-02-10 16:18:36,135:INFO:Preprocessing pipeline created successfully
2023-02-10 16:18:36,135:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 16:18:36,135:INFO:Creating global containers
2023-02-10 16:18:36,136:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 16:38:04,006:INFO:Creating grid variables
2023-02-10 16:38:04,173:INFO:create_model_container: 0
2023-02-10 16:38:04,173:INFO:master_model_container: 0
2023-02-10 16:38:04,173:INFO:display_container: 1
2023-02-10 16:38:04,175:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward24HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward1HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward1HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward1HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-10 16:38:04,175:INFO:setup() succesfully completed......................................
2023-02-10 16:38:04,303:INFO:Initializing compare_models()
2023-02-10 16:38:04,303:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-02-10 16:38:04,303:INFO:Checking exceptions
2023-02-10 16:38:04,303:INFO:Preparing display monitor
2023-02-10 16:38:04,303:INFO:Preparing display monitor
2023-02-10 16:38:04,313:INFO:Initializing Linear Regression
2023-02-10 16:38:04,313:INFO:Total runtime is 1.6450881958007813e-06 minutes
2023-02-10 16:38:04,316:INFO:SubProcess create_model() called ==================================
2023-02-10 16:38:04,316:INFO:Initializing create_model()
2023-02-10 16:38:04,316:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:38:04,316:INFO:Checking exceptions
2023-02-10 16:38:04,316:INFO:Importing libraries
2023-02-10 16:38:04,317:INFO:Copying training dataset
2023-02-10 16:38:04,336:INFO:Defining folds
2023-02-10 16:38:04,336:INFO:Declaring metric variables
2023-02-10 16:38:04,340:INFO:Importing untrained model
2023-02-10 16:38:04,343:INFO:Linear Regression Imported succesfully
2023-02-10 16:38:04,349:INFO:Starting cross validation
2023-02-10 16:38:04,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:38:31,259:INFO:Calculating mean and std
2023-02-10 16:38:31,261:INFO:Creating metrics dataframe
2023-02-10 16:38:31,266:INFO:Uploading results into container
2023-02-10 16:38:31,266:INFO:Uploading model into container now
2023-02-10 16:38:31,266:INFO:create_model_container: 1
2023-02-10 16:38:31,266:INFO:master_model_container: 1
2023-02-10 16:38:31,266:INFO:display_container: 2
2023-02-10 16:38:31,267:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-10 16:38:31,267:INFO:create_model() succesfully completed......................................
2023-02-10 16:38:31,368:INFO:SubProcess create_model() end ==================================
2023-02-10 16:38:31,368:INFO:Creating metrics dataframe
2023-02-10 16:38:31,373:INFO:Initializing Lasso Regression
2023-02-10 16:38:31,373:INFO:Total runtime is 0.45100579261779783 minutes
2023-02-10 16:38:31,376:INFO:SubProcess create_model() called ==================================
2023-02-10 16:38:31,377:INFO:Initializing create_model()
2023-02-10 16:38:31,377:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:38:31,377:INFO:Checking exceptions
2023-02-10 16:38:31,377:INFO:Importing libraries
2023-02-10 16:38:31,377:INFO:Copying training dataset
2023-02-10 16:38:31,389:INFO:Defining folds
2023-02-10 16:38:31,389:INFO:Declaring metric variables
2023-02-10 16:38:31,392:INFO:Importing untrained model
2023-02-10 16:38:31,395:INFO:Lasso Regression Imported succesfully
2023-02-10 16:38:31,401:INFO:Starting cross validation
2023-02-10 16:38:31,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:39:28,082:INFO:Calculating mean and std
2023-02-10 16:39:28,083:INFO:Creating metrics dataframe
2023-02-10 16:39:28,086:INFO:Uploading results into container
2023-02-10 16:39:28,086:INFO:Uploading model into container now
2023-02-10 16:39:28,086:INFO:create_model_container: 2
2023-02-10 16:39:28,086:INFO:master_model_container: 2
2023-02-10 16:39:28,086:INFO:display_container: 2
2023-02-10 16:39:28,086:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 16:39:28,086:INFO:create_model() succesfully completed......................................
2023-02-10 16:39:28,183:INFO:SubProcess create_model() end ==================================
2023-02-10 16:39:28,183:INFO:Creating metrics dataframe
2023-02-10 16:39:28,189:INFO:Initializing Ridge Regression
2023-02-10 16:39:28,189:INFO:Total runtime is 1.3979408899943033 minutes
2023-02-10 16:39:28,193:INFO:SubProcess create_model() called ==================================
2023-02-10 16:39:28,193:INFO:Initializing create_model()
2023-02-10 16:39:28,193:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:39:28,193:INFO:Checking exceptions
2023-02-10 16:39:28,193:INFO:Importing libraries
2023-02-10 16:39:28,193:INFO:Copying training dataset
2023-02-10 16:39:28,206:INFO:Defining folds
2023-02-10 16:39:28,206:INFO:Declaring metric variables
2023-02-10 16:39:28,209:INFO:Importing untrained model
2023-02-10 16:39:28,212:INFO:Ridge Regression Imported succesfully
2023-02-10 16:39:28,218:INFO:Starting cross validation
2023-02-10 16:39:28,218:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:40:15,103:INFO:Calculating mean and std
2023-02-10 16:40:15,104:INFO:Creating metrics dataframe
2023-02-10 16:40:15,108:INFO:Uploading results into container
2023-02-10 16:40:15,108:INFO:Uploading model into container now
2023-02-10 16:40:15,108:INFO:create_model_container: 3
2023-02-10 16:40:15,108:INFO:master_model_container: 3
2023-02-10 16:40:15,108:INFO:display_container: 2
2023-02-10 16:40:15,108:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-10 16:40:15,108:INFO:create_model() succesfully completed......................................
2023-02-10 16:40:15,201:INFO:SubProcess create_model() end ==================================
2023-02-10 16:40:15,201:INFO:Creating metrics dataframe
2023-02-10 16:40:15,207:INFO:Initializing Elastic Net
2023-02-10 16:40:15,207:INFO:Total runtime is 2.181575584411621 minutes
2023-02-10 16:40:15,211:INFO:SubProcess create_model() called ==================================
2023-02-10 16:40:15,211:INFO:Initializing create_model()
2023-02-10 16:40:15,211:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:40:15,211:INFO:Checking exceptions
2023-02-10 16:40:15,211:INFO:Importing libraries
2023-02-10 16:40:15,211:INFO:Copying training dataset
2023-02-10 16:40:15,224:INFO:Defining folds
2023-02-10 16:40:15,224:INFO:Declaring metric variables
2023-02-10 16:40:15,227:INFO:Importing untrained model
2023-02-10 16:40:15,230:INFO:Elastic Net Imported succesfully
2023-02-10 16:40:15,236:INFO:Starting cross validation
2023-02-10 16:40:15,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:41:11,434:INFO:Calculating mean and std
2023-02-10 16:41:11,434:INFO:Creating metrics dataframe
2023-02-10 16:41:11,439:INFO:Uploading results into container
2023-02-10 16:41:11,439:INFO:Uploading model into container now
2023-02-10 16:41:11,439:INFO:create_model_container: 4
2023-02-10 16:41:11,439:INFO:master_model_container: 4
2023-02-10 16:41:11,439:INFO:display_container: 2
2023-02-10 16:41:11,439:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 16:41:11,439:INFO:create_model() succesfully completed......................................
2023-02-10 16:41:11,546:INFO:SubProcess create_model() end ==================================
2023-02-10 16:41:11,546:INFO:Creating metrics dataframe
2023-02-10 16:41:11,553:INFO:Initializing Least Angle Regression
2023-02-10 16:41:11,553:INFO:Total runtime is 3.1206680456797278 minutes
2023-02-10 16:41:11,556:INFO:SubProcess create_model() called ==================================
2023-02-10 16:41:11,557:INFO:Initializing create_model()
2023-02-10 16:41:11,557:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:41:11,557:INFO:Checking exceptions
2023-02-10 16:41:11,557:INFO:Importing libraries
2023-02-10 16:41:11,557:INFO:Copying training dataset
2023-02-10 16:41:11,569:INFO:Defining folds
2023-02-10 16:41:11,570:INFO:Declaring metric variables
2023-02-10 16:41:11,573:INFO:Importing untrained model
2023-02-10 16:41:11,576:INFO:Least Angle Regression Imported succesfully
2023-02-10 16:41:11,582:INFO:Starting cross validation
2023-02-10 16:41:11,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:41:14,464:INFO:Calculating mean and std
2023-02-10 16:41:14,465:INFO:Creating metrics dataframe
2023-02-10 16:41:14,469:INFO:Uploading results into container
2023-02-10 16:41:14,469:INFO:Uploading model into container now
2023-02-10 16:41:14,469:INFO:create_model_container: 5
2023-02-10 16:41:14,469:INFO:master_model_container: 5
2023-02-10 16:41:14,469:INFO:display_container: 2
2023-02-10 16:41:14,469:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize=True, precompute='auto',
     random_state=11, verbose=False)
2023-02-10 16:41:14,469:INFO:create_model() succesfully completed......................................
2023-02-10 16:41:14,576:INFO:SubProcess create_model() end ==================================
2023-02-10 16:41:14,577:INFO:Creating metrics dataframe
2023-02-10 16:41:14,583:INFO:Initializing Lasso Least Angle Regression
2023-02-10 16:41:14,583:INFO:Total runtime is 3.1711675961812333 minutes
2023-02-10 16:41:14,587:INFO:SubProcess create_model() called ==================================
2023-02-10 16:41:14,587:INFO:Initializing create_model()
2023-02-10 16:41:14,587:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:41:14,587:INFO:Checking exceptions
2023-02-10 16:41:14,587:INFO:Importing libraries
2023-02-10 16:41:14,587:INFO:Copying training dataset
2023-02-10 16:41:14,599:INFO:Defining folds
2023-02-10 16:41:14,599:INFO:Declaring metric variables
2023-02-10 16:41:14,603:INFO:Importing untrained model
2023-02-10 16:41:14,606:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-10 16:41:14,612:INFO:Starting cross validation
2023-02-10 16:41:14,612:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:41:17,279:INFO:Calculating mean and std
2023-02-10 16:41:17,279:INFO:Creating metrics dataframe
2023-02-10 16:41:17,283:INFO:Uploading results into container
2023-02-10 16:41:17,283:INFO:Uploading model into container now
2023-02-10 16:41:17,283:INFO:create_model_container: 6
2023-02-10 16:41:17,283:INFO:master_model_container: 6
2023-02-10 16:41:17,283:INFO:display_container: 2
2023-02-10 16:41:17,283:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-10 16:41:17,284:INFO:create_model() succesfully completed......................................
2023-02-10 16:41:17,382:INFO:SubProcess create_model() end ==================================
2023-02-10 16:41:17,382:INFO:Creating metrics dataframe
2023-02-10 16:41:17,388:INFO:Initializing Orthogonal Matching Pursuit
2023-02-10 16:41:17,389:INFO:Total runtime is 3.2179274121920263 minutes
2023-02-10 16:41:17,392:INFO:SubProcess create_model() called ==================================
2023-02-10 16:41:17,392:INFO:Initializing create_model()
2023-02-10 16:41:17,392:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:41:17,392:INFO:Checking exceptions
2023-02-10 16:41:17,392:INFO:Importing libraries
2023-02-10 16:41:17,392:INFO:Copying training dataset
2023-02-10 16:41:17,405:INFO:Defining folds
2023-02-10 16:41:17,405:INFO:Declaring metric variables
2023-02-10 16:41:17,408:INFO:Importing untrained model
2023-02-10 16:41:17,411:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 16:41:17,417:INFO:Starting cross validation
2023-02-10 16:41:17,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:41:20,152:INFO:Calculating mean and std
2023-02-10 16:41:20,153:INFO:Creating metrics dataframe
2023-02-10 16:41:20,156:INFO:Uploading results into container
2023-02-10 16:41:20,156:INFO:Uploading model into container now
2023-02-10 16:41:20,156:INFO:create_model_container: 7
2023-02-10 16:41:20,156:INFO:master_model_container: 7
2023-02-10 16:41:20,156:INFO:display_container: 2
2023-02-10 16:41:20,156:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 16:41:20,156:INFO:create_model() succesfully completed......................................
2023-02-10 16:41:20,274:INFO:SubProcess create_model() end ==================================
2023-02-10 16:41:20,274:INFO:Creating metrics dataframe
2023-02-10 16:41:20,281:INFO:Initializing Bayesian Ridge
2023-02-10 16:41:20,281:INFO:Total runtime is 3.2661334633827206 minutes
2023-02-10 16:41:20,284:INFO:SubProcess create_model() called ==================================
2023-02-10 16:41:20,285:INFO:Initializing create_model()
2023-02-10 16:41:20,285:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:41:20,285:INFO:Checking exceptions
2023-02-10 16:41:20,285:INFO:Importing libraries
2023-02-10 16:41:20,285:INFO:Copying training dataset
2023-02-10 16:41:20,297:INFO:Defining folds
2023-02-10 16:41:20,297:INFO:Declaring metric variables
2023-02-10 16:41:20,300:INFO:Importing untrained model
2023-02-10 16:41:20,303:INFO:Bayesian Ridge Imported succesfully
2023-02-10 16:41:20,309:INFO:Starting cross validation
2023-02-10 16:41:20,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:43:23,420:INFO:Calculating mean and std
2023-02-10 16:43:23,421:INFO:Creating metrics dataframe
2023-02-10 16:43:23,425:INFO:Uploading results into container
2023-02-10 16:43:23,425:INFO:Uploading model into container now
2023-02-10 16:43:23,425:INFO:create_model_container: 8
2023-02-10 16:43:23,425:INFO:master_model_container: 8
2023-02-10 16:43:23,425:INFO:display_container: 2
2023-02-10 16:43:23,426:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-10 16:43:23,426:INFO:create_model() succesfully completed......................................
2023-02-10 16:43:23,522:INFO:SubProcess create_model() end ==================================
2023-02-10 16:43:23,522:INFO:Creating metrics dataframe
2023-02-10 16:43:23,528:INFO:Initializing Passive Aggressive Regressor
2023-02-10 16:43:23,528:INFO:Total runtime is 5.320256038506825 minutes
2023-02-10 16:43:23,532:INFO:SubProcess create_model() called ==================================
2023-02-10 16:43:23,532:INFO:Initializing create_model()
2023-02-10 16:43:23,532:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:43:23,532:INFO:Checking exceptions
2023-02-10 16:43:23,532:INFO:Importing libraries
2023-02-10 16:43:23,532:INFO:Copying training dataset
2023-02-10 16:43:23,544:INFO:Defining folds
2023-02-10 16:43:23,544:INFO:Declaring metric variables
2023-02-10 16:43:23,547:INFO:Importing untrained model
2023-02-10 16:43:23,550:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-10 16:43:23,556:INFO:Starting cross validation
2023-02-10 16:43:23,556:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:43:25,591:INFO:Calculating mean and std
2023-02-10 16:43:25,591:INFO:Creating metrics dataframe
2023-02-10 16:43:25,595:INFO:Uploading results into container
2023-02-10 16:43:25,595:INFO:Uploading model into container now
2023-02-10 16:43:25,595:INFO:create_model_container: 9
2023-02-10 16:43:25,595:INFO:master_model_container: 9
2023-02-10 16:43:25,595:INFO:display_container: 2
2023-02-10 16:43:25,596:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-10 16:43:25,596:INFO:create_model() succesfully completed......................................
2023-02-10 16:43:25,693:INFO:SubProcess create_model() end ==================================
2023-02-10 16:43:25,694:INFO:Creating metrics dataframe
2023-02-10 16:43:25,700:INFO:Initializing Huber Regressor
2023-02-10 16:43:25,700:INFO:Total runtime is 5.356454988320667 minutes
2023-02-10 16:43:25,704:INFO:SubProcess create_model() called ==================================
2023-02-10 16:43:25,704:INFO:Initializing create_model()
2023-02-10 16:43:25,704:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:43:25,704:INFO:Checking exceptions
2023-02-10 16:43:25,704:INFO:Importing libraries
2023-02-10 16:43:25,704:INFO:Copying training dataset
2023-02-10 16:43:25,716:INFO:Defining folds
2023-02-10 16:43:25,716:INFO:Declaring metric variables
2023-02-10 16:43:25,719:INFO:Importing untrained model
2023-02-10 16:43:25,722:INFO:Huber Regressor Imported succesfully
2023-02-10 16:43:25,728:INFO:Starting cross validation
2023-02-10 16:43:25,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:43:52,115:INFO:Calculating mean and std
2023-02-10 16:43:52,116:INFO:Creating metrics dataframe
2023-02-10 16:43:52,119:INFO:Uploading results into container
2023-02-10 16:43:52,119:INFO:Uploading model into container now
2023-02-10 16:43:52,119:INFO:create_model_container: 10
2023-02-10 16:43:52,119:INFO:master_model_container: 10
2023-02-10 16:43:52,119:INFO:display_container: 2
2023-02-10 16:43:52,119:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-10 16:43:52,119:INFO:create_model() succesfully completed......................................
2023-02-10 16:43:52,237:INFO:SubProcess create_model() end ==================================
2023-02-10 16:43:52,237:INFO:Creating metrics dataframe
2023-02-10 16:43:52,244:INFO:Initializing K Neighbors Regressor
2023-02-10 16:43:52,244:INFO:Total runtime is 5.798857684930164 minutes
2023-02-10 16:43:52,248:INFO:SubProcess create_model() called ==================================
2023-02-10 16:43:52,248:INFO:Initializing create_model()
2023-02-10 16:43:52,248:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:43:52,248:INFO:Checking exceptions
2023-02-10 16:43:52,248:INFO:Importing libraries
2023-02-10 16:43:52,248:INFO:Copying training dataset
2023-02-10 16:43:52,262:INFO:Defining folds
2023-02-10 16:43:52,263:INFO:Declaring metric variables
2023-02-10 16:43:52,266:INFO:Importing untrained model
2023-02-10 16:43:52,269:INFO:K Neighbors Regressor Imported succesfully
2023-02-10 16:43:52,275:INFO:Starting cross validation
2023-02-10 16:43:52,276:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:44:03,282:INFO:Calculating mean and std
2023-02-10 16:44:03,282:INFO:Creating metrics dataframe
2023-02-10 16:44:03,286:INFO:Uploading results into container
2023-02-10 16:44:03,286:INFO:Uploading model into container now
2023-02-10 16:44:03,286:INFO:create_model_container: 11
2023-02-10 16:44:03,286:INFO:master_model_container: 11
2023-02-10 16:44:03,286:INFO:display_container: 2
2023-02-10 16:44:03,286:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-10 16:44:03,286:INFO:create_model() succesfully completed......................................
2023-02-10 16:44:03,401:INFO:SubProcess create_model() end ==================================
2023-02-10 16:44:03,401:INFO:Creating metrics dataframe
2023-02-10 16:44:03,408:INFO:Initializing Decision Tree Regressor
2023-02-10 16:44:03,408:INFO:Total runtime is 5.984922234217325 minutes
2023-02-10 16:44:03,412:INFO:SubProcess create_model() called ==================================
2023-02-10 16:44:03,412:INFO:Initializing create_model()
2023-02-10 16:44:03,412:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:44:03,412:INFO:Checking exceptions
2023-02-10 16:44:03,412:INFO:Importing libraries
2023-02-10 16:44:03,413:INFO:Copying training dataset
2023-02-10 16:44:03,425:INFO:Defining folds
2023-02-10 16:44:03,425:INFO:Declaring metric variables
2023-02-10 16:44:03,428:INFO:Importing untrained model
2023-02-10 16:44:03,432:INFO:Decision Tree Regressor Imported succesfully
2023-02-10 16:44:03,438:INFO:Starting cross validation
2023-02-10 16:44:03,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 16:46:46,952:INFO:Calculating mean and std
2023-02-10 16:46:46,953:INFO:Creating metrics dataframe
2023-02-10 16:46:46,956:INFO:Uploading results into container
2023-02-10 16:46:46,956:INFO:Uploading model into container now
2023-02-10 16:46:46,956:INFO:create_model_container: 12
2023-02-10 16:46:46,956:INFO:master_model_container: 12
2023-02-10 16:46:46,956:INFO:display_container: 2
2023-02-10 16:46:46,956:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-10 16:46:46,956:INFO:create_model() succesfully completed......................................
2023-02-10 16:46:47,068:INFO:SubProcess create_model() end ==================================
2023-02-10 16:46:47,068:INFO:Creating metrics dataframe
2023-02-10 16:46:47,075:INFO:Initializing Random Forest Regressor
2023-02-10 16:46:47,075:INFO:Total runtime is 8.712708648045856 minutes
2023-02-10 16:46:47,079:INFO:SubProcess create_model() called ==================================
2023-02-10 16:46:47,079:INFO:Initializing create_model()
2023-02-10 16:46:47,079:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 16:46:47,079:INFO:Checking exceptions
2023-02-10 16:46:47,079:INFO:Importing libraries
2023-02-10 16:46:47,079:INFO:Copying training dataset
2023-02-10 16:46:47,091:INFO:Defining folds
2023-02-10 16:46:47,092:INFO:Declaring metric variables
2023-02-10 16:46:47,094:INFO:Importing untrained model
2023-02-10 16:46:47,097:INFO:Random Forest Regressor Imported succesfully
2023-02-10 16:46:47,103:INFO:Starting cross validation
2023-02-10 16:46:47,104:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 17:53:15,036:INFO:Calculating mean and std
2023-02-10 17:53:15,037:INFO:Creating metrics dataframe
2023-02-10 17:53:15,041:INFO:Uploading results into container
2023-02-10 17:53:15,041:INFO:Uploading model into container now
2023-02-10 17:53:15,041:INFO:create_model_container: 13
2023-02-10 17:53:15,041:INFO:master_model_container: 13
2023-02-10 17:53:15,041:INFO:display_container: 2
2023-02-10 17:53:15,042:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-10 17:53:15,042:INFO:create_model() succesfully completed......................................
2023-02-10 17:53:15,136:INFO:SubProcess create_model() end ==================================
2023-02-10 17:53:15,136:INFO:Creating metrics dataframe
2023-02-10 17:53:15,143:INFO:Initializing Extra Trees Regressor
2023-02-10 17:53:15,143:INFO:Total runtime is 75.18050581614177 minutes
2023-02-10 17:53:15,147:INFO:SubProcess create_model() called ==================================
2023-02-10 17:53:15,147:INFO:Initializing create_model()
2023-02-10 17:53:15,147:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 17:53:15,147:INFO:Checking exceptions
2023-02-10 17:53:15,147:INFO:Importing libraries
2023-02-10 17:53:15,147:INFO:Copying training dataset
2023-02-10 17:53:15,159:INFO:Defining folds
2023-02-10 17:53:15,159:INFO:Declaring metric variables
2023-02-10 17:53:15,162:INFO:Importing untrained model
2023-02-10 17:53:15,165:INFO:Extra Trees Regressor Imported succesfully
2023-02-10 17:53:15,171:INFO:Starting cross validation
2023-02-10 17:53:15,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 18:39:32,298:INFO:Calculating mean and std
2023-02-10 18:39:32,299:INFO:Creating metrics dataframe
2023-02-10 18:39:32,302:INFO:Uploading results into container
2023-02-10 18:39:32,302:INFO:Uploading model into container now
2023-02-10 18:39:32,302:INFO:create_model_container: 14
2023-02-10 18:39:32,302:INFO:master_model_container: 14
2023-02-10 18:39:32,302:INFO:display_container: 2
2023-02-10 18:39:32,302:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-10 18:39:32,302:INFO:create_model() succesfully completed......................................
2023-02-10 18:39:32,423:INFO:SubProcess create_model() end ==================================
2023-02-10 18:39:32,423:INFO:Creating metrics dataframe
2023-02-10 18:39:32,431:INFO:Initializing AdaBoost Regressor
2023-02-10 18:39:32,431:INFO:Total runtime is 121.46862922906877 minutes
2023-02-10 18:39:32,435:INFO:SubProcess create_model() called ==================================
2023-02-10 18:39:32,435:INFO:Initializing create_model()
2023-02-10 18:39:32,435:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 18:39:32,435:INFO:Checking exceptions
2023-02-10 18:39:32,435:INFO:Importing libraries
2023-02-10 18:39:32,435:INFO:Copying training dataset
2023-02-10 18:39:32,450:INFO:Defining folds
2023-02-10 18:39:32,450:INFO:Declaring metric variables
2023-02-10 18:39:32,453:INFO:Importing untrained model
2023-02-10 18:39:32,456:INFO:AdaBoost Regressor Imported succesfully
2023-02-10 18:39:32,462:INFO:Starting cross validation
2023-02-10 18:39:32,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 18:44:05,468:INFO:Calculating mean and std
2023-02-10 18:44:05,469:INFO:Creating metrics dataframe
2023-02-10 18:44:05,473:INFO:Uploading results into container
2023-02-10 18:44:05,474:INFO:Uploading model into container now
2023-02-10 18:44:05,474:INFO:create_model_container: 15
2023-02-10 18:44:05,474:INFO:master_model_container: 15
2023-02-10 18:44:05,474:INFO:display_container: 2
2023-02-10 18:44:05,474:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-10 18:44:05,474:INFO:create_model() succesfully completed......................................
2023-02-10 18:44:05,577:INFO:SubProcess create_model() end ==================================
2023-02-10 18:44:05,577:INFO:Creating metrics dataframe
2023-02-10 18:44:05,585:INFO:Initializing Gradient Boosting Regressor
2023-02-10 18:44:05,585:INFO:Total runtime is 126.0211957216263 minutes
2023-02-10 18:44:05,588:INFO:SubProcess create_model() called ==================================
2023-02-10 18:44:05,588:INFO:Initializing create_model()
2023-02-10 18:44:05,588:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 18:44:05,588:INFO:Checking exceptions
2023-02-10 18:44:05,588:INFO:Importing libraries
2023-02-10 18:44:05,588:INFO:Copying training dataset
2023-02-10 18:44:05,601:INFO:Defining folds
2023-02-10 18:44:05,602:INFO:Declaring metric variables
2023-02-10 18:44:05,605:INFO:Importing untrained model
2023-02-10 18:44:05,608:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-10 18:44:05,614:INFO:Starting cross validation
2023-02-10 18:44:05,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:03:36,362:INFO:Calculating mean and std
2023-02-10 19:03:36,363:INFO:Creating metrics dataframe
2023-02-10 19:03:36,367:INFO:Uploading results into container
2023-02-10 19:03:36,367:INFO:Uploading model into container now
2023-02-10 19:03:36,367:INFO:create_model_container: 16
2023-02-10 19:03:36,367:INFO:master_model_container: 16
2023-02-10 19:03:36,367:INFO:display_container: 2
2023-02-10 19:03:36,368:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-10 19:03:36,368:INFO:create_model() succesfully completed......................................
2023-02-10 19:03:36,464:INFO:SubProcess create_model() end ==================================
2023-02-10 19:03:36,464:INFO:Creating metrics dataframe
2023-02-10 19:03:36,472:INFO:Initializing Extreme Gradient Boosting
2023-02-10 19:03:36,472:INFO:Total runtime is 145.5359892288844 minutes
2023-02-10 19:03:36,476:INFO:SubProcess create_model() called ==================================
2023-02-10 19:03:36,476:INFO:Initializing create_model()
2023-02-10 19:03:36,476:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 19:03:36,476:INFO:Checking exceptions
2023-02-10 19:03:36,476:INFO:Importing libraries
2023-02-10 19:03:36,476:INFO:Copying training dataset
2023-02-10 19:03:36,488:INFO:Defining folds
2023-02-10 19:03:36,488:INFO:Declaring metric variables
2023-02-10 19:03:36,492:INFO:Importing untrained model
2023-02-10 19:03:36,495:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-10 19:03:36,501:INFO:Starting cross validation
2023-02-10 19:03:36,502:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:11:45,825:INFO:Calculating mean and std
2023-02-10 19:11:45,826:INFO:Creating metrics dataframe
2023-02-10 19:11:45,831:INFO:Uploading results into container
2023-02-10 19:11:45,831:INFO:Uploading model into container now
2023-02-10 19:11:45,832:INFO:create_model_container: 17
2023-02-10 19:11:45,832:INFO:master_model_container: 17
2023-02-10 19:11:45,832:INFO:display_container: 2
2023-02-10 19:11:45,833:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-10 19:11:45,833:INFO:create_model() succesfully completed......................................
2023-02-10 19:11:45,933:INFO:SubProcess create_model() end ==================================
2023-02-10 19:11:45,933:INFO:Creating metrics dataframe
2023-02-10 19:11:45,941:INFO:Initializing Light Gradient Boosting Machine
2023-02-10 19:11:45,941:INFO:Total runtime is 153.69379905064903 minutes
2023-02-10 19:11:45,944:INFO:SubProcess create_model() called ==================================
2023-02-10 19:11:45,944:INFO:Initializing create_model()
2023-02-10 19:11:45,944:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 19:11:45,944:INFO:Checking exceptions
2023-02-10 19:11:45,944:INFO:Importing libraries
2023-02-10 19:11:45,944:INFO:Copying training dataset
2023-02-10 19:11:45,957:INFO:Defining folds
2023-02-10 19:11:45,957:INFO:Declaring metric variables
2023-02-10 19:11:45,960:INFO:Importing untrained model
2023-02-10 19:11:45,963:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-10 19:11:45,968:INFO:Starting cross validation
2023-02-10 19:11:45,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:13:00,220:INFO:Calculating mean and std
2023-02-10 19:13:00,221:INFO:Creating metrics dataframe
2023-02-10 19:13:00,227:INFO:Uploading results into container
2023-02-10 19:13:00,227:INFO:Uploading model into container now
2023-02-10 19:13:00,227:INFO:create_model_container: 18
2023-02-10 19:13:00,227:INFO:master_model_container: 18
2023-02-10 19:13:00,227:INFO:display_container: 2
2023-02-10 19:13:00,228:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-10 19:13:00,228:INFO:create_model() succesfully completed......................................
2023-02-10 19:13:00,335:INFO:SubProcess create_model() end ==================================
2023-02-10 19:13:00,335:INFO:Creating metrics dataframe
2023-02-10 19:13:00,343:INFO:Initializing CatBoost Regressor
2023-02-10 19:13:00,343:INFO:Total runtime is 154.93383920590085 minutes
2023-02-10 19:13:00,347:INFO:SubProcess create_model() called ==================================
2023-02-10 19:13:00,347:INFO:Initializing create_model()
2023-02-10 19:13:00,347:INFO:create_model(estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 19:13:00,347:INFO:Checking exceptions
2023-02-10 19:13:00,347:INFO:Importing libraries
2023-02-10 19:13:00,347:INFO:Copying training dataset
2023-02-10 19:13:00,360:INFO:Defining folds
2023-02-10 19:13:00,361:INFO:Declaring metric variables
2023-02-10 19:13:00,364:INFO:Importing untrained model
2023-02-10 19:13:00,367:INFO:CatBoost Regressor Imported succesfully
2023-02-10 19:13:00,373:INFO:Starting cross validation
2023-02-10 19:13:00,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:31:15,886:INFO:Calculating mean and std
2023-02-10 19:31:15,887:INFO:Creating metrics dataframe
2023-02-10 19:31:15,890:INFO:Uploading results into container
2023-02-10 19:31:15,890:INFO:Uploading model into container now
2023-02-10 19:31:15,890:INFO:create_model_container: 19
2023-02-10 19:31:15,890:INFO:master_model_container: 19
2023-02-10 19:31:15,890:INFO:display_container: 2
2023-02-10 19:31:15,890:INFO:<catboost.core.CatBoostRegressor object at 0x7f4abd5033a0>
2023-02-10 19:31:15,890:INFO:create_model() succesfully completed......................................
2023-02-10 19:31:15,998:INFO:SubProcess create_model() end ==================================
2023-02-10 19:31:15,998:INFO:Creating metrics dataframe
2023-02-10 19:31:16,006:INFO:Initializing Dummy Regressor
2023-02-10 19:31:16,007:INFO:Total runtime is 173.19489454825722 minutes
2023-02-10 19:31:16,010:INFO:SubProcess create_model() called ==================================
2023-02-10 19:31:16,010:INFO:Initializing create_model()
2023-02-10 19:31:16,010:INFO:create_model(estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdb9bee0>, return_train_score=False, kwargs={})
2023-02-10 19:31:16,010:INFO:Checking exceptions
2023-02-10 19:31:16,011:INFO:Importing libraries
2023-02-10 19:31:16,011:INFO:Copying training dataset
2023-02-10 19:31:16,023:INFO:Defining folds
2023-02-10 19:31:16,023:INFO:Declaring metric variables
2023-02-10 19:31:16,027:INFO:Importing untrained model
2023-02-10 19:31:16,030:INFO:Dummy Regressor Imported succesfully
2023-02-10 19:31:16,036:INFO:Starting cross validation
2023-02-10 19:31:16,036:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:31:16,975:INFO:Calculating mean and std
2023-02-10 19:31:16,976:INFO:Creating metrics dataframe
2023-02-10 19:31:16,979:INFO:Uploading results into container
2023-02-10 19:31:16,980:INFO:Uploading model into container now
2023-02-10 19:31:16,980:INFO:create_model_container: 20
2023-02-10 19:31:16,980:INFO:master_model_container: 20
2023-02-10 19:31:16,980:INFO:display_container: 2
2023-02-10 19:31:16,980:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-02-10 19:31:16,980:INFO:create_model() succesfully completed......................................
2023-02-10 19:31:17,087:INFO:SubProcess create_model() end ==================================
2023-02-10 19:31:17,087:INFO:Creating metrics dataframe
2023-02-10 19:31:17,103:INFO:Initializing create_model()
2023-02-10 19:31:17,103:INFO:create_model(estimator=<catboost.core.CatBoostRegressor object at 0x7f4abd5033a0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 19:31:17,103:INFO:Checking exceptions
2023-02-10 19:31:17,103:INFO:Importing libraries
2023-02-10 19:31:17,103:INFO:Copying training dataset
2023-02-10 19:31:17,116:INFO:Defining folds
2023-02-10 19:31:17,116:INFO:Declaring metric variables
2023-02-10 19:31:17,116:INFO:Importing untrained model
2023-02-10 19:31:17,116:INFO:Declaring custom model
2023-02-10 19:31:17,116:INFO:CatBoost Regressor Imported succesfully
2023-02-10 19:31:17,116:INFO:Cross validation set to False
2023-02-10 19:31:17,116:INFO:Fitting Model
2023-02-10 19:33:02,853:INFO:<catboost.core.CatBoostRegressor object at 0x7f4bc43ab730>
2023-02-10 19:33:02,853:INFO:create_models() succesfully completed......................................
2023-02-10 19:33:02,979:INFO:create_model_container: 20
2023-02-10 19:33:02,979:INFO:master_model_container: 20
2023-02-10 19:33:02,980:INFO:display_container: 2
2023-02-10 19:33:02,980:INFO:<catboost.core.CatBoostRegressor object at 0x7f4bc43ab730>
2023-02-10 19:33:02,980:INFO:compare_models() succesfully completed......................................
2023-02-10 19:35:42,203:INFO:PyCaret Supervised Module
2023-02-10 19:35:42,203:INFO:ML Usecase: regression
2023-02-10 19:35:42,203:INFO:version 2.3.10
2023-02-10 19:35:42,203:INFO:Initializing setup()
2023-02-10 19:35:42,203:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-10 19:35:42,203:INFO:Checking environment
2023-02-10 19:35:42,203:INFO:python_version: 3.9.16
2023-02-10 19:35:42,203:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-10 19:35:42,203:INFO:machine: x86_64
2023-02-10 19:35:42,203:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-10 19:35:42,203:INFO:Memory: svmem(total=134979592192, available=78125019136, percent=42.1, used=52812386304, free=33729105920, active=5589262336, inactive=92201250816, buffers=1455923200, cached=46982176768, shared=3222056960, slab=2633158656)
2023-02-10 19:35:42,204:INFO:Physical Core: 16
2023-02-10 19:35:42,204:INFO:Logical Core: 32
2023-02-10 19:35:42,204:INFO:Checking libraries
2023-02-10 19:35:42,204:INFO:pd==1.5.2
2023-02-10 19:35:42,204:INFO:numpy==1.20.3
2023-02-10 19:35:42,204:INFO:sklearn==0.23.2
2023-02-10 19:35:42,204:INFO:lightgbm==3.3.5
2023-02-10 19:35:42,204:INFO:catboost==1.1.1
2023-02-10 19:35:42,204:INFO:xgboost==1.7.3
2023-02-10 19:35:42,204:INFO:mlflow==2.1.1
2023-02-10 19:35:42,204:INFO:Checking Exceptions
2023-02-10 19:35:42,205:INFO:Declaring global variables
2023-02-10 19:35:42,205:INFO:USI: e2a3
2023-02-10 19:35:42,205:INFO:pycaret_globals: {'_ml_usecase', '_all_metrics', 'stratify_param', '_all_models', 'imputation_regressor', 'fold_shuffle_param', '_available_plots', 'fold_param', 'experiment__', 'create_model_container', 'gpu_param', 'pycaret_globals', 'data_before_preprocess', 'seed', 'fix_imbalance_param', 'X_train', 'target_param', 'X', 'prep_pipe', 'y_test', 'exp_name_log', '_internal_pipeline', 'n_jobs_param', 'master_model_container', 'fix_imbalance_method_param', 'dashboard_logger', 'transform_target_param', 'fold_groups_param_full', '_all_models_internal', 'logging_param', '_gpu_n_jobs_param', 'imputation_classifier', 'X_test', 'transform_target_method_param', 'y', 'display_container', 'fold_generator', 'fold_groups_param', 'USI', 'iterative_imputation_iters_param', 'y_train', 'log_plots_param', 'html_param'}
2023-02-10 19:35:42,205:INFO:Preparing display monitor
2023-02-10 19:35:42,205:INFO:Preparing display monitor
2023-02-10 19:35:42,209:INFO:Importing libraries
2023-02-10 19:35:42,210:INFO:Copying data for preprocessing
2023-02-10 19:35:42,378:INFO:Declaring preprocessing parameters
2023-02-10 19:35:42,688:INFO:Creating preprocessing pipeline
2023-02-10 19:35:50,513:INFO:Preprocessing pipeline created successfully
2023-02-10 19:35:50,513:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-10 19:35:50,513:INFO:Creating global containers
2023-02-10 19:35:50,514:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-10 19:53:15,135:INFO:Creating grid variables
2023-02-10 19:53:15,295:INFO:create_model_container: 0
2023-02-10 19:53:15,295:INFO:master_model_container: 0
2023-02-10 19:53:15,295:INFO:display_container: 1
2023-02-10 19:53:15,298:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-10 19:53:15,298:INFO:setup() succesfully completed......................................
2023-02-10 19:53:15,406:INFO:Initializing compare_models()
2023-02-10 19:53:15,406:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-02-10 19:53:15,406:INFO:Checking exceptions
2023-02-10 19:53:15,406:INFO:Preparing display monitor
2023-02-10 19:53:15,406:INFO:Preparing display monitor
2023-02-10 19:53:15,417:INFO:Initializing Linear Regression
2023-02-10 19:53:15,417:INFO:Total runtime is 1.4464060465494791e-06 minutes
2023-02-10 19:53:15,420:INFO:SubProcess create_model() called ==================================
2023-02-10 19:53:15,421:INFO:Initializing create_model()
2023-02-10 19:53:15,421:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 19:53:15,421:INFO:Checking exceptions
2023-02-10 19:53:15,421:INFO:Importing libraries
2023-02-10 19:53:15,421:INFO:Copying training dataset
2023-02-10 19:53:15,443:INFO:Defining folds
2023-02-10 19:53:15,444:INFO:Declaring metric variables
2023-02-10 19:53:15,447:INFO:Importing untrained model
2023-02-10 19:53:15,451:INFO:Linear Regression Imported succesfully
2023-02-10 19:53:15,457:INFO:Starting cross validation
2023-02-10 19:53:15,457:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:53:35,573:INFO:Calculating mean and std
2023-02-10 19:53:35,574:INFO:Creating metrics dataframe
2023-02-10 19:53:35,578:INFO:Uploading results into container
2023-02-10 19:53:35,578:INFO:Uploading model into container now
2023-02-10 19:53:35,578:INFO:create_model_container: 1
2023-02-10 19:53:35,578:INFO:master_model_container: 1
2023-02-10 19:53:35,578:INFO:display_container: 2
2023-02-10 19:53:35,579:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-10 19:53:35,579:INFO:create_model() succesfully completed......................................
2023-02-10 19:53:35,682:INFO:SubProcess create_model() end ==================================
2023-02-10 19:53:35,682:INFO:Creating metrics dataframe
2023-02-10 19:53:35,688:INFO:Initializing Lasso Regression
2023-02-10 19:53:35,688:INFO:Total runtime is 0.33784695466359455 minutes
2023-02-10 19:53:35,691:INFO:SubProcess create_model() called ==================================
2023-02-10 19:53:35,691:INFO:Initializing create_model()
2023-02-10 19:53:35,691:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 19:53:35,691:INFO:Checking exceptions
2023-02-10 19:53:35,692:INFO:Importing libraries
2023-02-10 19:53:35,692:INFO:Copying training dataset
2023-02-10 19:53:35,714:INFO:Defining folds
2023-02-10 19:53:35,714:INFO:Declaring metric variables
2023-02-10 19:53:35,718:INFO:Importing untrained model
2023-02-10 19:53:35,721:INFO:Lasso Regression Imported succesfully
2023-02-10 19:53:35,727:INFO:Starting cross validation
2023-02-10 19:53:35,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:54:25,604:INFO:Calculating mean and std
2023-02-10 19:54:25,605:INFO:Creating metrics dataframe
2023-02-10 19:54:25,610:INFO:Uploading results into container
2023-02-10 19:54:25,610:INFO:Uploading model into container now
2023-02-10 19:54:25,610:INFO:create_model_container: 2
2023-02-10 19:54:25,610:INFO:master_model_container: 2
2023-02-10 19:54:25,610:INFO:display_container: 2
2023-02-10 19:54:25,610:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 19:54:25,611:INFO:create_model() succesfully completed......................................
2023-02-10 19:54:25,705:INFO:SubProcess create_model() end ==================================
2023-02-10 19:54:25,705:INFO:Creating metrics dataframe
2023-02-10 19:54:25,711:INFO:Initializing Ridge Regression
2023-02-10 19:54:25,712:INFO:Total runtime is 1.1715744018554688 minutes
2023-02-10 19:54:25,715:INFO:SubProcess create_model() called ==================================
2023-02-10 19:54:25,715:INFO:Initializing create_model()
2023-02-10 19:54:25,715:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 19:54:25,715:INFO:Checking exceptions
2023-02-10 19:54:25,716:INFO:Importing libraries
2023-02-10 19:54:25,716:INFO:Copying training dataset
2023-02-10 19:54:25,738:INFO:Defining folds
2023-02-10 19:54:25,738:INFO:Declaring metric variables
2023-02-10 19:54:25,742:INFO:Importing untrained model
2023-02-10 19:54:25,745:INFO:Ridge Regression Imported succesfully
2023-02-10 19:54:25,752:INFO:Starting cross validation
2023-02-10 19:54:25,752:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:55:01,767:INFO:Calculating mean and std
2023-02-10 19:55:01,767:INFO:Creating metrics dataframe
2023-02-10 19:55:01,771:INFO:Uploading results into container
2023-02-10 19:55:01,771:INFO:Uploading model into container now
2023-02-10 19:55:01,771:INFO:create_model_container: 3
2023-02-10 19:55:01,771:INFO:master_model_container: 3
2023-02-10 19:55:01,771:INFO:display_container: 2
2023-02-10 19:55:01,771:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-10 19:55:01,771:INFO:create_model() succesfully completed......................................
2023-02-10 19:55:01,866:INFO:SubProcess create_model() end ==================================
2023-02-10 19:55:01,867:INFO:Creating metrics dataframe
2023-02-10 19:55:01,873:INFO:Initializing Elastic Net
2023-02-10 19:55:01,873:INFO:Total runtime is 1.7742625991503398 minutes
2023-02-10 19:55:01,876:INFO:SubProcess create_model() called ==================================
2023-02-10 19:55:01,877:INFO:Initializing create_model()
2023-02-10 19:55:01,877:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 19:55:01,877:INFO:Checking exceptions
2023-02-10 19:55:01,877:INFO:Importing libraries
2023-02-10 19:55:01,877:INFO:Copying training dataset
2023-02-10 19:55:01,900:INFO:Defining folds
2023-02-10 19:55:01,900:INFO:Declaring metric variables
2023-02-10 19:55:01,903:INFO:Importing untrained model
2023-02-10 19:55:01,907:INFO:Elastic Net Imported succesfully
2023-02-10 19:55:01,913:INFO:Starting cross validation
2023-02-10 19:55:01,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:55:50,909:INFO:Calculating mean and std
2023-02-10 19:55:50,910:INFO:Creating metrics dataframe
2023-02-10 19:55:50,914:INFO:Uploading results into container
2023-02-10 19:55:50,914:INFO:Uploading model into container now
2023-02-10 19:55:50,914:INFO:create_model_container: 4
2023-02-10 19:55:50,914:INFO:master_model_container: 4
2023-02-10 19:55:50,914:INFO:display_container: 2
2023-02-10 19:55:50,915:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-10 19:55:50,915:INFO:create_model() succesfully completed......................................
2023-02-10 19:55:51,008:INFO:SubProcess create_model() end ==================================
2023-02-10 19:55:51,008:INFO:Creating metrics dataframe
2023-02-10 19:55:51,014:INFO:Initializing Least Angle Regression
2023-02-10 19:55:51,014:INFO:Total runtime is 2.5932908852895102 minutes
2023-02-10 19:55:51,018:INFO:SubProcess create_model() called ==================================
2023-02-10 19:55:51,018:INFO:Initializing create_model()
2023-02-10 19:55:51,018:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 19:55:51,018:INFO:Checking exceptions
2023-02-10 19:55:51,018:INFO:Importing libraries
2023-02-10 19:55:51,018:INFO:Copying training dataset
2023-02-10 19:55:51,040:INFO:Defining folds
2023-02-10 19:55:51,041:INFO:Declaring metric variables
2023-02-10 19:55:51,044:INFO:Importing untrained model
2023-02-10 19:55:51,047:INFO:Least Angle Regression Imported succesfully
2023-02-10 19:55:51,052:INFO:Starting cross validation
2023-02-10 19:55:51,053:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:55:53,523:INFO:Calculating mean and std
2023-02-10 19:55:53,524:INFO:Creating metrics dataframe
2023-02-10 19:55:53,528:INFO:Uploading results into container
2023-02-10 19:55:53,528:INFO:Uploading model into container now
2023-02-10 19:55:53,528:INFO:create_model_container: 5
2023-02-10 19:55:53,528:INFO:master_model_container: 5
2023-02-10 19:55:53,528:INFO:display_container: 2
2023-02-10 19:55:53,528:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize=True, precompute='auto',
     random_state=11, verbose=False)
2023-02-10 19:55:53,528:INFO:create_model() succesfully completed......................................
2023-02-10 19:55:53,624:INFO:SubProcess create_model() end ==================================
2023-02-10 19:55:53,624:INFO:Creating metrics dataframe
2023-02-10 19:55:53,630:INFO:Initializing Lasso Least Angle Regression
2023-02-10 19:55:53,630:INFO:Total runtime is 2.6368832548459373 minutes
2023-02-10 19:55:53,633:INFO:SubProcess create_model() called ==================================
2023-02-10 19:55:53,634:INFO:Initializing create_model()
2023-02-10 19:55:53,634:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 19:55:53,634:INFO:Checking exceptions
2023-02-10 19:55:53,634:INFO:Importing libraries
2023-02-10 19:55:53,634:INFO:Copying training dataset
2023-02-10 19:55:53,657:INFO:Defining folds
2023-02-10 19:55:53,657:INFO:Declaring metric variables
2023-02-10 19:55:53,661:INFO:Importing untrained model
2023-02-10 19:55:53,664:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-10 19:55:53,669:INFO:Starting cross validation
2023-02-10 19:55:53,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:55:55,969:INFO:Calculating mean and std
2023-02-10 19:55:55,970:INFO:Creating metrics dataframe
2023-02-10 19:55:55,975:INFO:Uploading results into container
2023-02-10 19:55:55,975:INFO:Uploading model into container now
2023-02-10 19:55:55,975:INFO:create_model_container: 6
2023-02-10 19:55:55,975:INFO:master_model_container: 6
2023-02-10 19:55:55,975:INFO:display_container: 2
2023-02-10 19:55:55,975:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-10 19:55:55,975:INFO:create_model() succesfully completed......................................
2023-02-10 19:55:56,070:INFO:SubProcess create_model() end ==================================
2023-02-10 19:55:56,070:INFO:Creating metrics dataframe
2023-02-10 19:55:56,076:INFO:Initializing Orthogonal Matching Pursuit
2023-02-10 19:55:56,076:INFO:Total runtime is 2.6776511947313946 minutes
2023-02-10 19:55:56,079:INFO:SubProcess create_model() called ==================================
2023-02-10 19:55:56,079:INFO:Initializing create_model()
2023-02-10 19:55:56,080:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 19:55:56,080:INFO:Checking exceptions
2023-02-10 19:55:56,080:INFO:Importing libraries
2023-02-10 19:55:56,080:INFO:Copying training dataset
2023-02-10 19:55:56,102:INFO:Defining folds
2023-02-10 19:55:56,102:INFO:Declaring metric variables
2023-02-10 19:55:56,106:INFO:Importing untrained model
2023-02-10 19:55:56,108:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 19:55:56,114:INFO:Starting cross validation
2023-02-10 19:55:56,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 19:55:58,450:INFO:Calculating mean and std
2023-02-10 19:55:58,451:INFO:Creating metrics dataframe
2023-02-10 19:55:58,454:INFO:Uploading results into container
2023-02-10 19:55:58,454:INFO:Uploading model into container now
2023-02-10 19:55:58,455:INFO:create_model_container: 7
2023-02-10 19:55:58,455:INFO:master_model_container: 7
2023-02-10 19:55:58,455:INFO:display_container: 2
2023-02-10 19:55:58,455:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 19:55:58,455:INFO:create_model() succesfully completed......................................
2023-02-10 19:55:58,559:INFO:SubProcess create_model() end ==================================
2023-02-10 19:55:58,559:INFO:Creating metrics dataframe
2023-02-10 19:55:58,565:INFO:Initializing Bayesian Ridge
2023-02-10 19:55:58,565:INFO:Total runtime is 2.719138026237488 minutes
2023-02-10 19:55:58,569:INFO:SubProcess create_model() called ==================================
2023-02-10 19:55:58,569:INFO:Initializing create_model()
2023-02-10 19:55:58,569:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 19:55:58,569:INFO:Checking exceptions
2023-02-10 19:55:58,569:INFO:Importing libraries
2023-02-10 19:55:58,569:INFO:Copying training dataset
2023-02-10 19:55:58,591:INFO:Defining folds
2023-02-10 19:55:58,591:INFO:Declaring metric variables
2023-02-10 19:55:58,595:INFO:Importing untrained model
2023-02-10 19:55:58,598:INFO:Bayesian Ridge Imported succesfully
2023-02-10 19:55:58,603:INFO:Starting cross validation
2023-02-10 19:55:58,604:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 20:01:00,818:INFO:Calculating mean and std
2023-02-10 20:01:00,819:INFO:Creating metrics dataframe
2023-02-10 20:01:00,823:INFO:Uploading results into container
2023-02-10 20:01:00,823:INFO:Uploading model into container now
2023-02-10 20:01:00,823:INFO:create_model_container: 8
2023-02-10 20:01:00,823:INFO:master_model_container: 8
2023-02-10 20:01:00,823:INFO:display_container: 2
2023-02-10 20:01:00,824:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-10 20:01:00,824:INFO:create_model() succesfully completed......................................
2023-02-10 20:01:00,918:INFO:SubProcess create_model() end ==================================
2023-02-10 20:01:00,918:INFO:Creating metrics dataframe
2023-02-10 20:01:00,924:INFO:Initializing Passive Aggressive Regressor
2023-02-10 20:01:00,924:INFO:Total runtime is 7.758456556002299 minutes
2023-02-10 20:01:00,928:INFO:SubProcess create_model() called ==================================
2023-02-10 20:01:00,928:INFO:Initializing create_model()
2023-02-10 20:01:00,928:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 20:01:00,928:INFO:Checking exceptions
2023-02-10 20:01:00,928:INFO:Importing libraries
2023-02-10 20:01:00,928:INFO:Copying training dataset
2023-02-10 20:01:00,953:INFO:Defining folds
2023-02-10 20:01:00,953:INFO:Declaring metric variables
2023-02-10 20:01:00,956:INFO:Importing untrained model
2023-02-10 20:01:00,959:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-10 20:01:00,965:INFO:Starting cross validation
2023-02-10 20:01:00,966:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 20:01:03,456:INFO:Calculating mean and std
2023-02-10 20:01:03,457:INFO:Creating metrics dataframe
2023-02-10 20:01:03,462:INFO:Uploading results into container
2023-02-10 20:01:03,462:INFO:Uploading model into container now
2023-02-10 20:01:03,462:INFO:create_model_container: 9
2023-02-10 20:01:03,462:INFO:master_model_container: 9
2023-02-10 20:01:03,462:INFO:display_container: 2
2023-02-10 20:01:03,463:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-10 20:01:03,463:INFO:create_model() succesfully completed......................................
2023-02-10 20:01:03,568:INFO:SubProcess create_model() end ==================================
2023-02-10 20:01:03,569:INFO:Creating metrics dataframe
2023-02-10 20:01:03,576:INFO:Initializing Huber Regressor
2023-02-10 20:01:03,576:INFO:Total runtime is 7.802643219629924 minutes
2023-02-10 20:01:03,579:INFO:SubProcess create_model() called ==================================
2023-02-10 20:01:03,579:INFO:Initializing create_model()
2023-02-10 20:01:03,579:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 20:01:03,579:INFO:Checking exceptions
2023-02-10 20:01:03,579:INFO:Importing libraries
2023-02-10 20:01:03,579:INFO:Copying training dataset
2023-02-10 20:01:03,602:INFO:Defining folds
2023-02-10 20:01:03,602:INFO:Declaring metric variables
2023-02-10 20:01:03,605:INFO:Importing untrained model
2023-02-10 20:01:03,608:INFO:Huber Regressor Imported succesfully
2023-02-10 20:01:03,614:INFO:Starting cross validation
2023-02-10 20:01:03,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 20:02:21,222:INFO:Calculating mean and std
2023-02-10 20:02:21,223:INFO:Creating metrics dataframe
2023-02-10 20:02:21,227:INFO:Uploading results into container
2023-02-10 20:02:21,227:INFO:Uploading model into container now
2023-02-10 20:02:21,227:INFO:create_model_container: 10
2023-02-10 20:02:21,227:INFO:master_model_container: 10
2023-02-10 20:02:21,227:INFO:display_container: 2
2023-02-10 20:02:21,228:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-10 20:02:21,228:INFO:create_model() succesfully completed......................................
2023-02-10 20:02:21,342:INFO:SubProcess create_model() end ==================================
2023-02-10 20:02:21,342:INFO:Creating metrics dataframe
2023-02-10 20:02:21,355:INFO:Initializing K Neighbors Regressor
2023-02-10 20:02:21,355:INFO:Total runtime is 9.098972098032634 minutes
2023-02-10 20:02:21,360:INFO:SubProcess create_model() called ==================================
2023-02-10 20:02:21,360:INFO:Initializing create_model()
2023-02-10 20:02:21,361:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 20:02:21,361:INFO:Checking exceptions
2023-02-10 20:02:21,361:INFO:Importing libraries
2023-02-10 20:02:21,361:INFO:Copying training dataset
2023-02-10 20:02:21,384:INFO:Defining folds
2023-02-10 20:02:21,384:INFO:Declaring metric variables
2023-02-10 20:02:21,387:INFO:Importing untrained model
2023-02-10 20:02:21,391:INFO:K Neighbors Regressor Imported succesfully
2023-02-10 20:02:21,397:INFO:Starting cross validation
2023-02-10 20:02:21,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 20:02:30,514:INFO:Calculating mean and std
2023-02-10 20:02:30,515:INFO:Creating metrics dataframe
2023-02-10 20:02:30,519:INFO:Uploading results into container
2023-02-10 20:02:30,519:INFO:Uploading model into container now
2023-02-10 20:02:30,519:INFO:create_model_container: 11
2023-02-10 20:02:30,520:INFO:master_model_container: 11
2023-02-10 20:02:30,520:INFO:display_container: 2
2023-02-10 20:02:30,520:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-10 20:02:30,520:INFO:create_model() succesfully completed......................................
2023-02-10 20:02:30,616:INFO:SubProcess create_model() end ==================================
2023-02-10 20:02:30,616:INFO:Creating metrics dataframe
2023-02-10 20:02:30,623:INFO:Initializing Decision Tree Regressor
2023-02-10 20:02:30,623:INFO:Total runtime is 9.25343821446101 minutes
2023-02-10 20:02:30,627:INFO:SubProcess create_model() called ==================================
2023-02-10 20:02:30,627:INFO:Initializing create_model()
2023-02-10 20:02:30,627:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 20:02:30,627:INFO:Checking exceptions
2023-02-10 20:02:30,627:INFO:Importing libraries
2023-02-10 20:02:30,627:INFO:Copying training dataset
2023-02-10 20:02:30,650:INFO:Defining folds
2023-02-10 20:02:30,650:INFO:Declaring metric variables
2023-02-10 20:02:30,654:INFO:Importing untrained model
2023-02-10 20:02:30,658:INFO:Decision Tree Regressor Imported succesfully
2023-02-10 20:02:30,664:INFO:Starting cross validation
2023-02-10 20:02:30,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 20:03:18,838:INFO:Calculating mean and std
2023-02-10 20:03:18,839:INFO:Creating metrics dataframe
2023-02-10 20:03:18,842:INFO:Uploading results into container
2023-02-10 20:03:18,842:INFO:Uploading model into container now
2023-02-10 20:03:18,842:INFO:create_model_container: 12
2023-02-10 20:03:18,842:INFO:master_model_container: 12
2023-02-10 20:03:18,842:INFO:display_container: 2
2023-02-10 20:03:18,842:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-10 20:03:18,843:INFO:create_model() succesfully completed......................................
2023-02-10 20:03:18,940:INFO:SubProcess create_model() end ==================================
2023-02-10 20:03:18,940:INFO:Creating metrics dataframe
2023-02-10 20:03:18,947:INFO:Initializing Random Forest Regressor
2023-02-10 20:03:18,947:INFO:Total runtime is 10.05883770386378 minutes
2023-02-10 20:03:18,951:INFO:SubProcess create_model() called ==================================
2023-02-10 20:03:18,951:INFO:Initializing create_model()
2023-02-10 20:03:18,951:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 20:03:18,951:INFO:Checking exceptions
2023-02-10 20:03:18,951:INFO:Importing libraries
2023-02-10 20:03:18,951:INFO:Copying training dataset
2023-02-10 20:03:18,974:INFO:Defining folds
2023-02-10 20:03:18,974:INFO:Declaring metric variables
2023-02-10 20:03:18,978:INFO:Importing untrained model
2023-02-10 20:03:18,982:INFO:Random Forest Regressor Imported succesfully
2023-02-10 20:03:18,988:INFO:Starting cross validation
2023-02-10 20:03:18,988:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 20:25:11,129:INFO:Calculating mean and std
2023-02-10 20:25:11,130:INFO:Creating metrics dataframe
2023-02-10 20:25:11,134:INFO:Uploading results into container
2023-02-10 20:25:11,134:INFO:Uploading model into container now
2023-02-10 20:25:11,135:INFO:create_model_container: 13
2023-02-10 20:25:11,135:INFO:master_model_container: 13
2023-02-10 20:25:11,135:INFO:display_container: 2
2023-02-10 20:25:11,135:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-10 20:25:11,135:INFO:create_model() succesfully completed......................................
2023-02-10 20:25:11,233:INFO:SubProcess create_model() end ==================================
2023-02-10 20:25:11,233:INFO:Creating metrics dataframe
2023-02-10 20:25:11,240:INFO:Initializing Extra Trees Regressor
2023-02-10 20:25:11,241:INFO:Total runtime is 31.93039207061132 minutes
2023-02-10 20:25:11,245:INFO:SubProcess create_model() called ==================================
2023-02-10 20:25:11,245:INFO:Initializing create_model()
2023-02-10 20:25:11,245:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 20:25:11,245:INFO:Checking exceptions
2023-02-10 20:25:11,245:INFO:Importing libraries
2023-02-10 20:25:11,245:INFO:Copying training dataset
2023-02-10 20:25:11,268:INFO:Defining folds
2023-02-10 20:25:11,268:INFO:Declaring metric variables
2023-02-10 20:25:11,271:INFO:Importing untrained model
2023-02-10 20:25:11,274:INFO:Extra Trees Regressor Imported succesfully
2023-02-10 20:25:11,280:INFO:Starting cross validation
2023-02-10 20:25:11,280:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 20:45:55,944:INFO:Calculating mean and std
2023-02-10 20:45:55,945:INFO:Creating metrics dataframe
2023-02-10 20:45:55,952:INFO:Uploading results into container
2023-02-10 20:45:55,952:INFO:Uploading model into container now
2023-02-10 20:45:55,952:INFO:create_model_container: 14
2023-02-10 20:45:55,952:INFO:master_model_container: 14
2023-02-10 20:45:55,952:INFO:display_container: 2
2023-02-10 20:45:55,953:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-10 20:45:55,953:INFO:create_model() succesfully completed......................................
2023-02-10 20:45:56,062:INFO:SubProcess create_model() end ==================================
2023-02-10 20:45:56,062:INFO:Creating metrics dataframe
2023-02-10 20:45:56,069:INFO:Initializing AdaBoost Regressor
2023-02-10 20:45:56,069:INFO:Total runtime is 52.67753800948461 minutes
2023-02-10 20:45:56,073:INFO:SubProcess create_model() called ==================================
2023-02-10 20:45:56,073:INFO:Initializing create_model()
2023-02-10 20:45:56,073:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 20:45:56,073:INFO:Checking exceptions
2023-02-10 20:45:56,073:INFO:Importing libraries
2023-02-10 20:45:56,073:INFO:Copying training dataset
2023-02-10 20:45:56,097:INFO:Defining folds
2023-02-10 20:45:56,097:INFO:Declaring metric variables
2023-02-10 20:45:56,101:INFO:Importing untrained model
2023-02-10 20:45:56,104:INFO:AdaBoost Regressor Imported succesfully
2023-02-10 20:45:56,110:INFO:Starting cross validation
2023-02-10 20:45:56,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 20:50:50,095:INFO:Calculating mean and std
2023-02-10 20:50:50,096:INFO:Creating metrics dataframe
2023-02-10 20:50:50,100:INFO:Uploading results into container
2023-02-10 20:50:50,100:INFO:Uploading model into container now
2023-02-10 20:50:50,100:INFO:create_model_container: 15
2023-02-10 20:50:50,100:INFO:master_model_container: 15
2023-02-10 20:50:50,100:INFO:display_container: 2
2023-02-10 20:50:50,100:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-10 20:50:50,101:INFO:create_model() succesfully completed......................................
2023-02-10 20:50:50,201:INFO:SubProcess create_model() end ==================================
2023-02-10 20:50:50,201:INFO:Creating metrics dataframe
2023-02-10 20:50:50,209:INFO:Initializing Gradient Boosting Regressor
2023-02-10 20:50:50,209:INFO:Total runtime is 57.579860325654344 minutes
2023-02-10 20:50:50,213:INFO:SubProcess create_model() called ==================================
2023-02-10 20:50:50,213:INFO:Initializing create_model()
2023-02-10 20:50:50,213:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 20:50:50,213:INFO:Checking exceptions
2023-02-10 20:50:50,213:INFO:Importing libraries
2023-02-10 20:50:50,213:INFO:Copying training dataset
2023-02-10 20:50:50,236:INFO:Defining folds
2023-02-10 20:50:50,236:INFO:Declaring metric variables
2023-02-10 20:50:50,239:INFO:Importing untrained model
2023-02-10 20:50:50,242:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-10 20:50:50,248:INFO:Starting cross validation
2023-02-10 20:50:50,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:08:17,893:INFO:Calculating mean and std
2023-02-10 21:08:17,894:INFO:Creating metrics dataframe
2023-02-10 21:08:17,899:INFO:Uploading results into container
2023-02-10 21:08:17,899:INFO:Uploading model into container now
2023-02-10 21:08:17,899:INFO:create_model_container: 16
2023-02-10 21:08:17,899:INFO:master_model_container: 16
2023-02-10 21:08:17,899:INFO:display_container: 2
2023-02-10 21:08:17,899:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-10 21:08:17,900:INFO:create_model() succesfully completed......................................
2023-02-10 21:08:17,993:INFO:SubProcess create_model() end ==================================
2023-02-10 21:08:17,993:INFO:Creating metrics dataframe
2023-02-10 21:08:18,000:INFO:Initializing Extreme Gradient Boosting
2023-02-10 21:08:18,000:INFO:Total runtime is 75.04305095672606 minutes
2023-02-10 21:08:18,003:INFO:SubProcess create_model() called ==================================
2023-02-10 21:08:18,003:INFO:Initializing create_model()
2023-02-10 21:08:18,003:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 21:08:18,004:INFO:Checking exceptions
2023-02-10 21:08:18,004:INFO:Importing libraries
2023-02-10 21:08:18,004:INFO:Copying training dataset
2023-02-10 21:08:18,026:INFO:Defining folds
2023-02-10 21:08:18,026:INFO:Declaring metric variables
2023-02-10 21:08:18,030:INFO:Importing untrained model
2023-02-10 21:08:18,033:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-10 21:08:18,038:INFO:Starting cross validation
2023-02-10 21:08:18,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:15:46,111:INFO:Calculating mean and std
2023-02-10 21:15:46,112:INFO:Creating metrics dataframe
2023-02-10 21:15:46,116:INFO:Uploading results into container
2023-02-10 21:15:46,116:INFO:Uploading model into container now
2023-02-10 21:15:46,116:INFO:create_model_container: 17
2023-02-10 21:15:46,116:INFO:master_model_container: 17
2023-02-10 21:15:46,116:INFO:display_container: 2
2023-02-10 21:15:46,116:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-10 21:15:46,116:INFO:create_model() succesfully completed......................................
2023-02-10 21:15:46,218:INFO:SubProcess create_model() end ==================================
2023-02-10 21:15:46,219:INFO:Creating metrics dataframe
2023-02-10 21:15:46,226:INFO:Initializing Light Gradient Boosting Machine
2023-02-10 21:15:46,226:INFO:Total runtime is 82.51348392963408 minutes
2023-02-10 21:15:46,229:INFO:SubProcess create_model() called ==================================
2023-02-10 21:15:46,230:INFO:Initializing create_model()
2023-02-10 21:15:46,230:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 21:15:46,230:INFO:Checking exceptions
2023-02-10 21:15:46,230:INFO:Importing libraries
2023-02-10 21:15:46,230:INFO:Copying training dataset
2023-02-10 21:15:46,252:INFO:Defining folds
2023-02-10 21:15:46,253:INFO:Declaring metric variables
2023-02-10 21:15:46,256:INFO:Importing untrained model
2023-02-10 21:15:46,259:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-10 21:15:46,265:INFO:Starting cross validation
2023-02-10 21:15:46,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:16:57,970:INFO:Calculating mean and std
2023-02-10 21:16:57,971:INFO:Creating metrics dataframe
2023-02-10 21:16:57,977:INFO:Uploading results into container
2023-02-10 21:16:57,977:INFO:Uploading model into container now
2023-02-10 21:16:57,977:INFO:create_model_container: 18
2023-02-10 21:16:57,977:INFO:master_model_container: 18
2023-02-10 21:16:57,977:INFO:display_container: 2
2023-02-10 21:16:57,978:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-10 21:16:57,978:INFO:create_model() succesfully completed......................................
2023-02-10 21:16:58,081:INFO:SubProcess create_model() end ==================================
2023-02-10 21:16:58,081:INFO:Creating metrics dataframe
2023-02-10 21:16:58,089:INFO:Initializing CatBoost Regressor
2023-02-10 21:16:58,090:INFO:Total runtime is 83.71120918591815 minutes
2023-02-10 21:16:58,096:INFO:SubProcess create_model() called ==================================
2023-02-10 21:16:58,096:INFO:Initializing create_model()
2023-02-10 21:16:58,097:INFO:create_model(estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 21:16:58,097:INFO:Checking exceptions
2023-02-10 21:16:58,097:INFO:Importing libraries
2023-02-10 21:16:58,097:INFO:Copying training dataset
2023-02-10 21:16:58,123:INFO:Defining folds
2023-02-10 21:16:58,123:INFO:Declaring metric variables
2023-02-10 21:16:58,127:INFO:Importing untrained model
2023-02-10 21:16:58,131:INFO:CatBoost Regressor Imported succesfully
2023-02-10 21:16:58,138:INFO:Starting cross validation
2023-02-10 21:16:58,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:33:45,409:INFO:Calculating mean and std
2023-02-10 21:33:45,410:INFO:Creating metrics dataframe
2023-02-10 21:33:45,415:INFO:Uploading results into container
2023-02-10 21:33:45,415:INFO:Uploading model into container now
2023-02-10 21:33:45,416:INFO:create_model_container: 19
2023-02-10 21:33:45,416:INFO:master_model_container: 19
2023-02-10 21:33:45,416:INFO:display_container: 2
2023-02-10 21:33:45,416:INFO:<catboost.core.CatBoostRegressor object at 0x7f4bc44fa520>
2023-02-10 21:33:45,416:INFO:create_model() succesfully completed......................................
2023-02-10 21:33:45,522:INFO:SubProcess create_model() end ==================================
2023-02-10 21:33:45,522:INFO:Creating metrics dataframe
2023-02-10 21:33:45,531:INFO:Initializing Dummy Regressor
2023-02-10 21:33:45,531:INFO:Total runtime is 100.50190222263333 minutes
2023-02-10 21:33:45,535:INFO:SubProcess create_model() called ==================================
2023-02-10 21:33:45,535:INFO:Initializing create_model()
2023-02-10 21:33:45,535:INFO:create_model(estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6f34be0>, return_train_score=False, kwargs={})
2023-02-10 21:33:45,535:INFO:Checking exceptions
2023-02-10 21:33:45,535:INFO:Importing libraries
2023-02-10 21:33:45,535:INFO:Copying training dataset
2023-02-10 21:33:45,557:INFO:Defining folds
2023-02-10 21:33:45,558:INFO:Declaring metric variables
2023-02-10 21:33:45,561:INFO:Importing untrained model
2023-02-10 21:33:45,564:INFO:Dummy Regressor Imported succesfully
2023-02-10 21:33:45,570:INFO:Starting cross validation
2023-02-10 21:33:45,570:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:33:46,563:INFO:Calculating mean and std
2023-02-10 21:33:46,563:INFO:Creating metrics dataframe
2023-02-10 21:33:46,567:INFO:Uploading results into container
2023-02-10 21:33:46,567:INFO:Uploading model into container now
2023-02-10 21:33:46,568:INFO:create_model_container: 20
2023-02-10 21:33:46,568:INFO:master_model_container: 20
2023-02-10 21:33:46,568:INFO:display_container: 2
2023-02-10 21:33:46,568:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-02-10 21:33:46,568:INFO:create_model() succesfully completed......................................
2023-02-10 21:33:46,670:INFO:SubProcess create_model() end ==================================
2023-02-10 21:33:46,671:INFO:Creating metrics dataframe
2023-02-10 21:33:46,686:INFO:Initializing create_model()
2023-02-10 21:33:46,686:INFO:create_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 21:33:46,686:INFO:Checking exceptions
2023-02-10 21:33:46,687:INFO:Importing libraries
2023-02-10 21:33:46,687:INFO:Copying training dataset
2023-02-10 21:33:46,709:INFO:Defining folds
2023-02-10 21:33:46,710:INFO:Declaring metric variables
2023-02-10 21:33:46,710:INFO:Importing untrained model
2023-02-10 21:33:46,710:INFO:Declaring custom model
2023-02-10 21:33:46,710:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 21:33:46,710:INFO:Cross validation set to False
2023-02-10 21:33:46,710:INFO:Fitting Model
2023-02-10 21:33:47,030:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:33:47,030:INFO:create_models() succesfully completed......................................
2023-02-10 21:33:47,162:INFO:create_model_container: 20
2023-02-10 21:33:47,162:INFO:master_model_container: 20
2023-02-10 21:33:47,162:INFO:display_container: 2
2023-02-10 21:33:47,162:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:33:47,162:INFO:compare_models() succesfully completed......................................
2023-02-10 21:40:55,784:INFO:Initializing create_model()
2023-02-10 21:40:55,784:INFO:create_model(estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 21:40:55,784:INFO:Checking exceptions
2023-02-10 21:40:55,784:INFO:Preparing display monitor
2023-02-10 21:40:55,793:INFO:Importing libraries
2023-02-10 21:40:55,793:INFO:Copying training dataset
2023-02-10 21:40:55,817:INFO:Defining folds
2023-02-10 21:40:55,818:INFO:Declaring metric variables
2023-02-10 21:40:55,823:INFO:Importing untrained model
2023-02-10 21:40:55,828:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 21:40:55,837:INFO:Starting cross validation
2023-02-10 21:40:55,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:40:59,775:INFO:Calculating mean and std
2023-02-10 21:40:59,776:INFO:Creating metrics dataframe
2023-02-10 21:40:59,786:INFO:Finalizing model
2023-02-10 21:41:00,133:INFO:Uploading results into container
2023-02-10 21:41:00,133:INFO:Uploading model into container now
2023-02-10 21:41:00,139:INFO:create_model_container: 21
2023-02-10 21:41:00,139:INFO:master_model_container: 21
2023-02-10 21:41:00,139:INFO:display_container: 3
2023-02-10 21:41:00,139:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:41:00,139:INFO:create_model() succesfully completed......................................
2023-02-10 21:41:00,303:INFO:Initializing tune_model()
2023-02-10 21:41:00,303:INFO:tune_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=False, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={'select_best': True})
2023-02-10 21:41:00,303:INFO:Checking exceptions
2023-02-10 21:41:00,303:INFO:Preparing display monitor
2023-02-10 21:41:00,311:INFO:Copying training dataset
2023-02-10 21:41:00,324:INFO:Checking base model
2023-02-10 21:41:00,325:INFO:Base model : Orthogonal Matching Pursuit
2023-02-10 21:41:00,331:INFO:Declaring metric variables
2023-02-10 21:41:00,337:INFO:Defining Hyperparameters
2023-02-10 21:41:00,436:INFO:Tuning with n_jobs=-1
2023-02-10 21:41:00,436:INFO:Initializing RandomizedSearchCV
2023-02-10 21:42:34,213:INFO:Initializing create_model()
2023-02-10 21:42:34,214:INFO:create_model(estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 21:42:34,214:INFO:Checking exceptions
2023-02-10 21:42:34,214:INFO:Preparing display monitor
2023-02-10 21:42:34,222:INFO:Importing libraries
2023-02-10 21:42:34,223:INFO:Copying training dataset
2023-02-10 21:42:34,245:INFO:Defining folds
2023-02-10 21:42:34,245:INFO:Declaring metric variables
2023-02-10 21:42:34,251:INFO:Importing untrained model
2023-02-10 21:42:34,256:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 21:42:34,266:INFO:Starting cross validation
2023-02-10 21:42:34,266:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:42:37,605:INFO:Calculating mean and std
2023-02-10 21:42:37,605:INFO:Creating metrics dataframe
2023-02-10 21:42:37,613:INFO:Finalizing model
2023-02-10 21:42:37,923:INFO:Uploading results into container
2023-02-10 21:42:37,923:INFO:Uploading model into container now
2023-02-10 21:42:37,929:INFO:create_model_container: 22
2023-02-10 21:42:37,929:INFO:master_model_container: 22
2023-02-10 21:42:37,929:INFO:display_container: 4
2023-02-10 21:42:37,929:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:42:37,929:INFO:create_model() succesfully completed......................................
2023-02-10 21:42:38,042:INFO:Initializing tune_model()
2023-02-10 21:42:38,042:INFO:tune_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-02-10 21:42:38,042:INFO:Checking exceptions
2023-02-10 21:42:38,042:INFO:Preparing display monitor
2023-02-10 21:42:38,049:INFO:Copying training dataset
2023-02-10 21:42:38,061:INFO:Checking base model
2023-02-10 21:42:38,061:INFO:Base model : Orthogonal Matching Pursuit
2023-02-10 21:42:38,066:INFO:Declaring metric variables
2023-02-10 21:42:38,071:INFO:Defining Hyperparameters
2023-02-10 21:42:38,164:INFO:Tuning with n_jobs=-1
2023-02-10 21:42:38,165:INFO:Initializing RandomizedSearchCV
2023-02-10 21:43:00,940:INFO:best_params: {'actual_estimator__normalize': True, 'actual_estimator__n_nonzero_coefs': 1933, 'actual_estimator__fit_intercept': True}
2023-02-10 21:43:00,940:INFO:Hyperparameter search completed
2023-02-10 21:43:00,940:INFO:SubProcess create_model() called ==================================
2023-02-10 21:43:00,941:INFO:Initializing create_model()
2023-02-10 21:43:00,941:INFO:create_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc40c90a0>, return_train_score=False, kwargs={'normalize': True, 'n_nonzero_coefs': 1933, 'fit_intercept': True})
2023-02-10 21:43:00,941:INFO:Checking exceptions
2023-02-10 21:43:00,941:INFO:Importing libraries
2023-02-10 21:43:00,941:INFO:Copying training dataset
2023-02-10 21:43:00,965:INFO:Defining folds
2023-02-10 21:43:00,965:INFO:Declaring metric variables
2023-02-10 21:43:00,970:INFO:Importing untrained model
2023-02-10 21:43:00,970:INFO:Declaring custom model
2023-02-10 21:43:00,976:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 21:43:00,985:INFO:Starting cross validation
2023-02-10 21:43:00,986:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:43:04,890:INFO:Calculating mean and std
2023-02-10 21:43:04,891:INFO:Creating metrics dataframe
2023-02-10 21:43:04,901:INFO:Finalizing model
2023-02-10 21:43:05,958:INFO:Uploading results into container
2023-02-10 21:43:05,958:INFO:Uploading model into container now
2023-02-10 21:43:05,958:INFO:create_model_container: 23
2023-02-10 21:43:05,958:INFO:master_model_container: 23
2023-02-10 21:43:05,958:INFO:display_container: 5
2023-02-10 21:43:05,958:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=1933,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:43:05,958:INFO:create_model() succesfully completed......................................
2023-02-10 21:43:06,097:INFO:SubProcess create_model() end ==================================
2023-02-10 21:43:06,097:INFO:choose_better activated
2023-02-10 21:43:06,103:INFO:SubProcess create_model() called ==================================
2023-02-10 21:43:06,103:INFO:Initializing create_model()
2023-02-10 21:43:06,103:INFO:create_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 21:43:06,103:INFO:Checking exceptions
2023-02-10 21:43:06,103:INFO:Importing libraries
2023-02-10 21:43:06,103:INFO:Copying training dataset
2023-02-10 21:43:06,126:INFO:Defining folds
2023-02-10 21:43:06,126:INFO:Declaring metric variables
2023-02-10 21:43:06,126:INFO:Importing untrained model
2023-02-10 21:43:06,126:INFO:Declaring custom model
2023-02-10 21:43:06,126:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 21:43:06,126:INFO:Starting cross validation
2023-02-10 21:43:06,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:43:08,470:INFO:Calculating mean and std
2023-02-10 21:43:08,470:INFO:Creating metrics dataframe
2023-02-10 21:43:08,472:INFO:Finalizing model
2023-02-10 21:43:08,783:INFO:Uploading results into container
2023-02-10 21:43:08,783:INFO:Uploading model into container now
2023-02-10 21:43:08,783:INFO:create_model_container: 24
2023-02-10 21:43:08,783:INFO:master_model_container: 24
2023-02-10 21:43:08,783:INFO:display_container: 6
2023-02-10 21:43:08,783:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:43:08,783:INFO:create_model() succesfully completed......................................
2023-02-10 21:43:08,895:INFO:SubProcess create_model() end ==================================
2023-02-10 21:43:08,896:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None) result for R2 is 0.9531
2023-02-10 21:43:08,896:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=1933,
                          normalize=True, precompute='auto', tol=None) result for R2 is 0.9452
2023-02-10 21:43:08,896:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None) is best model
2023-02-10 21:43:08,896:INFO:choose_better completed
2023-02-10 21:43:08,900:INFO:create_model_container: 24
2023-02-10 21:43:08,900:INFO:master_model_container: 24
2023-02-10 21:43:08,900:INFO:display_container: 5
2023-02-10 21:43:08,900:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:43:08,900:INFO:tune_model() succesfully completed......................................
2023-02-10 21:48:03,897:INFO:Initializing create_model()
2023-02-10 21:48:03,897:INFO:create_model(estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 21:48:03,897:INFO:Checking exceptions
2023-02-10 21:48:03,897:INFO:Preparing display monitor
2023-02-10 21:48:03,907:INFO:Importing libraries
2023-02-10 21:48:03,907:INFO:Copying training dataset
2023-02-10 21:48:03,918:INFO:Defining folds
2023-02-10 21:48:03,918:INFO:Declaring metric variables
2023-02-10 21:48:03,923:INFO:Importing untrained model
2023-02-10 21:48:03,928:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 21:48:03,937:INFO:Starting cross validation
2023-02-10 21:48:03,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:48:06,492:INFO:Calculating mean and std
2023-02-10 21:48:06,492:INFO:Creating metrics dataframe
2023-02-10 21:48:06,501:INFO:Finalizing model
2023-02-10 21:48:06,829:INFO:Uploading results into container
2023-02-10 21:48:06,829:INFO:Uploading model into container now
2023-02-10 21:48:06,835:INFO:create_model_container: 25
2023-02-10 21:48:06,835:INFO:master_model_container: 25
2023-02-10 21:48:06,836:INFO:display_container: 6
2023-02-10 21:48:06,837:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:48:06,837:INFO:create_model() succesfully completed......................................
2023-02-10 21:48:06,957:INFO:Initializing tune_model()
2023-02-10 21:48:06,957:INFO:tune_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-02-10 21:48:06,957:INFO:Checking exceptions
2023-02-10 21:48:06,957:INFO:Preparing display monitor
2023-02-10 21:48:06,965:INFO:Copying training dataset
2023-02-10 21:48:06,976:INFO:Checking base model
2023-02-10 21:48:06,977:INFO:Base model : Orthogonal Matching Pursuit
2023-02-10 21:48:06,982:INFO:Declaring metric variables
2023-02-10 21:48:06,986:INFO:Defining Hyperparameters
2023-02-10 21:48:07,076:INFO:Tuning with n_jobs=-1
2023-02-10 21:48:07,077:INFO:Initializing RandomizedSearchCV
2023-02-10 21:48:29,508:INFO:best_params: {'actual_estimator__normalize': True, 'actual_estimator__n_nonzero_coefs': 1933, 'actual_estimator__fit_intercept': True}
2023-02-10 21:48:29,508:INFO:Hyperparameter search completed
2023-02-10 21:48:29,509:INFO:SubProcess create_model() called ==================================
2023-02-10 21:48:29,509:INFO:Initializing create_model()
2023-02-10 21:48:29,509:INFO:create_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4abdefd7f0>, return_train_score=False, kwargs={'normalize': True, 'n_nonzero_coefs': 1933, 'fit_intercept': True})
2023-02-10 21:48:29,509:INFO:Checking exceptions
2023-02-10 21:48:29,509:INFO:Importing libraries
2023-02-10 21:48:29,509:INFO:Copying training dataset
2023-02-10 21:48:29,523:INFO:Defining folds
2023-02-10 21:48:29,523:INFO:Declaring metric variables
2023-02-10 21:48:29,534:INFO:Importing untrained model
2023-02-10 21:48:29,534:INFO:Declaring custom model
2023-02-10 21:48:29,543:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 21:48:29,557:INFO:Starting cross validation
2023-02-10 21:48:29,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:48:33,602:INFO:Calculating mean and std
2023-02-10 21:48:33,603:INFO:Creating metrics dataframe
2023-02-10 21:48:33,611:INFO:Finalizing model
2023-02-10 21:48:34,748:INFO:Uploading results into container
2023-02-10 21:48:34,748:INFO:Uploading model into container now
2023-02-10 21:48:34,748:INFO:create_model_container: 26
2023-02-10 21:48:34,748:INFO:master_model_container: 26
2023-02-10 21:48:34,748:INFO:display_container: 7
2023-02-10 21:48:34,748:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=1933,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:48:34,748:INFO:create_model() succesfully completed......................................
2023-02-10 21:48:34,890:INFO:SubProcess create_model() end ==================================
2023-02-10 21:48:34,890:INFO:choose_better activated
2023-02-10 21:48:34,896:INFO:SubProcess create_model() called ==================================
2023-02-10 21:48:34,896:INFO:Initializing create_model()
2023-02-10 21:48:34,896:INFO:create_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 21:48:34,896:INFO:Checking exceptions
2023-02-10 21:48:34,896:INFO:Importing libraries
2023-02-10 21:48:34,896:INFO:Copying training dataset
2023-02-10 21:48:34,907:INFO:Defining folds
2023-02-10 21:48:34,907:INFO:Declaring metric variables
2023-02-10 21:48:34,907:INFO:Importing untrained model
2023-02-10 21:48:34,907:INFO:Declaring custom model
2023-02-10 21:48:34,907:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-10 21:48:34,907:INFO:Starting cross validation
2023-02-10 21:48:34,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 21:48:37,219:INFO:Calculating mean and std
2023-02-10 21:48:37,220:INFO:Creating metrics dataframe
2023-02-10 21:48:37,221:INFO:Finalizing model
2023-02-10 21:48:37,535:INFO:Uploading results into container
2023-02-10 21:48:37,535:INFO:Uploading model into container now
2023-02-10 21:48:37,535:INFO:create_model_container: 27
2023-02-10 21:48:37,536:INFO:master_model_container: 27
2023-02-10 21:48:37,536:INFO:display_container: 8
2023-02-10 21:48:37,536:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:48:37,536:INFO:create_model() succesfully completed......................................
2023-02-10 21:48:37,647:INFO:SubProcess create_model() end ==================================
2023-02-10 21:48:37,647:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None) result for R2 is 0.9531
2023-02-10 21:48:37,648:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=1933,
                          normalize=True, precompute='auto', tol=None) result for R2 is 0.9452
2023-02-10 21:48:37,648:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None) is best model
2023-02-10 21:48:37,648:INFO:choose_better completed
2023-02-10 21:48:37,651:INFO:create_model_container: 27
2023-02-10 21:48:37,651:INFO:master_model_container: 27
2023-02-10 21:48:37,652:INFO:display_container: 7
2023-02-10 21:48:37,652:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-10 21:48:37,652:INFO:tune_model() succesfully completed......................................
2023-02-10 21:48:37,733:INFO:Initializing create_model()
2023-02-10 21:48:37,733:INFO:create_model(estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 21:48:37,733:INFO:Checking exceptions
2023-02-10 21:48:37,733:INFO:Preparing display monitor
2023-02-10 21:48:37,742:INFO:Importing libraries
2023-02-10 21:48:37,742:INFO:Copying training dataset
2023-02-10 21:48:37,753:INFO:Defining folds
2023-02-10 21:48:37,753:INFO:Declaring metric variables
2023-02-10 21:48:37,758:INFO:Importing untrained model
2023-02-10 21:48:37,763:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-10 21:48:37,772:INFO:Starting cross validation
2023-02-10 21:48:37,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 22:06:11,871:INFO:Calculating mean and std
2023-02-10 22:06:11,872:INFO:Creating metrics dataframe
2023-02-10 22:06:11,881:INFO:Finalizing model
2023-02-10 22:24:39,134:INFO:Uploading results into container
2023-02-10 22:24:39,134:INFO:Uploading model into container now
2023-02-10 22:24:39,138:INFO:create_model_container: 28
2023-02-10 22:24:39,139:INFO:master_model_container: 28
2023-02-10 22:24:39,139:INFO:display_container: 8
2023-02-10 22:24:39,139:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-10 22:24:39,139:INFO:create_model() succesfully completed......................................
2023-02-10 22:24:39,238:INFO:Initializing tune_model()
2023-02-10 22:24:39,238:INFO:tune_model(estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-02-10 22:24:39,238:INFO:Checking exceptions
2023-02-10 22:24:39,238:INFO:Preparing display monitor
2023-02-10 22:24:39,246:INFO:Copying training dataset
2023-02-10 22:24:39,257:INFO:Checking base model
2023-02-10 22:24:39,257:INFO:Base model : Gradient Boosting Regressor
2023-02-10 22:24:39,263:INFO:Declaring metric variables
2023-02-10 22:24:39,268:INFO:Defining Hyperparameters
2023-02-10 22:24:39,359:INFO:Tuning with n_jobs=-1
2023-02-10 22:24:39,359:INFO:Initializing RandomizedSearchCV
2023-02-10 23:22:12,599:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 110, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 11, 'actual_estimator__learning_rate': 0.05}
2023-02-10 23:22:12,600:INFO:Hyperparameter search completed
2023-02-10 23:22:12,600:INFO:SubProcess create_model() called ==================================
2023-02-10 23:22:12,601:INFO:Initializing create_model()
2023-02-10 23:22:12,601:INFO:create_model(estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bda8f98b0>, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 110, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.001, 'max_features': 1.0, 'max_depth': 11, 'learning_rate': 0.05})
2023-02-10 23:22:12,601:INFO:Checking exceptions
2023-02-10 23:22:12,601:INFO:Importing libraries
2023-02-10 23:22:12,601:INFO:Copying training dataset
2023-02-10 23:22:12,624:INFO:Defining folds
2023-02-10 23:22:12,624:INFO:Declaring metric variables
2023-02-10 23:22:12,630:INFO:Importing untrained model
2023-02-10 23:22:12,630:INFO:Declaring custom model
2023-02-10 23:22:12,635:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-10 23:22:12,645:INFO:Starting cross validation
2023-02-10 23:22:12,645:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-10 23:35:36,855:INFO:Calculating mean and std
2023-02-10 23:35:36,856:INFO:Creating metrics dataframe
2023-02-10 23:35:36,866:INFO:Finalizing model
2023-02-10 23:50:00,879:INFO:Uploading results into container
2023-02-10 23:50:00,879:INFO:Uploading model into container now
2023-02-10 23:50:00,879:INFO:create_model_container: 29
2023-02-10 23:50:00,879:INFO:master_model_container: 29
2023-02-10 23:50:00,879:INFO:display_container: 9
2023-02-10 23:50:00,880:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.05, loss='ls',
                          max_depth=11, max_features=1.0, max_leaf_nodes=None,
                          min_impurity_decrease=0.001, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=110,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=0.35, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-10 23:50:00,880:INFO:create_model() succesfully completed......................................
2023-02-10 23:50:00,981:INFO:SubProcess create_model() end ==================================
2023-02-10 23:50:00,981:INFO:choose_better activated
2023-02-10 23:50:00,986:INFO:SubProcess create_model() called ==================================
2023-02-10 23:50:00,987:INFO:Initializing create_model()
2023-02-10 23:50:00,987:INFO:create_model(estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-10 23:50:00,987:INFO:Checking exceptions
2023-02-10 23:50:00,987:INFO:Importing libraries
2023-02-10 23:50:00,987:INFO:Copying training dataset
2023-02-10 23:50:01,008:INFO:Defining folds
2023-02-10 23:50:01,008:INFO:Declaring metric variables
2023-02-10 23:50:01,008:INFO:Importing untrained model
2023-02-10 23:50:01,008:INFO:Declaring custom model
2023-02-10 23:50:01,008:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-10 23:50:01,008:INFO:Starting cross validation
2023-02-10 23:50:01,009:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-11 00:07:34,465:INFO:Calculating mean and std
2023-02-11 00:07:34,466:INFO:Creating metrics dataframe
2023-02-11 00:07:34,467:INFO:Finalizing model
2023-02-11 00:25:45,743:INFO:Uploading results into container
2023-02-11 00:25:45,743:INFO:Uploading model into container now
2023-02-11 00:25:45,743:INFO:create_model_container: 30
2023-02-11 00:25:45,743:INFO:master_model_container: 30
2023-02-11 00:25:45,743:INFO:display_container: 10
2023-02-11 00:25:45,743:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-11 00:25:45,743:INFO:create_model() succesfully completed......................................
2023-02-11 00:25:45,842:INFO:SubProcess create_model() end ==================================
2023-02-11 00:25:45,843:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for R2 is 0.9516
2023-02-11 00:25:45,843:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.05, loss='ls',
                          max_depth=11, max_features=1.0, max_leaf_nodes=None,
                          min_impurity_decrease=0.001, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=110,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=0.35, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for R2 is 0.9476
2023-02-11 00:25:45,843:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) is best model
2023-02-11 00:25:45,844:INFO:choose_better completed
2023-02-11 00:25:45,848:INFO:create_model_container: 30
2023-02-11 00:25:45,848:INFO:master_model_container: 30
2023-02-11 00:25:45,848:INFO:display_container: 9
2023-02-11 00:25:45,848:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-11 00:25:45,848:INFO:tune_model() succesfully completed......................................
2023-02-11 00:25:45,931:INFO:Initializing create_model()
2023-02-11 00:25:45,931:INFO:create_model(estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-11 00:25:45,931:INFO:Checking exceptions
2023-02-11 00:25:45,931:INFO:Preparing display monitor
2023-02-11 00:25:45,939:INFO:Importing libraries
2023-02-11 00:25:45,939:INFO:Copying training dataset
2023-02-11 00:25:45,950:INFO:Defining folds
2023-02-11 00:25:45,950:INFO:Declaring metric variables
2023-02-11 00:25:45,955:INFO:Importing untrained model
2023-02-11 00:25:45,960:INFO:CatBoost Regressor Imported succesfully
2023-02-11 00:25:45,969:INFO:Starting cross validation
2023-02-11 00:25:45,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-11 00:42:33,209:INFO:Calculating mean and std
2023-02-11 00:42:33,210:INFO:Creating metrics dataframe
2023-02-11 00:42:33,219:INFO:Finalizing model
2023-02-11 00:44:10,876:INFO:Uploading results into container
2023-02-11 00:44:10,877:INFO:Uploading model into container now
2023-02-11 00:44:10,881:INFO:create_model_container: 31
2023-02-11 00:44:10,881:INFO:master_model_container: 31
2023-02-11 00:44:10,881:INFO:display_container: 10
2023-02-11 00:44:10,881:INFO:<catboost.core.CatBoostRegressor object at 0x7f4bc6ddcb20>
2023-02-11 00:44:10,881:INFO:create_model() succesfully completed......................................
2023-02-11 00:44:11,001:INFO:Initializing tune_model()
2023-02-11 00:44:11,001:INFO:tune_model(estimator=<catboost.core.CatBoostRegressor object at 0x7f4bc6ddcb20>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-02-11 00:44:11,001:INFO:Checking exceptions
2023-02-11 00:44:11,001:INFO:Preparing display monitor
2023-02-11 00:44:11,009:INFO:Copying training dataset
2023-02-11 00:44:11,020:INFO:Checking base model
2023-02-11 00:44:11,020:INFO:Base model : CatBoost Regressor
2023-02-11 00:44:11,026:INFO:Declaring metric variables
2023-02-11 00:44:11,031:INFO:Defining Hyperparameters
2023-02-11 00:44:11,124:INFO:Tuning with n_jobs=-1
2023-02-11 00:44:11,124:INFO:Initializing RandomizedSearchCV
2023-02-11 02:14:26,138:INFO:best_params: {'actual_estimator__random_strength': 0.5, 'actual_estimator__n_estimators': 280, 'actual_estimator__l2_leaf_reg': 9, 'actual_estimator__eta': 0.1, 'actual_estimator__depth': 8}
2023-02-11 02:14:26,138:INFO:Hyperparameter search completed
2023-02-11 02:14:26,138:INFO:SubProcess create_model() called ==================================
2023-02-11 02:14:26,139:INFO:Initializing create_model()
2023-02-11 02:14:26,139:INFO:create_model(estimator=<catboost.core.CatBoostRegressor object at 0x7f4abd5dd640>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc44db760>, return_train_score=False, kwargs={'random_strength': 0.5, 'n_estimators': 280, 'l2_leaf_reg': 9, 'eta': 0.1, 'depth': 8})
2023-02-11 02:14:26,139:INFO:Checking exceptions
2023-02-11 02:14:26,139:INFO:Importing libraries
2023-02-11 02:14:26,139:INFO:Copying training dataset
2023-02-11 02:14:26,162:INFO:Defining folds
2023-02-11 02:14:26,162:INFO:Declaring metric variables
2023-02-11 02:14:26,168:INFO:Importing untrained model
2023-02-11 02:14:26,168:INFO:Declaring custom model
2023-02-11 02:14:26,173:INFO:CatBoost Regressor Imported succesfully
2023-02-11 02:14:26,182:INFO:Starting cross validation
2023-02-11 02:14:26,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-11 02:32:17,231:INFO:Calculating mean and std
2023-02-11 02:32:17,232:INFO:Creating metrics dataframe
2023-02-11 02:32:17,240:INFO:Finalizing model
2023-02-11 02:34:01,683:INFO:Uploading results into container
2023-02-11 02:34:01,684:INFO:Uploading model into container now
2023-02-11 02:34:01,684:INFO:create_model_container: 32
2023-02-11 02:34:01,684:INFO:master_model_container: 32
2023-02-11 02:34:01,684:INFO:display_container: 11
2023-02-11 02:34:01,684:INFO:<catboost.core.CatBoostRegressor object at 0x7f4abd5ddd60>
2023-02-11 02:34:01,684:INFO:create_model() succesfully completed......................................
2023-02-11 02:34:01,803:INFO:SubProcess create_model() end ==================================
2023-02-11 02:34:01,803:INFO:choose_better activated
2023-02-11 02:34:01,810:INFO:SubProcess create_model() called ==================================
2023-02-11 02:34:01,810:INFO:Initializing create_model()
2023-02-11 02:34:01,810:INFO:create_model(estimator=<catboost.core.CatBoostRegressor object at 0x7f4bc6ddcb20>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-11 02:34:01,810:INFO:Checking exceptions
2023-02-11 02:34:01,810:INFO:Importing libraries
2023-02-11 02:34:01,810:INFO:Copying training dataset
2023-02-11 02:34:01,832:INFO:Defining folds
2023-02-11 02:34:01,832:INFO:Declaring metric variables
2023-02-11 02:34:01,832:INFO:Importing untrained model
2023-02-11 02:34:01,832:INFO:Declaring custom model
2023-02-11 02:34:01,833:INFO:CatBoost Regressor Imported succesfully
2023-02-11 02:34:01,833:INFO:Starting cross validation
2023-02-11 02:34:01,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-11 02:50:47,413:INFO:Calculating mean and std
2023-02-11 02:50:47,414:INFO:Creating metrics dataframe
2023-02-11 02:50:47,416:INFO:Finalizing model
2023-02-11 02:52:24,997:INFO:Uploading results into container
2023-02-11 02:52:24,997:INFO:Uploading model into container now
2023-02-11 02:52:24,997:INFO:create_model_container: 33
2023-02-11 02:52:24,997:INFO:master_model_container: 33
2023-02-11 02:52:24,997:INFO:display_container: 12
2023-02-11 02:52:24,997:INFO:<catboost.core.CatBoostRegressor object at 0x7f4abd5e3f70>
2023-02-11 02:52:24,997:INFO:create_model() succesfully completed......................................
2023-02-11 02:52:25,119:INFO:SubProcess create_model() end ==================================
2023-02-11 02:52:25,119:INFO:<catboost.core.CatBoostRegressor object at 0x7f4abd5e3f70> result for R2 is 0.9485
2023-02-11 02:52:25,120:INFO:<catboost.core.CatBoostRegressor object at 0x7f4abd5ddd60> result for R2 is 0.9462
2023-02-11 02:52:25,120:INFO:<catboost.core.CatBoostRegressor object at 0x7f4abd5e3f70> is best model
2023-02-11 02:52:25,120:INFO:choose_better completed
2023-02-11 02:52:25,124:INFO:create_model_container: 33
2023-02-11 02:52:25,124:INFO:master_model_container: 33
2023-02-11 02:52:25,124:INFO:display_container: 11
2023-02-11 02:52:25,124:INFO:<catboost.core.CatBoostRegressor object at 0x7f4abd5e3f70>
2023-02-11 02:52:25,124:INFO:tune_model() succesfully completed......................................
2023-02-11 02:52:25,211:INFO:Initializing create_model()
2023-02-11 02:52:25,212:INFO:create_model(estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-11 02:52:25,212:INFO:Checking exceptions
2023-02-11 02:52:25,212:INFO:Preparing display monitor
2023-02-11 02:52:25,220:INFO:Importing libraries
2023-02-11 02:52:25,220:INFO:Copying training dataset
2023-02-11 02:52:25,232:INFO:Defining folds
2023-02-11 02:52:25,232:INFO:Declaring metric variables
2023-02-11 02:52:25,237:INFO:Importing untrained model
2023-02-11 02:52:25,242:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-11 02:52:25,254:INFO:Starting cross validation
2023-02-11 02:52:25,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-11 02:53:37,515:INFO:Calculating mean and std
2023-02-11 02:53:37,516:INFO:Creating metrics dataframe
2023-02-11 02:53:37,528:INFO:Finalizing model
2023-02-11 02:53:43,998:INFO:Uploading results into container
2023-02-11 02:53:43,999:INFO:Uploading model into container now
2023-02-11 02:53:44,003:INFO:create_model_container: 34
2023-02-11 02:53:44,003:INFO:master_model_container: 34
2023-02-11 02:53:44,003:INFO:display_container: 12
2023-02-11 02:53:44,003:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-11 02:53:44,003:INFO:create_model() succesfully completed......................................
2023-02-11 02:53:44,109:INFO:Initializing tune_model()
2023-02-11 02:53:44,109:INFO:tune_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-02-11 02:53:44,109:INFO:Checking exceptions
2023-02-11 02:53:44,109:INFO:Preparing display monitor
2023-02-11 02:53:44,117:INFO:Copying training dataset
2023-02-11 02:53:44,129:INFO:Checking base model
2023-02-11 02:53:44,129:INFO:Base model : Light Gradient Boosting Machine
2023-02-11 02:53:44,134:INFO:Declaring metric variables
2023-02-11 02:53:44,139:INFO:Defining Hyperparameters
2023-02-11 02:53:44,236:INFO:Tuning with n_jobs=-1
2023-02-11 02:53:44,236:INFO:Initializing RandomizedSearchCV
2023-02-11 02:56:20,573:INFO:best_params: {'actual_estimator__reg_lambda': 0.01, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 290, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 0.6}
2023-02-11 02:56:20,574:INFO:Hyperparameter search completed
2023-02-11 02:56:20,574:INFO:SubProcess create_model() called ==================================
2023-02-11 02:56:20,575:INFO:Initializing create_model()
2023-02-11 02:56:20,575:INFO:create_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f4bc6c522b0>, return_train_score=False, kwargs={'reg_lambda': 0.01, 'reg_alpha': 0.5, 'num_leaves': 256, 'n_estimators': 290, 'min_split_gain': 0.3, 'min_child_samples': 61, 'learning_rate': 0.3, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 0.6})
2023-02-11 02:56:20,575:INFO:Checking exceptions
2023-02-11 02:56:20,575:INFO:Importing libraries
2023-02-11 02:56:20,575:INFO:Copying training dataset
2023-02-11 02:56:20,597:INFO:Defining folds
2023-02-11 02:56:20,598:INFO:Declaring metric variables
2023-02-11 02:56:20,604:INFO:Importing untrained model
2023-02-11 02:56:20,604:INFO:Declaring custom model
2023-02-11 02:56:20,609:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-11 02:56:20,619:INFO:Starting cross validation
2023-02-11 02:56:20,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-11 02:56:37,529:INFO:Calculating mean and std
2023-02-11 02:56:37,530:INFO:Creating metrics dataframe
2023-02-11 02:56:37,541:INFO:Finalizing model
2023-02-11 02:56:39,451:INFO:Uploading results into container
2023-02-11 02:56:39,451:INFO:Uploading model into container now
2023-02-11 02:56:39,451:INFO:create_model_container: 35
2023-02-11 02:56:39,451:INFO:master_model_container: 35
2023-02-11 02:56:39,451:INFO:display_container: 13
2023-02-11 02:56:39,452:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=7, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
              importance_type='split', learning_rate=0.3, max_depth=-1,
              min_child_samples=61, min_child_weight=0.001, min_split_gain=0.3,
              n_estimators=290, n_jobs=-1, num_leaves=256, objective=None,
              random_state=11, reg_alpha=0.5, reg_lambda=0.01, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-11 02:56:39,452:INFO:create_model() succesfully completed......................................
2023-02-11 02:56:39,555:INFO:SubProcess create_model() end ==================================
2023-02-11 02:56:39,555:INFO:choose_better activated
2023-02-11 02:56:39,561:INFO:SubProcess create_model() called ==================================
2023-02-11 02:56:39,561:INFO:Initializing create_model()
2023-02-11 02:56:39,561:INFO:create_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-11 02:56:39,561:INFO:Checking exceptions
2023-02-11 02:56:39,561:INFO:Importing libraries
2023-02-11 02:56:39,561:INFO:Copying training dataset
2023-02-11 02:56:39,582:INFO:Defining folds
2023-02-11 02:56:39,582:INFO:Declaring metric variables
2023-02-11 02:56:39,582:INFO:Importing untrained model
2023-02-11 02:56:39,582:INFO:Declaring custom model
2023-02-11 02:56:39,583:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-11 02:56:39,583:INFO:Starting cross validation
2023-02-11 02:56:39,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-11 02:57:51,858:INFO:Calculating mean and std
2023-02-11 02:57:51,858:INFO:Creating metrics dataframe
2023-02-11 02:57:51,860:INFO:Finalizing model
2023-02-11 02:57:58,702:INFO:Uploading results into container
2023-02-11 02:57:58,702:INFO:Uploading model into container now
2023-02-11 02:57:58,702:INFO:create_model_container: 36
2023-02-11 02:57:58,702:INFO:master_model_container: 36
2023-02-11 02:57:58,702:INFO:display_container: 14
2023-02-11 02:57:58,702:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-11 02:57:58,702:INFO:create_model() succesfully completed......................................
2023-02-11 02:57:58,800:INFO:SubProcess create_model() end ==================================
2023-02-11 02:57:58,800:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.9472
2023-02-11 02:57:58,801:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=7, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
              importance_type='split', learning_rate=0.3, max_depth=-1,
              min_child_samples=61, min_child_weight=0.001, min_split_gain=0.3,
              n_estimators=290, n_jobs=-1, num_leaves=256, objective=None,
              random_state=11, reg_alpha=0.5, reg_lambda=0.01, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.823
2023-02-11 02:57:58,801:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-02-11 02:57:58,801:INFO:choose_better completed
2023-02-11 02:57:58,805:INFO:create_model_container: 36
2023-02-11 02:57:58,805:INFO:master_model_container: 36
2023-02-11 02:57:58,805:INFO:display_container: 13
2023-02-11 02:57:58,805:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-11 02:57:58,805:INFO:tune_model() succesfully completed......................................
2023-02-14 10:04:31,399:INFO:PyCaret Supervised Module
2023-02-14 10:04:31,400:INFO:ML Usecase: regression
2023-02-14 10:04:31,400:INFO:version 2.3.10
2023-02-14 10:04:31,400:INFO:Initializing setup()
2023-02-14 10:04:31,400:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 10:04:31,400:INFO:Checking environment
2023-02-14 10:04:31,400:INFO:python_version: 3.9.16
2023-02-14 10:04:31,400:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 10:04:31,400:INFO:machine: x86_64
2023-02-14 10:04:31,400:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 10:04:31,400:INFO:Memory: svmem(total=134979592192, available=124267356160, percent=7.9, used=9231568896, free=121051717632, active=1356472320, inactive=11546660864, buffers=232296448, cached=4464009216, shared=305840128, slab=489324544)
2023-02-14 10:04:31,401:INFO:Physical Core: 16
2023-02-14 10:04:31,401:INFO:Logical Core: 32
2023-02-14 10:04:31,401:INFO:Checking libraries
2023-02-14 10:04:31,401:INFO:pd==1.5.2
2023-02-14 10:04:31,401:INFO:numpy==1.20.3
2023-02-14 10:04:31,401:INFO:sklearn==0.23.2
2023-02-14 10:04:31,401:INFO:lightgbm==3.3.5
2023-02-14 10:04:31,559:INFO:catboost==1.1.1
2023-02-14 10:04:31,559:INFO:xgboost==1.7.3
2023-02-14 10:04:31,559:INFO:mlflow==2.1.1
2023-02-14 10:04:31,559:INFO:Checking Exceptions
2023-02-14 10:04:31,560:INFO:Declaring global variables
2023-02-14 10:04:31,560:INFO:USI: 3ba4
2023-02-14 10:04:31,560:INFO:pycaret_globals: {'html_param', '_all_metrics', 'master_model_container', 'X', 'exp_name_log', 'target_param', 'iterative_imputation_iters_param', 'data_before_preprocess', 'USI', 'dashboard_logger', 'create_model_container', 'logging_param', 'fold_generator', 'prep_pipe', 'imputation_classifier', '_gpu_n_jobs_param', 'log_plots_param', 'y_test', '_all_models_internal', 'fold_groups_param_full', 'transform_target_method_param', 'gpu_param', '_all_models', 'y_train', 'fix_imbalance_method_param', 'imputation_regressor', 'fix_imbalance_param', 'y', '_ml_usecase', 'experiment__', 'fold_shuffle_param', 'fold_groups_param', '_available_plots', 'n_jobs_param', 'fold_param', 'X_train', 'X_test', 'transform_target_param', '_internal_pipeline', 'stratify_param', 'seed', 'display_container', 'pycaret_globals'}
2023-02-14 10:04:31,560:INFO:Preparing display monitor
2023-02-14 10:04:31,560:INFO:Preparing display monitor
2023-02-14 10:04:31,565:INFO:Importing libraries
2023-02-14 10:04:31,565:INFO:Copying data for preprocessing
2023-02-14 10:04:31,727:INFO:Declaring preprocessing parameters
2023-02-14 10:04:32,043:INFO:Creating preprocessing pipeline
2023-02-14 10:04:39,670:INFO:Preprocessing pipeline created successfully
2023-02-14 10:04:39,670:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 10:04:39,670:INFO:Creating global containers
2023-02-14 10:04:39,671:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 10:08:33,175:INFO:PyCaret Supervised Module
2023-02-14 10:08:33,175:INFO:ML Usecase: regression
2023-02-14 10:08:33,175:INFO:version 2.3.10
2023-02-14 10:08:33,176:INFO:Initializing setup()
2023-02-14 10:08:33,176:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 10:08:33,176:INFO:Checking environment
2023-02-14 10:08:33,176:INFO:python_version: 3.9.16
2023-02-14 10:08:33,176:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 10:08:33,176:INFO:machine: x86_64
2023-02-14 10:08:33,176:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 10:08:33,176:INFO:Memory: svmem(total=134979592192, available=115625459712, percent=14.3, used=17933606912, free=112364150784, active=1364893696, inactive=20210466816, buffers=234254336, cached=4447580160, shared=244846592, slab=491270144)
2023-02-14 10:08:33,176:INFO:Physical Core: 16
2023-02-14 10:08:33,176:INFO:Logical Core: 32
2023-02-14 10:08:33,176:INFO:Checking libraries
2023-02-14 10:08:33,176:INFO:pd==1.5.2
2023-02-14 10:08:33,176:INFO:numpy==1.20.3
2023-02-14 10:08:33,176:INFO:sklearn==0.23.2
2023-02-14 10:08:33,176:INFO:lightgbm==3.3.5
2023-02-14 10:08:33,176:INFO:catboost==1.1.1
2023-02-14 10:08:33,176:INFO:xgboost==1.7.3
2023-02-14 10:08:33,176:INFO:mlflow==2.1.1
2023-02-14 10:08:33,176:INFO:Checking Exceptions
2023-02-14 10:08:33,177:INFO:Declaring global variables
2023-02-14 10:08:33,177:INFO:USI: 5641
2023-02-14 10:08:33,177:INFO:pycaret_globals: {'html_param', '_all_metrics', 'master_model_container', 'X', 'exp_name_log', 'target_param', 'iterative_imputation_iters_param', 'data_before_preprocess', 'USI', 'dashboard_logger', 'create_model_container', 'logging_param', 'fold_generator', 'prep_pipe', 'imputation_classifier', '_gpu_n_jobs_param', 'log_plots_param', 'y_test', '_all_models_internal', 'fold_groups_param_full', 'transform_target_method_param', 'gpu_param', '_all_models', 'y_train', 'fix_imbalance_method_param', 'imputation_regressor', 'fix_imbalance_param', 'y', '_ml_usecase', 'experiment__', 'fold_shuffle_param', 'fold_groups_param', '_available_plots', 'n_jobs_param', 'fold_param', 'X_train', 'X_test', 'transform_target_param', '_internal_pipeline', 'stratify_param', 'seed', 'display_container', 'pycaret_globals'}
2023-02-14 10:08:33,177:INFO:Preparing display monitor
2023-02-14 10:08:33,177:INFO:Preparing display monitor
2023-02-14 10:08:33,182:INFO:Importing libraries
2023-02-14 10:08:33,182:INFO:Copying data for preprocessing
2023-02-14 10:08:33,291:INFO:Declaring preprocessing parameters
2023-02-14 10:08:33,484:INFO:Creating preprocessing pipeline
2023-02-14 10:08:38,380:INFO:Preprocessing pipeline created successfully
2023-02-14 10:08:38,381:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 10:08:38,381:INFO:Creating global containers
2023-02-14 10:08:38,381:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 10:12:21,405:INFO:PyCaret Supervised Module
2023-02-14 10:12:21,405:INFO:ML Usecase: regression
2023-02-14 10:12:21,405:INFO:version 2.3.10
2023-02-14 10:12:21,405:INFO:Initializing setup()
2023-02-14 10:12:21,405:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 10:12:21,405:INFO:Checking environment
2023-02-14 10:12:21,405:INFO:python_version: 3.9.16
2023-02-14 10:12:21,405:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 10:12:21,405:INFO:machine: x86_64
2023-02-14 10:12:21,405:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 10:12:21,405:INFO:Memory: svmem(total=134979592192, available=113993584640, percent=15.5, used=19537993728, free=110709272576, active=1374044160, inactive=21839560704, buffers=236335104, cached=4495990784, shared=271708160, slab=495091712)
2023-02-14 10:12:21,406:INFO:Physical Core: 16
2023-02-14 10:12:21,406:INFO:Logical Core: 32
2023-02-14 10:12:21,406:INFO:Checking libraries
2023-02-14 10:12:21,406:INFO:pd==1.5.2
2023-02-14 10:12:21,406:INFO:numpy==1.20.3
2023-02-14 10:12:21,406:INFO:sklearn==0.23.2
2023-02-14 10:12:21,406:INFO:lightgbm==3.3.5
2023-02-14 10:12:21,406:INFO:catboost==1.1.1
2023-02-14 10:12:21,406:INFO:xgboost==1.7.3
2023-02-14 10:12:21,406:INFO:mlflow==2.1.1
2023-02-14 10:12:21,406:INFO:Checking Exceptions
2023-02-14 10:12:21,406:INFO:Declaring global variables
2023-02-14 10:12:21,406:INFO:USI: c265
2023-02-14 10:12:21,406:INFO:pycaret_globals: {'html_param', '_all_metrics', 'master_model_container', 'X', 'exp_name_log', 'target_param', 'iterative_imputation_iters_param', 'data_before_preprocess', 'USI', 'dashboard_logger', 'create_model_container', 'logging_param', 'fold_generator', 'prep_pipe', 'imputation_classifier', '_gpu_n_jobs_param', 'log_plots_param', 'y_test', '_all_models_internal', 'fold_groups_param_full', 'transform_target_method_param', 'gpu_param', '_all_models', 'y_train', 'fix_imbalance_method_param', 'imputation_regressor', 'fix_imbalance_param', 'y', '_ml_usecase', 'experiment__', 'fold_shuffle_param', 'fold_groups_param', '_available_plots', 'n_jobs_param', 'fold_param', 'X_train', 'X_test', 'transform_target_param', '_internal_pipeline', 'stratify_param', 'seed', 'display_container', 'pycaret_globals'}
2023-02-14 10:12:21,406:INFO:Preparing display monitor
2023-02-14 10:12:21,406:INFO:Preparing display monitor
2023-02-14 10:12:21,411:INFO:Importing libraries
2023-02-14 10:12:21,411:INFO:Copying data for preprocessing
2023-02-14 10:12:21,514:INFO:Declaring preprocessing parameters
2023-02-14 10:12:21,706:INFO:Creating preprocessing pipeline
2023-02-14 10:12:57,691:INFO:PyCaret Supervised Module
2023-02-14 10:12:57,692:INFO:ML Usecase: regression
2023-02-14 10:12:57,692:INFO:version 2.3.10
2023-02-14 10:12:57,692:INFO:Initializing setup()
2023-02-14 10:12:57,692:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 10:12:57,692:INFO:Checking environment
2023-02-14 10:12:57,692:INFO:python_version: 3.9.16
2023-02-14 10:12:57,692:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 10:12:57,692:INFO:machine: x86_64
2023-02-14 10:12:57,692:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 10:12:57,692:INFO:Memory: svmem(total=134979592192, available=117688381440, percent=12.8, used=15807102976, free=114403438592, active=1375547392, inactive=18154491904, buffers=236707840, cached=4532342784, shared=307818496, slab=495271936)
2023-02-14 10:12:57,693:INFO:Physical Core: 16
2023-02-14 10:12:57,693:INFO:Logical Core: 32
2023-02-14 10:12:57,693:INFO:Checking libraries
2023-02-14 10:12:57,693:INFO:pd==1.5.2
2023-02-14 10:12:57,693:INFO:numpy==1.20.3
2023-02-14 10:12:57,693:INFO:sklearn==0.23.2
2023-02-14 10:12:57,693:INFO:lightgbm==3.3.5
2023-02-14 10:12:57,693:INFO:catboost==1.1.1
2023-02-14 10:12:57,693:INFO:xgboost==1.7.3
2023-02-14 10:12:57,693:INFO:mlflow==2.1.1
2023-02-14 10:12:57,693:INFO:Checking Exceptions
2023-02-14 10:12:57,693:INFO:Declaring global variables
2023-02-14 10:12:57,693:INFO:USI: 1fff
2023-02-14 10:12:57,693:INFO:pycaret_globals: {'html_param', '_all_metrics', 'master_model_container', 'X', 'exp_name_log', 'target_param', 'iterative_imputation_iters_param', 'data_before_preprocess', 'USI', 'dashboard_logger', 'create_model_container', 'logging_param', 'fold_generator', 'prep_pipe', 'imputation_classifier', '_gpu_n_jobs_param', 'log_plots_param', 'y_test', '_all_models_internal', 'fold_groups_param_full', 'transform_target_method_param', 'gpu_param', '_all_models', 'y_train', 'fix_imbalance_method_param', 'imputation_regressor', 'fix_imbalance_param', 'y', '_ml_usecase', 'experiment__', 'fold_shuffle_param', 'fold_groups_param', '_available_plots', 'n_jobs_param', 'fold_param', 'X_train', 'X_test', 'transform_target_param', '_internal_pipeline', 'stratify_param', 'seed', 'display_container', 'pycaret_globals'}
2023-02-14 10:12:57,693:INFO:Preparing display monitor
2023-02-14 10:12:57,693:INFO:Preparing display monitor
2023-02-14 10:12:57,698:INFO:Importing libraries
2023-02-14 10:12:57,698:INFO:Copying data for preprocessing
2023-02-14 10:12:57,813:INFO:Declaring preprocessing parameters
2023-02-14 10:12:58,017:INFO:Creating preprocessing pipeline
2023-02-14 10:13:03,063:INFO:Preprocessing pipeline created successfully
2023-02-14 10:13:03,063:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 10:13:03,063:INFO:Creating global containers
2023-02-14 10:13:03,064:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 10:13:19,895:INFO:PyCaret Supervised Module
2023-02-14 10:13:19,895:INFO:ML Usecase: regression
2023-02-14 10:13:19,895:INFO:version 2.3.10
2023-02-14 10:13:19,895:INFO:Initializing setup()
2023-02-14 10:13:19,895:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 10:13:19,895:INFO:Checking environment
2023-02-14 10:13:19,895:INFO:python_version: 3.9.16
2023-02-14 10:13:19,895:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 10:13:19,895:INFO:machine: x86_64
2023-02-14 10:13:19,896:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 10:13:19,896:INFO:Memory: svmem(total=134979592192, available=119608328192, percent=11.4, used=13871398912, free=116321046528, active=1376706560, inactive=16235565056, buffers=237035520, cached=4550111232, shared=323399680, slab=495988736)
2023-02-14 10:13:19,896:INFO:Physical Core: 16
2023-02-14 10:13:19,896:INFO:Logical Core: 32
2023-02-14 10:13:19,896:INFO:Checking libraries
2023-02-14 10:13:19,896:INFO:pd==1.5.2
2023-02-14 10:13:19,896:INFO:numpy==1.20.3
2023-02-14 10:13:19,896:INFO:sklearn==0.23.2
2023-02-14 10:13:19,896:INFO:lightgbm==3.3.5
2023-02-14 10:13:19,896:INFO:catboost==1.1.1
2023-02-14 10:13:19,897:INFO:xgboost==1.7.3
2023-02-14 10:13:19,897:INFO:mlflow==2.1.1
2023-02-14 10:13:19,897:INFO:Checking Exceptions
2023-02-14 10:13:19,897:INFO:Declaring global variables
2023-02-14 10:13:19,897:INFO:USI: 5b04
2023-02-14 10:13:19,897:INFO:pycaret_globals: {'html_param', '_all_metrics', 'master_model_container', 'X', 'exp_name_log', 'target_param', 'iterative_imputation_iters_param', 'data_before_preprocess', 'USI', 'dashboard_logger', 'create_model_container', 'logging_param', 'fold_generator', 'prep_pipe', 'imputation_classifier', '_gpu_n_jobs_param', 'log_plots_param', 'y_test', '_all_models_internal', 'fold_groups_param_full', 'transform_target_method_param', 'gpu_param', '_all_models', 'y_train', 'fix_imbalance_method_param', 'imputation_regressor', 'fix_imbalance_param', 'y', '_ml_usecase', 'experiment__', 'fold_shuffle_param', 'fold_groups_param', '_available_plots', 'n_jobs_param', 'fold_param', 'X_train', 'X_test', 'transform_target_param', '_internal_pipeline', 'stratify_param', 'seed', 'display_container', 'pycaret_globals'}
2023-02-14 10:13:19,897:INFO:Preparing display monitor
2023-02-14 10:13:19,897:INFO:Preparing display monitor
2023-02-14 10:13:19,902:INFO:Importing libraries
2023-02-14 10:13:19,902:INFO:Copying data for preprocessing
2023-02-14 10:13:20,004:INFO:Declaring preprocessing parameters
2023-02-14 10:13:20,198:INFO:Creating preprocessing pipeline
2023-02-14 10:13:25,018:INFO:Preprocessing pipeline created successfully
2023-02-14 10:13:25,018:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 10:13:25,018:INFO:Creating global containers
2023-02-14 10:13:25,018:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 10:20:20,845:INFO:Creating grid variables
2023-02-14 10:20:20,949:INFO:create_model_container: 0
2023-02-14 10:20:20,949:INFO:master_model_container: 0
2023-02-14 10:20:20,949:INFO:display_container: 1
2023-02-14 10:20:20,951:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-14 10:20:20,951:INFO:setup() succesfully completed......................................
2023-02-14 10:20:21,057:INFO:Initializing compare_models()
2023-02-14 10:20:21,057:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=['tr'])
2023-02-14 10:20:21,057:INFO:Checking exceptions
2023-02-14 10:20:21,057:INFO:Preparing display monitor
2023-02-14 10:20:21,058:INFO:Preparing display monitor
2023-02-14 10:20:21,068:INFO:Initializing Linear Regression
2023-02-14 10:20:21,068:INFO:Total runtime is 1.8437703450520833e-06 minutes
2023-02-14 10:20:21,072:INFO:SubProcess create_model() called ==================================
2023-02-14 10:20:21,072:INFO:Initializing create_model()
2023-02-14 10:20:21,072:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:20:21,072:INFO:Checking exceptions
2023-02-14 10:20:21,072:INFO:Importing libraries
2023-02-14 10:20:21,072:INFO:Copying training dataset
2023-02-14 10:20:21,090:INFO:Defining folds
2023-02-14 10:20:21,090:INFO:Declaring metric variables
2023-02-14 10:20:21,094:INFO:Importing untrained model
2023-02-14 10:20:21,097:INFO:Linear Regression Imported succesfully
2023-02-14 10:20:21,103:INFO:Starting cross validation
2023-02-14 10:20:21,106:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:20:31,188:INFO:Calculating mean and std
2023-02-14 10:20:31,189:INFO:Creating metrics dataframe
2023-02-14 10:20:31,193:INFO:Uploading results into container
2023-02-14 10:20:31,193:INFO:Uploading model into container now
2023-02-14 10:20:31,194:INFO:create_model_container: 1
2023-02-14 10:20:31,194:INFO:master_model_container: 1
2023-02-14 10:20:31,194:INFO:display_container: 2
2023-02-14 10:20:31,194:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-14 10:20:31,194:INFO:create_model() succesfully completed......................................
2023-02-14 10:20:31,300:INFO:SubProcess create_model() end ==================================
2023-02-14 10:20:31,300:INFO:Creating metrics dataframe
2023-02-14 10:20:31,305:INFO:Initializing Lasso Regression
2023-02-14 10:20:31,305:INFO:Total runtime is 0.17061887582143145 minutes
2023-02-14 10:20:31,309:INFO:SubProcess create_model() called ==================================
2023-02-14 10:20:31,309:INFO:Initializing create_model()
2023-02-14 10:20:31,309:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:20:31,309:INFO:Checking exceptions
2023-02-14 10:20:31,309:INFO:Importing libraries
2023-02-14 10:20:31,309:INFO:Copying training dataset
2023-02-14 10:20:31,328:INFO:Defining folds
2023-02-14 10:20:31,328:INFO:Declaring metric variables
2023-02-14 10:20:31,331:INFO:Importing untrained model
2023-02-14 10:20:31,334:INFO:Lasso Regression Imported succesfully
2023-02-14 10:20:31,340:INFO:Starting cross validation
2023-02-14 10:20:31,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:21:10,233:INFO:Calculating mean and std
2023-02-14 10:21:10,233:INFO:Creating metrics dataframe
2023-02-14 10:21:10,236:INFO:Uploading results into container
2023-02-14 10:21:10,236:INFO:Uploading model into container now
2023-02-14 10:21:10,236:INFO:create_model_container: 2
2023-02-14 10:21:10,237:INFO:master_model_container: 2
2023-02-14 10:21:10,237:INFO:display_container: 2
2023-02-14 10:21:10,237:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-14 10:21:10,237:INFO:create_model() succesfully completed......................................
2023-02-14 10:21:10,340:INFO:SubProcess create_model() end ==================================
2023-02-14 10:21:10,341:INFO:Creating metrics dataframe
2023-02-14 10:21:10,346:INFO:Initializing Ridge Regression
2023-02-14 10:21:10,346:INFO:Total runtime is 0.8213029384613036 minutes
2023-02-14 10:21:10,350:INFO:SubProcess create_model() called ==================================
2023-02-14 10:21:10,350:INFO:Initializing create_model()
2023-02-14 10:21:10,350:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:21:10,351:INFO:Checking exceptions
2023-02-14 10:21:10,351:INFO:Importing libraries
2023-02-14 10:21:10,351:INFO:Copying training dataset
2023-02-14 10:21:10,369:INFO:Defining folds
2023-02-14 10:21:10,369:INFO:Declaring metric variables
2023-02-14 10:21:10,372:INFO:Importing untrained model
2023-02-14 10:21:10,375:INFO:Ridge Regression Imported succesfully
2023-02-14 10:21:10,382:INFO:Starting cross validation
2023-02-14 10:21:10,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:21:28,673:INFO:Calculating mean and std
2023-02-14 10:21:28,673:INFO:Creating metrics dataframe
2023-02-14 10:21:28,676:INFO:Uploading results into container
2023-02-14 10:21:28,676:INFO:Uploading model into container now
2023-02-14 10:21:28,676:INFO:create_model_container: 3
2023-02-14 10:21:28,676:INFO:master_model_container: 3
2023-02-14 10:21:28,676:INFO:display_container: 2
2023-02-14 10:21:28,676:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-14 10:21:28,676:INFO:create_model() succesfully completed......................................
2023-02-14 10:21:28,772:INFO:SubProcess create_model() end ==================================
2023-02-14 10:21:28,772:INFO:Creating metrics dataframe
2023-02-14 10:21:28,778:INFO:Initializing Elastic Net
2023-02-14 10:21:28,778:INFO:Total runtime is 1.1285024126370748 minutes
2023-02-14 10:21:28,782:INFO:SubProcess create_model() called ==================================
2023-02-14 10:21:28,782:INFO:Initializing create_model()
2023-02-14 10:21:28,782:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:21:28,782:INFO:Checking exceptions
2023-02-14 10:21:28,782:INFO:Importing libraries
2023-02-14 10:21:28,782:INFO:Copying training dataset
2023-02-14 10:21:28,800:INFO:Defining folds
2023-02-14 10:21:28,801:INFO:Declaring metric variables
2023-02-14 10:21:28,804:INFO:Importing untrained model
2023-02-14 10:21:28,807:INFO:Elastic Net Imported succesfully
2023-02-14 10:21:28,813:INFO:Starting cross validation
2023-02-14 10:21:28,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:22:06,729:INFO:Calculating mean and std
2023-02-14 10:22:06,730:INFO:Creating metrics dataframe
2023-02-14 10:22:06,734:INFO:Uploading results into container
2023-02-14 10:22:06,734:INFO:Uploading model into container now
2023-02-14 10:22:06,735:INFO:create_model_container: 4
2023-02-14 10:22:06,735:INFO:master_model_container: 4
2023-02-14 10:22:06,735:INFO:display_container: 2
2023-02-14 10:22:06,735:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-14 10:22:06,735:INFO:create_model() succesfully completed......................................
2023-02-14 10:22:06,836:INFO:SubProcess create_model() end ==================================
2023-02-14 10:22:06,836:INFO:Creating metrics dataframe
2023-02-14 10:22:06,842:INFO:Initializing Least Angle Regression
2023-02-14 10:22:06,842:INFO:Total runtime is 1.7628974874814352 minutes
2023-02-14 10:22:06,846:INFO:SubProcess create_model() called ==================================
2023-02-14 10:22:06,846:INFO:Initializing create_model()
2023-02-14 10:22:06,846:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:22:06,846:INFO:Checking exceptions
2023-02-14 10:22:06,846:INFO:Importing libraries
2023-02-14 10:22:06,846:INFO:Copying training dataset
2023-02-14 10:22:06,865:INFO:Defining folds
2023-02-14 10:22:06,865:INFO:Declaring metric variables
2023-02-14 10:22:06,869:INFO:Importing untrained model
2023-02-14 10:22:06,872:INFO:Least Angle Regression Imported succesfully
2023-02-14 10:22:06,878:INFO:Starting cross validation
2023-02-14 10:22:06,879:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:22:08,686:INFO:Calculating mean and std
2023-02-14 10:22:08,687:INFO:Creating metrics dataframe
2023-02-14 10:22:08,689:INFO:Uploading results into container
2023-02-14 10:22:08,689:INFO:Uploading model into container now
2023-02-14 10:22:08,689:INFO:create_model_container: 5
2023-02-14 10:22:08,689:INFO:master_model_container: 5
2023-02-14 10:22:08,689:INFO:display_container: 2
2023-02-14 10:22:08,690:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize=True, precompute='auto',
     random_state=11, verbose=False)
2023-02-14 10:22:08,690:INFO:create_model() succesfully completed......................................
2023-02-14 10:22:08,782:INFO:SubProcess create_model() end ==================================
2023-02-14 10:22:08,782:INFO:Creating metrics dataframe
2023-02-14 10:22:08,789:INFO:Initializing Lasso Least Angle Regression
2023-02-14 10:22:08,789:INFO:Total runtime is 1.7953472216924031 minutes
2023-02-14 10:22:08,793:INFO:SubProcess create_model() called ==================================
2023-02-14 10:22:08,793:INFO:Initializing create_model()
2023-02-14 10:22:08,793:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:22:08,793:INFO:Checking exceptions
2023-02-14 10:22:08,793:INFO:Importing libraries
2023-02-14 10:22:08,793:INFO:Copying training dataset
2023-02-14 10:22:08,811:INFO:Defining folds
2023-02-14 10:22:08,811:INFO:Declaring metric variables
2023-02-14 10:22:08,815:INFO:Importing untrained model
2023-02-14 10:22:08,818:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-14 10:22:08,824:INFO:Starting cross validation
2023-02-14 10:22:08,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:22:10,420:INFO:Calculating mean and std
2023-02-14 10:22:10,421:INFO:Creating metrics dataframe
2023-02-14 10:22:10,424:INFO:Uploading results into container
2023-02-14 10:22:10,425:INFO:Uploading model into container now
2023-02-14 10:22:10,425:INFO:create_model_container: 6
2023-02-14 10:22:10,425:INFO:master_model_container: 6
2023-02-14 10:22:10,425:INFO:display_container: 2
2023-02-14 10:22:10,425:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-14 10:22:10,425:INFO:create_model() succesfully completed......................................
2023-02-14 10:22:10,520:INFO:SubProcess create_model() end ==================================
2023-02-14 10:22:10,520:INFO:Creating metrics dataframe
2023-02-14 10:22:10,526:INFO:Initializing Orthogonal Matching Pursuit
2023-02-14 10:22:10,526:INFO:Total runtime is 1.8242948095003764 minutes
2023-02-14 10:22:10,530:INFO:SubProcess create_model() called ==================================
2023-02-14 10:22:10,530:INFO:Initializing create_model()
2023-02-14 10:22:10,530:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:22:10,530:INFO:Checking exceptions
2023-02-14 10:22:10,530:INFO:Importing libraries
2023-02-14 10:22:10,530:INFO:Copying training dataset
2023-02-14 10:22:10,548:INFO:Defining folds
2023-02-14 10:22:10,549:INFO:Declaring metric variables
2023-02-14 10:22:10,552:INFO:Importing untrained model
2023-02-14 10:22:10,556:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-14 10:22:10,562:INFO:Starting cross validation
2023-02-14 10:22:10,562:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:22:12,199:INFO:Calculating mean and std
2023-02-14 10:22:12,199:INFO:Creating metrics dataframe
2023-02-14 10:22:12,203:INFO:Uploading results into container
2023-02-14 10:22:12,203:INFO:Uploading model into container now
2023-02-14 10:22:12,203:INFO:create_model_container: 7
2023-02-14 10:22:12,203:INFO:master_model_container: 7
2023-02-14 10:22:12,203:INFO:display_container: 2
2023-02-14 10:22:12,203:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-14 10:22:12,203:INFO:create_model() succesfully completed......................................
2023-02-14 10:22:12,299:INFO:SubProcess create_model() end ==================================
2023-02-14 10:22:12,300:INFO:Creating metrics dataframe
2023-02-14 10:22:12,307:INFO:Initializing Bayesian Ridge
2023-02-14 10:22:12,307:INFO:Total runtime is 1.8539818088213602 minutes
2023-02-14 10:22:12,311:INFO:SubProcess create_model() called ==================================
2023-02-14 10:22:12,311:INFO:Initializing create_model()
2023-02-14 10:22:12,311:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:22:12,311:INFO:Checking exceptions
2023-02-14 10:22:12,311:INFO:Importing libraries
2023-02-14 10:22:12,311:INFO:Copying training dataset
2023-02-14 10:22:12,331:INFO:Defining folds
2023-02-14 10:22:12,331:INFO:Declaring metric variables
2023-02-14 10:22:12,335:INFO:Importing untrained model
2023-02-14 10:22:12,339:INFO:Bayesian Ridge Imported succesfully
2023-02-14 10:22:12,346:INFO:Starting cross validation
2023-02-14 10:22:12,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:24:28,666:INFO:Calculating mean and std
2023-02-14 10:24:28,667:INFO:Creating metrics dataframe
2023-02-14 10:24:28,671:INFO:Uploading results into container
2023-02-14 10:24:28,671:INFO:Uploading model into container now
2023-02-14 10:24:28,671:INFO:create_model_container: 8
2023-02-14 10:24:28,671:INFO:master_model_container: 8
2023-02-14 10:24:28,671:INFO:display_container: 2
2023-02-14 10:24:28,671:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-14 10:24:28,671:INFO:create_model() succesfully completed......................................
2023-02-14 10:24:28,776:INFO:SubProcess create_model() end ==================================
2023-02-14 10:24:28,776:INFO:Creating metrics dataframe
2023-02-14 10:24:28,783:INFO:Initializing Passive Aggressive Regressor
2023-02-14 10:24:28,783:INFO:Total runtime is 4.128584746519724 minutes
2023-02-14 10:24:28,787:INFO:SubProcess create_model() called ==================================
2023-02-14 10:24:28,787:INFO:Initializing create_model()
2023-02-14 10:24:28,787:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:24:28,787:INFO:Checking exceptions
2023-02-14 10:24:28,787:INFO:Importing libraries
2023-02-14 10:24:28,787:INFO:Copying training dataset
2023-02-14 10:24:28,805:INFO:Defining folds
2023-02-14 10:24:28,806:INFO:Declaring metric variables
2023-02-14 10:24:28,809:INFO:Importing untrained model
2023-02-14 10:24:28,813:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-14 10:24:28,819:INFO:Starting cross validation
2023-02-14 10:24:28,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:24:30,331:INFO:Calculating mean and std
2023-02-14 10:24:30,332:INFO:Creating metrics dataframe
2023-02-14 10:24:30,336:INFO:Uploading results into container
2023-02-14 10:24:30,336:INFO:Uploading model into container now
2023-02-14 10:24:30,336:INFO:create_model_container: 9
2023-02-14 10:24:30,336:INFO:master_model_container: 9
2023-02-14 10:24:30,336:INFO:display_container: 2
2023-02-14 10:24:30,336:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-14 10:24:30,336:INFO:create_model() succesfully completed......................................
2023-02-14 10:24:30,434:INFO:SubProcess create_model() end ==================================
2023-02-14 10:24:30,434:INFO:Creating metrics dataframe
2023-02-14 10:24:30,442:INFO:Initializing Huber Regressor
2023-02-14 10:24:30,442:INFO:Total runtime is 4.156232142448425 minutes
2023-02-14 10:24:30,446:INFO:SubProcess create_model() called ==================================
2023-02-14 10:24:30,446:INFO:Initializing create_model()
2023-02-14 10:24:30,446:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:24:30,446:INFO:Checking exceptions
2023-02-14 10:24:30,446:INFO:Importing libraries
2023-02-14 10:24:30,446:INFO:Copying training dataset
2023-02-14 10:24:30,465:INFO:Defining folds
2023-02-14 10:24:30,465:INFO:Declaring metric variables
2023-02-14 10:24:30,469:INFO:Importing untrained model
2023-02-14 10:24:30,472:INFO:Huber Regressor Imported succesfully
2023-02-14 10:24:30,479:INFO:Starting cross validation
2023-02-14 10:24:30,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:25:30,586:INFO:Calculating mean and std
2023-02-14 10:25:30,587:INFO:Creating metrics dataframe
2023-02-14 10:25:30,591:INFO:Uploading results into container
2023-02-14 10:25:30,592:INFO:Uploading model into container now
2023-02-14 10:25:30,592:INFO:create_model_container: 10
2023-02-14 10:25:30,592:INFO:master_model_container: 10
2023-02-14 10:25:30,592:INFO:display_container: 2
2023-02-14 10:25:30,592:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-14 10:25:30,592:INFO:create_model() succesfully completed......................................
2023-02-14 10:25:30,703:INFO:SubProcess create_model() end ==================================
2023-02-14 10:25:30,703:INFO:Creating metrics dataframe
2023-02-14 10:25:30,710:INFO:Initializing K Neighbors Regressor
2023-02-14 10:25:30,710:INFO:Total runtime is 5.16070126692454 minutes
2023-02-14 10:25:30,714:INFO:SubProcess create_model() called ==================================
2023-02-14 10:25:30,714:INFO:Initializing create_model()
2023-02-14 10:25:30,714:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:25:30,714:INFO:Checking exceptions
2023-02-14 10:25:30,714:INFO:Importing libraries
2023-02-14 10:25:30,714:INFO:Copying training dataset
2023-02-14 10:25:30,734:INFO:Defining folds
2023-02-14 10:25:30,734:INFO:Declaring metric variables
2023-02-14 10:25:30,738:INFO:Importing untrained model
2023-02-14 10:25:30,741:INFO:K Neighbors Regressor Imported succesfully
2023-02-14 10:25:30,747:INFO:Starting cross validation
2023-02-14 10:25:30,748:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:25:37,348:INFO:Calculating mean and std
2023-02-14 10:25:37,349:INFO:Creating metrics dataframe
2023-02-14 10:25:37,353:INFO:Uploading results into container
2023-02-14 10:25:37,353:INFO:Uploading model into container now
2023-02-14 10:25:37,353:INFO:create_model_container: 11
2023-02-14 10:25:37,353:INFO:master_model_container: 11
2023-02-14 10:25:37,353:INFO:display_container: 2
2023-02-14 10:25:37,354:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-14 10:25:37,354:INFO:create_model() succesfully completed......................................
2023-02-14 10:25:37,454:INFO:SubProcess create_model() end ==================================
2023-02-14 10:25:37,455:INFO:Creating metrics dataframe
2023-02-14 10:25:37,461:INFO:Initializing Decision Tree Regressor
2023-02-14 10:25:37,461:INFO:Total runtime is 5.273216712474823 minutes
2023-02-14 10:25:37,465:INFO:SubProcess create_model() called ==================================
2023-02-14 10:25:37,465:INFO:Initializing create_model()
2023-02-14 10:25:37,465:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:25:37,465:INFO:Checking exceptions
2023-02-14 10:25:37,465:INFO:Importing libraries
2023-02-14 10:25:37,465:INFO:Copying training dataset
2023-02-14 10:25:37,483:INFO:Defining folds
2023-02-14 10:25:37,483:INFO:Declaring metric variables
2023-02-14 10:25:37,486:INFO:Importing untrained model
2023-02-14 10:25:37,489:INFO:Decision Tree Regressor Imported succesfully
2023-02-14 10:25:37,495:INFO:Starting cross validation
2023-02-14 10:25:37,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:26:14,078:INFO:Calculating mean and std
2023-02-14 10:26:14,078:INFO:Creating metrics dataframe
2023-02-14 10:26:14,083:INFO:Uploading results into container
2023-02-14 10:26:14,083:INFO:Uploading model into container now
2023-02-14 10:26:14,083:INFO:create_model_container: 12
2023-02-14 10:26:14,083:INFO:master_model_container: 12
2023-02-14 10:26:14,083:INFO:display_container: 2
2023-02-14 10:26:14,084:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-14 10:26:14,084:INFO:create_model() succesfully completed......................................
2023-02-14 10:26:14,186:INFO:SubProcess create_model() end ==================================
2023-02-14 10:26:14,186:INFO:Creating metrics dataframe
2023-02-14 10:26:14,192:INFO:Initializing Random Forest Regressor
2023-02-14 10:26:14,192:INFO:Total runtime is 5.8854004343350725 minutes
2023-02-14 10:26:14,196:INFO:SubProcess create_model() called ==================================
2023-02-14 10:26:14,196:INFO:Initializing create_model()
2023-02-14 10:26:14,196:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:26:14,196:INFO:Checking exceptions
2023-02-14 10:26:14,196:INFO:Importing libraries
2023-02-14 10:26:14,196:INFO:Copying training dataset
2023-02-14 10:26:14,215:INFO:Defining folds
2023-02-14 10:26:14,215:INFO:Declaring metric variables
2023-02-14 10:26:14,218:INFO:Importing untrained model
2023-02-14 10:26:14,221:INFO:Random Forest Regressor Imported succesfully
2023-02-14 10:26:14,227:INFO:Starting cross validation
2023-02-14 10:26:14,227:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:42:58,655:INFO:Calculating mean and std
2023-02-14 10:42:58,656:INFO:Creating metrics dataframe
2023-02-14 10:42:58,660:INFO:Uploading results into container
2023-02-14 10:42:58,660:INFO:Uploading model into container now
2023-02-14 10:42:58,660:INFO:create_model_container: 13
2023-02-14 10:42:58,660:INFO:master_model_container: 13
2023-02-14 10:42:58,660:INFO:display_container: 2
2023-02-14 10:42:58,660:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-14 10:42:58,660:INFO:create_model() succesfully completed......................................
2023-02-14 10:42:58,764:INFO:SubProcess create_model() end ==================================
2023-02-14 10:42:58,764:INFO:Creating metrics dataframe
2023-02-14 10:42:58,771:INFO:Initializing Extra Trees Regressor
2023-02-14 10:42:58,771:INFO:Total runtime is 22.628377660115557 minutes
2023-02-14 10:42:58,774:INFO:SubProcess create_model() called ==================================
2023-02-14 10:42:58,774:INFO:Initializing create_model()
2023-02-14 10:42:58,774:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:42:58,774:INFO:Checking exceptions
2023-02-14 10:42:58,775:INFO:Importing libraries
2023-02-14 10:42:58,775:INFO:Copying training dataset
2023-02-14 10:42:58,793:INFO:Defining folds
2023-02-14 10:42:58,793:INFO:Declaring metric variables
2023-02-14 10:42:58,797:INFO:Importing untrained model
2023-02-14 10:42:58,800:INFO:Extra Trees Regressor Imported succesfully
2023-02-14 10:42:58,806:INFO:Starting cross validation
2023-02-14 10:42:58,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 10:57:59,222:INFO:Calculating mean and std
2023-02-14 10:57:59,223:INFO:Creating metrics dataframe
2023-02-14 10:57:59,227:INFO:Uploading results into container
2023-02-14 10:57:59,227:INFO:Uploading model into container now
2023-02-14 10:57:59,227:INFO:create_model_container: 14
2023-02-14 10:57:59,227:INFO:master_model_container: 14
2023-02-14 10:57:59,227:INFO:display_container: 2
2023-02-14 10:57:59,227:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-14 10:57:59,227:INFO:create_model() succesfully completed......................................
2023-02-14 10:57:59,330:INFO:SubProcess create_model() end ==================================
2023-02-14 10:57:59,331:INFO:Creating metrics dataframe
2023-02-14 10:57:59,338:INFO:Initializing AdaBoost Regressor
2023-02-14 10:57:59,338:INFO:Total runtime is 37.63783489863077 minutes
2023-02-14 10:57:59,342:INFO:SubProcess create_model() called ==================================
2023-02-14 10:57:59,342:INFO:Initializing create_model()
2023-02-14 10:57:59,342:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 10:57:59,342:INFO:Checking exceptions
2023-02-14 10:57:59,342:INFO:Importing libraries
2023-02-14 10:57:59,342:INFO:Copying training dataset
2023-02-14 10:57:59,360:INFO:Defining folds
2023-02-14 10:57:59,361:INFO:Declaring metric variables
2023-02-14 10:57:59,364:INFO:Importing untrained model
2023-02-14 10:57:59,367:INFO:AdaBoost Regressor Imported succesfully
2023-02-14 10:57:59,373:INFO:Starting cross validation
2023-02-14 10:57:59,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 11:01:36,540:INFO:Calculating mean and std
2023-02-14 11:01:36,541:INFO:Creating metrics dataframe
2023-02-14 11:01:36,546:INFO:Uploading results into container
2023-02-14 11:01:36,546:INFO:Uploading model into container now
2023-02-14 11:01:36,546:INFO:create_model_container: 15
2023-02-14 11:01:36,546:INFO:master_model_container: 15
2023-02-14 11:01:36,546:INFO:display_container: 2
2023-02-14 11:01:36,546:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-14 11:01:36,547:INFO:create_model() succesfully completed......................................
2023-02-14 11:01:36,657:INFO:SubProcess create_model() end ==================================
2023-02-14 11:01:36,657:INFO:Creating metrics dataframe
2023-02-14 11:01:36,665:INFO:Initializing Gradient Boosting Regressor
2023-02-14 11:01:36,665:INFO:Total runtime is 41.259945817788434 minutes
2023-02-14 11:01:36,668:INFO:SubProcess create_model() called ==================================
2023-02-14 11:01:36,669:INFO:Initializing create_model()
2023-02-14 11:01:36,669:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 11:01:36,669:INFO:Checking exceptions
2023-02-14 11:01:36,669:INFO:Importing libraries
2023-02-14 11:01:36,669:INFO:Copying training dataset
2023-02-14 11:01:36,687:INFO:Defining folds
2023-02-14 11:01:36,688:INFO:Declaring metric variables
2023-02-14 11:01:36,691:INFO:Importing untrained model
2023-02-14 11:01:36,694:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-14 11:01:36,700:INFO:Starting cross validation
2023-02-14 11:01:36,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 11:14:36,896:INFO:Calculating mean and std
2023-02-14 11:14:36,897:INFO:Creating metrics dataframe
2023-02-14 11:14:36,901:INFO:Uploading results into container
2023-02-14 11:14:36,902:INFO:Uploading model into container now
2023-02-14 11:14:36,902:INFO:create_model_container: 16
2023-02-14 11:14:36,902:INFO:master_model_container: 16
2023-02-14 11:14:36,902:INFO:display_container: 2
2023-02-14 11:14:36,902:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-14 11:14:36,902:INFO:create_model() succesfully completed......................................
2023-02-14 11:14:36,997:INFO:SubProcess create_model() end ==================================
2023-02-14 11:14:36,997:INFO:Creating metrics dataframe
2023-02-14 11:14:37,005:INFO:Initializing Extreme Gradient Boosting
2023-02-14 11:14:37,005:INFO:Total runtime is 54.265605382124576 minutes
2023-02-14 11:14:37,008:INFO:SubProcess create_model() called ==================================
2023-02-14 11:14:37,008:INFO:Initializing create_model()
2023-02-14 11:14:37,008:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 11:14:37,008:INFO:Checking exceptions
2023-02-14 11:14:37,008:INFO:Importing libraries
2023-02-14 11:14:37,008:INFO:Copying training dataset
2023-02-14 11:14:37,026:INFO:Defining folds
2023-02-14 11:14:37,026:INFO:Declaring metric variables
2023-02-14 11:14:37,029:INFO:Importing untrained model
2023-02-14 11:14:37,033:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-14 11:14:37,039:INFO:Starting cross validation
2023-02-14 11:14:37,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 11:20:15,061:INFO:Calculating mean and std
2023-02-14 11:20:15,062:INFO:Creating metrics dataframe
2023-02-14 11:20:15,067:INFO:Uploading results into container
2023-02-14 11:20:15,067:INFO:Uploading model into container now
2023-02-14 11:20:15,067:INFO:create_model_container: 17
2023-02-14 11:20:15,067:INFO:master_model_container: 17
2023-02-14 11:20:15,067:INFO:display_container: 2
2023-02-14 11:20:15,068:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-14 11:20:15,068:INFO:create_model() succesfully completed......................................
2023-02-14 11:20:15,173:INFO:SubProcess create_model() end ==================================
2023-02-14 11:20:15,173:INFO:Creating metrics dataframe
2023-02-14 11:20:15,181:INFO:Initializing Light Gradient Boosting Machine
2023-02-14 11:20:15,181:INFO:Total runtime is 59.90187410116195 minutes
2023-02-14 11:20:15,184:INFO:SubProcess create_model() called ==================================
2023-02-14 11:20:15,184:INFO:Initializing create_model()
2023-02-14 11:20:15,184:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 11:20:15,184:INFO:Checking exceptions
2023-02-14 11:20:15,184:INFO:Importing libraries
2023-02-14 11:20:15,184:INFO:Copying training dataset
2023-02-14 11:20:15,202:INFO:Defining folds
2023-02-14 11:20:15,202:INFO:Declaring metric variables
2023-02-14 11:20:15,206:INFO:Importing untrained model
2023-02-14 11:20:15,209:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-14 11:20:15,215:INFO:Starting cross validation
2023-02-14 11:20:15,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 11:21:07,976:INFO:Calculating mean and std
2023-02-14 11:21:07,977:INFO:Creating metrics dataframe
2023-02-14 11:21:07,984:INFO:Uploading results into container
2023-02-14 11:21:07,984:INFO:Uploading model into container now
2023-02-14 11:21:07,984:INFO:create_model_container: 18
2023-02-14 11:21:07,984:INFO:master_model_container: 18
2023-02-14 11:21:07,984:INFO:display_container: 2
2023-02-14 11:21:07,985:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 11:21:07,985:INFO:create_model() succesfully completed......................................
2023-02-14 11:21:08,089:INFO:SubProcess create_model() end ==================================
2023-02-14 11:21:08,089:INFO:Creating metrics dataframe
2023-02-14 11:21:08,097:INFO:Initializing CatBoost Regressor
2023-02-14 11:21:08,097:INFO:Total runtime is 60.78381452957789 minutes
2023-02-14 11:21:08,101:INFO:SubProcess create_model() called ==================================
2023-02-14 11:21:08,101:INFO:Initializing create_model()
2023-02-14 11:21:08,101:INFO:create_model(estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 11:21:08,101:INFO:Checking exceptions
2023-02-14 11:21:08,101:INFO:Importing libraries
2023-02-14 11:21:08,101:INFO:Copying training dataset
2023-02-14 11:21:08,120:INFO:Defining folds
2023-02-14 11:21:08,121:INFO:Declaring metric variables
2023-02-14 11:21:08,124:INFO:Importing untrained model
2023-02-14 11:21:08,129:INFO:CatBoost Regressor Imported succesfully
2023-02-14 11:21:08,136:INFO:Starting cross validation
2023-02-14 11:21:08,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 11:34:07,735:INFO:Calculating mean and std
2023-02-14 11:34:07,736:INFO:Creating metrics dataframe
2023-02-14 11:34:07,742:INFO:Uploading results into container
2023-02-14 11:34:07,742:INFO:Uploading model into container now
2023-02-14 11:34:07,742:INFO:create_model_container: 19
2023-02-14 11:34:07,742:INFO:master_model_container: 19
2023-02-14 11:34:07,742:INFO:display_container: 2
2023-02-14 11:34:07,742:INFO:<catboost.core.CatBoostRegressor object at 0x7f66da9f62e0>
2023-02-14 11:34:07,742:INFO:create_model() succesfully completed......................................
2023-02-14 11:34:07,845:INFO:SubProcess create_model() end ==================================
2023-02-14 11:34:07,845:INFO:Creating metrics dataframe
2023-02-14 11:34:07,853:INFO:Initializing Dummy Regressor
2023-02-14 11:34:07,853:INFO:Total runtime is 73.77974536418914 minutes
2023-02-14 11:34:07,856:INFO:SubProcess create_model() called ==================================
2023-02-14 11:34:07,857:INFO:Initializing create_model()
2023-02-14 11:34:07,857:INFO:create_model(estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f66da3db4c0>, return_train_score=False, kwargs={})
2023-02-14 11:34:07,857:INFO:Checking exceptions
2023-02-14 11:34:07,857:INFO:Importing libraries
2023-02-14 11:34:07,857:INFO:Copying training dataset
2023-02-14 11:34:07,875:INFO:Defining folds
2023-02-14 11:34:07,875:INFO:Declaring metric variables
2023-02-14 11:34:07,878:INFO:Importing untrained model
2023-02-14 11:34:07,881:INFO:Dummy Regressor Imported succesfully
2023-02-14 11:34:07,887:INFO:Starting cross validation
2023-02-14 11:34:07,888:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 11:34:08,542:INFO:Calculating mean and std
2023-02-14 11:34:08,542:INFO:Creating metrics dataframe
2023-02-14 11:34:08,546:INFO:Uploading results into container
2023-02-14 11:34:08,546:INFO:Uploading model into container now
2023-02-14 11:34:08,546:INFO:create_model_container: 20
2023-02-14 11:34:08,546:INFO:master_model_container: 20
2023-02-14 11:34:08,546:INFO:display_container: 2
2023-02-14 11:34:08,546:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-02-14 11:34:08,546:INFO:create_model() succesfully completed......................................
2023-02-14 11:34:08,655:INFO:SubProcess create_model() end ==================================
2023-02-14 11:34:08,656:INFO:Creating metrics dataframe
2023-02-14 11:34:08,672:INFO:Initializing create_model()
2023-02-14 11:34:08,672:INFO:create_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-14 11:34:08,672:INFO:Checking exceptions
2023-02-14 11:34:08,672:INFO:Importing libraries
2023-02-14 11:34:08,672:INFO:Copying training dataset
2023-02-14 11:34:08,689:INFO:Defining folds
2023-02-14 11:34:08,689:INFO:Declaring metric variables
2023-02-14 11:34:08,689:INFO:Importing untrained model
2023-02-14 11:34:08,689:INFO:Declaring custom model
2023-02-14 11:34:08,689:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-14 11:34:08,689:INFO:Cross validation set to False
2023-02-14 11:34:08,690:INFO:Fitting Model
2023-02-14 11:34:08,936:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-14 11:34:08,936:INFO:create_models() succesfully completed......................................
2023-02-14 11:34:09,079:INFO:create_model_container: 20
2023-02-14 11:34:09,079:INFO:master_model_container: 20
2023-02-14 11:34:09,079:INFO:display_container: 2
2023-02-14 11:34:09,079:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-14 11:34:09,079:INFO:compare_models() succesfully completed......................................
2023-02-14 13:28:36,842:INFO:Initializing create_model()
2023-02-14 13:28:36,842:INFO:create_model(estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-14 13:28:36,842:INFO:Checking exceptions
2023-02-14 13:28:36,842:INFO:Preparing display monitor
2023-02-14 13:28:36,851:INFO:Importing libraries
2023-02-14 13:28:36,851:INFO:Copying training dataset
2023-02-14 13:28:36,869:INFO:Defining folds
2023-02-14 13:28:36,870:INFO:Declaring metric variables
2023-02-14 13:28:36,875:INFO:Importing untrained model
2023-02-14 13:28:36,880:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-14 13:28:36,889:INFO:Starting cross validation
2023-02-14 13:28:36,889:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 13:28:39,691:INFO:Calculating mean and std
2023-02-14 13:28:39,692:INFO:Creating metrics dataframe
2023-02-14 13:28:39,701:INFO:Finalizing model
2023-02-14 13:28:39,959:INFO:Uploading results into container
2023-02-14 13:28:39,959:INFO:Uploading model into container now
2023-02-14 13:28:39,965:INFO:create_model_container: 21
2023-02-14 13:28:39,965:INFO:master_model_container: 21
2023-02-14 13:28:39,965:INFO:display_container: 3
2023-02-14 13:28:39,965:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-14 13:28:39,965:INFO:create_model() succesfully completed......................................
2023-02-14 13:28:40,089:INFO:Initializing tune_model()
2023-02-14 13:28:40,089:INFO:tune_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-02-14 13:28:40,089:INFO:Checking exceptions
2023-02-14 13:28:40,089:INFO:Preparing display monitor
2023-02-14 13:28:40,098:INFO:Copying training dataset
2023-02-14 13:28:40,116:INFO:Checking base model
2023-02-14 13:28:40,116:INFO:Base model : Orthogonal Matching Pursuit
2023-02-14 13:28:40,122:INFO:Declaring metric variables
2023-02-14 13:28:40,127:INFO:Defining Hyperparameters
2023-02-14 13:28:40,219:INFO:Tuning with n_jobs=-1
2023-02-14 13:28:40,219:INFO:Initializing RandomizedSearchCV
2023-02-14 13:28:54,150:INFO:best_params: {'actual_estimator__normalize': True, 'actual_estimator__n_nonzero_coefs': 167, 'actual_estimator__fit_intercept': True}
2023-02-14 13:28:54,150:INFO:Hyperparameter search completed
2023-02-14 13:28:54,150:INFO:SubProcess create_model() called ==================================
2023-02-14 13:28:54,151:INFO:Initializing create_model()
2023-02-14 13:28:54,151:INFO:create_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f692aed7ca0>, return_train_score=False, kwargs={'normalize': True, 'n_nonzero_coefs': 167, 'fit_intercept': True})
2023-02-14 13:28:54,151:INFO:Checking exceptions
2023-02-14 13:28:54,151:INFO:Importing libraries
2023-02-14 13:28:54,151:INFO:Copying training dataset
2023-02-14 13:28:54,169:INFO:Defining folds
2023-02-14 13:28:54,169:INFO:Declaring metric variables
2023-02-14 13:28:54,175:INFO:Importing untrained model
2023-02-14 13:28:54,175:INFO:Declaring custom model
2023-02-14 13:28:54,181:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-14 13:28:54,191:INFO:Starting cross validation
2023-02-14 13:28:54,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 13:28:55,800:INFO:Calculating mean and std
2023-02-14 13:28:55,801:INFO:Creating metrics dataframe
2023-02-14 13:28:55,808:INFO:Finalizing model
2023-02-14 13:28:56,024:INFO:Uploading results into container
2023-02-14 13:28:56,024:INFO:Uploading model into container now
2023-02-14 13:28:56,024:INFO:create_model_container: 22
2023-02-14 13:28:56,024:INFO:master_model_container: 22
2023-02-14 13:28:56,025:INFO:display_container: 4
2023-02-14 13:28:56,025:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=167,
                          normalize=True, precompute='auto', tol=None)
2023-02-14 13:28:56,025:INFO:create_model() succesfully completed......................................
2023-02-14 13:28:56,146:INFO:SubProcess create_model() end ==================================
2023-02-14 13:28:56,146:INFO:choose_better activated
2023-02-14 13:28:56,152:INFO:SubProcess create_model() called ==================================
2023-02-14 13:28:56,152:INFO:Initializing create_model()
2023-02-14 13:28:56,152:INFO:create_model(estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-14 13:28:56,152:INFO:Checking exceptions
2023-02-14 13:28:56,152:INFO:Importing libraries
2023-02-14 13:28:56,152:INFO:Copying training dataset
2023-02-14 13:28:56,170:INFO:Defining folds
2023-02-14 13:28:56,170:INFO:Declaring metric variables
2023-02-14 13:28:56,170:INFO:Importing untrained model
2023-02-14 13:28:56,170:INFO:Declaring custom model
2023-02-14 13:28:56,170:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-14 13:28:56,170:INFO:Starting cross validation
2023-02-14 13:28:56,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 13:28:57,799:INFO:Calculating mean and std
2023-02-14 13:28:57,799:INFO:Creating metrics dataframe
2023-02-14 13:28:57,800:INFO:Finalizing model
2023-02-14 13:28:58,007:INFO:Uploading results into container
2023-02-14 13:28:58,007:INFO:Uploading model into container now
2023-02-14 13:28:58,007:INFO:create_model_container: 23
2023-02-14 13:28:58,007:INFO:master_model_container: 23
2023-02-14 13:28:58,007:INFO:display_container: 5
2023-02-14 13:28:58,007:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-14 13:28:58,008:INFO:create_model() succesfully completed......................................
2023-02-14 13:28:58,125:INFO:SubProcess create_model() end ==================================
2023-02-14 13:28:58,125:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None) result for R2 is 0.9544
2023-02-14 13:28:58,125:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=167,
                          normalize=True, precompute='auto', tol=None) result for R2 is 0.9545
2023-02-14 13:28:58,126:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=167,
                          normalize=True, precompute='auto', tol=None) is best model
2023-02-14 13:28:58,126:INFO:choose_better completed
2023-02-14 13:28:58,131:INFO:create_model_container: 23
2023-02-14 13:28:58,131:INFO:master_model_container: 23
2023-02-14 13:28:58,131:INFO:display_container: 4
2023-02-14 13:28:58,131:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=167,
                          normalize=True, precompute='auto', tol=None)
2023-02-14 13:28:58,131:INFO:tune_model() succesfully completed......................................
2023-02-14 13:28:58,229:INFO:Initializing create_model()
2023-02-14 13:28:58,229:INFO:create_model(estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-14 13:28:58,229:INFO:Checking exceptions
2023-02-14 13:28:58,229:INFO:Preparing display monitor
2023-02-14 13:28:58,237:INFO:Importing libraries
2023-02-14 13:28:58,237:INFO:Copying training dataset
2023-02-14 13:28:58,256:INFO:Defining folds
2023-02-14 13:28:58,256:INFO:Declaring metric variables
2023-02-14 13:28:58,261:INFO:Importing untrained model
2023-02-14 13:28:58,268:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-14 13:28:58,278:INFO:Starting cross validation
2023-02-14 13:28:58,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 13:33:40,900:INFO:PyCaret Supervised Module
2023-02-14 13:33:40,900:INFO:ML Usecase: regression
2023-02-14 13:33:40,900:INFO:version 2.3.10
2023-02-14 13:33:40,900:INFO:Initializing setup()
2023-02-14 13:33:40,900:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=True, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 13:33:40,900:INFO:Checking environment
2023-02-14 13:33:40,900:INFO:python_version: 3.9.16
2023-02-14 13:33:40,900:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 13:33:40,900:INFO:machine: x86_64
2023-02-14 13:33:40,900:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 13:33:40,901:INFO:Memory: svmem(total=134979592192, available=115045122048, percent=14.8, used=18216714240, free=111211110400, active=1799077888, inactive=20814913536, buffers=331014144, cached=5220753408, shared=525717504, slab=560562176)
2023-02-14 13:33:40,901:INFO:Physical Core: 16
2023-02-14 13:33:40,901:INFO:Logical Core: 32
2023-02-14 13:33:40,901:INFO:Checking libraries
2023-02-14 13:33:40,901:INFO:pd==1.5.2
2023-02-14 13:33:40,901:INFO:numpy==1.20.3
2023-02-14 13:33:40,901:INFO:sklearn==0.23.2
2023-02-14 13:33:40,901:INFO:lightgbm==3.3.5
2023-02-14 13:33:40,901:INFO:catboost==1.1.1
2023-02-14 13:33:40,901:INFO:xgboost==1.7.3
2023-02-14 13:33:40,901:INFO:mlflow==2.1.1
2023-02-14 13:33:40,901:INFO:Checking Exceptions
2023-02-14 13:33:40,902:INFO:Declaring global variables
2023-02-14 13:33:40,902:INFO:USI: 23c1
2023-02-14 13:33:40,902:INFO:pycaret_globals: {'html_param', '_all_metrics', 'master_model_container', 'X', 'exp_name_log', 'target_param', 'iterative_imputation_iters_param', 'data_before_preprocess', 'USI', 'dashboard_logger', 'create_model_container', 'logging_param', 'fold_generator', 'prep_pipe', 'imputation_classifier', '_gpu_n_jobs_param', 'log_plots_param', 'y_test', '_all_models_internal', 'fold_groups_param_full', 'transform_target_method_param', 'gpu_param', '_all_models', 'y_train', 'fix_imbalance_method_param', 'imputation_regressor', 'fix_imbalance_param', 'y', '_ml_usecase', 'experiment__', 'fold_shuffle_param', 'fold_groups_param', '_available_plots', 'n_jobs_param', 'fold_param', 'X_train', 'X_test', 'transform_target_param', '_internal_pipeline', 'stratify_param', 'seed', 'display_container', 'pycaret_globals'}
2023-02-14 13:33:40,902:INFO:Preparing display monitor
2023-02-14 13:33:40,902:INFO:Preparing display monitor
2023-02-14 13:33:40,906:INFO:Importing libraries
2023-02-14 13:33:40,906:INFO:Copying data for preprocessing
2023-02-14 13:33:41,018:INFO:Declaring preprocessing parameters
2023-02-14 13:33:41,226:INFO:Creating preprocessing pipeline
2023-02-14 13:33:46,224:INFO:Preprocessing pipeline created successfully
2023-02-14 13:33:46,225:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 13:33:46,225:INFO:Creating global containers
2023-02-14 13:33:46,225:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 13:39:54,117:INFO:PyCaret Supervised Module
2023-02-14 13:39:54,117:INFO:ML Usecase: regression
2023-02-14 13:39:54,117:INFO:version 2.3.10
2023-02-14 13:39:54,117:INFO:Initializing setup()
2023-02-14 13:39:54,117:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 13:39:54,117:INFO:Checking environment
2023-02-14 13:39:54,117:INFO:python_version: 3.9.16
2023-02-14 13:39:54,117:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 13:39:54,117:INFO:machine: x86_64
2023-02-14 13:39:54,117:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 13:39:54,117:INFO:Memory: svmem(total=134979592192, available=113619517440, percent=15.8, used=19650605056, free=109785268224, active=1805225984, inactive=22235561984, buffers=334102528, cached=5209616384, shared=518086656, slab=557912064)
2023-02-14 13:39:54,118:INFO:Physical Core: 16
2023-02-14 13:39:54,118:INFO:Logical Core: 32
2023-02-14 13:39:54,118:INFO:Checking libraries
2023-02-14 13:39:54,118:INFO:pd==1.5.2
2023-02-14 13:39:54,118:INFO:numpy==1.20.3
2023-02-14 13:39:54,118:INFO:sklearn==0.23.2
2023-02-14 13:39:54,118:INFO:lightgbm==3.3.5
2023-02-14 13:39:54,118:INFO:catboost==1.1.1
2023-02-14 13:39:54,118:INFO:xgboost==1.7.3
2023-02-14 13:39:54,118:INFO:mlflow==2.1.1
2023-02-14 13:39:54,118:INFO:Checking Exceptions
2023-02-14 13:39:54,118:INFO:Declaring global variables
2023-02-14 13:39:54,118:INFO:USI: 41af
2023-02-14 13:39:54,118:INFO:pycaret_globals: {'html_param', '_all_metrics', 'master_model_container', 'X', 'exp_name_log', 'target_param', 'iterative_imputation_iters_param', 'data_before_preprocess', 'USI', 'dashboard_logger', 'create_model_container', 'logging_param', 'fold_generator', 'prep_pipe', 'imputation_classifier', '_gpu_n_jobs_param', 'log_plots_param', 'y_test', '_all_models_internal', 'fold_groups_param_full', 'transform_target_method_param', 'gpu_param', '_all_models', 'y_train', 'fix_imbalance_method_param', 'imputation_regressor', 'fix_imbalance_param', 'y', '_ml_usecase', 'experiment__', 'fold_shuffle_param', 'fold_groups_param', '_available_plots', 'n_jobs_param', 'fold_param', 'X_train', 'X_test', 'transform_target_param', '_internal_pipeline', 'stratify_param', 'seed', 'display_container', 'pycaret_globals'}
2023-02-14 13:39:54,118:INFO:Preparing display monitor
2023-02-14 13:39:54,119:INFO:Preparing display monitor
2023-02-14 13:39:54,123:INFO:Importing libraries
2023-02-14 13:39:54,123:INFO:Copying data for preprocessing
2023-02-14 13:39:54,229:INFO:Declaring preprocessing parameters
2023-02-14 13:39:54,230:WARNING:cuML not found
2023-02-14 13:39:54,230:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-14 13:39:54,424:INFO:Creating preprocessing pipeline
2023-02-14 13:39:59,120:INFO:Preprocessing pipeline created successfully
2023-02-14 13:39:59,121:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 13:39:59,121:INFO:Creating global containers
2023-02-14 13:39:59,121:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 13:41:39,087:INFO:PyCaret Supervised Module
2023-02-14 13:41:39,087:INFO:ML Usecase: regression
2023-02-14 13:41:39,087:INFO:version 2.3.10
2023-02-14 13:41:39,087:INFO:Initializing setup()
2023-02-14 13:41:39,087:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 13:41:39,088:INFO:Checking environment
2023-02-14 13:41:39,088:INFO:python_version: 3.9.16
2023-02-14 13:41:39,088:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 13:41:39,088:INFO:machine: x86_64
2023-02-14 13:41:39,088:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 13:41:39,088:INFO:Memory: svmem(total=134979592192, available=119482281984, percent=11.5, used=13765967872, free=115625865216, active=1829117952, inactive=16378155008, buffers=335261696, cached=5252497408, shared=539713536, slab=557383680)
2023-02-14 13:41:39,088:INFO:Physical Core: 16
2023-02-14 13:41:39,088:INFO:Logical Core: 32
2023-02-14 13:41:39,088:INFO:Checking libraries
2023-02-14 13:41:39,088:INFO:pd==1.5.2
2023-02-14 13:41:39,088:INFO:numpy==1.20.3
2023-02-14 13:41:39,088:INFO:sklearn==0.23.2
2023-02-14 13:41:39,089:INFO:lightgbm==3.3.5
2023-02-14 13:41:39,104:INFO:catboost==1.1.1
2023-02-14 13:41:39,104:INFO:xgboost==1.7.3
2023-02-14 13:41:39,104:INFO:mlflow==2.1.1
2023-02-14 13:41:39,104:INFO:Checking Exceptions
2023-02-14 13:41:39,105:INFO:Declaring global variables
2023-02-14 13:41:39,105:INFO:USI: 0530
2023-02-14 13:41:39,105:INFO:pycaret_globals: {'y', 'pycaret_globals', 'X', 'exp_name_log', '_all_metrics', 'fold_shuffle_param', '_ml_usecase', '_internal_pipeline', 'html_param', 'USI', 'imputation_regressor', 'create_model_container', 'fold_generator', 'X_train', 'imputation_classifier', 'logging_param', '_all_models_internal', 'fold_param', 'iterative_imputation_iters_param', 'stratify_param', 'transform_target_param', 'fix_imbalance_param', 'seed', 'display_container', 'fix_imbalance_method_param', 'y_train', 'fold_groups_param', 'target_param', 'n_jobs_param', '_available_plots', 'y_test', 'master_model_container', 'X_test', '_all_models', 'data_before_preprocess', 'fold_groups_param_full', 'gpu_param', 'prep_pipe', 'dashboard_logger', 'experiment__', '_gpu_n_jobs_param', 'transform_target_method_param', 'log_plots_param'}
2023-02-14 13:41:39,105:INFO:Preparing display monitor
2023-02-14 13:41:39,105:INFO:Preparing display monitor
2023-02-14 13:41:39,110:INFO:Importing libraries
2023-02-14 13:41:39,110:INFO:Copying data for preprocessing
2023-02-14 13:41:39,211:INFO:Declaring preprocessing parameters
2023-02-14 13:41:39,211:WARNING:cuML not found
2023-02-14 13:41:39,211:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-14 13:41:39,405:INFO:Creating preprocessing pipeline
2023-02-14 13:42:19,241:INFO:PyCaret Supervised Module
2023-02-14 13:42:19,241:INFO:ML Usecase: regression
2023-02-14 13:42:19,241:INFO:version 2.3.10
2023-02-14 13:42:19,241:INFO:Initializing setup()
2023-02-14 13:42:19,241:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 13:42:19,242:INFO:Checking environment
2023-02-14 13:42:19,242:INFO:python_version: 3.9.16
2023-02-14 13:42:19,242:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 13:42:19,242:INFO:machine: x86_64
2023-02-14 13:42:19,242:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 13:42:19,242:INFO:Memory: svmem(total=134979592192, available=116208443392, percent=13.9, used=17043275776, free=112351514624, active=1830313984, inactive=19654598656, buffers=335601664, cached=5249200128, shared=536236032, slab=557461504)
2023-02-14 13:42:19,242:INFO:Physical Core: 16
2023-02-14 13:42:19,242:INFO:Logical Core: 32
2023-02-14 13:42:19,242:INFO:Checking libraries
2023-02-14 13:42:19,242:INFO:pd==1.5.2
2023-02-14 13:42:19,242:INFO:numpy==1.20.3
2023-02-14 13:42:19,242:INFO:sklearn==0.23.2
2023-02-14 13:42:19,242:INFO:lightgbm==3.3.5
2023-02-14 13:42:19,242:INFO:catboost==1.1.1
2023-02-14 13:42:19,242:INFO:xgboost==1.7.3
2023-02-14 13:42:19,243:INFO:mlflow==2.1.1
2023-02-14 13:42:19,243:INFO:Checking Exceptions
2023-02-14 13:42:19,243:INFO:Declaring global variables
2023-02-14 13:42:19,243:INFO:USI: ebb9
2023-02-14 13:42:19,243:INFO:pycaret_globals: {'y', 'pycaret_globals', 'X', 'exp_name_log', '_all_metrics', 'fold_shuffle_param', '_ml_usecase', '_internal_pipeline', 'html_param', 'USI', 'imputation_regressor', 'create_model_container', 'fold_generator', 'X_train', 'imputation_classifier', 'logging_param', '_all_models_internal', 'fold_param', 'iterative_imputation_iters_param', 'stratify_param', 'transform_target_param', 'fix_imbalance_param', 'seed', 'display_container', 'fix_imbalance_method_param', 'y_train', 'fold_groups_param', 'target_param', 'n_jobs_param', '_available_plots', 'y_test', 'master_model_container', 'X_test', '_all_models', 'data_before_preprocess', 'fold_groups_param_full', 'gpu_param', 'prep_pipe', 'dashboard_logger', 'experiment__', '_gpu_n_jobs_param', 'transform_target_method_param', 'log_plots_param'}
2023-02-14 13:42:19,243:INFO:Preparing display monitor
2023-02-14 13:42:19,243:INFO:Preparing display monitor
2023-02-14 13:42:19,247:INFO:Importing libraries
2023-02-14 13:42:19,247:INFO:Copying data for preprocessing
2023-02-14 13:42:19,350:INFO:Declaring preprocessing parameters
2023-02-14 13:42:19,350:WARNING:cuML not found
2023-02-14 13:42:19,351:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-14 13:42:19,542:INFO:Creating preprocessing pipeline
2023-02-14 13:42:24,345:INFO:Preprocessing pipeline created successfully
2023-02-14 13:42:24,346:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 13:42:24,346:INFO:Creating global containers
2023-02-14 13:42:24,346:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 13:52:30,247:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 13:52:30,247:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 13:52:30,250:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 13:52:30,252:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 13:52:30,285:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 13:52:30,311:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 13:52:30,311:WARNING:Couldn't import cuml.ensemble
2023-02-14 13:52:30,361:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 13:52:30,362:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 13:52:30,365:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 13:52:30,368:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 13:52:30,400:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 13:52:30,425:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 13:52:30,425:WARNING:Couldn't import cuml.ensemble
2023-02-14 13:52:30,438:INFO:Creating grid variables
2023-02-14 13:52:30,537:INFO:create_model_container: 0
2023-02-14 13:52:30,537:INFO:master_model_container: 0
2023-02-14 13:52:30,537:INFO:display_container: 1
2023-02-14 13:52:30,540:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select',
                 Advanced_Feature_Selection_Classic(ml_usecase='regression',
                                                    n_jobs=-1, random_state=11,
                                                    subclass='binary',
                                                    target='closeChg%_forward24HR',
                                                    top_features_to_pick=0.19999999999999996)),
                ('fix_multi', 'passthrough'), ('dfs', 'passthrough'),
                ('pca', 'passthrough')],
         verbose=False)
2023-02-14 13:52:30,540:INFO:setup() succesfully completed......................................
2023-02-14 13:52:30,672:INFO:Initializing compare_models()
2023-02-14 13:52:30,672:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=['tr'])
2023-02-14 13:52:30,672:INFO:Checking exceptions
2023-02-14 13:52:30,672:INFO:Preparing display monitor
2023-02-14 13:52:30,672:INFO:Preparing display monitor
2023-02-14 13:52:30,683:INFO:Initializing Linear Regression
2023-02-14 13:52:30,683:INFO:Total runtime is 1.5099843343098958e-06 minutes
2023-02-14 13:52:30,686:INFO:SubProcess create_model() called ==================================
2023-02-14 13:52:30,687:INFO:Initializing create_model()
2023-02-14 13:52:30,687:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:52:30,687:INFO:Checking exceptions
2023-02-14 13:52:30,687:INFO:Importing libraries
2023-02-14 13:52:30,687:INFO:Copying training dataset
2023-02-14 13:52:30,704:INFO:Defining folds
2023-02-14 13:52:30,704:INFO:Declaring metric variables
2023-02-14 13:52:30,708:INFO:Importing untrained model
2023-02-14 13:52:30,711:INFO:Linear Regression Imported succesfully
2023-02-14 13:52:30,717:INFO:Starting cross validation
2023-02-14 13:52:30,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 13:52:53,830:INFO:Calculating mean and std
2023-02-14 13:52:53,832:INFO:Creating metrics dataframe
2023-02-14 13:52:53,838:INFO:Uploading results into container
2023-02-14 13:52:53,838:INFO:Uploading model into container now
2023-02-14 13:52:53,838:INFO:create_model_container: 1
2023-02-14 13:52:53,838:INFO:master_model_container: 1
2023-02-14 13:52:53,838:INFO:display_container: 2
2023-02-14 13:52:53,839:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-14 13:52:53,839:INFO:create_model() succesfully completed......................................
2023-02-14 13:52:54,000:INFO:SubProcess create_model() end ==================================
2023-02-14 13:52:54,000:INFO:Creating metrics dataframe
2023-02-14 13:52:54,005:INFO:Initializing Lasso Regression
2023-02-14 13:52:54,005:INFO:Total runtime is 0.3887048641840617 minutes
2023-02-14 13:52:54,009:INFO:SubProcess create_model() called ==================================
2023-02-14 13:52:54,010:INFO:Initializing create_model()
2023-02-14 13:52:54,010:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:52:54,010:INFO:Checking exceptions
2023-02-14 13:52:54,010:INFO:Importing libraries
2023-02-14 13:52:54,010:INFO:Copying training dataset
2023-02-14 13:52:54,028:INFO:Defining folds
2023-02-14 13:52:54,028:INFO:Declaring metric variables
2023-02-14 13:52:54,032:INFO:Importing untrained model
2023-02-14 13:52:54,035:INFO:Lasso Regression Imported succesfully
2023-02-14 13:52:54,041:INFO:Starting cross validation
2023-02-14 13:52:54,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 13:52:55,954:INFO:Calculating mean and std
2023-02-14 13:52:55,955:INFO:Creating metrics dataframe
2023-02-14 13:52:55,962:INFO:Uploading results into container
2023-02-14 13:52:55,964:INFO:Uploading model into container now
2023-02-14 13:52:55,964:INFO:create_model_container: 2
2023-02-14 13:52:55,964:INFO:master_model_container: 2
2023-02-14 13:52:55,964:INFO:display_container: 2
2023-02-14 13:52:55,964:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-14 13:52:55,964:INFO:create_model() succesfully completed......................................
2023-02-14 13:52:56,113:INFO:SubProcess create_model() end ==================================
2023-02-14 13:52:56,113:INFO:Creating metrics dataframe
2023-02-14 13:52:56,119:INFO:Initializing Ridge Regression
2023-02-14 13:52:56,119:INFO:Total runtime is 0.42393932342529295 minutes
2023-02-14 13:52:56,123:INFO:SubProcess create_model() called ==================================
2023-02-14 13:52:56,123:INFO:Initializing create_model()
2023-02-14 13:52:56,123:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:52:56,123:INFO:Checking exceptions
2023-02-14 13:52:56,123:INFO:Importing libraries
2023-02-14 13:52:56,123:INFO:Copying training dataset
2023-02-14 13:52:56,140:INFO:Defining folds
2023-02-14 13:52:56,140:INFO:Declaring metric variables
2023-02-14 13:52:56,144:INFO:Importing untrained model
2023-02-14 13:52:56,147:INFO:Ridge Regression Imported succesfully
2023-02-14 13:52:56,152:INFO:Starting cross validation
2023-02-14 13:52:56,153:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 13:52:59,256:INFO:Calculating mean and std
2023-02-14 13:52:59,257:INFO:Creating metrics dataframe
2023-02-14 13:52:59,265:INFO:Uploading results into container
2023-02-14 13:52:59,272:INFO:Uploading model into container now
2023-02-14 13:52:59,272:INFO:create_model_container: 3
2023-02-14 13:52:59,272:INFO:master_model_container: 3
2023-02-14 13:52:59,272:INFO:display_container: 2
2023-02-14 13:52:59,272:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-14 13:52:59,272:INFO:create_model() succesfully completed......................................
2023-02-14 13:52:59,408:INFO:SubProcess create_model() end ==================================
2023-02-14 13:52:59,408:INFO:Creating metrics dataframe
2023-02-14 13:52:59,415:INFO:Initializing Elastic Net
2023-02-14 13:52:59,415:INFO:Total runtime is 0.4788600524266561 minutes
2023-02-14 13:52:59,418:INFO:SubProcess create_model() called ==================================
2023-02-14 13:52:59,418:INFO:Initializing create_model()
2023-02-14 13:52:59,418:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:52:59,418:INFO:Checking exceptions
2023-02-14 13:52:59,418:INFO:Importing libraries
2023-02-14 13:52:59,418:INFO:Copying training dataset
2023-02-14 13:52:59,436:INFO:Defining folds
2023-02-14 13:52:59,436:INFO:Declaring metric variables
2023-02-14 13:52:59,439:INFO:Importing untrained model
2023-02-14 13:52:59,442:INFO:Elastic Net Imported succesfully
2023-02-14 13:52:59,448:INFO:Starting cross validation
2023-02-14 13:52:59,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 13:53:01,316:INFO:Calculating mean and std
2023-02-14 13:53:01,317:INFO:Creating metrics dataframe
2023-02-14 13:53:01,322:INFO:Uploading results into container
2023-02-14 13:53:01,326:INFO:Uploading model into container now
2023-02-14 13:53:01,326:INFO:create_model_container: 4
2023-02-14 13:53:01,326:INFO:master_model_container: 4
2023-02-14 13:53:01,326:INFO:display_container: 2
2023-02-14 13:53:01,326:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-14 13:53:01,326:INFO:create_model() succesfully completed......................................
2023-02-14 13:53:01,480:INFO:SubProcess create_model() end ==================================
2023-02-14 13:53:01,480:INFO:Creating metrics dataframe
2023-02-14 13:53:01,487:INFO:Initializing Least Angle Regression
2023-02-14 13:53:01,487:INFO:Total runtime is 0.5133986274401346 minutes
2023-02-14 13:53:01,490:INFO:SubProcess create_model() called ==================================
2023-02-14 13:53:01,490:INFO:Initializing create_model()
2023-02-14 13:53:01,490:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:53:01,490:INFO:Checking exceptions
2023-02-14 13:53:01,490:INFO:Importing libraries
2023-02-14 13:53:01,491:INFO:Copying training dataset
2023-02-14 13:53:01,508:INFO:Defining folds
2023-02-14 13:53:01,508:INFO:Declaring metric variables
2023-02-14 13:53:01,512:INFO:Importing untrained model
2023-02-14 13:53:01,514:INFO:Least Angle Regression Imported succesfully
2023-02-14 13:53:01,520:INFO:Starting cross validation
2023-02-14 13:53:01,521:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 13:53:08,294:INFO:Calculating mean and std
2023-02-14 13:53:08,295:INFO:Creating metrics dataframe
2023-02-14 13:53:08,298:INFO:Uploading results into container
2023-02-14 13:53:08,298:INFO:Uploading model into container now
2023-02-14 13:53:08,298:INFO:create_model_container: 5
2023-02-14 13:53:08,298:INFO:master_model_container: 5
2023-02-14 13:53:08,299:INFO:display_container: 2
2023-02-14 13:53:08,299:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize=True, precompute='auto',
     random_state=11, verbose=False)
2023-02-14 13:53:08,299:INFO:create_model() succesfully completed......................................
2023-02-14 13:53:08,442:INFO:SubProcess create_model() end ==================================
2023-02-14 13:53:08,442:INFO:Creating metrics dataframe
2023-02-14 13:53:08,448:INFO:Initializing Lasso Least Angle Regression
2023-02-14 13:53:08,448:INFO:Total runtime is 0.6294217467308044 minutes
2023-02-14 13:53:08,452:INFO:SubProcess create_model() called ==================================
2023-02-14 13:53:08,452:INFO:Initializing create_model()
2023-02-14 13:53:08,452:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:53:08,452:INFO:Checking exceptions
2023-02-14 13:53:08,452:INFO:Importing libraries
2023-02-14 13:53:08,452:INFO:Copying training dataset
2023-02-14 13:53:08,469:INFO:Defining folds
2023-02-14 13:53:08,469:INFO:Declaring metric variables
2023-02-14 13:53:08,473:INFO:Importing untrained model
2023-02-14 13:53:08,476:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-14 13:53:08,481:INFO:Starting cross validation
2023-02-14 13:53:08,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 13:53:11,145:INFO:Calculating mean and std
2023-02-14 13:53:11,146:INFO:Creating metrics dataframe
2023-02-14 13:53:11,149:INFO:Uploading results into container
2023-02-14 13:53:11,150:INFO:Uploading model into container now
2023-02-14 13:53:11,150:INFO:create_model_container: 6
2023-02-14 13:53:11,150:INFO:master_model_container: 6
2023-02-14 13:53:11,150:INFO:display_container: 2
2023-02-14 13:53:11,150:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-14 13:53:11,150:INFO:create_model() succesfully completed......................................
2023-02-14 13:53:11,292:INFO:SubProcess create_model() end ==================================
2023-02-14 13:53:11,293:INFO:Creating metrics dataframe
2023-02-14 13:53:11,299:INFO:Initializing Orthogonal Matching Pursuit
2023-02-14 13:53:11,299:INFO:Total runtime is 0.6769339958826701 minutes
2023-02-14 13:53:11,302:INFO:SubProcess create_model() called ==================================
2023-02-14 13:53:11,303:INFO:Initializing create_model()
2023-02-14 13:53:11,303:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:53:11,303:INFO:Checking exceptions
2023-02-14 13:53:11,303:INFO:Importing libraries
2023-02-14 13:53:11,303:INFO:Copying training dataset
2023-02-14 13:53:11,320:INFO:Defining folds
2023-02-14 13:53:11,320:INFO:Declaring metric variables
2023-02-14 13:53:11,324:INFO:Importing untrained model
2023-02-14 13:53:11,327:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-14 13:53:11,332:INFO:Starting cross validation
2023-02-14 13:53:11,333:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 13:53:14,203:INFO:Calculating mean and std
2023-02-14 13:53:14,204:INFO:Creating metrics dataframe
2023-02-14 13:53:14,208:INFO:Uploading results into container
2023-02-14 13:53:14,208:INFO:Uploading model into container now
2023-02-14 13:53:14,208:INFO:create_model_container: 7
2023-02-14 13:53:14,208:INFO:master_model_container: 7
2023-02-14 13:53:14,208:INFO:display_container: 2
2023-02-14 13:53:14,208:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-14 13:53:14,208:INFO:create_model() succesfully completed......................................
2023-02-14 13:53:14,346:INFO:SubProcess create_model() end ==================================
2023-02-14 13:53:14,346:INFO:Creating metrics dataframe
2023-02-14 13:53:14,353:INFO:Initializing Bayesian Ridge
2023-02-14 13:53:14,353:INFO:Total runtime is 0.7278276125590006 minutes
2023-02-14 13:53:14,356:INFO:SubProcess create_model() called ==================================
2023-02-14 13:53:14,356:INFO:Initializing create_model()
2023-02-14 13:53:14,356:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:53:14,356:INFO:Checking exceptions
2023-02-14 13:53:14,356:INFO:Importing libraries
2023-02-14 13:53:14,356:INFO:Copying training dataset
2023-02-14 13:53:14,374:INFO:Defining folds
2023-02-14 13:53:14,374:INFO:Declaring metric variables
2023-02-14 13:53:14,378:INFO:Importing untrained model
2023-02-14 13:53:14,381:INFO:Bayesian Ridge Imported succesfully
2023-02-14 13:53:14,388:INFO:Starting cross validation
2023-02-14 13:53:14,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 13:54:27,383:INFO:Calculating mean and std
2023-02-14 13:54:27,384:INFO:Creating metrics dataframe
2023-02-14 13:54:27,387:INFO:Uploading results into container
2023-02-14 13:54:27,387:INFO:Uploading model into container now
2023-02-14 13:54:27,387:INFO:create_model_container: 8
2023-02-14 13:54:27,387:INFO:master_model_container: 8
2023-02-14 13:54:27,387:INFO:display_container: 2
2023-02-14 13:54:27,387:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-14 13:54:27,387:INFO:create_model() succesfully completed......................................
2023-02-14 13:54:27,543:INFO:SubProcess create_model() end ==================================
2023-02-14 13:54:27,543:INFO:Creating metrics dataframe
2023-02-14 13:54:27,550:INFO:Initializing Passive Aggressive Regressor
2023-02-14 13:54:27,550:INFO:Total runtime is 1.9477856357892354 minutes
2023-02-14 13:54:27,554:INFO:SubProcess create_model() called ==================================
2023-02-14 13:54:27,554:INFO:Initializing create_model()
2023-02-14 13:54:27,554:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:54:27,554:INFO:Checking exceptions
2023-02-14 13:54:27,554:INFO:Importing libraries
2023-02-14 13:54:27,554:INFO:Copying training dataset
2023-02-14 13:54:27,572:INFO:Defining folds
2023-02-14 13:54:27,572:INFO:Declaring metric variables
2023-02-14 13:54:27,575:INFO:Importing untrained model
2023-02-14 13:54:27,579:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-14 13:54:27,584:INFO:Starting cross validation
2023-02-14 13:54:27,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 13:54:32,065:INFO:Calculating mean and std
2023-02-14 13:54:32,065:INFO:Creating metrics dataframe
2023-02-14 13:54:32,068:INFO:Uploading results into container
2023-02-14 13:54:32,068:INFO:Uploading model into container now
2023-02-14 13:54:32,068:INFO:create_model_container: 9
2023-02-14 13:54:32,068:INFO:master_model_container: 9
2023-02-14 13:54:32,068:INFO:display_container: 2
2023-02-14 13:54:32,068:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-14 13:54:32,068:INFO:create_model() succesfully completed......................................
2023-02-14 13:54:32,209:INFO:SubProcess create_model() end ==================================
2023-02-14 13:54:32,209:INFO:Creating metrics dataframe
2023-02-14 13:54:32,216:INFO:Initializing Huber Regressor
2023-02-14 13:54:32,216:INFO:Total runtime is 2.025556099414825 minutes
2023-02-14 13:54:32,220:INFO:SubProcess create_model() called ==================================
2023-02-14 13:54:32,220:INFO:Initializing create_model()
2023-02-14 13:54:32,220:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:54:32,220:INFO:Checking exceptions
2023-02-14 13:54:32,220:INFO:Importing libraries
2023-02-14 13:54:32,220:INFO:Copying training dataset
2023-02-14 13:54:32,238:INFO:Defining folds
2023-02-14 13:54:32,238:INFO:Declaring metric variables
2023-02-14 13:54:32,241:INFO:Importing untrained model
2023-02-14 13:54:32,244:INFO:Huber Regressor Imported succesfully
2023-02-14 13:54:32,250:INFO:Starting cross validation
2023-02-14 13:54:32,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 13:59:18,743:INFO:Calculating mean and std
2023-02-14 13:59:18,744:INFO:Creating metrics dataframe
2023-02-14 13:59:18,747:INFO:Uploading results into container
2023-02-14 13:59:18,747:INFO:Uploading model into container now
2023-02-14 13:59:18,747:INFO:create_model_container: 10
2023-02-14 13:59:18,747:INFO:master_model_container: 10
2023-02-14 13:59:18,747:INFO:display_container: 2
2023-02-14 13:59:18,747:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-14 13:59:18,747:INFO:create_model() succesfully completed......................................
2023-02-14 13:59:18,895:INFO:SubProcess create_model() end ==================================
2023-02-14 13:59:18,896:INFO:Creating metrics dataframe
2023-02-14 13:59:18,907:INFO:Initializing K Neighbors Regressor
2023-02-14 13:59:18,907:INFO:Total runtime is 6.803733289241791 minutes
2023-02-14 13:59:18,910:INFO:SubProcess create_model() called ==================================
2023-02-14 13:59:18,911:INFO:Initializing create_model()
2023-02-14 13:59:18,911:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 13:59:18,911:INFO:Checking exceptions
2023-02-14 13:59:18,911:INFO:Importing libraries
2023-02-14 13:59:18,911:INFO:Copying training dataset
2023-02-14 13:59:18,928:INFO:Defining folds
2023-02-14 13:59:18,929:INFO:Declaring metric variables
2023-02-14 13:59:18,932:INFO:Importing untrained model
2023-02-14 13:59:18,935:INFO:K Neighbors Regressor Imported succesfully
2023-02-14 13:59:18,941:INFO:Starting cross validation
2023-02-14 13:59:18,941:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 14:02:27,034:INFO:Calculating mean and std
2023-02-14 14:02:27,035:INFO:Creating metrics dataframe
2023-02-14 14:02:27,040:INFO:Uploading results into container
2023-02-14 14:02:27,040:INFO:Uploading model into container now
2023-02-14 14:02:27,040:INFO:create_model_container: 11
2023-02-14 14:02:27,040:INFO:master_model_container: 11
2023-02-14 14:02:27,040:INFO:display_container: 2
2023-02-14 14:02:27,040:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-14 14:02:27,040:INFO:create_model() succesfully completed......................................
2023-02-14 14:02:27,171:INFO:SubProcess create_model() end ==================================
2023-02-14 14:02:27,171:INFO:Creating metrics dataframe
2023-02-14 14:02:27,179:INFO:Initializing Decision Tree Regressor
2023-02-14 14:02:27,179:INFO:Total runtime is 9.941597870985667 minutes
2023-02-14 14:02:27,183:INFO:SubProcess create_model() called ==================================
2023-02-14 14:02:27,183:INFO:Initializing create_model()
2023-02-14 14:02:27,183:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 14:02:27,183:INFO:Checking exceptions
2023-02-14 14:02:27,183:INFO:Importing libraries
2023-02-14 14:02:27,183:INFO:Copying training dataset
2023-02-14 14:02:27,201:INFO:Defining folds
2023-02-14 14:02:27,201:INFO:Declaring metric variables
2023-02-14 14:02:27,205:INFO:Importing untrained model
2023-02-14 14:02:27,208:INFO:Decision Tree Regressor Imported succesfully
2023-02-14 14:02:27,214:INFO:Starting cross validation
2023-02-14 14:02:27,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 14:08:03,838:INFO:Calculating mean and std
2023-02-14 14:08:03,839:INFO:Creating metrics dataframe
2023-02-14 14:08:03,841:INFO:Uploading results into container
2023-02-14 14:08:03,841:INFO:Uploading model into container now
2023-02-14 14:08:03,841:INFO:create_model_container: 12
2023-02-14 14:08:03,841:INFO:master_model_container: 12
2023-02-14 14:08:03,841:INFO:display_container: 2
2023-02-14 14:08:03,841:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-14 14:08:03,841:INFO:create_model() succesfully completed......................................
2023-02-14 14:08:03,963:INFO:SubProcess create_model() end ==================================
2023-02-14 14:08:03,963:INFO:Creating metrics dataframe
2023-02-14 14:08:03,970:INFO:Initializing Random Forest Regressor
2023-02-14 14:08:03,970:INFO:Total runtime is 15.554777308305106 minutes
2023-02-14 14:08:03,973:INFO:SubProcess create_model() called ==================================
2023-02-14 14:08:03,973:INFO:Initializing create_model()
2023-02-14 14:08:03,973:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 14:08:03,973:INFO:Checking exceptions
2023-02-14 14:08:03,973:INFO:Importing libraries
2023-02-14 14:08:03,973:INFO:Copying training dataset
2023-02-14 14:08:03,991:INFO:Defining folds
2023-02-14 14:08:03,991:INFO:Declaring metric variables
2023-02-14 14:08:03,994:INFO:Importing untrained model
2023-02-14 14:08:03,997:INFO:Random Forest Regressor Imported succesfully
2023-02-14 14:08:04,003:INFO:Starting cross validation
2023-02-14 14:08:04,003:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 14:27:34,843:INFO:Calculating mean and std
2023-02-14 14:27:34,844:INFO:Creating metrics dataframe
2023-02-14 14:27:34,846:INFO:Uploading results into container
2023-02-14 14:27:34,846:INFO:Uploading model into container now
2023-02-14 14:27:34,846:INFO:create_model_container: 13
2023-02-14 14:27:34,846:INFO:master_model_container: 13
2023-02-14 14:27:34,846:INFO:display_container: 2
2023-02-14 14:27:34,846:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-14 14:27:34,846:INFO:create_model() succesfully completed......................................
2023-02-14 14:27:34,990:INFO:SubProcess create_model() end ==================================
2023-02-14 14:27:34,990:INFO:Creating metrics dataframe
2023-02-14 14:27:34,998:INFO:Initializing Extra Trees Regressor
2023-02-14 14:27:34,998:INFO:Total runtime is 35.07191848754883 minutes
2023-02-14 14:27:35,003:INFO:SubProcess create_model() called ==================================
2023-02-14 14:27:35,003:INFO:Initializing create_model()
2023-02-14 14:27:35,003:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 14:27:35,003:INFO:Checking exceptions
2023-02-14 14:27:35,003:INFO:Importing libraries
2023-02-14 14:27:35,003:INFO:Copying training dataset
2023-02-14 14:27:35,021:INFO:Defining folds
2023-02-14 14:27:35,021:INFO:Declaring metric variables
2023-02-14 14:27:35,025:INFO:Importing untrained model
2023-02-14 14:27:35,028:INFO:Extra Trees Regressor Imported succesfully
2023-02-14 14:27:35,034:INFO:Starting cross validation
2023-02-14 14:27:35,034:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 14:40:07,854:INFO:Calculating mean and std
2023-02-14 14:40:07,855:INFO:Creating metrics dataframe
2023-02-14 14:40:07,857:INFO:Uploading results into container
2023-02-14 14:40:07,858:INFO:Uploading model into container now
2023-02-14 14:40:07,858:INFO:create_model_container: 14
2023-02-14 14:40:07,858:INFO:master_model_container: 14
2023-02-14 14:40:07,858:INFO:display_container: 2
2023-02-14 14:40:07,858:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-14 14:40:07,858:INFO:create_model() succesfully completed......................................
2023-02-14 14:40:07,981:INFO:SubProcess create_model() end ==================================
2023-02-14 14:40:07,981:INFO:Creating metrics dataframe
2023-02-14 14:40:07,988:INFO:Initializing AdaBoost Regressor
2023-02-14 14:40:07,989:INFO:Total runtime is 47.6217583656311 minutes
2023-02-14 14:40:07,992:INFO:SubProcess create_model() called ==================================
2023-02-14 14:40:07,992:INFO:Initializing create_model()
2023-02-14 14:40:07,992:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 14:40:07,992:INFO:Checking exceptions
2023-02-14 14:40:07,992:INFO:Importing libraries
2023-02-14 14:40:07,993:INFO:Copying training dataset
2023-02-14 14:40:08,010:INFO:Defining folds
2023-02-14 14:40:08,010:INFO:Declaring metric variables
2023-02-14 14:40:08,014:INFO:Importing untrained model
2023-02-14 14:40:08,017:INFO:AdaBoost Regressor Imported succesfully
2023-02-14 14:40:08,022:INFO:Starting cross validation
2023-02-14 14:40:08,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 15:11:24,837:INFO:Calculating mean and std
2023-02-14 15:11:24,838:INFO:Creating metrics dataframe
2023-02-14 15:11:24,840:INFO:Uploading results into container
2023-02-14 15:11:24,840:INFO:Uploading model into container now
2023-02-14 15:11:24,840:INFO:create_model_container: 15
2023-02-14 15:11:24,840:INFO:master_model_container: 15
2023-02-14 15:11:24,840:INFO:display_container: 2
2023-02-14 15:11:24,840:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-14 15:11:24,840:INFO:create_model() succesfully completed......................................
2023-02-14 15:11:24,965:INFO:SubProcess create_model() end ==================================
2023-02-14 15:11:24,965:INFO:Creating metrics dataframe
2023-02-14 15:11:24,973:INFO:Initializing Gradient Boosting Regressor
2023-02-14 15:11:24,973:INFO:Total runtime is 78.90483370224635 minutes
2023-02-14 15:11:24,977:INFO:SubProcess create_model() called ==================================
2023-02-14 15:11:24,977:INFO:Initializing create_model()
2023-02-14 15:11:24,977:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 15:11:24,977:INFO:Checking exceptions
2023-02-14 15:11:24,977:INFO:Importing libraries
2023-02-14 15:11:24,977:INFO:Copying training dataset
2023-02-14 15:11:24,994:INFO:Defining folds
2023-02-14 15:11:24,994:INFO:Declaring metric variables
2023-02-14 15:11:24,998:INFO:Importing untrained model
2023-02-14 15:11:25,001:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-14 15:11:25,008:INFO:Starting cross validation
2023-02-14 15:11:25,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 15:20:31,331:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-14 15:20:31,338:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 597, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 531, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 118, in fit
    result = super().fit(X, y=y, **fit_kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/imblearn/pipeline.py", line 281, in fit
    self._final_estimator.fit(Xt, yt, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_gb.py", line 498, in fit
    n_stages = self._fit_stages(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_gb.py", line 555, in _fit_stages
    raw_predictions = self._fit_stage(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_gb.py", line 211, in _fit_stage
    tree.fit(X, residual, sample_weight=sample_weight,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 1242, in fit
    super().fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 375, in fit
    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)
KeyboardInterrupt

2023-02-14 15:20:31,338:INFO:Initializing create_model()
2023-02-14 15:20:31,338:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f88ed151640>, return_train_score=False, kwargs={})
2023-02-14 15:20:31,338:INFO:Checking exceptions
2023-02-14 15:20:31,338:INFO:Importing libraries
2023-02-14 15:20:31,338:INFO:Copying training dataset
2023-02-14 15:20:31,357:INFO:Defining folds
2023-02-14 15:20:31,358:INFO:Declaring metric variables
2023-02-14 15:20:31,361:INFO:Importing untrained model
2023-02-14 15:20:31,364:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-14 15:20:31,371:INFO:Starting cross validation
2023-02-14 15:20:31,371:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-14 16:02:07,225:INFO:PyCaret Supervised Module
2023-02-14 16:02:07,225:INFO:ML Usecase: regression
2023-02-14 16:02:07,225:INFO:version 2.3.10
2023-02-14 16:02:07,225:INFO:Initializing setup()
2023-02-14 16:02:07,225:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 16:02:07,225:INFO:Checking environment
2023-02-14 16:02:07,225:INFO:python_version: 3.9.16
2023-02-14 16:02:07,225:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 16:02:07,225:INFO:machine: x86_64
2023-02-14 16:02:07,225:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 16:02:07,225:INFO:Memory: svmem(total=134979592192, available=116501438464, percent=13.7, used=16472891392, free=74464976896, active=3498582016, inactive=51740893184, buffers=1325174784, cached=42716549120, shared=741142528, slab=4619694080)
2023-02-14 16:02:07,226:INFO:Physical Core: 16
2023-02-14 16:02:07,226:INFO:Logical Core: 32
2023-02-14 16:02:07,226:INFO:Checking libraries
2023-02-14 16:02:07,226:INFO:pd==1.5.2
2023-02-14 16:02:07,226:INFO:numpy==1.20.3
2023-02-14 16:02:07,226:INFO:sklearn==0.23.2
2023-02-14 16:02:07,226:INFO:lightgbm==3.3.5
2023-02-14 16:02:07,241:INFO:catboost==1.1.1
2023-02-14 16:02:07,241:INFO:xgboost==1.7.3
2023-02-14 16:02:07,241:INFO:mlflow==2.1.1
2023-02-14 16:02:07,241:INFO:Checking Exceptions
2023-02-14 16:02:07,242:INFO:Declaring global variables
2023-02-14 16:02:07,242:INFO:USI: fea5
2023-02-14 16:02:07,242:INFO:pycaret_globals: {'log_plots_param', 'exp_name_log', '_all_models', 'master_model_container', 'X', 'seed', 'USI', 'imputation_regressor', 'data_before_preprocess', 'gpu_param', 'fix_imbalance_param', 'logging_param', 'experiment__', '_gpu_n_jobs_param', 'fold_groups_param_full', 'pycaret_globals', 'fix_imbalance_method_param', '_available_plots', 'target_param', 'fold_param', 'prep_pipe', 'display_container', 'y_test', 'n_jobs_param', '_internal_pipeline', 'imputation_classifier', 'stratify_param', 'fold_groups_param', 'fold_generator', 'create_model_container', '_all_metrics', 'transform_target_method_param', 'iterative_imputation_iters_param', 'html_param', '_all_models_internal', '_ml_usecase', 'y_train', 'dashboard_logger', 'transform_target_param', 'y', 'X_train', 'X_test', 'fold_shuffle_param'}
2023-02-14 16:02:07,242:INFO:Preparing display monitor
2023-02-14 16:02:07,242:INFO:Preparing display monitor
2023-02-14 16:02:07,247:INFO:Importing libraries
2023-02-14 16:02:07,247:INFO:Copying data for preprocessing
2023-02-14 16:02:07,255:INFO:Declaring preprocessing parameters
2023-02-14 16:02:07,255:WARNING:cuML not found
2023-02-14 16:02:07,255:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-14 16:02:07,265:INFO:Creating preprocessing pipeline
2023-02-14 16:02:07,490:INFO:Preprocessing pipeline created successfully
2023-02-14 16:02:07,490:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 16:02:07,490:INFO:Creating global containers
2023-02-14 16:02:07,490:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 16:02:10,672:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 16:02:10,672:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 16:02:10,675:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 16:02:10,678:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 16:02:10,712:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 16:02:10,739:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 16:02:10,739:WARNING:Couldn't import cuml.ensemble
2023-02-14 16:02:10,761:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 16:02:10,762:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 16:02:10,766:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 16:02:10,769:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 16:02:10,802:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 16:02:10,829:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 16:02:10,829:WARNING:Couldn't import cuml.ensemble
2023-02-14 16:02:10,835:INFO:Creating grid variables
2023-02-14 16:02:10,849:INFO:create_model_container: 0
2023-02-14 16:02:10,849:INFO:master_model_container: 0
2023-02-14 16:02:10,849:INFO:display_container: 1
2023-02-14 16:02:10,853:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select',
                 Advanced_Feature_Selection_Classic(ml_usecase='regression',
                                                    n_jobs=-1, random_state=11,
                                                    subclass='binary',
                                                    target='closeChg%_forward24HR',
                                                    top_features_to_pick=0.19999999999999996)),
                ('fix_multi', 'passthrough'), ('dfs', 'passthrough'),
                ('pca', 'passthrough')],
         verbose=False)
2023-02-14 16:02:10,853:INFO:setup() succesfully completed......................................
2023-02-14 16:03:29,379:INFO:PyCaret Supervised Module
2023-02-14 16:03:29,379:INFO:ML Usecase: regression
2023-02-14 16:03:29,379:INFO:version 2.3.10
2023-02-14 16:03:29,379:INFO:Initializing setup()
2023-02-14 16:03:29,379:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 16:03:29,379:INFO:Checking environment
2023-02-14 16:03:29,379:INFO:python_version: 3.9.16
2023-02-14 16:03:29,379:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 16:03:29,379:INFO:machine: x86_64
2023-02-14 16:03:29,379:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 16:03:29,379:INFO:Memory: svmem(total=134979592192, available=116333510656, percent=13.8, used=16572428288, free=74306732032, active=3496210432, inactive=51903152128, buffers=1325924352, cached=42774507520, shared=809529344, slab=4617637888)
2023-02-14 16:03:29,380:INFO:Physical Core: 16
2023-02-14 16:03:29,380:INFO:Logical Core: 32
2023-02-14 16:03:29,380:INFO:Checking libraries
2023-02-14 16:03:29,380:INFO:pd==1.5.2
2023-02-14 16:03:29,380:INFO:numpy==1.20.3
2023-02-14 16:03:29,380:INFO:sklearn==0.23.2
2023-02-14 16:03:29,380:INFO:lightgbm==3.3.5
2023-02-14 16:03:29,380:INFO:catboost==1.1.1
2023-02-14 16:03:29,380:INFO:xgboost==1.7.3
2023-02-14 16:03:29,380:INFO:mlflow==2.1.1
2023-02-14 16:03:29,380:INFO:Checking Exceptions
2023-02-14 16:03:29,380:INFO:Declaring global variables
2023-02-14 16:03:29,380:INFO:USI: a77c
2023-02-14 16:03:29,380:INFO:pycaret_globals: {'log_plots_param', 'exp_name_log', '_all_models', 'master_model_container', 'X', 'seed', 'USI', 'imputation_regressor', 'data_before_preprocess', 'gpu_param', 'fix_imbalance_param', 'logging_param', 'experiment__', '_gpu_n_jobs_param', 'fold_groups_param_full', 'pycaret_globals', 'fix_imbalance_method_param', '_available_plots', 'target_param', 'fold_param', 'prep_pipe', 'display_container', 'y_test', 'n_jobs_param', '_internal_pipeline', 'imputation_classifier', 'stratify_param', 'fold_groups_param', 'fold_generator', 'create_model_container', '_all_metrics', 'transform_target_method_param', 'iterative_imputation_iters_param', 'html_param', '_all_models_internal', '_ml_usecase', 'y_train', 'dashboard_logger', 'transform_target_param', 'y', 'X_train', 'X_test', 'fold_shuffle_param'}
2023-02-14 16:03:29,380:INFO:Preparing display monitor
2023-02-14 16:03:29,380:INFO:Preparing display monitor
2023-02-14 16:03:29,385:INFO:Importing libraries
2023-02-14 16:03:29,385:INFO:Copying data for preprocessing
2023-02-14 16:03:29,392:INFO:Declaring preprocessing parameters
2023-02-14 16:03:29,392:WARNING:cuML not found
2023-02-14 16:03:29,392:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-14 16:03:29,402:INFO:Creating preprocessing pipeline
2023-02-14 16:03:29,632:INFO:Preprocessing pipeline created successfully
2023-02-14 16:03:29,632:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 16:03:29,633:INFO:Creating global containers
2023-02-14 16:03:29,633:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 16:53:41,592:INFO:PyCaret Supervised Module
2023-02-14 16:53:41,593:INFO:ML Usecase: regression
2023-02-14 16:53:41,593:INFO:version 2.3.10
2023-02-14 16:53:41,593:INFO:Initializing setup()
2023-02-14 16:53:41,593:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 16:53:41,593:INFO:Checking environment
2023-02-14 16:53:41,593:INFO:python_version: 3.9.16
2023-02-14 16:53:41,593:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 16:53:41,593:INFO:machine: x86_64
2023-02-14 16:53:41,593:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 16:53:41,593:INFO:Memory: svmem(total=134979592192, available=119180902400, percent=11.7, used=13909872640, free=77120282624, active=3528081408, inactive=49150873600, buffers=1344094208, cached=42605342720, shared=624689152, slab=4558950400)
2023-02-14 16:53:41,593:INFO:Physical Core: 16
2023-02-14 16:53:41,593:INFO:Logical Core: 32
2023-02-14 16:53:41,593:INFO:Checking libraries
2023-02-14 16:53:41,593:INFO:pd==1.5.2
2023-02-14 16:53:41,593:INFO:numpy==1.20.3
2023-02-14 16:53:41,593:INFO:sklearn==0.23.2
2023-02-14 16:53:41,593:INFO:lightgbm==3.3.5
2023-02-14 16:53:41,593:INFO:catboost==1.1.1
2023-02-14 16:53:41,594:INFO:xgboost==1.7.3
2023-02-14 16:53:41,594:INFO:mlflow==2.1.1
2023-02-14 16:53:41,594:INFO:Checking Exceptions
2023-02-14 16:53:41,594:INFO:Declaring global variables
2023-02-14 16:53:41,594:INFO:USI: 9c28
2023-02-14 16:53:41,594:INFO:pycaret_globals: {'log_plots_param', 'exp_name_log', '_all_models', 'master_model_container', 'X', 'seed', 'USI', 'imputation_regressor', 'data_before_preprocess', 'gpu_param', 'fix_imbalance_param', 'logging_param', 'experiment__', '_gpu_n_jobs_param', 'fold_groups_param_full', 'pycaret_globals', 'fix_imbalance_method_param', '_available_plots', 'target_param', 'fold_param', 'prep_pipe', 'display_container', 'y_test', 'n_jobs_param', '_internal_pipeline', 'imputation_classifier', 'stratify_param', 'fold_groups_param', 'fold_generator', 'create_model_container', '_all_metrics', 'transform_target_method_param', 'iterative_imputation_iters_param', 'html_param', '_all_models_internal', '_ml_usecase', 'y_train', 'dashboard_logger', 'transform_target_param', 'y', 'X_train', 'X_test', 'fold_shuffle_param'}
2023-02-14 16:53:41,594:INFO:Preparing display monitor
2023-02-14 16:53:41,594:INFO:Preparing display monitor
2023-02-14 16:53:41,598:INFO:Importing libraries
2023-02-14 16:53:41,598:INFO:Copying data for preprocessing
2023-02-14 16:53:41,607:INFO:Declaring preprocessing parameters
2023-02-14 16:53:41,608:WARNING:cuML not found
2023-02-14 16:53:41,608:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-14 16:53:41,615:INFO:Creating preprocessing pipeline
2023-02-14 16:53:41,842:INFO:Preprocessing pipeline created successfully
2023-02-14 16:53:41,843:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 16:53:41,843:INFO:Creating global containers
2023-02-14 16:53:41,843:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 16:53:43,687:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 16:53:43,687:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 16:53:43,690:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 16:53:43,693:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 16:53:43,726:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 16:53:43,753:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 16:53:43,753:WARNING:Couldn't import cuml.ensemble
2023-02-14 16:53:43,758:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 16:53:43,758:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 16:53:43,763:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 16:53:43,766:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 16:53:43,799:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 16:53:43,826:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 16:53:43,826:WARNING:Couldn't import cuml.ensemble
2023-02-14 16:53:43,833:INFO:Creating grid variables
2023-02-14 16:53:43,848:INFO:create_model_container: 0
2023-02-14 16:53:43,849:INFO:master_model_container: 0
2023-02-14 16:53:43,849:INFO:display_container: 1
2023-02-14 16:53:43,851:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select',
                 Advanced_Feature_Selection_Classic(ml_usecase='regression',
                                                    n_jobs=-1, random_state=11,
                                                    subclass='binary',
                                                    target='closeChg%_forward24HR',
                                                    top_features_to_pick=0.19999999999999996)),
                ('fix_multi', 'passthrough'), ('dfs', 'passthrough'),
                ('pca', 'passthrough')],
         verbose=False)
2023-02-14 16:53:43,851:INFO:setup() succesfully completed......................................
2023-02-14 16:53:54,804:INFO:PyCaret Supervised Module
2023-02-14 16:53:54,804:INFO:ML Usecase: regression
2023-02-14 16:53:54,804:INFO:version 2.3.10
2023-02-14 16:53:54,804:INFO:Initializing setup()
2023-02-14 16:53:54,804:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 16:53:54,804:INFO:Checking environment
2023-02-14 16:53:54,804:INFO:python_version: 3.9.16
2023-02-14 16:53:54,804:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 16:53:54,804:INFO:machine: x86_64
2023-02-14 16:53:54,804:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 16:53:54,804:INFO:Memory: svmem(total=134979592192, available=119181774848, percent=11.7, used=13904846848, free=77118590976, active=3528146944, inactive=49151172608, buffers=1344143360, cached=42612011008, shared=628850688, slab=4558888960)
2023-02-14 16:53:54,805:INFO:Physical Core: 16
2023-02-14 16:53:54,805:INFO:Logical Core: 32
2023-02-14 16:53:54,805:INFO:Checking libraries
2023-02-14 16:53:54,805:INFO:pd==1.5.2
2023-02-14 16:53:54,805:INFO:numpy==1.20.3
2023-02-14 16:53:54,805:INFO:sklearn==0.23.2
2023-02-14 16:53:54,805:INFO:lightgbm==3.3.5
2023-02-14 16:53:54,805:INFO:catboost==1.1.1
2023-02-14 16:53:54,805:INFO:xgboost==1.7.3
2023-02-14 16:53:54,805:INFO:mlflow==2.1.1
2023-02-14 16:53:54,805:INFO:Checking Exceptions
2023-02-14 16:53:54,805:INFO:Declaring global variables
2023-02-14 16:53:54,805:INFO:USI: 4277
2023-02-14 16:53:54,805:INFO:pycaret_globals: {'log_plots_param', 'exp_name_log', '_all_models', 'master_model_container', 'X', 'seed', 'USI', 'imputation_regressor', 'data_before_preprocess', 'gpu_param', 'fix_imbalance_param', 'logging_param', 'experiment__', '_gpu_n_jobs_param', 'fold_groups_param_full', 'pycaret_globals', 'fix_imbalance_method_param', '_available_plots', 'target_param', 'fold_param', 'prep_pipe', 'display_container', 'y_test', 'n_jobs_param', '_internal_pipeline', 'imputation_classifier', 'stratify_param', 'fold_groups_param', 'fold_generator', 'create_model_container', '_all_metrics', 'transform_target_method_param', 'iterative_imputation_iters_param', 'html_param', '_all_models_internal', '_ml_usecase', 'y_train', 'dashboard_logger', 'transform_target_param', 'y', 'X_train', 'X_test', 'fold_shuffle_param'}
2023-02-14 16:53:54,805:INFO:Preparing display monitor
2023-02-14 16:53:54,805:INFO:Preparing display monitor
2023-02-14 16:53:54,810:INFO:Importing libraries
2023-02-14 16:53:54,810:INFO:Copying data for preprocessing
2023-02-14 16:53:54,816:INFO:Declaring preprocessing parameters
2023-02-14 16:53:54,827:INFO:Creating preprocessing pipeline
2023-02-14 16:53:55,057:INFO:Preprocessing pipeline created successfully
2023-02-14 16:53:55,057:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 16:53:55,057:INFO:Creating global containers
2023-02-14 16:53:55,057:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 16:53:57,263:INFO:Creating grid variables
2023-02-14 16:53:57,277:INFO:create_model_container: 0
2023-02-14 16:53:57,277:INFO:master_model_container: 0
2023-02-14 16:53:57,277:INFO:display_container: 1
2023-02-14 16:53:57,280:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select',
                 Advanced_Feature_Selection_Classic(ml_usecase='regression',
                                                    n_jobs=-1, random_state=11,
                                                    subclass='binary',
                                                    target='closeChg%_forward24HR',
                                                    top_features_to_pick=0.19999999999999996)),
                ('fix_multi', 'passthrough'), ('dfs', 'passthrough'),
                ('pca', 'passthrough')],
         verbose=False)
2023-02-14 16:53:57,280:INFO:setup() succesfully completed......................................
2023-02-14 17:03:48,926:INFO:PyCaret Supervised Module
2023-02-14 17:03:48,926:INFO:ML Usecase: regression
2023-02-14 17:03:48,926:INFO:version 2.3.10
2023-02-14 17:03:48,926:INFO:Initializing setup()
2023-02-14 17:03:48,926:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 17:03:48,927:INFO:Checking environment
2023-02-14 17:03:48,927:INFO:python_version: 3.9.16
2023-02-14 17:03:48,927:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 17:03:48,927:INFO:machine: x86_64
2023-02-14 17:03:48,927:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 17:03:48,927:INFO:Memory: svmem(total=134979592192, available=126892756992, percent=6.0, used=6664519680, free=124872040448, active=742170624, inactive=8453210112, buffers=195080192, cached=3247951872, shared=279212032, slab=409272320)
2023-02-14 17:03:48,927:INFO:Physical Core: 16
2023-02-14 17:03:48,927:INFO:Logical Core: 32
2023-02-14 17:03:48,927:INFO:Checking libraries
2023-02-14 17:03:48,927:INFO:pd==1.5.2
2023-02-14 17:03:48,927:INFO:numpy==1.20.3
2023-02-14 17:03:48,928:INFO:sklearn==0.23.2
2023-02-14 17:03:48,928:INFO:lightgbm==3.3.5
2023-02-14 17:03:49,085:INFO:catboost==1.1.1
2023-02-14 17:03:49,085:INFO:xgboost==1.7.3
2023-02-14 17:03:49,085:INFO:mlflow==2.1.1
2023-02-14 17:03:49,085:INFO:Checking Exceptions
2023-02-14 17:03:49,085:INFO:Declaring global variables
2023-02-14 17:03:49,085:INFO:USI: cf43
2023-02-14 17:03:49,085:INFO:pycaret_globals: {'seed', '_all_models', 'y', '_all_models_internal', 'transform_target_param', 'USI', 'X_test', '_ml_usecase', 'fold_generator', 'imputation_regressor', 'create_model_container', 'pycaret_globals', 'y_train', 'X', 'exp_name_log', 'fix_imbalance_method_param', '_available_plots', 'gpu_param', 'target_param', 'data_before_preprocess', 'y_test', 'master_model_container', 'fix_imbalance_param', 'fold_param', '_internal_pipeline', 'dashboard_logger', 'logging_param', 'iterative_imputation_iters_param', 'fold_shuffle_param', 'fold_groups_param_full', 'experiment__', 'imputation_classifier', 'prep_pipe', 'transform_target_method_param', 'display_container', 'fold_groups_param', 'X_train', 'stratify_param', 'log_plots_param', '_gpu_n_jobs_param', 'html_param', 'n_jobs_param', '_all_metrics'}
2023-02-14 17:03:49,085:INFO:Preparing display monitor
2023-02-14 17:03:49,085:INFO:Preparing display monitor
2023-02-14 17:03:49,091:INFO:Importing libraries
2023-02-14 17:03:49,091:INFO:Copying data for preprocessing
2023-02-14 17:03:49,114:INFO:Declaring preprocessing parameters
2023-02-14 17:03:49,115:WARNING:cuML not found
2023-02-14 17:03:49,115:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-14 17:03:49,125:INFO:Creating preprocessing pipeline
2023-02-14 17:03:49,322:INFO:Preprocessing pipeline created successfully
2023-02-14 17:03:49,322:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 17:03:49,322:INFO:Creating global containers
2023-02-14 17:03:49,323:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 17:03:51,890:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 17:03:51,890:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 17:03:51,893:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 17:03:51,896:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 17:03:51,929:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 17:03:51,955:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 17:03:51,956:WARNING:Couldn't import cuml.ensemble
2023-02-14 17:03:51,961:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 17:03:51,961:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 17:03:51,966:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 17:03:51,969:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 17:03:52,004:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 17:03:52,034:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 17:03:52,034:WARNING:Couldn't import cuml.ensemble
2023-02-14 17:03:52,038:INFO:Creating grid variables
2023-02-14 17:03:52,054:INFO:create_model_container: 0
2023-02-14 17:03:52,054:INFO:master_model_container: 0
2023-02-14 17:03:52,054:INFO:display_container: 1
2023-02-14 17:03:52,057:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select',
                 Advanced_Feature_Selection_Classic(ml_usecase='regression',
                                                    n_jobs=-1, random_state=11,
                                                    subclass='binary',
                                                    target='closeChg%_forward24HR',
                                                    top_features_to_pick=0.19999999999999996)),
                ('fix_multi', 'passthrough'), ('dfs', 'passthrough'),
                ('pca', 'passthrough')],
         verbose=False)
2023-02-14 17:03:52,057:INFO:setup() succesfully completed......................................
2023-02-14 17:04:51,464:INFO:PyCaret Supervised Module
2023-02-14 17:04:51,465:INFO:ML Usecase: regression
2023-02-14 17:04:51,465:INFO:version 2.3.10
2023-02-14 17:04:51,465:INFO:Initializing setup()
2023-02-14 17:04:51,465:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 17:04:51,465:INFO:Checking environment
2023-02-14 17:04:51,465:INFO:python_version: 3.9.16
2023-02-14 17:04:51,465:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 17:04:51,465:INFO:machine: x86_64
2023-02-14 17:04:51,465:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 17:04:51,465:INFO:Memory: svmem(total=134979592192, available=126190657536, percent=6.5, used=7344775168, free=124044136448, active=812044288, inactive=9185746944, buffers=201965568, cached=3388715008, shared=299143168, slab=420257792)
2023-02-14 17:04:51,466:INFO:Physical Core: 16
2023-02-14 17:04:51,466:INFO:Logical Core: 32
2023-02-14 17:04:51,466:INFO:Checking libraries
2023-02-14 17:04:51,466:INFO:pd==1.5.2
2023-02-14 17:04:51,466:INFO:numpy==1.20.3
2023-02-14 17:04:51,466:INFO:sklearn==0.23.2
2023-02-14 17:04:51,466:INFO:lightgbm==3.3.5
2023-02-14 17:04:51,466:INFO:catboost==1.1.1
2023-02-14 17:04:51,466:INFO:xgboost==1.7.3
2023-02-14 17:04:51,466:INFO:mlflow==2.1.1
2023-02-14 17:04:51,466:INFO:Checking Exceptions
2023-02-14 17:04:51,466:INFO:Declaring global variables
2023-02-14 17:04:51,466:INFO:USI: 72a2
2023-02-14 17:04:51,466:INFO:pycaret_globals: {'seed', '_all_models', 'y', '_all_models_internal', 'transform_target_param', 'USI', 'X_test', '_ml_usecase', 'fold_generator', 'imputation_regressor', 'create_model_container', 'pycaret_globals', 'y_train', 'X', 'exp_name_log', 'fix_imbalance_method_param', '_available_plots', 'gpu_param', 'target_param', 'data_before_preprocess', 'y_test', 'master_model_container', 'fix_imbalance_param', 'fold_param', '_internal_pipeline', 'dashboard_logger', 'logging_param', 'iterative_imputation_iters_param', 'fold_shuffle_param', 'fold_groups_param_full', 'experiment__', 'imputation_classifier', 'prep_pipe', 'transform_target_method_param', 'display_container', 'fold_groups_param', 'X_train', 'stratify_param', 'log_plots_param', '_gpu_n_jobs_param', 'html_param', 'n_jobs_param', '_all_metrics'}
2023-02-14 17:04:51,466:INFO:Preparing display monitor
2023-02-14 17:04:51,466:INFO:Preparing display monitor
2023-02-14 17:04:51,473:INFO:Importing libraries
2023-02-14 17:04:51,473:INFO:Copying data for preprocessing
2023-02-14 17:04:51,487:INFO:Declaring preprocessing parameters
2023-02-14 17:04:51,488:WARNING:cuML not found
2023-02-14 17:04:51,488:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-14 17:04:51,495:INFO:Creating preprocessing pipeline
2023-02-14 17:04:51,684:INFO:Preprocessing pipeline created successfully
2023-02-14 17:04:51,685:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 17:04:51,685:INFO:Creating global containers
2023-02-14 17:04:51,685:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 17:04:53,533:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 17:04:53,533:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 17:04:53,536:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 17:04:53,539:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 17:04:53,570:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 17:04:53,596:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 17:04:53,596:WARNING:Couldn't import cuml.ensemble
2023-02-14 17:04:53,600:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 17:04:53,600:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 17:04:53,604:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 17:04:53,607:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 17:04:53,639:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 17:04:53,665:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 17:04:53,665:WARNING:Couldn't import cuml.ensemble
2023-02-14 17:04:53,673:INFO:Creating grid variables
2023-02-14 17:04:53,688:INFO:create_model_container: 0
2023-02-14 17:04:53,688:INFO:master_model_container: 0
2023-02-14 17:04:53,688:INFO:display_container: 1
2023-02-14 17:04:53,691:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select',
                 Advanced_Feature_Selection_Classic(ml_usecase='regression',
                                                    n_jobs=-1, random_state=11,
                                                    subclass='binary',
                                                    target='closeChg%_forward24HR',
                                                    top_features_to_pick=0.19999999999999996)),
                ('fix_multi', 'passthrough'), ('dfs', 'passthrough'),
                ('pca', 'passthrough')],
         verbose=False)
2023-02-14 17:04:53,691:INFO:setup() succesfully completed......................................
2023-02-14 18:06:24,304:INFO:PyCaret Supervised Module
2023-02-14 18:06:24,305:INFO:ML Usecase: regression
2023-02-14 18:06:24,305:INFO:version 2.3.10
2023-02-14 18:06:24,305:INFO:Initializing setup()
2023-02-14 18:06:24,305:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 18:06:24,305:INFO:Checking environment
2023-02-14 18:06:24,305:INFO:python_version: 3.9.16
2023-02-14 18:06:24,305:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 18:06:24,305:INFO:machine: x86_64
2023-02-14 18:06:24,305:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 18:06:24,305:INFO:Memory: svmem(total=134979592192, available=121566330880, percent=9.9, used=11668205568, free=115639898112, active=2411679744, inactive=14759649280, buffers=1056526336, cached=6614962176, shared=479158272, slab=1571303424)
2023-02-14 18:06:24,305:INFO:Physical Core: 16
2023-02-14 18:06:24,305:INFO:Logical Core: 32
2023-02-14 18:06:24,306:INFO:Checking libraries
2023-02-14 18:06:24,306:INFO:pd==1.5.2
2023-02-14 18:06:24,306:INFO:numpy==1.20.3
2023-02-14 18:06:24,306:INFO:sklearn==1.2.0
2023-02-14 18:09:47,994:INFO:PyCaret Supervised Module
2023-02-14 18:09:47,994:INFO:ML Usecase: regression
2023-02-14 18:09:47,994:INFO:version 2.3.10
2023-02-14 18:09:47,994:INFO:Initializing setup()
2023-02-14 18:09:47,994:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-14 18:09:47,994:INFO:Checking environment
2023-02-14 18:09:47,994:INFO:python_version: 3.9.16
2023-02-14 18:09:47,994:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-14 18:09:47,994:INFO:machine: x86_64
2023-02-14 18:09:47,994:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-14 18:09:47,994:INFO:Memory: svmem(total=134979592192, available=121683750912, percent=9.9, used=11557019648, free=115589201920, active=2525274112, inactive=14697086976, buffers=1059598336, cached=6773772288, shared=472928256, slab=1579294720)
2023-02-14 18:09:47,995:INFO:Physical Core: 16
2023-02-14 18:09:47,995:INFO:Logical Core: 32
2023-02-14 18:09:47,995:INFO:Checking libraries
2023-02-14 18:09:47,995:INFO:pd==1.5.2
2023-02-14 18:09:47,995:INFO:numpy==1.20.3
2023-02-14 18:09:47,995:INFO:sklearn==0.23.2
2023-02-14 18:09:47,995:INFO:lightgbm==3.2.1
2023-02-14 18:09:48,012:INFO:catboost==1.1.1
2023-02-14 18:09:48,012:INFO:xgboost==1.7.3
2023-02-14 18:09:48,012:INFO:mlflow==2.1.1
2023-02-14 18:09:48,012:INFO:Checking Exceptions
2023-02-14 18:09:48,012:INFO:Declaring global variables
2023-02-14 18:09:48,012:INFO:USI: 506b
2023-02-14 18:09:48,012:INFO:pycaret_globals: {'transform_target_param', '_all_models_internal', 'imputation_regressor', 'target_param', 'stratify_param', 'create_model_container', 'y_train', 'dashboard_logger', '_internal_pipeline', 'fix_imbalance_method_param', 'data_before_preprocess', 'imputation_classifier', 'X_train', 'html_param', '_all_metrics', 'y', 'fold_groups_param', 'pycaret_globals', 'gpu_param', 'USI', 'fold_groups_param_full', 'logging_param', 'iterative_imputation_iters_param', 'transform_target_method_param', 'seed', '_ml_usecase', '_all_models', 'experiment__', 'X', 'fold_param', 'X_test', 'fold_shuffle_param', 'fix_imbalance_param', 'fold_generator', 'y_test', 'exp_name_log', 'display_container', 'log_plots_param', '_gpu_n_jobs_param', 'prep_pipe', 'master_model_container', 'n_jobs_param', '_available_plots'}
2023-02-14 18:09:48,012:INFO:Preparing display monitor
2023-02-14 18:09:48,012:INFO:Preparing display monitor
2023-02-14 18:09:48,017:INFO:Importing libraries
2023-02-14 18:09:48,017:INFO:Copying data for preprocessing
2023-02-14 18:09:48,026:INFO:Declaring preprocessing parameters
2023-02-14 18:09:48,026:WARNING:cuML not found
2023-02-14 18:09:48,026:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-14 18:09:48,036:INFO:Creating preprocessing pipeline
2023-02-14 18:09:48,267:INFO:Preprocessing pipeline created successfully
2023-02-14 18:09:48,268:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-14 18:09:48,268:INFO:Creating global containers
2023-02-14 18:09:48,268:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-14 18:09:50,031:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 18:09:50,031:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 18:09:50,034:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 18:09:50,036:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 18:09:50,068:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 18:09:50,094:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 18:09:50,094:WARNING:Couldn't import cuml.ensemble
2023-02-14 18:09:50,099:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-14 18:09:50,099:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-14 18:09:50,102:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-14 18:09:50,105:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-14 18:09:50,152:WARNING:Couldn't import cuml.svm.SVR
2023-02-14 18:09:50,197:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-14 18:09:50,198:WARNING:Couldn't import cuml.ensemble
2023-02-14 18:09:50,203:INFO:Creating grid variables
2023-02-14 18:09:50,224:INFO:create_model_container: 0
2023-02-14 18:09:50,224:INFO:master_model_container: 0
2023-02-14 18:09:50,224:INFO:display_container: 1
2023-02-14 18:09:50,228:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select',
                 Advanced_Feature_Selection_Classic(ml_usecase='regression',
                                                    n_jobs=-1, random_state=11,
                                                    subclass='binary',
                                                    target='closeChg%_forward24HR',
                                                    top_features_to_pick=0.19999999999999996)),
                ('fix_multi', 'passthrough'), ('dfs', 'passthrough'),
                ('pca', 'passthrough')],
         verbose=False)
2023-02-14 18:09:50,228:INFO:setup() succesfully completed......................................
2023-02-15 11:27:37,301:INFO:PyCaret Supervised Module
2023-02-15 11:27:37,301:INFO:ML Usecase: regression
2023-02-15 11:27:37,301:INFO:version 2.3.10
2023-02-15 11:27:37,301:INFO:Initializing setup()
2023-02-15 11:27:37,301:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-15 11:27:37,301:INFO:Checking environment
2023-02-15 11:27:37,301:INFO:python_version: 3.9.16
2023-02-15 11:27:37,301:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-15 11:27:37,301:INFO:machine: x86_64
2023-02-15 11:27:37,301:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-15 11:27:37,301:INFO:Memory: svmem(total=134979592192, available=122902937600, percent=8.9, used=10376855552, free=102711398400, active=3718012928, inactive=25960148992, buffers=1417588736, cached=20473749504, shared=437440512, slab=2003038208)
2023-02-15 11:27:37,302:INFO:Physical Core: 16
2023-02-15 11:27:37,302:INFO:Logical Core: 32
2023-02-15 11:27:37,302:INFO:Checking libraries
2023-02-15 11:27:37,302:INFO:pd==1.5.2
2023-02-15 11:27:37,302:INFO:numpy==1.20.3
2023-02-15 11:27:37,302:INFO:sklearn==0.23.2
2023-02-15 11:27:37,302:INFO:lightgbm==3.3.5.99
2023-02-15 11:27:37,319:INFO:catboost==1.1.1
2023-02-15 11:27:37,319:INFO:xgboost==1.7.3
2023-02-15 11:27:37,319:INFO:mlflow==2.1.1
2023-02-15 11:27:37,319:INFO:Checking Exceptions
2023-02-15 11:27:37,319:INFO:Declaring global variables
2023-02-15 11:27:37,319:INFO:USI: 8752
2023-02-15 11:27:37,319:INFO:pycaret_globals: {'logging_param', 'X_train', 'target_param', 'fold_param', '_all_models', '_gpu_n_jobs_param', 'USI', 'X', '_all_models_internal', '_internal_pipeline', 'log_plots_param', 'transform_target_method_param', 'iterative_imputation_iters_param', 'gpu_param', 'y_train', 'dashboard_logger', '_all_metrics', '_ml_usecase', 'y', 'X_test', '_available_plots', 'fold_groups_param_full', 'seed', 'fold_generator', 'n_jobs_param', 'display_container', 'stratify_param', 'imputation_regressor', 'imputation_classifier', 'fold_shuffle_param', 'master_model_container', 'transform_target_param', 'y_test', 'fix_imbalance_param', 'fold_groups_param', 'exp_name_log', 'prep_pipe', 'pycaret_globals', 'html_param', 'fix_imbalance_method_param', 'data_before_preprocess', 'create_model_container', 'experiment__'}
2023-02-15 11:27:37,319:INFO:Preparing display monitor
2023-02-15 11:27:37,319:INFO:Preparing display monitor
2023-02-15 11:27:37,325:INFO:Importing libraries
2023-02-15 11:27:37,325:INFO:Copying data for preprocessing
2023-02-15 11:27:37,334:INFO:Declaring preprocessing parameters
2023-02-15 11:27:37,334:WARNING:cuML not found
2023-02-15 11:27:37,334:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-15 11:27:37,344:INFO:Creating preprocessing pipeline
2023-02-15 11:27:37,567:INFO:Preprocessing pipeline created successfully
2023-02-15 11:27:37,567:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-15 11:27:37,567:INFO:Creating global containers
2023-02-15 11:27:37,568:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-15 11:27:40,011:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:27:40,011:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:27:40,014:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:27:40,016:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:27:40,048:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:27:40,073:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:27:40,074:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:27:40,105:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:27:40,105:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:27:40,111:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:27:40,115:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:27:40,170:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:27:40,212:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:27:40,212:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:27:40,216:INFO:Creating grid variables
2023-02-15 11:27:40,231:INFO:create_model_container: 0
2023-02-15 11:27:40,232:INFO:master_model_container: 0
2023-02-15 11:27:40,232:INFO:display_container: 1
2023-02-15 11:27:40,235:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select',
                 Advanced_Feature_Selection_Classic(ml_usecase='regression',
                                                    n_jobs=-1, random_state=11,
                                                    subclass='binary',
                                                    target='closeChg%_forward24HR',
                                                    top_features_to_pick=0.19999999999999996)),
                ('fix_multi', 'passthrough'), ('dfs', 'passthrough'),
                ('pca', 'passthrough')],
         verbose=False)
2023-02-15 11:27:40,235:INFO:setup() succesfully completed......................................
2023-02-15 11:30:53,289:INFO:PyCaret Supervised Module
2023-02-15 11:30:53,289:INFO:ML Usecase: regression
2023-02-15 11:30:53,289:INFO:version 2.3.10
2023-02-15 11:30:53,289:INFO:Initializing setup()
2023-02-15 11:30:53,289:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=True, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-15 11:30:53,289:INFO:Checking environment
2023-02-15 11:30:53,289:INFO:python_version: 3.9.16
2023-02-15 11:30:53,289:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-15 11:30:53,289:INFO:machine: x86_64
2023-02-15 11:30:53,289:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-15 11:30:53,290:INFO:Memory: svmem(total=134979592192, available=122498187264, percent=9.2, used=10791804928, free=102300962816, active=3724804096, inactive=26364932096, buffers=1418989568, cached=20467834880, shared=427241472, slab=1999867904)
2023-02-15 11:30:53,290:INFO:Physical Core: 16
2023-02-15 11:30:53,290:INFO:Logical Core: 32
2023-02-15 11:30:53,290:INFO:Checking libraries
2023-02-15 11:30:53,290:INFO:pd==1.5.2
2023-02-15 11:30:53,290:INFO:numpy==1.20.3
2023-02-15 11:30:53,290:INFO:sklearn==0.23.2
2023-02-15 11:30:53,290:INFO:lightgbm==3.3.5.99
2023-02-15 11:30:53,290:INFO:catboost==1.1.1
2023-02-15 11:30:53,290:INFO:xgboost==1.7.3
2023-02-15 11:30:53,290:INFO:mlflow==2.1.1
2023-02-15 11:30:53,290:INFO:Checking Exceptions
2023-02-15 11:30:53,290:INFO:Declaring global variables
2023-02-15 11:30:53,290:INFO:USI: 3ca8
2023-02-15 11:30:53,291:INFO:pycaret_globals: {'logging_param', 'X_train', 'target_param', 'fold_param', '_all_models', '_gpu_n_jobs_param', 'USI', 'X', '_all_models_internal', '_internal_pipeline', 'log_plots_param', 'transform_target_method_param', 'iterative_imputation_iters_param', 'gpu_param', 'y_train', 'dashboard_logger', '_all_metrics', '_ml_usecase', 'y', 'X_test', '_available_plots', 'fold_groups_param_full', 'seed', 'fold_generator', 'n_jobs_param', 'display_container', 'stratify_param', 'imputation_regressor', 'imputation_classifier', 'fold_shuffle_param', 'master_model_container', 'transform_target_param', 'y_test', 'fix_imbalance_param', 'fold_groups_param', 'exp_name_log', 'prep_pipe', 'pycaret_globals', 'html_param', 'fix_imbalance_method_param', 'data_before_preprocess', 'create_model_container', 'experiment__'}
2023-02-15 11:30:53,291:INFO:Preparing display monitor
2023-02-15 11:30:53,291:INFO:Preparing display monitor
2023-02-15 11:30:53,296:INFO:Importing libraries
2023-02-15 11:30:53,296:INFO:Copying data for preprocessing
2023-02-15 11:30:53,302:INFO:Declaring preprocessing parameters
2023-02-15 11:30:53,302:WARNING:cuML not found
2023-02-15 11:30:53,302:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-15 11:30:53,313:INFO:Creating preprocessing pipeline
2023-02-15 11:30:53,539:INFO:Preprocessing pipeline created successfully
2023-02-15 11:30:53,539:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-15 11:30:53,539:INFO:Creating global containers
2023-02-15 11:30:53,539:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-15 11:30:55,606:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:30:55,606:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:30:55,609:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:30:55,612:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:30:55,644:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:30:55,671:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:30:55,671:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:30:55,676:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:30:55,676:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:30:55,679:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:30:55,682:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:30:55,714:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:30:55,742:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:30:55,742:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:30:55,745:INFO:Creating grid variables
2023-02-15 11:30:55,759:INFO:create_model_container: 0
2023-02-15 11:30:55,759:INFO:master_model_container: 0
2023-02-15 11:30:55,759:INFO:display_container: 1
2023-02-15 11:30:55,762:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select',
                 Advanced_Feature_Selection_Classic(ml_usecase='regression',
                                                    n_jobs=-1, random_state=11,
                                                    subclass='binary',
                                                    target='closeChg%_forward24HR',
                                                    top_features_to_pick=0.19999999999999996)),
                ('fix_multi', 'passthrough'), ('dfs', 'passthrough'),
                ('pca', 'passthrough')],
         verbose=False)
2023-02-15 11:30:55,762:INFO:setup() succesfully completed......................................
2023-02-15 11:30:55,870:INFO:Initializing compare_models()
2023-02-15 11:30:55,870:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=['tr'])
2023-02-15 11:30:55,870:INFO:Checking exceptions
2023-02-15 11:30:55,870:INFO:Preparing display monitor
2023-02-15 11:30:55,870:INFO:Preparing display monitor
2023-02-15 11:30:55,881:INFO:Initializing Linear Regression
2023-02-15 11:30:55,881:INFO:Total runtime is 1.6411145528157553e-06 minutes
2023-02-15 11:30:55,885:INFO:SubProcess create_model() called ==================================
2023-02-15 11:30:55,886:INFO:Initializing create_model()
2023-02-15 11:30:55,886:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:30:55,886:INFO:Checking exceptions
2023-02-15 11:30:55,886:INFO:Importing libraries
2023-02-15 11:30:55,886:INFO:Copying training dataset
2023-02-15 11:30:55,886:INFO:Defining folds
2023-02-15 11:30:55,887:INFO:Declaring metric variables
2023-02-15 11:30:55,890:INFO:Importing untrained model
2023-02-15 11:30:55,895:INFO:Linear Regression Imported succesfully
2023-02-15 11:30:55,902:INFO:Starting cross validation
2023-02-15 11:30:55,904:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:30:56,846:INFO:Calculating mean and std
2023-02-15 11:30:56,849:INFO:Creating metrics dataframe
2023-02-15 11:30:56,856:INFO:Uploading results into container
2023-02-15 11:30:56,856:INFO:Uploading model into container now
2023-02-15 11:30:56,862:INFO:create_model_container: 1
2023-02-15 11:30:56,862:INFO:master_model_container: 1
2023-02-15 11:30:56,862:INFO:display_container: 2
2023-02-15 11:30:56,862:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-15 11:30:56,862:INFO:create_model() succesfully completed......................................
2023-02-15 11:30:56,989:INFO:SubProcess create_model() end ==================================
2023-02-15 11:30:56,989:INFO:Creating metrics dataframe
2023-02-15 11:30:56,994:INFO:Initializing Lasso Regression
2023-02-15 11:30:56,994:INFO:Total runtime is 0.0185531218846639 minutes
2023-02-15 11:30:56,998:INFO:SubProcess create_model() called ==================================
2023-02-15 11:30:56,998:INFO:Initializing create_model()
2023-02-15 11:30:56,998:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:30:56,998:INFO:Checking exceptions
2023-02-15 11:30:56,998:INFO:Importing libraries
2023-02-15 11:30:56,998:INFO:Copying training dataset
2023-02-15 11:30:56,999:INFO:Defining folds
2023-02-15 11:30:56,999:INFO:Declaring metric variables
2023-02-15 11:30:57,002:INFO:Importing untrained model
2023-02-15 11:30:57,005:INFO:Lasso Regression Imported succesfully
2023-02-15 11:30:57,012:INFO:Starting cross validation
2023-02-15 11:30:57,012:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:30:57,277:INFO:Calculating mean and std
2023-02-15 11:30:57,278:INFO:Creating metrics dataframe
2023-02-15 11:30:57,281:INFO:Uploading results into container
2023-02-15 11:30:57,281:INFO:Uploading model into container now
2023-02-15 11:30:57,281:INFO:create_model_container: 2
2023-02-15 11:30:57,281:INFO:master_model_container: 2
2023-02-15 11:30:57,281:INFO:display_container: 2
2023-02-15 11:30:57,282:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:30:57,282:INFO:create_model() succesfully completed......................................
2023-02-15 11:30:57,420:INFO:SubProcess create_model() end ==================================
2023-02-15 11:30:57,420:INFO:Creating metrics dataframe
2023-02-15 11:30:57,425:INFO:Initializing Ridge Regression
2023-02-15 11:30:57,426:INFO:Total runtime is 0.025738875071207683 minutes
2023-02-15 11:30:57,429:INFO:SubProcess create_model() called ==================================
2023-02-15 11:30:57,430:INFO:Initializing create_model()
2023-02-15 11:30:57,430:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:30:57,430:INFO:Checking exceptions
2023-02-15 11:30:57,430:INFO:Importing libraries
2023-02-15 11:30:57,430:INFO:Copying training dataset
2023-02-15 11:30:57,430:INFO:Defining folds
2023-02-15 11:30:57,430:INFO:Declaring metric variables
2023-02-15 11:30:57,434:INFO:Importing untrained model
2023-02-15 11:30:57,437:INFO:Ridge Regression Imported succesfully
2023-02-15 11:30:57,443:INFO:Starting cross validation
2023-02-15 11:30:57,443:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:30:57,726:INFO:Calculating mean and std
2023-02-15 11:30:57,729:INFO:Creating metrics dataframe
2023-02-15 11:30:57,736:INFO:Uploading results into container
2023-02-15 11:30:57,736:INFO:Uploading model into container now
2023-02-15 11:30:57,736:INFO:create_model_container: 3
2023-02-15 11:30:57,736:INFO:master_model_container: 3
2023-02-15 11:30:57,736:INFO:display_container: 2
2023-02-15 11:30:57,736:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-15 11:30:57,736:INFO:create_model() succesfully completed......................................
2023-02-15 11:30:57,882:INFO:SubProcess create_model() end ==================================
2023-02-15 11:30:57,882:INFO:Creating metrics dataframe
2023-02-15 11:30:57,889:INFO:Initializing Elastic Net
2023-02-15 11:30:57,889:INFO:Total runtime is 0.03346054553985596 minutes
2023-02-15 11:30:57,892:INFO:SubProcess create_model() called ==================================
2023-02-15 11:30:57,893:INFO:Initializing create_model()
2023-02-15 11:30:57,893:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:30:57,893:INFO:Checking exceptions
2023-02-15 11:30:57,893:INFO:Importing libraries
2023-02-15 11:30:57,893:INFO:Copying training dataset
2023-02-15 11:30:57,893:INFO:Defining folds
2023-02-15 11:30:57,893:INFO:Declaring metric variables
2023-02-15 11:30:57,896:INFO:Importing untrained model
2023-02-15 11:30:57,900:INFO:Elastic Net Imported succesfully
2023-02-15 11:30:57,906:INFO:Starting cross validation
2023-02-15 11:30:57,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:30:58,087:INFO:Calculating mean and std
2023-02-15 11:30:58,088:INFO:Creating metrics dataframe
2023-02-15 11:30:58,095:INFO:Uploading results into container
2023-02-15 11:30:58,097:INFO:Uploading model into container now
2023-02-15 11:30:58,097:INFO:create_model_container: 4
2023-02-15 11:30:58,097:INFO:master_model_container: 4
2023-02-15 11:30:58,097:INFO:display_container: 2
2023-02-15 11:30:58,097:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:30:58,097:INFO:create_model() succesfully completed......................................
2023-02-15 11:30:58,244:INFO:SubProcess create_model() end ==================================
2023-02-15 11:30:58,244:INFO:Creating metrics dataframe
2023-02-15 11:30:58,251:INFO:Initializing Least Angle Regression
2023-02-15 11:30:58,251:INFO:Total runtime is 0.039494927724202475 minutes
2023-02-15 11:30:58,255:INFO:SubProcess create_model() called ==================================
2023-02-15 11:30:58,255:INFO:Initializing create_model()
2023-02-15 11:30:58,255:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:30:58,255:INFO:Checking exceptions
2023-02-15 11:30:58,255:INFO:Importing libraries
2023-02-15 11:30:58,255:INFO:Copying training dataset
2023-02-15 11:30:58,256:INFO:Defining folds
2023-02-15 11:30:58,256:INFO:Declaring metric variables
2023-02-15 11:30:58,261:INFO:Importing untrained model
2023-02-15 11:30:58,264:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:30:58,270:INFO:Starting cross validation
2023-02-15 11:30:58,271:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:30:58,346:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:30:58,348:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1048, in __call__
    if self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:30:58,348:INFO:Initializing create_model()
2023-02-15 11:30:58,349:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:30:58,349:INFO:Checking exceptions
2023-02-15 11:30:58,349:INFO:Importing libraries
2023-02-15 11:30:58,349:INFO:Copying training dataset
2023-02-15 11:30:58,350:INFO:Defining folds
2023-02-15 11:30:58,350:INFO:Declaring metric variables
2023-02-15 11:30:58,355:INFO:Importing untrained model
2023-02-15 11:30:58,359:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:30:58,369:INFO:Starting cross validation
2023-02-15 11:30:58,369:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:30:58,449:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-02-15 11:30:58,450:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1048, in __call__
    if self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1048, in __call__
    if self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:30:58,450:INFO:Initializing Lasso Least Angle Regression
2023-02-15 11:30:58,450:INFO:Total runtime is 0.04280920823415121 minutes
2023-02-15 11:30:58,455:INFO:SubProcess create_model() called ==================================
2023-02-15 11:30:58,455:INFO:Initializing create_model()
2023-02-15 11:30:58,455:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:30:58,455:INFO:Checking exceptions
2023-02-15 11:30:58,455:INFO:Importing libraries
2023-02-15 11:30:58,455:INFO:Copying training dataset
2023-02-15 11:30:58,456:INFO:Defining folds
2023-02-15 11:30:58,456:INFO:Declaring metric variables
2023-02-15 11:30:58,461:INFO:Importing untrained model
2023-02-15 11:30:58,465:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-15 11:30:58,474:INFO:Starting cross validation
2023-02-15 11:30:58,475:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:30:58,616:INFO:Calculating mean and std
2023-02-15 11:30:58,616:INFO:Creating metrics dataframe
2023-02-15 11:30:58,619:INFO:Uploading results into container
2023-02-15 11:30:58,620:INFO:Uploading model into container now
2023-02-15 11:30:58,620:INFO:create_model_container: 5
2023-02-15 11:30:58,620:INFO:master_model_container: 5
2023-02-15 11:30:58,620:INFO:display_container: 2
2023-02-15 11:30:58,620:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-15 11:30:58,620:INFO:create_model() succesfully completed......................................
2023-02-15 11:30:58,733:INFO:SubProcess create_model() end ==================================
2023-02-15 11:30:58,733:INFO:Creating metrics dataframe
2023-02-15 11:30:58,740:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 11:30:58,740:INFO:Total runtime is 0.04764033953348796 minutes
2023-02-15 11:30:58,743:INFO:SubProcess create_model() called ==================================
2023-02-15 11:30:58,744:INFO:Initializing create_model()
2023-02-15 11:30:58,744:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:30:58,744:INFO:Checking exceptions
2023-02-15 11:30:58,744:INFO:Importing libraries
2023-02-15 11:30:58,744:INFO:Copying training dataset
2023-02-15 11:30:58,744:INFO:Defining folds
2023-02-15 11:30:58,744:INFO:Declaring metric variables
2023-02-15 11:30:58,748:INFO:Importing untrained model
2023-02-15 11:30:58,751:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-15 11:30:58,757:INFO:Starting cross validation
2023-02-15 11:30:58,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:30:58,913:INFO:Calculating mean and std
2023-02-15 11:30:58,914:INFO:Creating metrics dataframe
2023-02-15 11:30:58,917:INFO:Uploading results into container
2023-02-15 11:30:58,917:INFO:Uploading model into container now
2023-02-15 11:30:58,917:INFO:create_model_container: 6
2023-02-15 11:30:58,917:INFO:master_model_container: 6
2023-02-15 11:30:58,917:INFO:display_container: 2
2023-02-15 11:30:58,917:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-15 11:30:58,917:INFO:create_model() succesfully completed......................................
2023-02-15 11:30:59,030:INFO:SubProcess create_model() end ==================================
2023-02-15 11:30:59,030:INFO:Creating metrics dataframe
2023-02-15 11:30:59,037:INFO:Initializing Bayesian Ridge
2023-02-15 11:30:59,037:INFO:Total runtime is 0.05259157816569011 minutes
2023-02-15 11:30:59,040:INFO:SubProcess create_model() called ==================================
2023-02-15 11:30:59,040:INFO:Initializing create_model()
2023-02-15 11:30:59,040:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:30:59,040:INFO:Checking exceptions
2023-02-15 11:30:59,040:INFO:Importing libraries
2023-02-15 11:30:59,040:INFO:Copying training dataset
2023-02-15 11:30:59,041:INFO:Defining folds
2023-02-15 11:30:59,041:INFO:Declaring metric variables
2023-02-15 11:30:59,044:INFO:Importing untrained model
2023-02-15 11:30:59,047:INFO:Bayesian Ridge Imported succesfully
2023-02-15 11:30:59,053:INFO:Starting cross validation
2023-02-15 11:30:59,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:31:00,373:INFO:Calculating mean and std
2023-02-15 11:31:00,375:INFO:Creating metrics dataframe
2023-02-15 11:31:00,381:INFO:Uploading results into container
2023-02-15 11:31:00,381:INFO:Uploading model into container now
2023-02-15 11:31:00,381:INFO:create_model_container: 7
2023-02-15 11:31:00,381:INFO:master_model_container: 7
2023-02-15 11:31:00,381:INFO:display_container: 2
2023-02-15 11:31:00,381:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-15 11:31:00,381:INFO:create_model() succesfully completed......................................
2023-02-15 11:31:00,516:INFO:SubProcess create_model() end ==================================
2023-02-15 11:31:00,516:INFO:Creating metrics dataframe
2023-02-15 11:31:00,523:INFO:Initializing Passive Aggressive Regressor
2023-02-15 11:31:00,523:INFO:Total runtime is 0.07736774682998658 minutes
2023-02-15 11:31:00,527:INFO:SubProcess create_model() called ==================================
2023-02-15 11:31:00,527:INFO:Initializing create_model()
2023-02-15 11:31:00,527:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:31:00,527:INFO:Checking exceptions
2023-02-15 11:31:00,527:INFO:Importing libraries
2023-02-15 11:31:00,527:INFO:Copying training dataset
2023-02-15 11:31:00,528:INFO:Defining folds
2023-02-15 11:31:00,528:INFO:Declaring metric variables
2023-02-15 11:31:00,531:INFO:Importing untrained model
2023-02-15 11:31:00,534:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-15 11:31:00,540:INFO:Starting cross validation
2023-02-15 11:31:00,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:31:00,904:INFO:Calculating mean and std
2023-02-15 11:31:00,905:INFO:Creating metrics dataframe
2023-02-15 11:31:00,908:INFO:Uploading results into container
2023-02-15 11:31:00,908:INFO:Uploading model into container now
2023-02-15 11:31:00,908:INFO:create_model_container: 8
2023-02-15 11:31:00,908:INFO:master_model_container: 8
2023-02-15 11:31:00,908:INFO:display_container: 2
2023-02-15 11:31:00,908:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-15 11:31:00,908:INFO:create_model() succesfully completed......................................
2023-02-15 11:31:01,023:INFO:SubProcess create_model() end ==================================
2023-02-15 11:31:01,023:INFO:Creating metrics dataframe
2023-02-15 11:31:01,030:INFO:Initializing Huber Regressor
2023-02-15 11:31:01,030:INFO:Total runtime is 0.08581622044245403 minutes
2023-02-15 11:31:01,033:INFO:SubProcess create_model() called ==================================
2023-02-15 11:31:01,034:INFO:Initializing create_model()
2023-02-15 11:31:01,034:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:31:01,034:INFO:Checking exceptions
2023-02-15 11:31:01,034:INFO:Importing libraries
2023-02-15 11:31:01,034:INFO:Copying training dataset
2023-02-15 11:31:01,034:INFO:Defining folds
2023-02-15 11:31:01,034:INFO:Declaring metric variables
2023-02-15 11:31:01,037:INFO:Importing untrained model
2023-02-15 11:31:01,040:INFO:Huber Regressor Imported succesfully
2023-02-15 11:31:01,046:INFO:Starting cross validation
2023-02-15 11:31:01,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:31:16,744:INFO:Calculating mean and std
2023-02-15 11:31:16,745:INFO:Creating metrics dataframe
2023-02-15 11:31:16,748:INFO:Uploading results into container
2023-02-15 11:31:16,748:INFO:Uploading model into container now
2023-02-15 11:31:16,748:INFO:create_model_container: 9
2023-02-15 11:31:16,748:INFO:master_model_container: 9
2023-02-15 11:31:16,748:INFO:display_container: 2
2023-02-15 11:31:16,749:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-15 11:31:16,749:INFO:create_model() succesfully completed......................................
2023-02-15 11:31:16,860:INFO:SubProcess create_model() end ==================================
2023-02-15 11:31:16,860:INFO:Creating metrics dataframe
2023-02-15 11:31:16,866:INFO:Initializing K Neighbors Regressor
2023-02-15 11:31:16,866:INFO:Total runtime is 0.34975101550420123 minutes
2023-02-15 11:31:16,870:INFO:SubProcess create_model() called ==================================
2023-02-15 11:31:16,870:INFO:Initializing create_model()
2023-02-15 11:31:16,870:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:31:16,870:INFO:Checking exceptions
2023-02-15 11:31:16,870:INFO:Importing libraries
2023-02-15 11:31:16,870:INFO:Copying training dataset
2023-02-15 11:31:16,871:INFO:Defining folds
2023-02-15 11:31:16,871:INFO:Declaring metric variables
2023-02-15 11:31:16,874:INFO:Importing untrained model
2023-02-15 11:31:16,877:INFO:K Neighbors Regressor Imported succesfully
2023-02-15 11:31:16,883:INFO:Starting cross validation
2023-02-15 11:31:16,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:31:22,320:INFO:Calculating mean and std
2023-02-15 11:31:22,321:INFO:Creating metrics dataframe
2023-02-15 11:31:22,324:INFO:Uploading results into container
2023-02-15 11:31:22,325:INFO:Uploading model into container now
2023-02-15 11:31:22,325:INFO:create_model_container: 10
2023-02-15 11:31:22,325:INFO:master_model_container: 10
2023-02-15 11:31:22,325:INFO:display_container: 2
2023-02-15 11:31:22,325:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-15 11:31:22,325:INFO:create_model() succesfully completed......................................
2023-02-15 11:31:22,444:INFO:SubProcess create_model() end ==================================
2023-02-15 11:31:22,444:INFO:Creating metrics dataframe
2023-02-15 11:31:22,451:INFO:Initializing Decision Tree Regressor
2023-02-15 11:31:22,452:INFO:Total runtime is 0.44283946752548214 minutes
2023-02-15 11:31:22,455:INFO:SubProcess create_model() called ==================================
2023-02-15 11:31:22,456:INFO:Initializing create_model()
2023-02-15 11:31:22,456:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:31:22,456:INFO:Checking exceptions
2023-02-15 11:31:22,456:INFO:Importing libraries
2023-02-15 11:31:22,456:INFO:Copying training dataset
2023-02-15 11:31:22,457:INFO:Defining folds
2023-02-15 11:31:22,457:INFO:Declaring metric variables
2023-02-15 11:31:22,460:INFO:Importing untrained model
2023-02-15 11:31:22,464:INFO:Decision Tree Regressor Imported succesfully
2023-02-15 11:31:22,470:INFO:Starting cross validation
2023-02-15 11:31:22,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:31:44,379:INFO:Calculating mean and std
2023-02-15 11:31:44,379:INFO:Creating metrics dataframe
2023-02-15 11:31:44,382:INFO:Uploading results into container
2023-02-15 11:31:44,382:INFO:Uploading model into container now
2023-02-15 11:31:44,382:INFO:create_model_container: 11
2023-02-15 11:31:44,382:INFO:master_model_container: 11
2023-02-15 11:31:44,382:INFO:display_container: 2
2023-02-15 11:31:44,382:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-15 11:31:44,382:INFO:create_model() succesfully completed......................................
2023-02-15 11:31:44,483:INFO:SubProcess create_model() end ==================================
2023-02-15 11:31:44,483:INFO:Creating metrics dataframe
2023-02-15 11:31:44,495:INFO:Initializing Random Forest Regressor
2023-02-15 11:31:44,495:INFO:Total runtime is 0.8102294166882833 minutes
2023-02-15 11:31:44,499:INFO:SubProcess create_model() called ==================================
2023-02-15 11:31:44,499:INFO:Initializing create_model()
2023-02-15 11:31:44,499:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:31:44,499:INFO:Checking exceptions
2023-02-15 11:31:44,499:INFO:Importing libraries
2023-02-15 11:31:44,499:INFO:Copying training dataset
2023-02-15 11:31:44,500:INFO:Defining folds
2023-02-15 11:31:44,500:INFO:Declaring metric variables
2023-02-15 11:31:44,503:INFO:Importing untrained model
2023-02-15 11:31:44,506:INFO:Random Forest Regressor Imported succesfully
2023-02-15 11:31:44,513:INFO:Starting cross validation
2023-02-15 11:31:44,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:31:46,448:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:31:46,455:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1048, in __call__
    if self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 531, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 118, in fit
    result = super().fit(X, y=y, **fit_kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/imblearn/pipeline.py", line 281, in fit
    self._final_estimator.fit(Xt, yt, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 386, in fit
    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1061, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/concurrent/futures/_base.py", line 441, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

2023-02-15 11:31:46,455:INFO:Initializing create_model()
2023-02-15 11:31:46,455:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:31:46,455:INFO:Checking exceptions
2023-02-15 11:31:46,455:INFO:Importing libraries
2023-02-15 11:31:46,455:INFO:Copying training dataset
2023-02-15 11:31:46,457:INFO:Defining folds
2023-02-15 11:31:46,457:INFO:Declaring metric variables
2023-02-15 11:31:46,460:INFO:Importing untrained model
2023-02-15 11:31:46,464:INFO:Random Forest Regressor Imported succesfully
2023-02-15 11:31:46,471:INFO:Starting cross validation
2023-02-15 11:31:46,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:31:49,346:ERROR:create_model() for rf raised an exception or returned all 0.0:
2023-02-15 11:31:49,347:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1048, in __call__
    if self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 531, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 118, in fit
    result = super().fit(X, y=y, **fit_kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/imblearn/pipeline.py", line 281, in fit
    self._final_estimator.fit(Xt, yt, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 386, in fit
    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1061, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/concurrent/futures/_base.py", line 441, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/concurrent/futures/_base.py", line 441, in result
    self._condition.wait(timeout)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1048, in __call__
    if self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 531, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 118, in fit
    result = super().fit(X, y=y, **fit_kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/imblearn/pipeline.py", line 281, in fit
    self._final_estimator.fit(Xt, yt, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 386, in fit
    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1061, in __call__
    self.retrieve()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 960, in retrieve
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 561, in abort_everything
    self._workers.terminate(kill_workers=True)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/executor.py", line 74, in terminate
    self.shutdown(kill_workers=kill_workers)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 1185, in shutdown
    executor_manager_thread.join()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 1060, in join
    self._wait_for_tstate_lock()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt

2023-02-15 11:31:49,347:INFO:Initializing Extra Trees Regressor
2023-02-15 11:31:49,347:INFO:Total runtime is 0.8911016543706258 minutes
2023-02-15 11:31:49,353:INFO:SubProcess create_model() called ==================================
2023-02-15 11:31:49,353:INFO:Initializing create_model()
2023-02-15 11:31:49,353:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f5249e502b0>, return_train_score=False, kwargs={})
2023-02-15 11:31:49,353:INFO:Checking exceptions
2023-02-15 11:31:49,353:INFO:Importing libraries
2023-02-15 11:31:49,353:INFO:Copying training dataset
2023-02-15 11:31:49,354:INFO:Defining folds
2023-02-15 11:31:49,354:INFO:Declaring metric variables
2023-02-15 11:31:49,357:INFO:Importing untrained model
2023-02-15 11:31:49,361:INFO:Extra Trees Regressor Imported succesfully
2023-02-15 11:31:49,368:INFO:Starting cross validation
2023-02-15 11:31:49,368:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:03,955:INFO:PyCaret Supervised Module
2023-02-15 11:32:03,955:INFO:ML Usecase: regression
2023-02-15 11:32:03,955:INFO:version 2.3.10
2023-02-15 11:32:03,955:INFO:Initializing setup()
2023-02-15 11:32:03,955:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-15 11:32:03,955:INFO:Checking environment
2023-02-15 11:32:03,955:INFO:python_version: 3.9.16
2023-02-15 11:32:03,955:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-15 11:32:03,955:INFO:machine: x86_64
2023-02-15 11:32:03,955:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-15 11:32:03,955:INFO:Memory: svmem(total=134979592192, available=122874839040, percent=9.0, used=10424528896, free=102678945792, active=3772354560, inactive=25941057536, buffers=1419374592, cached=20456742912, shared=417865728, slab=1998516224)
2023-02-15 11:32:03,956:INFO:Physical Core: 16
2023-02-15 11:32:03,956:INFO:Logical Core: 32
2023-02-15 11:32:03,956:INFO:Checking libraries
2023-02-15 11:32:03,956:INFO:pd==1.5.2
2023-02-15 11:32:03,956:INFO:numpy==1.20.3
2023-02-15 11:32:03,956:INFO:sklearn==0.23.2
2023-02-15 11:32:03,956:INFO:lightgbm==3.3.5.99
2023-02-15 11:32:03,972:INFO:catboost==1.1.1
2023-02-15 11:32:03,972:INFO:xgboost==1.7.3
2023-02-15 11:32:03,972:INFO:mlflow==2.1.1
2023-02-15 11:32:03,972:INFO:Checking Exceptions
2023-02-15 11:32:03,973:INFO:Declaring global variables
2023-02-15 11:32:03,973:INFO:USI: af6f
2023-02-15 11:32:03,973:INFO:pycaret_globals: {'create_model_container', 'transform_target_method_param', 'USI', 'pycaret_globals', 'html_param', '_internal_pipeline', 'iterative_imputation_iters_param', 'fold_groups_param_full', 'gpu_param', '_all_metrics', '_all_models', 'imputation_classifier', 'y', 'n_jobs_param', 'log_plots_param', '_all_models_internal', 'logging_param', 'dashboard_logger', 'imputation_regressor', 'target_param', '_ml_usecase', 'data_before_preprocess', 'fold_shuffle_param', '_gpu_n_jobs_param', 'X_test', 'fold_param', 'master_model_container', 'exp_name_log', 'experiment__', 'prep_pipe', 'fix_imbalance_param', 'fix_imbalance_method_param', 'X', '_available_plots', 'display_container', 'fold_generator', 'stratify_param', 'fold_groups_param', 'seed', 'y_test', 'transform_target_param', 'y_train', 'X_train'}
2023-02-15 11:32:03,973:INFO:Preparing display monitor
2023-02-15 11:32:03,973:INFO:Preparing display monitor
2023-02-15 11:32:03,978:INFO:Importing libraries
2023-02-15 11:32:03,978:INFO:Copying data for preprocessing
2023-02-15 11:32:03,986:INFO:Declaring preprocessing parameters
2023-02-15 11:32:03,987:WARNING:cuML not found
2023-02-15 11:32:03,987:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-15 11:32:03,997:INFO:Creating preprocessing pipeline
2023-02-15 11:32:04,232:INFO:Preprocessing pipeline created successfully
2023-02-15 11:32:04,232:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-15 11:32:04,232:INFO:Creating global containers
2023-02-15 11:32:04,232:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-15 11:32:05,721:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:32:05,721:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:32:05,724:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:32:05,727:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:32:05,760:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:32:05,787:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:32:05,787:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:32:05,841:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:32:05,841:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:32:05,846:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:32:05,850:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:32:05,905:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:32:05,949:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:32:05,950:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:32:05,955:INFO:Creating grid variables
2023-02-15 11:32:05,975:INFO:create_model_container: 0
2023-02-15 11:32:05,975:INFO:master_model_container: 0
2023-02-15 11:32:05,975:INFO:display_container: 1
2023-02-15 11:32:05,978:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('P_transform', 'passthrough'), ('binn', 'passthrough'),
                ('rem_outliers', 'passthrough'), ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-15 11:32:05,978:INFO:setup() succesfully completed......................................
2023-02-15 11:32:06,096:INFO:Initializing compare_models()
2023-02-15 11:32:06,096:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=['tr'])
2023-02-15 11:32:06,096:INFO:Checking exceptions
2023-02-15 11:32:06,097:INFO:Preparing display monitor
2023-02-15 11:32:06,097:INFO:Preparing display monitor
2023-02-15 11:32:06,107:INFO:Initializing Linear Regression
2023-02-15 11:32:06,107:INFO:Total runtime is 1.5497207641601562e-06 minutes
2023-02-15 11:32:06,110:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:06,110:INFO:Initializing create_model()
2023-02-15 11:32:06,110:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:06,110:INFO:Checking exceptions
2023-02-15 11:32:06,110:INFO:Importing libraries
2023-02-15 11:32:06,110:INFO:Copying training dataset
2023-02-15 11:32:06,111:INFO:Defining folds
2023-02-15 11:32:06,111:INFO:Declaring metric variables
2023-02-15 11:32:06,114:INFO:Importing untrained model
2023-02-15 11:32:06,117:INFO:Linear Regression Imported succesfully
2023-02-15 11:32:06,124:INFO:Starting cross validation
2023-02-15 11:32:06,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:07,044:INFO:Calculating mean and std
2023-02-15 11:32:07,047:INFO:Creating metrics dataframe
2023-02-15 11:32:07,053:INFO:Uploading results into container
2023-02-15 11:32:07,053:INFO:Uploading model into container now
2023-02-15 11:32:07,053:INFO:create_model_container: 1
2023-02-15 11:32:07,053:INFO:master_model_container: 1
2023-02-15 11:32:07,053:INFO:display_container: 2
2023-02-15 11:32:07,054:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-15 11:32:07,054:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:07,183:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:07,183:INFO:Creating metrics dataframe
2023-02-15 11:32:07,189:INFO:Initializing Lasso Regression
2023-02-15 11:32:07,189:INFO:Total runtime is 0.018031517664591473 minutes
2023-02-15 11:32:07,192:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:07,192:INFO:Initializing create_model()
2023-02-15 11:32:07,192:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:07,192:INFO:Checking exceptions
2023-02-15 11:32:07,193:INFO:Importing libraries
2023-02-15 11:32:07,193:INFO:Copying training dataset
2023-02-15 11:32:07,193:INFO:Defining folds
2023-02-15 11:32:07,193:INFO:Declaring metric variables
2023-02-15 11:32:07,196:INFO:Importing untrained model
2023-02-15 11:32:07,200:INFO:Lasso Regression Imported succesfully
2023-02-15 11:32:07,206:INFO:Starting cross validation
2023-02-15 11:32:07,206:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:07,479:INFO:Calculating mean and std
2023-02-15 11:32:07,482:INFO:Creating metrics dataframe
2023-02-15 11:32:07,488:INFO:Uploading results into container
2023-02-15 11:32:07,488:INFO:Uploading model into container now
2023-02-15 11:32:07,488:INFO:create_model_container: 2
2023-02-15 11:32:07,488:INFO:master_model_container: 2
2023-02-15 11:32:07,488:INFO:display_container: 2
2023-02-15 11:32:07,489:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:32:07,489:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:07,616:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:07,616:INFO:Creating metrics dataframe
2023-02-15 11:32:07,623:INFO:Initializing Ridge Regression
2023-02-15 11:32:07,623:INFO:Total runtime is 0.025261278947194418 minutes
2023-02-15 11:32:07,626:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:07,626:INFO:Initializing create_model()
2023-02-15 11:32:07,626:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:07,626:INFO:Checking exceptions
2023-02-15 11:32:07,626:INFO:Importing libraries
2023-02-15 11:32:07,626:INFO:Copying training dataset
2023-02-15 11:32:07,627:INFO:Defining folds
2023-02-15 11:32:07,627:INFO:Declaring metric variables
2023-02-15 11:32:07,630:INFO:Importing untrained model
2023-02-15 11:32:07,634:INFO:Ridge Regression Imported succesfully
2023-02-15 11:32:07,640:INFO:Starting cross validation
2023-02-15 11:32:07,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:07,916:INFO:Calculating mean and std
2023-02-15 11:32:07,916:INFO:Creating metrics dataframe
2023-02-15 11:32:07,919:INFO:Uploading results into container
2023-02-15 11:32:07,919:INFO:Uploading model into container now
2023-02-15 11:32:07,919:INFO:create_model_container: 3
2023-02-15 11:32:07,919:INFO:master_model_container: 3
2023-02-15 11:32:07,920:INFO:display_container: 2
2023-02-15 11:32:07,920:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-15 11:32:07,920:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:08,024:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:08,024:INFO:Creating metrics dataframe
2023-02-15 11:32:08,031:INFO:Initializing Elastic Net
2023-02-15 11:32:08,031:INFO:Total runtime is 0.032061970233917235 minutes
2023-02-15 11:32:08,034:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:08,034:INFO:Initializing create_model()
2023-02-15 11:32:08,034:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:08,034:INFO:Checking exceptions
2023-02-15 11:32:08,034:INFO:Importing libraries
2023-02-15 11:32:08,034:INFO:Copying training dataset
2023-02-15 11:32:08,035:INFO:Defining folds
2023-02-15 11:32:08,035:INFO:Declaring metric variables
2023-02-15 11:32:08,038:INFO:Importing untrained model
2023-02-15 11:32:08,041:INFO:Elastic Net Imported succesfully
2023-02-15 11:32:08,047:INFO:Starting cross validation
2023-02-15 11:32:08,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:08,194:INFO:Calculating mean and std
2023-02-15 11:32:08,195:INFO:Creating metrics dataframe
2023-02-15 11:32:08,198:INFO:Uploading results into container
2023-02-15 11:32:08,198:INFO:Uploading model into container now
2023-02-15 11:32:08,198:INFO:create_model_container: 4
2023-02-15 11:32:08,198:INFO:master_model_container: 4
2023-02-15 11:32:08,198:INFO:display_container: 2
2023-02-15 11:32:08,199:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:32:08,199:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:08,322:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:08,322:INFO:Creating metrics dataframe
2023-02-15 11:32:08,329:INFO:Initializing Least Angle Regression
2023-02-15 11:32:08,329:INFO:Total runtime is 0.037035377820332845 minutes
2023-02-15 11:32:08,332:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:08,333:INFO:Initializing create_model()
2023-02-15 11:32:08,333:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:08,333:INFO:Checking exceptions
2023-02-15 11:32:08,333:INFO:Importing libraries
2023-02-15 11:32:08,333:INFO:Copying training dataset
2023-02-15 11:32:08,333:INFO:Defining folds
2023-02-15 11:32:08,334:INFO:Declaring metric variables
2023-02-15 11:32:08,337:INFO:Importing untrained model
2023-02-15 11:32:08,340:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:32:08,346:INFO:Starting cross validation
2023-02-15 11:32:08,347:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:08,669:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:32:08,671:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:32:08,671:INFO:Initializing create_model()
2023-02-15 11:32:08,671:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:08,671:INFO:Checking exceptions
2023-02-15 11:32:08,671:INFO:Importing libraries
2023-02-15 11:32:08,671:INFO:Copying training dataset
2023-02-15 11:32:08,673:INFO:Defining folds
2023-02-15 11:32:08,673:INFO:Declaring metric variables
2023-02-15 11:32:08,678:INFO:Importing untrained model
2023-02-15 11:32:08,683:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:32:08,692:INFO:Starting cross validation
2023-02-15 11:32:08,692:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:09,022:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-02-15 11:32:09,022:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:32:09,022:INFO:Initializing Lasso Least Angle Regression
2023-02-15 11:32:09,022:INFO:Total runtime is 0.04859211842219035 minutes
2023-02-15 11:32:09,028:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:09,028:INFO:Initializing create_model()
2023-02-15 11:32:09,028:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:09,028:INFO:Checking exceptions
2023-02-15 11:32:09,028:INFO:Importing libraries
2023-02-15 11:32:09,028:INFO:Copying training dataset
2023-02-15 11:32:09,029:INFO:Defining folds
2023-02-15 11:32:09,029:INFO:Declaring metric variables
2023-02-15 11:32:09,033:INFO:Importing untrained model
2023-02-15 11:32:09,038:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-15 11:32:09,047:INFO:Starting cross validation
2023-02-15 11:32:09,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:09,201:INFO:Calculating mean and std
2023-02-15 11:32:09,201:INFO:Creating metrics dataframe
2023-02-15 11:32:09,204:INFO:Uploading results into container
2023-02-15 11:32:09,204:INFO:Uploading model into container now
2023-02-15 11:32:09,204:INFO:create_model_container: 5
2023-02-15 11:32:09,205:INFO:master_model_container: 5
2023-02-15 11:32:09,205:INFO:display_container: 2
2023-02-15 11:32:09,205:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-15 11:32:09,205:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:09,316:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:09,316:INFO:Creating metrics dataframe
2023-02-15 11:32:09,322:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 11:32:09,322:INFO:Total runtime is 0.05358403921127319 minutes
2023-02-15 11:32:09,326:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:09,326:INFO:Initializing create_model()
2023-02-15 11:32:09,326:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:09,326:INFO:Checking exceptions
2023-02-15 11:32:09,326:INFO:Importing libraries
2023-02-15 11:32:09,326:INFO:Copying training dataset
2023-02-15 11:32:09,327:INFO:Defining folds
2023-02-15 11:32:09,327:INFO:Declaring metric variables
2023-02-15 11:32:09,330:INFO:Importing untrained model
2023-02-15 11:32:09,333:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-15 11:32:09,338:INFO:Starting cross validation
2023-02-15 11:32:09,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:09,476:INFO:Calculating mean and std
2023-02-15 11:32:09,477:INFO:Creating metrics dataframe
2023-02-15 11:32:09,480:INFO:Uploading results into container
2023-02-15 11:32:09,480:INFO:Uploading model into container now
2023-02-15 11:32:09,480:INFO:create_model_container: 6
2023-02-15 11:32:09,480:INFO:master_model_container: 6
2023-02-15 11:32:09,480:INFO:display_container: 2
2023-02-15 11:32:09,480:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-15 11:32:09,480:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:09,590:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:09,591:INFO:Creating metrics dataframe
2023-02-15 11:32:09,597:INFO:Initializing Bayesian Ridge
2023-02-15 11:32:09,597:INFO:Total runtime is 0.05817259550094604 minutes
2023-02-15 11:32:09,601:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:09,601:INFO:Initializing create_model()
2023-02-15 11:32:09,601:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:09,601:INFO:Checking exceptions
2023-02-15 11:32:09,601:INFO:Importing libraries
2023-02-15 11:32:09,601:INFO:Copying training dataset
2023-02-15 11:32:09,602:INFO:Defining folds
2023-02-15 11:32:09,602:INFO:Declaring metric variables
2023-02-15 11:32:09,605:INFO:Importing untrained model
2023-02-15 11:32:09,608:INFO:Bayesian Ridge Imported succesfully
2023-02-15 11:32:09,614:INFO:Starting cross validation
2023-02-15 11:32:09,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:10,971:INFO:Calculating mean and std
2023-02-15 11:32:10,982:INFO:Creating metrics dataframe
2023-02-15 11:32:10,985:INFO:Uploading results into container
2023-02-15 11:32:10,985:INFO:Uploading model into container now
2023-02-15 11:32:10,985:INFO:create_model_container: 7
2023-02-15 11:32:10,985:INFO:master_model_container: 7
2023-02-15 11:32:10,985:INFO:display_container: 2
2023-02-15 11:32:10,986:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-15 11:32:10,986:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:11,114:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:11,115:INFO:Creating metrics dataframe
2023-02-15 11:32:11,122:INFO:Initializing Passive Aggressive Regressor
2023-02-15 11:32:11,122:INFO:Total runtime is 0.08357928196589151 minutes
2023-02-15 11:32:11,125:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:11,126:INFO:Initializing create_model()
2023-02-15 11:32:11,126:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:11,126:INFO:Checking exceptions
2023-02-15 11:32:11,126:INFO:Importing libraries
2023-02-15 11:32:11,126:INFO:Copying training dataset
2023-02-15 11:32:11,126:INFO:Defining folds
2023-02-15 11:32:11,127:INFO:Declaring metric variables
2023-02-15 11:32:11,130:INFO:Importing untrained model
2023-02-15 11:32:11,133:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-15 11:32:11,139:INFO:Starting cross validation
2023-02-15 11:32:11,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:11,485:INFO:Calculating mean and std
2023-02-15 11:32:11,486:INFO:Creating metrics dataframe
2023-02-15 11:32:11,489:INFO:Uploading results into container
2023-02-15 11:32:11,489:INFO:Uploading model into container now
2023-02-15 11:32:11,489:INFO:create_model_container: 8
2023-02-15 11:32:11,489:INFO:master_model_container: 8
2023-02-15 11:32:11,489:INFO:display_container: 2
2023-02-15 11:32:11,490:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-15 11:32:11,490:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:11,613:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:11,613:INFO:Creating metrics dataframe
2023-02-15 11:32:11,620:INFO:Initializing Huber Regressor
2023-02-15 11:32:11,620:INFO:Total runtime is 0.09188695748647054 minutes
2023-02-15 11:32:11,624:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:11,624:INFO:Initializing create_model()
2023-02-15 11:32:11,624:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:11,624:INFO:Checking exceptions
2023-02-15 11:32:11,624:INFO:Importing libraries
2023-02-15 11:32:11,624:INFO:Copying training dataset
2023-02-15 11:32:11,625:INFO:Defining folds
2023-02-15 11:32:11,625:INFO:Declaring metric variables
2023-02-15 11:32:11,628:INFO:Importing untrained model
2023-02-15 11:32:11,632:INFO:Huber Regressor Imported succesfully
2023-02-15 11:32:11,638:INFO:Starting cross validation
2023-02-15 11:32:11,638:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:26,660:INFO:Calculating mean and std
2023-02-15 11:32:26,661:INFO:Creating metrics dataframe
2023-02-15 11:32:26,664:INFO:Uploading results into container
2023-02-15 11:32:26,664:INFO:Uploading model into container now
2023-02-15 11:32:26,664:INFO:create_model_container: 9
2023-02-15 11:32:26,664:INFO:master_model_container: 9
2023-02-15 11:32:26,664:INFO:display_container: 2
2023-02-15 11:32:26,664:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-15 11:32:26,664:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:26,783:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:26,784:INFO:Creating metrics dataframe
2023-02-15 11:32:26,791:INFO:Initializing K Neighbors Regressor
2023-02-15 11:32:26,791:INFO:Total runtime is 0.3447374900182088 minutes
2023-02-15 11:32:26,795:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:26,795:INFO:Initializing create_model()
2023-02-15 11:32:26,795:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:26,795:INFO:Checking exceptions
2023-02-15 11:32:26,795:INFO:Importing libraries
2023-02-15 11:32:26,795:INFO:Copying training dataset
2023-02-15 11:32:26,796:INFO:Defining folds
2023-02-15 11:32:26,796:INFO:Declaring metric variables
2023-02-15 11:32:26,799:INFO:Importing untrained model
2023-02-15 11:32:26,802:INFO:K Neighbors Regressor Imported succesfully
2023-02-15 11:32:26,808:INFO:Starting cross validation
2023-02-15 11:32:26,808:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:32,325:INFO:Calculating mean and std
2023-02-15 11:32:32,326:INFO:Creating metrics dataframe
2023-02-15 11:32:32,329:INFO:Uploading results into container
2023-02-15 11:32:32,329:INFO:Uploading model into container now
2023-02-15 11:32:32,329:INFO:create_model_container: 10
2023-02-15 11:32:32,329:INFO:master_model_container: 10
2023-02-15 11:32:32,329:INFO:display_container: 2
2023-02-15 11:32:32,330:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-15 11:32:32,330:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:32,457:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:32,458:INFO:Creating metrics dataframe
2023-02-15 11:32:32,465:INFO:Initializing Decision Tree Regressor
2023-02-15 11:32:32,465:INFO:Total runtime is 0.43930144309997554 minutes
2023-02-15 11:32:32,468:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:32,469:INFO:Initializing create_model()
2023-02-15 11:32:32,469:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:32,469:INFO:Checking exceptions
2023-02-15 11:32:32,469:INFO:Importing libraries
2023-02-15 11:32:32,469:INFO:Copying training dataset
2023-02-15 11:32:32,469:INFO:Defining folds
2023-02-15 11:32:32,470:INFO:Declaring metric variables
2023-02-15 11:32:32,473:INFO:Importing untrained model
2023-02-15 11:32:32,476:INFO:Decision Tree Regressor Imported succesfully
2023-02-15 11:32:32,482:INFO:Starting cross validation
2023-02-15 11:32:32,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:32:54,890:INFO:Calculating mean and std
2023-02-15 11:32:54,891:INFO:Creating metrics dataframe
2023-02-15 11:32:54,893:INFO:Uploading results into container
2023-02-15 11:32:54,893:INFO:Uploading model into container now
2023-02-15 11:32:54,893:INFO:create_model_container: 11
2023-02-15 11:32:54,893:INFO:master_model_container: 11
2023-02-15 11:32:54,893:INFO:display_container: 2
2023-02-15 11:32:54,893:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-15 11:32:54,893:INFO:create_model() succesfully completed......................................
2023-02-15 11:32:54,998:INFO:SubProcess create_model() end ==================================
2023-02-15 11:32:54,998:INFO:Creating metrics dataframe
2023-02-15 11:32:55,005:INFO:Initializing Random Forest Regressor
2023-02-15 11:32:55,005:INFO:Total runtime is 0.8149698774019877 minutes
2023-02-15 11:32:55,009:INFO:SubProcess create_model() called ==================================
2023-02-15 11:32:55,009:INFO:Initializing create_model()
2023-02-15 11:32:55,009:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:32:55,009:INFO:Checking exceptions
2023-02-15 11:32:55,009:INFO:Importing libraries
2023-02-15 11:32:55,009:INFO:Copying training dataset
2023-02-15 11:32:55,010:INFO:Defining folds
2023-02-15 11:32:55,010:INFO:Declaring metric variables
2023-02-15 11:32:55,013:INFO:Importing untrained model
2023-02-15 11:32:55,016:INFO:Random Forest Regressor Imported succesfully
2023-02-15 11:32:55,022:INFO:Starting cross validation
2023-02-15 11:32:55,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:34:21,653:INFO:Calculating mean and std
2023-02-15 11:34:21,654:INFO:Creating metrics dataframe
2023-02-15 11:34:21,656:INFO:Uploading results into container
2023-02-15 11:34:21,656:INFO:Uploading model into container now
2023-02-15 11:34:21,656:INFO:create_model_container: 12
2023-02-15 11:34:21,656:INFO:master_model_container: 12
2023-02-15 11:34:21,656:INFO:display_container: 2
2023-02-15 11:34:21,656:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-15 11:34:21,657:INFO:create_model() succesfully completed......................................
2023-02-15 11:34:21,751:INFO:SubProcess create_model() end ==================================
2023-02-15 11:34:21,751:INFO:Creating metrics dataframe
2023-02-15 11:34:21,759:INFO:Initializing Extra Trees Regressor
2023-02-15 11:34:21,759:INFO:Total runtime is 2.2608728289604185 minutes
2023-02-15 11:34:21,763:INFO:SubProcess create_model() called ==================================
2023-02-15 11:34:21,763:INFO:Initializing create_model()
2023-02-15 11:34:21,763:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:34:21,763:INFO:Checking exceptions
2023-02-15 11:34:21,763:INFO:Importing libraries
2023-02-15 11:34:21,763:INFO:Copying training dataset
2023-02-15 11:34:21,764:INFO:Defining folds
2023-02-15 11:34:21,764:INFO:Declaring metric variables
2023-02-15 11:34:21,767:INFO:Importing untrained model
2023-02-15 11:34:21,770:INFO:Extra Trees Regressor Imported succesfully
2023-02-15 11:34:21,776:INFO:Starting cross validation
2023-02-15 11:34:21,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:34:47,236:INFO:Calculating mean and std
2023-02-15 11:34:47,237:INFO:Creating metrics dataframe
2023-02-15 11:34:47,239:INFO:Uploading results into container
2023-02-15 11:34:47,239:INFO:Uploading model into container now
2023-02-15 11:34:47,239:INFO:create_model_container: 13
2023-02-15 11:34:47,239:INFO:master_model_container: 13
2023-02-15 11:34:47,239:INFO:display_container: 2
2023-02-15 11:34:47,239:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-15 11:34:47,239:INFO:create_model() succesfully completed......................................
2023-02-15 11:34:47,349:INFO:SubProcess create_model() end ==================================
2023-02-15 11:34:47,350:INFO:Creating metrics dataframe
2023-02-15 11:34:47,358:INFO:Initializing AdaBoost Regressor
2023-02-15 11:34:47,358:INFO:Total runtime is 2.6875134189923604 minutes
2023-02-15 11:34:47,361:INFO:SubProcess create_model() called ==================================
2023-02-15 11:34:47,362:INFO:Initializing create_model()
2023-02-15 11:34:47,362:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:34:47,362:INFO:Checking exceptions
2023-02-15 11:34:47,362:INFO:Importing libraries
2023-02-15 11:34:47,362:INFO:Copying training dataset
2023-02-15 11:34:47,362:INFO:Defining folds
2023-02-15 11:34:47,362:INFO:Declaring metric variables
2023-02-15 11:34:47,366:INFO:Importing untrained model
2023-02-15 11:34:47,369:INFO:AdaBoost Regressor Imported succesfully
2023-02-15 11:34:47,375:INFO:Starting cross validation
2023-02-15 11:34:47,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:35:18,390:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:35:18,391:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 531, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 118, in fit
    result = super().fit(X, y=y, **fit_kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/imblearn/pipeline.py", line 281, in fit
    self._final_estimator.fit(Xt, yt, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py", line 1007, in fit
    return super().fit(X, y, sample_weight)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py", line 130, in fit
    sample_weight, estimator_weight, estimator_error = self._boost(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py", line 1068, in _boost
    estimator.fit(X_, y_)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 1242, in fit
    super().fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 375, in fit
    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)
KeyboardInterrupt

2023-02-15 11:35:18,392:INFO:Initializing create_model()
2023-02-15 11:35:18,392:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa3e5aa7070>, return_train_score=False, kwargs={})
2023-02-15 11:35:18,392:INFO:Checking exceptions
2023-02-15 11:35:18,392:INFO:Importing libraries
2023-02-15 11:35:18,392:INFO:Copying training dataset
2023-02-15 11:35:18,393:INFO:Defining folds
2023-02-15 11:35:18,393:INFO:Declaring metric variables
2023-02-15 11:35:18,397:INFO:Importing untrained model
2023-02-15 11:35:18,400:INFO:AdaBoost Regressor Imported succesfully
2023-02-15 11:35:18,406:INFO:Starting cross validation
2023-02-15 11:35:18,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:02,816:INFO:PyCaret Supervised Module
2023-02-15 11:37:02,816:INFO:ML Usecase: regression
2023-02-15 11:37:02,816:INFO:version 2.3.10
2023-02-15 11:37:02,816:INFO:Initializing setup()
2023-02-15 11:37:02,816:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-15 11:37:02,816:INFO:Checking environment
2023-02-15 11:37:02,816:INFO:python_version: 3.9.16
2023-02-15 11:37:02,816:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-15 11:37:02,816:INFO:machine: x86_64
2023-02-15 11:37:02,816:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-15 11:37:02,816:INFO:Memory: svmem(total=134979592192, available=123165392896, percent=8.8, used=10098016256, free=103014711296, active=3795398656, inactive=25642672128, buffers=1421467648, cached=20445396992, shared=453824512, slab=1953615872)
2023-02-15 11:37:02,817:INFO:Physical Core: 16
2023-02-15 11:37:02,817:INFO:Logical Core: 32
2023-02-15 11:37:02,817:INFO:Checking libraries
2023-02-15 11:37:02,817:INFO:pd==1.5.2
2023-02-15 11:37:02,817:INFO:numpy==1.20.3
2023-02-15 11:37:02,817:INFO:sklearn==0.23.2
2023-02-15 11:37:02,817:INFO:lightgbm==3.3.5.99
2023-02-15 11:37:02,834:INFO:catboost==1.1.1
2023-02-15 11:37:02,835:INFO:xgboost==1.7.3
2023-02-15 11:37:02,835:INFO:mlflow==2.1.1
2023-02-15 11:37:02,835:INFO:Checking Exceptions
2023-02-15 11:37:02,835:INFO:Declaring global variables
2023-02-15 11:37:02,835:INFO:USI: b4a8
2023-02-15 11:37:02,835:INFO:pycaret_globals: {'create_model_container', 'fix_imbalance_method_param', 'n_jobs_param', 'fold_groups_param_full', 'exp_name_log', '_all_metrics', 'seed', 'data_before_preprocess', '_ml_usecase', 'target_param', 'master_model_container', 'X_test', 'prep_pipe', 'log_plots_param', 'display_container', 'pycaret_globals', 'html_param', '_internal_pipeline', 'iterative_imputation_iters_param', 'imputation_regressor', 'y_train', 'USI', 'fold_shuffle_param', 'transform_target_method_param', '_all_models', 'dashboard_logger', 'fold_param', 'fold_groups_param', 'y_test', 'X_train', 'logging_param', 'imputation_classifier', 'y', '_all_models_internal', '_available_plots', 'fix_imbalance_param', 'X', 'transform_target_param', '_gpu_n_jobs_param', 'experiment__', 'gpu_param', 'stratify_param', 'fold_generator'}
2023-02-15 11:37:02,835:INFO:Preparing display monitor
2023-02-15 11:37:02,835:INFO:Preparing display monitor
2023-02-15 11:37:02,841:INFO:Importing libraries
2023-02-15 11:37:02,841:INFO:Copying data for preprocessing
2023-02-15 11:37:02,852:INFO:Declaring preprocessing parameters
2023-02-15 11:37:02,852:WARNING:cuML not found
2023-02-15 11:37:02,852:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-15 11:37:02,864:INFO:Creating preprocessing pipeline
2023-02-15 11:37:03,099:INFO:Preprocessing pipeline created successfully
2023-02-15 11:37:03,099:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-15 11:37:03,099:INFO:Creating global containers
2023-02-15 11:37:03,100:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-15 11:37:04,770:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:37:04,770:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:37:04,773:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:37:04,776:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:37:04,809:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:37:04,838:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:37:04,838:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:37:04,913:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:37:04,914:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:37:04,917:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:37:04,920:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:37:04,962:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:37:05,004:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:37:05,004:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:37:05,010:INFO:Creating grid variables
2023-02-15 11:37:05,029:INFO:create_model_container: 0
2023-02-15 11:37:05,029:INFO:master_model_container: 0
2023-02-15 11:37:05,029:INFO:display_container: 1
2023-02-15 11:37:05,034:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('P_transform', 'passthrough'), ('binn', 'passthrough'),
                ('rem_outliers', 'passthrough'), ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-15 11:37:05,034:INFO:setup() succesfully completed......................................
2023-02-15 11:37:05,177:INFO:Initializing compare_models()
2023-02-15 11:37:05,177:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=['tr'])
2023-02-15 11:37:05,177:INFO:Checking exceptions
2023-02-15 11:37:05,177:INFO:Preparing display monitor
2023-02-15 11:37:05,177:INFO:Preparing display monitor
2023-02-15 11:37:05,190:INFO:Initializing Linear Regression
2023-02-15 11:37:05,190:INFO:Total runtime is 2.133846282958984e-06 minutes
2023-02-15 11:37:05,194:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:05,194:INFO:Initializing create_model()
2023-02-15 11:37:05,195:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:05,195:INFO:Checking exceptions
2023-02-15 11:37:05,195:INFO:Importing libraries
2023-02-15 11:37:05,195:INFO:Copying training dataset
2023-02-15 11:37:05,195:INFO:Defining folds
2023-02-15 11:37:05,195:INFO:Declaring metric variables
2023-02-15 11:37:05,199:INFO:Importing untrained model
2023-02-15 11:37:05,203:INFO:Linear Regression Imported succesfully
2023-02-15 11:37:05,211:INFO:Starting cross validation
2023-02-15 11:37:05,213:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:06,054:INFO:Calculating mean and std
2023-02-15 11:37:06,057:INFO:Creating metrics dataframe
2023-02-15 11:37:06,065:INFO:Uploading results into container
2023-02-15 11:37:06,065:INFO:Uploading model into container now
2023-02-15 11:37:06,065:INFO:create_model_container: 1
2023-02-15 11:37:06,065:INFO:master_model_container: 1
2023-02-15 11:37:06,065:INFO:display_container: 2
2023-02-15 11:37:06,066:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-15 11:37:06,066:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:06,219:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:06,219:INFO:Creating metrics dataframe
2023-02-15 11:37:06,225:INFO:Initializing Lasso Regression
2023-02-15 11:37:06,225:INFO:Total runtime is 0.017255528767903646 minutes
2023-02-15 11:37:06,230:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:06,230:INFO:Initializing create_model()
2023-02-15 11:37:06,230:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:06,230:INFO:Checking exceptions
2023-02-15 11:37:06,230:INFO:Importing libraries
2023-02-15 11:37:06,230:INFO:Copying training dataset
2023-02-15 11:37:06,231:INFO:Defining folds
2023-02-15 11:37:06,231:INFO:Declaring metric variables
2023-02-15 11:37:06,235:INFO:Importing untrained model
2023-02-15 11:37:06,239:INFO:Lasso Regression Imported succesfully
2023-02-15 11:37:06,245:INFO:Starting cross validation
2023-02-15 11:37:06,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:06,503:INFO:Calculating mean and std
2023-02-15 11:37:06,507:INFO:Creating metrics dataframe
2023-02-15 11:37:06,513:INFO:Uploading results into container
2023-02-15 11:37:06,513:INFO:Uploading model into container now
2023-02-15 11:37:06,513:INFO:create_model_container: 2
2023-02-15 11:37:06,514:INFO:master_model_container: 2
2023-02-15 11:37:06,514:INFO:display_container: 2
2023-02-15 11:37:06,514:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:37:06,514:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:06,667:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:06,667:INFO:Creating metrics dataframe
2023-02-15 11:37:06,674:INFO:Initializing Ridge Regression
2023-02-15 11:37:06,674:INFO:Total runtime is 0.02473270098368327 minutes
2023-02-15 11:37:06,678:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:06,678:INFO:Initializing create_model()
2023-02-15 11:37:06,678:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:06,678:INFO:Checking exceptions
2023-02-15 11:37:06,678:INFO:Importing libraries
2023-02-15 11:37:06,678:INFO:Copying training dataset
2023-02-15 11:37:06,679:INFO:Defining folds
2023-02-15 11:37:06,679:INFO:Declaring metric variables
2023-02-15 11:37:06,683:INFO:Importing untrained model
2023-02-15 11:37:06,686:INFO:Ridge Regression Imported succesfully
2023-02-15 11:37:06,694:INFO:Starting cross validation
2023-02-15 11:37:06,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:06,904:INFO:Calculating mean and std
2023-02-15 11:37:06,905:INFO:Creating metrics dataframe
2023-02-15 11:37:06,910:INFO:Uploading results into container
2023-02-15 11:37:06,910:INFO:Uploading model into container now
2023-02-15 11:37:06,910:INFO:create_model_container: 3
2023-02-15 11:37:06,910:INFO:master_model_container: 3
2023-02-15 11:37:06,910:INFO:display_container: 2
2023-02-15 11:37:06,910:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-15 11:37:06,910:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:07,038:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:07,038:INFO:Creating metrics dataframe
2023-02-15 11:37:07,045:INFO:Initializing Elastic Net
2023-02-15 11:37:07,045:INFO:Total runtime is 0.03091930150985718 minutes
2023-02-15 11:37:07,049:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:07,050:INFO:Initializing create_model()
2023-02-15 11:37:07,050:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:07,050:INFO:Checking exceptions
2023-02-15 11:37:07,050:INFO:Importing libraries
2023-02-15 11:37:07,050:INFO:Copying training dataset
2023-02-15 11:37:07,051:INFO:Defining folds
2023-02-15 11:37:07,051:INFO:Declaring metric variables
2023-02-15 11:37:07,054:INFO:Importing untrained model
2023-02-15 11:37:07,058:INFO:Elastic Net Imported succesfully
2023-02-15 11:37:07,065:INFO:Starting cross validation
2023-02-15 11:37:07,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:07,328:INFO:Calculating mean and std
2023-02-15 11:37:07,332:INFO:Creating metrics dataframe
2023-02-15 11:37:07,338:INFO:Uploading results into container
2023-02-15 11:37:07,338:INFO:Uploading model into container now
2023-02-15 11:37:07,338:INFO:create_model_container: 4
2023-02-15 11:37:07,338:INFO:master_model_container: 4
2023-02-15 11:37:07,338:INFO:display_container: 2
2023-02-15 11:37:07,339:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:37:07,339:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:07,491:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:07,492:INFO:Creating metrics dataframe
2023-02-15 11:37:07,498:INFO:Initializing Least Angle Regression
2023-02-15 11:37:07,498:INFO:Total runtime is 0.03846878210703532 minutes
2023-02-15 11:37:07,503:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:07,503:INFO:Initializing create_model()
2023-02-15 11:37:07,503:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:07,503:INFO:Checking exceptions
2023-02-15 11:37:07,503:INFO:Importing libraries
2023-02-15 11:37:07,503:INFO:Copying training dataset
2023-02-15 11:37:07,504:INFO:Defining folds
2023-02-15 11:37:07,504:INFO:Declaring metric variables
2023-02-15 11:37:07,509:INFO:Importing untrained model
2023-02-15 11:37:07,513:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:37:07,520:INFO:Starting cross validation
2023-02-15 11:37:07,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:07,879:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:37:07,882:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:37:07,882:INFO:Initializing create_model()
2023-02-15 11:37:07,882:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:07,882:INFO:Checking exceptions
2023-02-15 11:37:07,884:INFO:Importing libraries
2023-02-15 11:37:07,884:INFO:Copying training dataset
2023-02-15 11:37:07,886:INFO:Defining folds
2023-02-15 11:37:07,886:INFO:Declaring metric variables
2023-02-15 11:37:07,892:INFO:Importing untrained model
2023-02-15 11:37:07,899:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:37:07,911:INFO:Starting cross validation
2023-02-15 11:37:07,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:08,286:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-02-15 11:37:08,287:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:37:08,287:INFO:Initializing Lasso Least Angle Regression
2023-02-15 11:37:08,287:INFO:Total runtime is 0.05161430438359578 minutes
2023-02-15 11:37:08,295:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:08,295:INFO:Initializing create_model()
2023-02-15 11:37:08,296:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:08,296:INFO:Checking exceptions
2023-02-15 11:37:08,296:INFO:Importing libraries
2023-02-15 11:37:08,296:INFO:Copying training dataset
2023-02-15 11:37:08,297:INFO:Defining folds
2023-02-15 11:37:08,297:INFO:Declaring metric variables
2023-02-15 11:37:08,303:INFO:Importing untrained model
2023-02-15 11:37:08,309:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-15 11:37:08,339:INFO:Starting cross validation
2023-02-15 11:37:08,340:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:08,570:INFO:Calculating mean and std
2023-02-15 11:37:08,572:INFO:Creating metrics dataframe
2023-02-15 11:37:08,577:INFO:Uploading results into container
2023-02-15 11:37:08,577:INFO:Uploading model into container now
2023-02-15 11:37:08,577:INFO:create_model_container: 5
2023-02-15 11:37:08,577:INFO:master_model_container: 5
2023-02-15 11:37:08,577:INFO:display_container: 2
2023-02-15 11:37:08,580:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-15 11:37:08,580:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:08,717:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:08,717:INFO:Creating metrics dataframe
2023-02-15 11:37:08,724:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 11:37:08,724:INFO:Total runtime is 0.058899378776550285 minutes
2023-02-15 11:37:08,728:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:08,728:INFO:Initializing create_model()
2023-02-15 11:37:08,728:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:08,728:INFO:Checking exceptions
2023-02-15 11:37:08,728:INFO:Importing libraries
2023-02-15 11:37:08,728:INFO:Copying training dataset
2023-02-15 11:37:08,729:INFO:Defining folds
2023-02-15 11:37:08,729:INFO:Declaring metric variables
2023-02-15 11:37:08,732:INFO:Importing untrained model
2023-02-15 11:37:08,735:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-15 11:37:08,741:INFO:Starting cross validation
2023-02-15 11:37:08,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:08,902:INFO:Calculating mean and std
2023-02-15 11:37:08,902:INFO:Creating metrics dataframe
2023-02-15 11:37:08,906:INFO:Uploading results into container
2023-02-15 11:37:08,906:INFO:Uploading model into container now
2023-02-15 11:37:08,906:INFO:create_model_container: 6
2023-02-15 11:37:08,906:INFO:master_model_container: 6
2023-02-15 11:37:08,906:INFO:display_container: 2
2023-02-15 11:37:08,906:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-15 11:37:08,906:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:09,023:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:09,023:INFO:Creating metrics dataframe
2023-02-15 11:37:09,030:INFO:Initializing Bayesian Ridge
2023-02-15 11:37:09,030:INFO:Total runtime is 0.06399327119191486 minutes
2023-02-15 11:37:09,033:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:09,033:INFO:Initializing create_model()
2023-02-15 11:37:09,034:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:09,034:INFO:Checking exceptions
2023-02-15 11:37:09,034:INFO:Importing libraries
2023-02-15 11:37:09,034:INFO:Copying training dataset
2023-02-15 11:37:09,034:INFO:Defining folds
2023-02-15 11:37:09,034:INFO:Declaring metric variables
2023-02-15 11:37:09,038:INFO:Importing untrained model
2023-02-15 11:37:09,041:INFO:Bayesian Ridge Imported succesfully
2023-02-15 11:37:09,047:INFO:Starting cross validation
2023-02-15 11:37:09,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:10,529:INFO:Calculating mean and std
2023-02-15 11:37:10,532:INFO:Creating metrics dataframe
2023-02-15 11:37:10,535:INFO:Uploading results into container
2023-02-15 11:37:10,538:INFO:Uploading model into container now
2023-02-15 11:37:10,538:INFO:create_model_container: 7
2023-02-15 11:37:10,538:INFO:master_model_container: 7
2023-02-15 11:37:10,538:INFO:display_container: 2
2023-02-15 11:37:10,539:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-15 11:37:10,539:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:10,679:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:10,679:INFO:Creating metrics dataframe
2023-02-15 11:37:10,685:INFO:Initializing Passive Aggressive Regressor
2023-02-15 11:37:10,685:INFO:Total runtime is 0.0915870984395345 minutes
2023-02-15 11:37:10,689:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:10,689:INFO:Initializing create_model()
2023-02-15 11:37:10,689:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:10,689:INFO:Checking exceptions
2023-02-15 11:37:10,689:INFO:Importing libraries
2023-02-15 11:37:10,689:INFO:Copying training dataset
2023-02-15 11:37:10,690:INFO:Defining folds
2023-02-15 11:37:10,690:INFO:Declaring metric variables
2023-02-15 11:37:10,693:INFO:Importing untrained model
2023-02-15 11:37:10,696:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-15 11:37:10,702:INFO:Starting cross validation
2023-02-15 11:37:10,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:11,059:INFO:Calculating mean and std
2023-02-15 11:37:11,060:INFO:Creating metrics dataframe
2023-02-15 11:37:11,063:INFO:Uploading results into container
2023-02-15 11:37:11,063:INFO:Uploading model into container now
2023-02-15 11:37:11,063:INFO:create_model_container: 8
2023-02-15 11:37:11,063:INFO:master_model_container: 8
2023-02-15 11:37:11,063:INFO:display_container: 2
2023-02-15 11:37:11,063:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-15 11:37:11,064:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:11,190:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:11,190:INFO:Creating metrics dataframe
2023-02-15 11:37:11,197:INFO:Initializing Huber Regressor
2023-02-15 11:37:11,197:INFO:Total runtime is 0.10011154413223267 minutes
2023-02-15 11:37:11,200:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:11,201:INFO:Initializing create_model()
2023-02-15 11:37:11,201:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:11,201:INFO:Checking exceptions
2023-02-15 11:37:11,201:INFO:Importing libraries
2023-02-15 11:37:11,201:INFO:Copying training dataset
2023-02-15 11:37:11,201:INFO:Defining folds
2023-02-15 11:37:11,201:INFO:Declaring metric variables
2023-02-15 11:37:11,204:INFO:Importing untrained model
2023-02-15 11:37:11,208:INFO:Huber Regressor Imported succesfully
2023-02-15 11:37:11,215:INFO:Starting cross validation
2023-02-15 11:37:11,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:27,131:INFO:Calculating mean and std
2023-02-15 11:37:27,132:INFO:Creating metrics dataframe
2023-02-15 11:37:27,135:INFO:Uploading results into container
2023-02-15 11:37:27,135:INFO:Uploading model into container now
2023-02-15 11:37:27,135:INFO:create_model_container: 9
2023-02-15 11:37:27,135:INFO:master_model_container: 9
2023-02-15 11:37:27,135:INFO:display_container: 2
2023-02-15 11:37:27,135:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-15 11:37:27,135:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:27,258:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:27,258:INFO:Creating metrics dataframe
2023-02-15 11:37:27,265:INFO:Initializing K Neighbors Regressor
2023-02-15 11:37:27,265:INFO:Total runtime is 0.36792141596476235 minutes
2023-02-15 11:37:27,270:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:27,270:INFO:Initializing create_model()
2023-02-15 11:37:27,270:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:27,270:INFO:Checking exceptions
2023-02-15 11:37:27,270:INFO:Importing libraries
2023-02-15 11:37:27,270:INFO:Copying training dataset
2023-02-15 11:37:27,271:INFO:Defining folds
2023-02-15 11:37:27,271:INFO:Declaring metric variables
2023-02-15 11:37:27,276:INFO:Importing untrained model
2023-02-15 11:37:27,279:INFO:K Neighbors Regressor Imported succesfully
2023-02-15 11:37:27,285:INFO:Starting cross validation
2023-02-15 11:37:27,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:32,688:INFO:Calculating mean and std
2023-02-15 11:37:32,689:INFO:Creating metrics dataframe
2023-02-15 11:37:32,692:INFO:Uploading results into container
2023-02-15 11:37:32,692:INFO:Uploading model into container now
2023-02-15 11:37:32,692:INFO:create_model_container: 10
2023-02-15 11:37:32,692:INFO:master_model_container: 10
2023-02-15 11:37:32,692:INFO:display_container: 2
2023-02-15 11:37:32,692:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-15 11:37:32,692:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:32,812:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:32,812:INFO:Creating metrics dataframe
2023-02-15 11:37:32,819:INFO:Initializing Decision Tree Regressor
2023-02-15 11:37:32,820:INFO:Total runtime is 0.4604914546012878 minutes
2023-02-15 11:37:32,823:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:32,823:INFO:Initializing create_model()
2023-02-15 11:37:32,824:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:32,824:INFO:Checking exceptions
2023-02-15 11:37:32,824:INFO:Importing libraries
2023-02-15 11:37:32,824:INFO:Copying training dataset
2023-02-15 11:37:32,824:INFO:Defining folds
2023-02-15 11:37:32,824:INFO:Declaring metric variables
2023-02-15 11:37:32,828:INFO:Importing untrained model
2023-02-15 11:37:32,831:INFO:Decision Tree Regressor Imported succesfully
2023-02-15 11:37:32,837:INFO:Starting cross validation
2023-02-15 11:37:32,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:37:54,921:INFO:Calculating mean and std
2023-02-15 11:37:54,922:INFO:Creating metrics dataframe
2023-02-15 11:37:54,924:INFO:Uploading results into container
2023-02-15 11:37:54,924:INFO:Uploading model into container now
2023-02-15 11:37:54,924:INFO:create_model_container: 11
2023-02-15 11:37:54,924:INFO:master_model_container: 11
2023-02-15 11:37:54,924:INFO:display_container: 2
2023-02-15 11:37:54,924:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-15 11:37:54,924:INFO:create_model() succesfully completed......................................
2023-02-15 11:37:55,019:INFO:SubProcess create_model() end ==================================
2023-02-15 11:37:55,020:INFO:Creating metrics dataframe
2023-02-15 11:37:55,031:INFO:Initializing Random Forest Regressor
2023-02-15 11:37:55,031:INFO:Total runtime is 0.8306833108266194 minutes
2023-02-15 11:37:55,035:INFO:SubProcess create_model() called ==================================
2023-02-15 11:37:55,035:INFO:Initializing create_model()
2023-02-15 11:37:55,035:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:37:55,035:INFO:Checking exceptions
2023-02-15 11:37:55,035:INFO:Importing libraries
2023-02-15 11:37:55,035:INFO:Copying training dataset
2023-02-15 11:37:55,036:INFO:Defining folds
2023-02-15 11:37:55,036:INFO:Declaring metric variables
2023-02-15 11:37:55,039:INFO:Importing untrained model
2023-02-15 11:37:55,043:INFO:Random Forest Regressor Imported succesfully
2023-02-15 11:37:55,049:INFO:Starting cross validation
2023-02-15 11:37:55,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:39:21,423:INFO:Calculating mean and std
2023-02-15 11:39:21,423:INFO:Creating metrics dataframe
2023-02-15 11:39:21,427:INFO:Uploading results into container
2023-02-15 11:39:21,427:INFO:Uploading model into container now
2023-02-15 11:39:21,427:INFO:create_model_container: 12
2023-02-15 11:39:21,427:INFO:master_model_container: 12
2023-02-15 11:39:21,427:INFO:display_container: 2
2023-02-15 11:39:21,428:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-15 11:39:21,428:INFO:create_model() succesfully completed......................................
2023-02-15 11:39:21,541:INFO:SubProcess create_model() end ==================================
2023-02-15 11:39:21,542:INFO:Creating metrics dataframe
2023-02-15 11:39:21,549:INFO:Initializing Extra Trees Regressor
2023-02-15 11:39:21,549:INFO:Total runtime is 2.2726488073666893 minutes
2023-02-15 11:39:21,553:INFO:SubProcess create_model() called ==================================
2023-02-15 11:39:21,553:INFO:Initializing create_model()
2023-02-15 11:39:21,553:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:39:21,553:INFO:Checking exceptions
2023-02-15 11:39:21,553:INFO:Importing libraries
2023-02-15 11:39:21,553:INFO:Copying training dataset
2023-02-15 11:39:21,554:INFO:Defining folds
2023-02-15 11:39:21,554:INFO:Declaring metric variables
2023-02-15 11:39:21,557:INFO:Importing untrained model
2023-02-15 11:39:21,560:INFO:Extra Trees Regressor Imported succesfully
2023-02-15 11:39:21,566:INFO:Starting cross validation
2023-02-15 11:39:21,567:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:39:47,338:INFO:Calculating mean and std
2023-02-15 11:39:47,338:INFO:Creating metrics dataframe
2023-02-15 11:39:47,341:INFO:Uploading results into container
2023-02-15 11:39:47,341:INFO:Uploading model into container now
2023-02-15 11:39:47,341:INFO:create_model_container: 13
2023-02-15 11:39:47,341:INFO:master_model_container: 13
2023-02-15 11:39:47,341:INFO:display_container: 2
2023-02-15 11:39:47,341:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-15 11:39:47,341:INFO:create_model() succesfully completed......................................
2023-02-15 11:39:47,455:INFO:SubProcess create_model() end ==================================
2023-02-15 11:39:47,455:INFO:Creating metrics dataframe
2023-02-15 11:39:47,465:INFO:Initializing AdaBoost Regressor
2023-02-15 11:39:47,466:INFO:Total runtime is 2.7045902927716576 minutes
2023-02-15 11:39:47,469:INFO:SubProcess create_model() called ==================================
2023-02-15 11:39:47,469:INFO:Initializing create_model()
2023-02-15 11:39:47,469:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:39:47,469:INFO:Checking exceptions
2023-02-15 11:39:47,469:INFO:Importing libraries
2023-02-15 11:39:47,469:INFO:Copying training dataset
2023-02-15 11:39:47,470:INFO:Defining folds
2023-02-15 11:39:47,470:INFO:Declaring metric variables
2023-02-15 11:39:47,473:INFO:Importing untrained model
2023-02-15 11:39:47,476:INFO:AdaBoost Regressor Imported succesfully
2023-02-15 11:39:47,482:INFO:Starting cross validation
2023-02-15 11:39:47,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:41:00,228:INFO:Calculating mean and std
2023-02-15 11:41:00,229:INFO:Creating metrics dataframe
2023-02-15 11:41:00,231:INFO:Uploading results into container
2023-02-15 11:41:00,231:INFO:Uploading model into container now
2023-02-15 11:41:00,231:INFO:create_model_container: 14
2023-02-15 11:41:00,231:INFO:master_model_container: 14
2023-02-15 11:41:00,231:INFO:display_container: 2
2023-02-15 11:41:00,231:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-15 11:41:00,231:INFO:create_model() succesfully completed......................................
2023-02-15 11:41:00,334:INFO:SubProcess create_model() end ==================================
2023-02-15 11:41:00,334:INFO:Creating metrics dataframe
2023-02-15 11:41:00,341:INFO:Initializing Gradient Boosting Regressor
2023-02-15 11:41:00,341:INFO:Total runtime is 3.919187351067861 minutes
2023-02-15 11:41:00,345:INFO:SubProcess create_model() called ==================================
2023-02-15 11:41:00,345:INFO:Initializing create_model()
2023-02-15 11:41:00,345:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:41:00,345:INFO:Checking exceptions
2023-02-15 11:41:00,345:INFO:Importing libraries
2023-02-15 11:41:00,345:INFO:Copying training dataset
2023-02-15 11:41:00,346:INFO:Defining folds
2023-02-15 11:41:00,346:INFO:Declaring metric variables
2023-02-15 11:41:00,349:INFO:Importing untrained model
2023-02-15 11:41:00,353:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-15 11:41:00,361:INFO:Starting cross validation
2023-02-15 11:41:00,362:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:34,550:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:42:34,551:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 531, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 118, in fit
    result = super().fit(X, y=y, **fit_kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/imblearn/pipeline.py", line 281, in fit
    self._final_estimator.fit(Xt, yt, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_gb.py", line 498, in fit
    n_stages = self._fit_stages(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_gb.py", line 555, in _fit_stages
    raw_predictions = self._fit_stage(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/ensemble/_gb.py", line 211, in _fit_stage
    tree.fit(X, residual, sample_weight=sample_weight,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 1242, in fit
    super().fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 375, in fit
    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)
KeyboardInterrupt

2023-02-15 11:42:34,552:INFO:Initializing create_model()
2023-02-15 11:42:34,552:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fb830d58f40>, return_train_score=False, kwargs={})
2023-02-15 11:42:34,552:INFO:Checking exceptions
2023-02-15 11:42:34,552:INFO:Importing libraries
2023-02-15 11:42:34,552:INFO:Copying training dataset
2023-02-15 11:42:34,553:INFO:Defining folds
2023-02-15 11:42:34,554:INFO:Declaring metric variables
2023-02-15 11:42:34,560:INFO:Importing untrained model
2023-02-15 11:42:34,566:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-15 11:42:34,575:INFO:Starting cross validation
2023-02-15 11:42:34,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:48,989:INFO:PyCaret Supervised Module
2023-02-15 11:42:48,990:INFO:ML Usecase: regression
2023-02-15 11:42:48,990:INFO:version 2.3.10
2023-02-15 11:42:48,990:INFO:Initializing setup()
2023-02-15 11:42:48,990:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-15 11:42:48,990:INFO:Checking environment
2023-02-15 11:42:48,990:INFO:python_version: 3.9.16
2023-02-15 11:42:48,990:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-15 11:42:48,990:INFO:machine: x86_64
2023-02-15 11:42:48,990:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-15 11:42:48,990:INFO:Memory: svmem(total=134979592192, available=123217448960, percent=8.7, used=10101399552, free=103046733824, active=3808219136, inactive=25598185472, buffers=1423925248, cached=20407533568, shared=398385152, slab=1948684288)
2023-02-15 11:42:48,990:INFO:Physical Core: 16
2023-02-15 11:42:48,991:INFO:Logical Core: 32
2023-02-15 11:42:48,991:INFO:Checking libraries
2023-02-15 11:42:48,991:INFO:pd==1.5.2
2023-02-15 11:42:48,991:INFO:numpy==1.20.3
2023-02-15 11:42:48,991:INFO:sklearn==0.23.2
2023-02-15 11:42:48,991:INFO:lightgbm==3.3.5.99
2023-02-15 11:42:49,007:INFO:catboost==1.1.1
2023-02-15 11:42:49,007:INFO:xgboost==1.7.3
2023-02-15 11:42:49,007:INFO:mlflow==2.1.1
2023-02-15 11:42:49,007:INFO:Checking Exceptions
2023-02-15 11:42:49,007:INFO:Declaring global variables
2023-02-15 11:42:49,007:INFO:USI: cb3f
2023-02-15 11:42:49,007:INFO:pycaret_globals: {'X_train', 'y_test', 'fold_shuffle_param', 'html_param', 'experiment__', 'imputation_classifier', '_all_models_internal', 'USI', 'display_container', 'logging_param', 'transform_target_method_param', 'n_jobs_param', 'log_plots_param', 'pycaret_globals', 'X', 'gpu_param', 'fold_groups_param', 'y', 'stratify_param', 'transform_target_param', 'X_test', '_all_models', '_ml_usecase', 'exp_name_log', 'fix_imbalance_param', '_all_metrics', 'iterative_imputation_iters_param', 'imputation_regressor', 'data_before_preprocess', 'seed', 'dashboard_logger', '_available_plots', 'master_model_container', 'create_model_container', 'y_train', 'fold_param', 'fix_imbalance_method_param', '_gpu_n_jobs_param', 'fold_groups_param_full', 'target_param', 'prep_pipe', 'fold_generator', '_internal_pipeline'}
2023-02-15 11:42:49,007:INFO:Preparing display monitor
2023-02-15 11:42:49,007:INFO:Preparing display monitor
2023-02-15 11:42:49,013:INFO:Importing libraries
2023-02-15 11:42:49,013:INFO:Copying data for preprocessing
2023-02-15 11:42:49,022:INFO:Declaring preprocessing parameters
2023-02-15 11:42:49,022:WARNING:cuML not found
2023-02-15 11:42:49,022:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-15 11:42:49,032:INFO:Creating preprocessing pipeline
2023-02-15 11:42:49,251:INFO:Preprocessing pipeline created successfully
2023-02-15 11:42:49,251:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-15 11:42:49,251:INFO:Creating global containers
2023-02-15 11:42:49,252:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-15 11:42:50,753:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:42:50,753:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:42:50,756:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:42:50,759:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:42:50,791:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:42:50,818:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:42:50,818:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:42:50,877:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:42:50,877:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:42:50,882:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:42:50,887:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:42:50,942:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:42:50,988:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:42:50,988:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:42:50,994:INFO:Creating grid variables
2023-02-15 11:42:51,014:INFO:create_model_container: 0
2023-02-15 11:42:51,014:INFO:master_model_container: 0
2023-02-15 11:42:51,014:INFO:display_container: 1
2023-02-15 11:42:51,017:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('P_transform', 'passthrough'), ('binn', 'passthrough'),
                ('rem_outliers', 'passthrough'), ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-15 11:42:51,017:INFO:setup() succesfully completed......................................
2023-02-15 11:42:51,146:INFO:Initializing compare_models()
2023-02-15 11:42:51,146:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=['tr'])
2023-02-15 11:42:51,146:INFO:Checking exceptions
2023-02-15 11:42:51,146:INFO:Preparing display monitor
2023-02-15 11:42:51,146:INFO:Preparing display monitor
2023-02-15 11:42:51,157:INFO:Initializing Linear Regression
2023-02-15 11:42:51,158:INFO:Total runtime is 1.633167266845703e-06 minutes
2023-02-15 11:42:51,161:INFO:SubProcess create_model() called ==================================
2023-02-15 11:42:51,161:INFO:Initializing create_model()
2023-02-15 11:42:51,161:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:51,161:INFO:Checking exceptions
2023-02-15 11:42:51,161:INFO:Importing libraries
2023-02-15 11:42:51,161:INFO:Copying training dataset
2023-02-15 11:42:51,162:INFO:Defining folds
2023-02-15 11:42:51,162:INFO:Declaring metric variables
2023-02-15 11:42:51,166:INFO:Importing untrained model
2023-02-15 11:42:51,169:INFO:Linear Regression Imported succesfully
2023-02-15 11:42:51,176:INFO:Starting cross validation
2023-02-15 11:42:51,177:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:52,059:INFO:Calculating mean and std
2023-02-15 11:42:52,061:INFO:Creating metrics dataframe
2023-02-15 11:42:52,073:INFO:Uploading results into container
2023-02-15 11:42:52,073:INFO:Uploading model into container now
2023-02-15 11:42:52,073:INFO:create_model_container: 1
2023-02-15 11:42:52,073:INFO:master_model_container: 1
2023-02-15 11:42:52,073:INFO:display_container: 2
2023-02-15 11:42:52,073:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-15 11:42:52,073:INFO:create_model() succesfully completed......................................
2023-02-15 11:42:52,204:INFO:SubProcess create_model() end ==================================
2023-02-15 11:42:52,204:INFO:Creating metrics dataframe
2023-02-15 11:42:52,210:INFO:Initializing Lasso Regression
2023-02-15 11:42:52,210:INFO:Total runtime is 0.017543192704518637 minutes
2023-02-15 11:42:52,214:INFO:SubProcess create_model() called ==================================
2023-02-15 11:42:52,214:INFO:Initializing create_model()
2023-02-15 11:42:52,214:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:52,214:INFO:Checking exceptions
2023-02-15 11:42:52,214:INFO:Importing libraries
2023-02-15 11:42:52,214:INFO:Copying training dataset
2023-02-15 11:42:52,215:INFO:Defining folds
2023-02-15 11:42:52,215:INFO:Declaring metric variables
2023-02-15 11:42:52,218:INFO:Importing untrained model
2023-02-15 11:42:52,223:INFO:Lasso Regression Imported succesfully
2023-02-15 11:42:52,231:INFO:Starting cross validation
2023-02-15 11:42:52,231:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:52,512:INFO:Calculating mean and std
2023-02-15 11:42:52,525:INFO:Creating metrics dataframe
2023-02-15 11:42:52,534:INFO:Uploading results into container
2023-02-15 11:42:52,535:INFO:Uploading model into container now
2023-02-15 11:42:52,535:INFO:create_model_container: 2
2023-02-15 11:42:52,535:INFO:master_model_container: 2
2023-02-15 11:42:52,535:INFO:display_container: 2
2023-02-15 11:42:52,536:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:42:52,536:INFO:create_model() succesfully completed......................................
2023-02-15 11:42:52,665:INFO:SubProcess create_model() end ==================================
2023-02-15 11:42:52,665:INFO:Creating metrics dataframe
2023-02-15 11:42:52,671:INFO:Initializing Ridge Regression
2023-02-15 11:42:52,671:INFO:Total runtime is 0.025219357013702395 minutes
2023-02-15 11:42:52,674:INFO:SubProcess create_model() called ==================================
2023-02-15 11:42:52,674:INFO:Initializing create_model()
2023-02-15 11:42:52,674:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:52,674:INFO:Checking exceptions
2023-02-15 11:42:52,675:INFO:Importing libraries
2023-02-15 11:42:52,675:INFO:Copying training dataset
2023-02-15 11:42:52,675:INFO:Defining folds
2023-02-15 11:42:52,675:INFO:Declaring metric variables
2023-02-15 11:42:52,678:INFO:Importing untrained model
2023-02-15 11:42:52,681:INFO:Ridge Regression Imported succesfully
2023-02-15 11:42:52,687:INFO:Starting cross validation
2023-02-15 11:42:52,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:52,991:INFO:Calculating mean and std
2023-02-15 11:42:52,991:INFO:Creating metrics dataframe
2023-02-15 11:42:52,996:INFO:Uploading results into container
2023-02-15 11:42:52,999:INFO:Uploading model into container now
2023-02-15 11:42:52,999:INFO:create_model_container: 3
2023-02-15 11:42:52,999:INFO:master_model_container: 3
2023-02-15 11:42:52,999:INFO:display_container: 2
2023-02-15 11:42:53,000:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-15 11:42:53,000:INFO:create_model() succesfully completed......................................
2023-02-15 11:42:53,142:INFO:SubProcess create_model() end ==================================
2023-02-15 11:42:53,142:INFO:Creating metrics dataframe
2023-02-15 11:42:53,148:INFO:Initializing Elastic Net
2023-02-15 11:42:53,148:INFO:Total runtime is 0.033178822199503584 minutes
2023-02-15 11:42:53,152:INFO:SubProcess create_model() called ==================================
2023-02-15 11:42:53,152:INFO:Initializing create_model()
2023-02-15 11:42:53,152:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:53,152:INFO:Checking exceptions
2023-02-15 11:42:53,152:INFO:Importing libraries
2023-02-15 11:42:53,152:INFO:Copying training dataset
2023-02-15 11:42:53,153:INFO:Defining folds
2023-02-15 11:42:53,153:INFO:Declaring metric variables
2023-02-15 11:42:53,155:INFO:Importing untrained model
2023-02-15 11:42:53,159:INFO:Elastic Net Imported succesfully
2023-02-15 11:42:53,165:INFO:Starting cross validation
2023-02-15 11:42:53,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:53,437:INFO:Calculating mean and std
2023-02-15 11:42:53,440:INFO:Creating metrics dataframe
2023-02-15 11:42:53,446:INFO:Uploading results into container
2023-02-15 11:42:53,446:INFO:Uploading model into container now
2023-02-15 11:42:53,446:INFO:create_model_container: 4
2023-02-15 11:42:53,446:INFO:master_model_container: 4
2023-02-15 11:42:53,446:INFO:display_container: 2
2023-02-15 11:42:53,446:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:42:53,446:INFO:create_model() succesfully completed......................................
2023-02-15 11:42:53,574:INFO:SubProcess create_model() end ==================================
2023-02-15 11:42:53,574:INFO:Creating metrics dataframe
2023-02-15 11:42:53,580:INFO:Initializing Least Angle Regression
2023-02-15 11:42:53,580:INFO:Total runtime is 0.04038203954696656 minutes
2023-02-15 11:42:53,584:INFO:SubProcess create_model() called ==================================
2023-02-15 11:42:53,584:INFO:Initializing create_model()
2023-02-15 11:42:53,584:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:53,584:INFO:Checking exceptions
2023-02-15 11:42:53,584:INFO:Importing libraries
2023-02-15 11:42:53,584:INFO:Copying training dataset
2023-02-15 11:42:53,585:INFO:Defining folds
2023-02-15 11:42:53,585:INFO:Declaring metric variables
2023-02-15 11:42:53,588:INFO:Importing untrained model
2023-02-15 11:42:53,591:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:42:53,598:INFO:Starting cross validation
2023-02-15 11:42:53,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:53,954:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:42:53,956:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:42:53,956:INFO:Initializing create_model()
2023-02-15 11:42:53,957:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:53,957:INFO:Checking exceptions
2023-02-15 11:42:53,957:INFO:Importing libraries
2023-02-15 11:42:53,957:INFO:Copying training dataset
2023-02-15 11:42:53,958:INFO:Defining folds
2023-02-15 11:42:53,961:INFO:Declaring metric variables
2023-02-15 11:42:53,966:INFO:Importing untrained model
2023-02-15 11:42:53,972:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:42:53,982:INFO:Starting cross validation
2023-02-15 11:42:53,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:54,312:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-02-15 11:42:54,313:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:42:54,313:INFO:Initializing Lasso Least Angle Regression
2023-02-15 11:42:54,313:INFO:Total runtime is 0.05258631706237793 minutes
2023-02-15 11:42:54,317:INFO:SubProcess create_model() called ==================================
2023-02-15 11:42:54,318:INFO:Initializing create_model()
2023-02-15 11:42:54,318:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:54,318:INFO:Checking exceptions
2023-02-15 11:42:54,318:INFO:Importing libraries
2023-02-15 11:42:54,318:INFO:Copying training dataset
2023-02-15 11:42:54,319:INFO:Defining folds
2023-02-15 11:42:54,319:INFO:Declaring metric variables
2023-02-15 11:42:54,323:INFO:Importing untrained model
2023-02-15 11:42:54,327:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-15 11:42:54,336:INFO:Starting cross validation
2023-02-15 11:42:54,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:54,483:INFO:Calculating mean and std
2023-02-15 11:42:54,484:INFO:Creating metrics dataframe
2023-02-15 11:42:54,487:INFO:Uploading results into container
2023-02-15 11:42:54,487:INFO:Uploading model into container now
2023-02-15 11:42:54,487:INFO:create_model_container: 5
2023-02-15 11:42:54,487:INFO:master_model_container: 5
2023-02-15 11:42:54,487:INFO:display_container: 2
2023-02-15 11:42:54,488:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-15 11:42:54,488:INFO:create_model() succesfully completed......................................
2023-02-15 11:42:54,610:INFO:SubProcess create_model() end ==================================
2023-02-15 11:42:54,611:INFO:Creating metrics dataframe
2023-02-15 11:42:54,619:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 11:42:54,620:INFO:Total runtime is 0.057701075077056886 minutes
2023-02-15 11:42:54,623:INFO:SubProcess create_model() called ==================================
2023-02-15 11:42:54,623:INFO:Initializing create_model()
2023-02-15 11:42:54,623:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:54,623:INFO:Checking exceptions
2023-02-15 11:42:54,623:INFO:Importing libraries
2023-02-15 11:42:54,623:INFO:Copying training dataset
2023-02-15 11:42:54,624:INFO:Defining folds
2023-02-15 11:42:54,624:INFO:Declaring metric variables
2023-02-15 11:42:54,627:INFO:Importing untrained model
2023-02-15 11:42:54,630:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-15 11:42:54,636:INFO:Starting cross validation
2023-02-15 11:42:54,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:54,781:INFO:Calculating mean and std
2023-02-15 11:42:54,782:INFO:Creating metrics dataframe
2023-02-15 11:42:54,785:INFO:Uploading results into container
2023-02-15 11:42:54,785:INFO:Uploading model into container now
2023-02-15 11:42:54,785:INFO:create_model_container: 6
2023-02-15 11:42:54,785:INFO:master_model_container: 6
2023-02-15 11:42:54,785:INFO:display_container: 2
2023-02-15 11:42:54,785:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-15 11:42:54,785:INFO:create_model() succesfully completed......................................
2023-02-15 11:42:54,901:INFO:SubProcess create_model() end ==================================
2023-02-15 11:42:54,901:INFO:Creating metrics dataframe
2023-02-15 11:42:54,907:INFO:Initializing Bayesian Ridge
2023-02-15 11:42:54,907:INFO:Total runtime is 0.062499197324117024 minutes
2023-02-15 11:42:54,911:INFO:SubProcess create_model() called ==================================
2023-02-15 11:42:54,911:INFO:Initializing create_model()
2023-02-15 11:42:54,911:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:54,911:INFO:Checking exceptions
2023-02-15 11:42:54,911:INFO:Importing libraries
2023-02-15 11:42:54,911:INFO:Copying training dataset
2023-02-15 11:42:54,912:INFO:Defining folds
2023-02-15 11:42:54,912:INFO:Declaring metric variables
2023-02-15 11:42:54,915:INFO:Importing untrained model
2023-02-15 11:42:54,919:INFO:Bayesian Ridge Imported succesfully
2023-02-15 11:42:54,925:INFO:Starting cross validation
2023-02-15 11:42:54,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:56,411:INFO:Calculating mean and std
2023-02-15 11:42:56,414:INFO:Creating metrics dataframe
2023-02-15 11:42:56,421:INFO:Uploading results into container
2023-02-15 11:42:56,421:INFO:Uploading model into container now
2023-02-15 11:42:56,421:INFO:create_model_container: 7
2023-02-15 11:42:56,421:INFO:master_model_container: 7
2023-02-15 11:42:56,421:INFO:display_container: 2
2023-02-15 11:42:56,421:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-15 11:42:56,421:INFO:create_model() succesfully completed......................................
2023-02-15 11:42:56,555:INFO:SubProcess create_model() end ==================================
2023-02-15 11:42:56,555:INFO:Creating metrics dataframe
2023-02-15 11:42:56,561:INFO:Initializing Passive Aggressive Regressor
2023-02-15 11:42:56,562:INFO:Total runtime is 0.09006860653559368 minutes
2023-02-15 11:42:56,566:INFO:SubProcess create_model() called ==================================
2023-02-15 11:42:56,566:INFO:Initializing create_model()
2023-02-15 11:42:56,566:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:56,566:INFO:Checking exceptions
2023-02-15 11:42:56,566:INFO:Importing libraries
2023-02-15 11:42:56,566:INFO:Copying training dataset
2023-02-15 11:42:56,567:INFO:Defining folds
2023-02-15 11:42:56,567:INFO:Declaring metric variables
2023-02-15 11:42:56,571:INFO:Importing untrained model
2023-02-15 11:42:56,575:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-15 11:42:56,581:INFO:Starting cross validation
2023-02-15 11:42:56,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:42:56,922:INFO:Calculating mean and std
2023-02-15 11:42:56,923:INFO:Creating metrics dataframe
2023-02-15 11:42:56,926:INFO:Uploading results into container
2023-02-15 11:42:56,926:INFO:Uploading model into container now
2023-02-15 11:42:56,926:INFO:create_model_container: 8
2023-02-15 11:42:56,926:INFO:master_model_container: 8
2023-02-15 11:42:56,926:INFO:display_container: 2
2023-02-15 11:42:56,926:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-15 11:42:56,926:INFO:create_model() succesfully completed......................................
2023-02-15 11:42:57,045:INFO:SubProcess create_model() end ==================================
2023-02-15 11:42:57,045:INFO:Creating metrics dataframe
2023-02-15 11:42:57,052:INFO:Initializing Huber Regressor
2023-02-15 11:42:57,052:INFO:Total runtime is 0.09823612372080485 minutes
2023-02-15 11:42:57,055:INFO:SubProcess create_model() called ==================================
2023-02-15 11:42:57,055:INFO:Initializing create_model()
2023-02-15 11:42:57,055:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:42:57,055:INFO:Checking exceptions
2023-02-15 11:42:57,055:INFO:Importing libraries
2023-02-15 11:42:57,055:INFO:Copying training dataset
2023-02-15 11:42:57,056:INFO:Defining folds
2023-02-15 11:42:57,056:INFO:Declaring metric variables
2023-02-15 11:42:57,059:INFO:Importing untrained model
2023-02-15 11:42:57,062:INFO:Huber Regressor Imported succesfully
2023-02-15 11:42:57,068:INFO:Starting cross validation
2023-02-15 11:42:57,068:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:43:09,030:WARNING:create_model() for huber raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:43:09,034:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 531, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 118, in fit
    result = super().fit(X, y=y, **fit_kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/imblearn/pipeline.py", line 281, in fit
    self._final_estimator.fit(Xt, yt, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/linear_model/_huber.py", line 284, in fit
    opt_res = optimize.minimize(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/_minimize.py", line 617, in minimize
    return _minimize_lbfgsb(fun, x0, args, jac, bounds,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py", line 360, in _minimize_lbfgsb
    f, g = func_and_grad(x)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py", line 200, in fun_and_grad
    self._update_fun()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py", line 166, in _update_fun
    self._update_fun_impl()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py", line 73, in update_fun
    self.f = fun_wrapped(self.x)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py", line 70, in fun_wrapped
    return fun(x, *args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/optimize.py", line 74, in __call__
    self._compute_if_needed(x, *args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/optimize.py", line 68, in _compute_if_needed
    fg = self.fun(x, *args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/linear_model/_huber.py", line 62, in _huber_loss_and_gradient
    linear_loss = y - safe_sparse_dot(X, w)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/extmath.py", line 153, in safe_sparse_dot
    ret = a @ b
KeyboardInterrupt

2023-02-15 11:43:09,034:INFO:Initializing create_model()
2023-02-15 11:43:09,034:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:43:09,034:INFO:Checking exceptions
2023-02-15 11:43:09,034:INFO:Importing libraries
2023-02-15 11:43:09,034:INFO:Copying training dataset
2023-02-15 11:43:09,035:INFO:Defining folds
2023-02-15 11:43:09,035:INFO:Declaring metric variables
2023-02-15 11:43:09,040:INFO:Importing untrained model
2023-02-15 11:43:09,043:ERROR:create_model() for huber raised an exception or returned all 0.0:
2023-02-15 11:43:09,059:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 531, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 118, in fit
    result = super().fit(X, y=y, **fit_kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/imblearn/pipeline.py", line 281, in fit
    self._final_estimator.fit(Xt, yt, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/linear_model/_huber.py", line 284, in fit
    opt_res = optimize.minimize(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/_minimize.py", line 617, in minimize
    return _minimize_lbfgsb(fun, x0, args, jac, bounds,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py", line 360, in _minimize_lbfgsb
    f, g = func_and_grad(x)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py", line 200, in fun_and_grad
    self._update_fun()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py", line 166, in _update_fun
    self._update_fun_impl()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py", line 73, in update_fun
    self.f = fun_wrapped(self.x)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py", line 70, in fun_wrapped
    return fun(x, *args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/optimize.py", line 74, in __call__
    self._compute_if_needed(x, *args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/scipy/optimize/optimize.py", line 68, in _compute_if_needed
    fg = self.fun(x, *args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/linear_model/_huber.py", line 62, in _huber_loss_and_gradient
    linear_loss = y - safe_sparse_dot(X, w)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/extmath.py", line 153, in safe_sparse_dot
    ret = a @ b
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3090, in create_model_supervised
    display.update_monitor(2, full_name)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/Display.py", line 90, in update_monitor
    self.display_monitor()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/Display.py", line 66, in display_monitor
    self._update_display(self.monitor, display_id=self.monitor_id)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/Display.py", line 137, in _update_display
    return update_display(df, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/IPython/core/display.py", line 350, in update_display
    display(obj, display_id=display_id, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/IPython/core/display.py", line 327, in display
    publish_display_data(data=format_dict, metadata=md_dict, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/IPython/core/display.py", line 119, in publish_display_data
    display_pub.publish(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/ipykernel/zmqshell.py", line 129, in publish
    self.session.send(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/jupyter_client/session.py", line 859, in send
    stream.send_multipart(to_send, copy=copy)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/ipykernel/iostream.py", line 286, in send_multipart
    return self.io_thread.send_multipart(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/ipykernel/iostream.py", line 219, in send_multipart
    self.schedule(lambda: self._really_send(*args, **kwargs))
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/ipykernel/iostream.py", line 210, in schedule
    self._event_pipe.send(b"")
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/zmq/sugar/socket.py", line 618, in send
    return super().send(data, flags=flags, copy=copy, track=track)
  File "zmq/backend/cython/socket.pyx", line 740, in zmq.backend.cython.socket.Socket.send
  File "zmq/backend/cython/socket.pyx", line 787, in zmq.backend.cython.socket.Socket.send
  File "zmq/backend/cython/socket.pyx", line 244, in zmq.backend.cython.socket._send_copy
  File "zmq/backend/cython/checkrc.pxd", line 13, in zmq.backend.cython.checkrc._check_rc
KeyboardInterrupt

2023-02-15 11:43:09,059:INFO:Initializing K Neighbors Regressor
2023-02-15 11:43:09,059:INFO:Total runtime is 0.29835737943649293 minutes
2023-02-15 11:43:09,064:INFO:SubProcess create_model() called ==================================
2023-02-15 11:43:09,065:INFO:Initializing create_model()
2023-02-15 11:43:09,065:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7fa010953dc0>, return_train_score=False, kwargs={})
2023-02-15 11:43:09,065:INFO:Checking exceptions
2023-02-15 11:43:09,065:INFO:Importing libraries
2023-02-15 11:43:09,065:INFO:Copying training dataset
2023-02-15 11:43:09,066:INFO:Defining folds
2023-02-15 11:43:09,066:INFO:Declaring metric variables
2023-02-15 11:43:09,071:INFO:Importing untrained model
2023-02-15 11:43:09,076:INFO:K Neighbors Regressor Imported succesfully
2023-02-15 11:43:09,085:INFO:Starting cross validation
2023-02-15 11:43:09,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:43:55,410:INFO:PyCaret Supervised Module
2023-02-15 11:43:55,410:INFO:ML Usecase: regression
2023-02-15 11:43:55,410:INFO:version 2.3.10
2023-02-15 11:43:55,410:INFO:Initializing setup()
2023-02-15 11:43:55,410:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-15 11:43:55,410:INFO:Checking environment
2023-02-15 11:43:55,410:INFO:python_version: 3.9.16
2023-02-15 11:43:55,410:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-15 11:43:55,410:INFO:machine: x86_64
2023-02-15 11:43:55,410:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-15 11:43:55,410:INFO:Memory: svmem(total=134979592192, available=123056754688, percent=8.8, used=10213224448, free=102884765696, active=3809697792, inactive=25762455552, buffers=1424162816, cached=20457439232, shared=447254528, slab=1948692480)
2023-02-15 11:43:55,411:INFO:Physical Core: 16
2023-02-15 11:43:55,411:INFO:Logical Core: 32
2023-02-15 11:43:55,411:INFO:Checking libraries
2023-02-15 11:43:55,411:INFO:pd==1.5.2
2023-02-15 11:43:55,411:INFO:numpy==1.20.3
2023-02-15 11:43:55,411:INFO:sklearn==0.23.2
2023-02-15 11:43:55,411:INFO:lightgbm==3.3.5.99
2023-02-15 11:43:55,428:INFO:catboost==1.1.1
2023-02-15 11:43:55,428:INFO:xgboost==1.7.3
2023-02-15 11:43:55,428:INFO:mlflow==2.1.1
2023-02-15 11:43:55,428:INFO:Checking Exceptions
2023-02-15 11:43:55,428:INFO:Declaring global variables
2023-02-15 11:43:55,428:INFO:USI: 47c1
2023-02-15 11:43:55,428:INFO:pycaret_globals: {'fold_groups_param_full', 'y_test', 'fold_generator', '_available_plots', 'fold_shuffle_param', 'iterative_imputation_iters_param', 'fix_imbalance_method_param', '_all_models_internal', 'seed', '_internal_pipeline', 'create_model_container', '_all_metrics', 'USI', 'display_container', 'dashboard_logger', 'experiment__', '_ml_usecase', 'data_before_preprocess', 'log_plots_param', 'X_train', 'y_train', 'transform_target_param', 'pycaret_globals', 'target_param', '_gpu_n_jobs_param', 'html_param', 'y', 'imputation_regressor', 'logging_param', 'prep_pipe', 'transform_target_method_param', 'n_jobs_param', 'exp_name_log', 'imputation_classifier', 'stratify_param', 'fold_groups_param', 'gpu_param', '_all_models', 'X', 'master_model_container', 'fold_param', 'X_test', 'fix_imbalance_param'}
2023-02-15 11:43:55,428:INFO:Preparing display monitor
2023-02-15 11:43:55,428:INFO:Preparing display monitor
2023-02-15 11:43:55,434:INFO:Importing libraries
2023-02-15 11:43:55,434:INFO:Copying data for preprocessing
2023-02-15 11:43:55,443:INFO:Declaring preprocessing parameters
2023-02-15 11:43:55,444:WARNING:cuML not found
2023-02-15 11:43:55,444:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-15 11:43:55,455:INFO:Creating preprocessing pipeline
2023-02-15 11:43:55,685:INFO:Preprocessing pipeline created successfully
2023-02-15 11:43:55,685:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-15 11:43:55,685:INFO:Creating global containers
2023-02-15 11:43:55,686:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-15 11:43:57,224:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:43:57,224:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:43:57,227:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:43:57,230:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:43:57,264:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:43:57,291:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:43:57,292:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:43:57,318:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:43:57,318:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:43:57,323:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:43:57,327:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:43:57,384:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:43:57,430:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:43:57,430:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:43:57,436:INFO:Creating grid variables
2023-02-15 11:43:57,455:INFO:create_model_container: 0
2023-02-15 11:43:57,455:INFO:master_model_container: 0
2023-02-15 11:43:57,455:INFO:display_container: 1
2023-02-15 11:43:57,459:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('P_transform', 'passthrough'), ('binn', 'passthrough'),
                ('rem_outliers', 'passthrough'), ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-15 11:43:57,459:INFO:setup() succesfully completed......................................
2023-02-15 11:43:57,570:INFO:Initializing compare_models()
2023-02-15 11:43:57,570:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=['tr'])
2023-02-15 11:43:57,570:INFO:Checking exceptions
2023-02-15 11:43:57,570:INFO:Preparing display monitor
2023-02-15 11:43:57,570:INFO:Preparing display monitor
2023-02-15 11:43:57,582:INFO:Initializing Linear Regression
2023-02-15 11:43:57,582:INFO:Total runtime is 3.5842259724934896e-06 minutes
2023-02-15 11:43:57,586:INFO:SubProcess create_model() called ==================================
2023-02-15 11:43:57,586:INFO:Initializing create_model()
2023-02-15 11:43:57,586:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:43:57,586:INFO:Checking exceptions
2023-02-15 11:43:57,586:INFO:Importing libraries
2023-02-15 11:43:57,586:INFO:Copying training dataset
2023-02-15 11:43:57,587:INFO:Defining folds
2023-02-15 11:43:57,587:INFO:Declaring metric variables
2023-02-15 11:43:57,591:INFO:Importing untrained model
2023-02-15 11:43:57,596:INFO:Linear Regression Imported succesfully
2023-02-15 11:43:57,603:INFO:Starting cross validation
2023-02-15 11:43:57,604:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:43:58,455:INFO:Calculating mean and std
2023-02-15 11:43:58,455:INFO:Creating metrics dataframe
2023-02-15 11:43:58,464:INFO:Uploading results into container
2023-02-15 11:43:58,464:INFO:Uploading model into container now
2023-02-15 11:43:58,464:INFO:create_model_container: 1
2023-02-15 11:43:58,465:INFO:master_model_container: 1
2023-02-15 11:43:58,465:INFO:display_container: 2
2023-02-15 11:43:58,465:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-15 11:43:58,465:INFO:create_model() succesfully completed......................................
2023-02-15 11:43:58,604:INFO:SubProcess create_model() end ==================================
2023-02-15 11:43:58,605:INFO:Creating metrics dataframe
2023-02-15 11:43:58,610:INFO:Initializing Lasso Regression
2023-02-15 11:43:58,610:INFO:Total runtime is 0.017147743701934816 minutes
2023-02-15 11:43:58,614:INFO:SubProcess create_model() called ==================================
2023-02-15 11:43:58,614:INFO:Initializing create_model()
2023-02-15 11:43:58,614:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:43:58,614:INFO:Checking exceptions
2023-02-15 11:43:58,614:INFO:Importing libraries
2023-02-15 11:43:58,614:INFO:Copying training dataset
2023-02-15 11:43:58,615:INFO:Defining folds
2023-02-15 11:43:58,615:INFO:Declaring metric variables
2023-02-15 11:43:58,618:INFO:Importing untrained model
2023-02-15 11:43:58,621:INFO:Lasso Regression Imported succesfully
2023-02-15 11:43:58,627:INFO:Starting cross validation
2023-02-15 11:43:58,628:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:43:58,906:INFO:Calculating mean and std
2023-02-15 11:43:58,907:INFO:Creating metrics dataframe
2023-02-15 11:43:58,912:INFO:Uploading results into container
2023-02-15 11:43:58,915:INFO:Uploading model into container now
2023-02-15 11:43:58,915:INFO:create_model_container: 2
2023-02-15 11:43:58,915:INFO:master_model_container: 2
2023-02-15 11:43:58,915:INFO:display_container: 2
2023-02-15 11:43:58,915:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:43:58,915:INFO:create_model() succesfully completed......................................
2023-02-15 11:43:59,048:INFO:SubProcess create_model() end ==================================
2023-02-15 11:43:59,049:INFO:Creating metrics dataframe
2023-02-15 11:43:59,055:INFO:Initializing Ridge Regression
2023-02-15 11:43:59,055:INFO:Total runtime is 0.02455380360285441 minutes
2023-02-15 11:43:59,058:INFO:SubProcess create_model() called ==================================
2023-02-15 11:43:59,058:INFO:Initializing create_model()
2023-02-15 11:43:59,058:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:43:59,058:INFO:Checking exceptions
2023-02-15 11:43:59,059:INFO:Importing libraries
2023-02-15 11:43:59,059:INFO:Copying training dataset
2023-02-15 11:43:59,059:INFO:Defining folds
2023-02-15 11:43:59,059:INFO:Declaring metric variables
2023-02-15 11:43:59,062:INFO:Importing untrained model
2023-02-15 11:43:59,065:INFO:Ridge Regression Imported succesfully
2023-02-15 11:43:59,071:INFO:Starting cross validation
2023-02-15 11:43:59,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:43:59,415:INFO:Calculating mean and std
2023-02-15 11:43:59,418:INFO:Creating metrics dataframe
2023-02-15 11:43:59,425:INFO:Uploading results into container
2023-02-15 11:43:59,425:INFO:Uploading model into container now
2023-02-15 11:43:59,425:INFO:create_model_container: 3
2023-02-15 11:43:59,425:INFO:master_model_container: 3
2023-02-15 11:43:59,425:INFO:display_container: 2
2023-02-15 11:43:59,425:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-15 11:43:59,425:INFO:create_model() succesfully completed......................................
2023-02-15 11:43:59,570:INFO:SubProcess create_model() end ==================================
2023-02-15 11:43:59,570:INFO:Creating metrics dataframe
2023-02-15 11:43:59,577:INFO:Initializing Elastic Net
2023-02-15 11:43:59,577:INFO:Total runtime is 0.033251468340555826 minutes
2023-02-15 11:43:59,580:INFO:SubProcess create_model() called ==================================
2023-02-15 11:43:59,580:INFO:Initializing create_model()
2023-02-15 11:43:59,580:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:43:59,580:INFO:Checking exceptions
2023-02-15 11:43:59,581:INFO:Importing libraries
2023-02-15 11:43:59,581:INFO:Copying training dataset
2023-02-15 11:43:59,581:INFO:Defining folds
2023-02-15 11:43:59,581:INFO:Declaring metric variables
2023-02-15 11:43:59,584:INFO:Importing untrained model
2023-02-15 11:43:59,588:INFO:Elastic Net Imported succesfully
2023-02-15 11:43:59,594:INFO:Starting cross validation
2023-02-15 11:43:59,594:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:43:59,831:INFO:Calculating mean and std
2023-02-15 11:43:59,834:INFO:Creating metrics dataframe
2023-02-15 11:43:59,840:INFO:Uploading results into container
2023-02-15 11:43:59,840:INFO:Uploading model into container now
2023-02-15 11:43:59,840:INFO:create_model_container: 4
2023-02-15 11:43:59,840:INFO:master_model_container: 4
2023-02-15 11:43:59,841:INFO:display_container: 2
2023-02-15 11:43:59,841:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:43:59,841:INFO:create_model() succesfully completed......................................
2023-02-15 11:43:59,976:INFO:SubProcess create_model() end ==================================
2023-02-15 11:43:59,976:INFO:Creating metrics dataframe
2023-02-15 11:43:59,982:INFO:Initializing Least Angle Regression
2023-02-15 11:43:59,982:INFO:Total runtime is 0.04001420736312866 minutes
2023-02-15 11:43:59,986:INFO:SubProcess create_model() called ==================================
2023-02-15 11:43:59,986:INFO:Initializing create_model()
2023-02-15 11:43:59,986:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:43:59,986:INFO:Checking exceptions
2023-02-15 11:43:59,986:INFO:Importing libraries
2023-02-15 11:43:59,987:INFO:Copying training dataset
2023-02-15 11:43:59,987:INFO:Defining folds
2023-02-15 11:43:59,987:INFO:Declaring metric variables
2023-02-15 11:43:59,991:INFO:Importing untrained model
2023-02-15 11:43:59,994:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:44:00,000:INFO:Starting cross validation
2023-02-15 11:44:00,001:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:44:00,338:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:44:00,340:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:44:00,340:INFO:Initializing create_model()
2023-02-15 11:44:00,340:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:44:00,340:INFO:Checking exceptions
2023-02-15 11:44:00,340:INFO:Importing libraries
2023-02-15 11:44:00,340:INFO:Copying training dataset
2023-02-15 11:44:00,342:INFO:Defining folds
2023-02-15 11:44:00,342:INFO:Declaring metric variables
2023-02-15 11:44:00,348:INFO:Importing untrained model
2023-02-15 11:44:00,355:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:44:00,366:INFO:Starting cross validation
2023-02-15 11:44:00,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:44:00,725:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-02-15 11:44:00,726:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:44:00,726:INFO:Initializing Lasso Least Angle Regression
2023-02-15 11:44:00,726:INFO:Total runtime is 0.05240562359491984 minutes
2023-02-15 11:44:00,732:INFO:SubProcess create_model() called ==================================
2023-02-15 11:44:00,732:INFO:Initializing create_model()
2023-02-15 11:44:00,732:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:44:00,732:INFO:Checking exceptions
2023-02-15 11:44:00,732:INFO:Importing libraries
2023-02-15 11:44:00,732:INFO:Copying training dataset
2023-02-15 11:44:00,733:INFO:Defining folds
2023-02-15 11:44:00,733:INFO:Declaring metric variables
2023-02-15 11:44:00,738:INFO:Importing untrained model
2023-02-15 11:44:00,744:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-15 11:44:00,753:INFO:Starting cross validation
2023-02-15 11:44:00,754:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:44:00,917:INFO:Calculating mean and std
2023-02-15 11:44:00,918:INFO:Creating metrics dataframe
2023-02-15 11:44:00,921:INFO:Uploading results into container
2023-02-15 11:44:00,921:INFO:Uploading model into container now
2023-02-15 11:44:00,921:INFO:create_model_container: 5
2023-02-15 11:44:00,921:INFO:master_model_container: 5
2023-02-15 11:44:00,921:INFO:display_container: 2
2023-02-15 11:44:00,922:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-15 11:44:00,922:INFO:create_model() succesfully completed......................................
2023-02-15 11:44:01,045:INFO:SubProcess create_model() end ==================================
2023-02-15 11:44:01,045:INFO:Creating metrics dataframe
2023-02-15 11:44:01,052:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 11:44:01,052:INFO:Total runtime is 0.0578365961710612 minutes
2023-02-15 11:44:01,056:INFO:SubProcess create_model() called ==================================
2023-02-15 11:44:01,056:INFO:Initializing create_model()
2023-02-15 11:44:01,056:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:44:01,056:INFO:Checking exceptions
2023-02-15 11:44:01,056:INFO:Importing libraries
2023-02-15 11:44:01,056:INFO:Copying training dataset
2023-02-15 11:44:01,057:INFO:Defining folds
2023-02-15 11:44:01,057:INFO:Declaring metric variables
2023-02-15 11:44:01,061:INFO:Importing untrained model
2023-02-15 11:44:01,065:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-15 11:44:01,072:INFO:Starting cross validation
2023-02-15 11:44:01,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:44:01,234:INFO:Calculating mean and std
2023-02-15 11:44:01,235:INFO:Creating metrics dataframe
2023-02-15 11:44:01,238:INFO:Uploading results into container
2023-02-15 11:44:01,238:INFO:Uploading model into container now
2023-02-15 11:44:01,238:INFO:create_model_container: 6
2023-02-15 11:44:01,238:INFO:master_model_container: 6
2023-02-15 11:44:01,238:INFO:display_container: 2
2023-02-15 11:44:01,239:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-15 11:44:01,239:INFO:create_model() succesfully completed......................................
2023-02-15 11:44:01,366:INFO:SubProcess create_model() end ==================================
2023-02-15 11:44:01,366:INFO:Creating metrics dataframe
2023-02-15 11:44:01,373:INFO:Initializing Bayesian Ridge
2023-02-15 11:44:01,373:INFO:Total runtime is 0.06319479942321778 minutes
2023-02-15 11:44:01,377:INFO:SubProcess create_model() called ==================================
2023-02-15 11:44:01,377:INFO:Initializing create_model()
2023-02-15 11:44:01,377:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:44:01,377:INFO:Checking exceptions
2023-02-15 11:44:01,377:INFO:Importing libraries
2023-02-15 11:44:01,377:INFO:Copying training dataset
2023-02-15 11:44:01,378:INFO:Defining folds
2023-02-15 11:44:01,378:INFO:Declaring metric variables
2023-02-15 11:44:01,381:INFO:Importing untrained model
2023-02-15 11:44:01,384:INFO:Bayesian Ridge Imported succesfully
2023-02-15 11:44:01,390:INFO:Starting cross validation
2023-02-15 11:44:01,391:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:44:02,690:INFO:Calculating mean and std
2023-02-15 11:44:02,691:INFO:Creating metrics dataframe
2023-02-15 11:44:02,700:INFO:Uploading results into container
2023-02-15 11:44:02,700:INFO:Uploading model into container now
2023-02-15 11:44:02,700:INFO:create_model_container: 7
2023-02-15 11:44:02,700:INFO:master_model_container: 7
2023-02-15 11:44:02,700:INFO:display_container: 2
2023-02-15 11:44:02,700:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-15 11:44:02,700:INFO:create_model() succesfully completed......................................
2023-02-15 11:44:02,834:INFO:SubProcess create_model() end ==================================
2023-02-15 11:44:02,834:INFO:Creating metrics dataframe
2023-02-15 11:44:02,843:INFO:Initializing Passive Aggressive Regressor
2023-02-15 11:44:02,843:INFO:Total runtime is 0.08768670558929444 minutes
2023-02-15 11:44:02,847:INFO:SubProcess create_model() called ==================================
2023-02-15 11:44:02,847:INFO:Initializing create_model()
2023-02-15 11:44:02,847:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:44:02,847:INFO:Checking exceptions
2023-02-15 11:44:02,847:INFO:Importing libraries
2023-02-15 11:44:02,847:INFO:Copying training dataset
2023-02-15 11:44:02,848:INFO:Defining folds
2023-02-15 11:44:02,848:INFO:Declaring metric variables
2023-02-15 11:44:02,851:INFO:Importing untrained model
2023-02-15 11:44:02,854:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-15 11:44:02,860:INFO:Starting cross validation
2023-02-15 11:44:02,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:44:03,215:INFO:Calculating mean and std
2023-02-15 11:44:03,216:INFO:Creating metrics dataframe
2023-02-15 11:44:03,219:INFO:Uploading results into container
2023-02-15 11:44:03,219:INFO:Uploading model into container now
2023-02-15 11:44:03,219:INFO:create_model_container: 8
2023-02-15 11:44:03,219:INFO:master_model_container: 8
2023-02-15 11:44:03,219:INFO:display_container: 2
2023-02-15 11:44:03,220:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-15 11:44:03,220:INFO:create_model() succesfully completed......................................
2023-02-15 11:44:03,336:INFO:SubProcess create_model() end ==================================
2023-02-15 11:44:03,336:INFO:Creating metrics dataframe
2023-02-15 11:44:03,343:INFO:Initializing Huber Regressor
2023-02-15 11:44:03,343:INFO:Total runtime is 0.09601856072743734 minutes
2023-02-15 11:44:03,346:INFO:SubProcess create_model() called ==================================
2023-02-15 11:44:03,346:INFO:Initializing create_model()
2023-02-15 11:44:03,346:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:44:03,346:INFO:Checking exceptions
2023-02-15 11:44:03,346:INFO:Importing libraries
2023-02-15 11:44:03,346:INFO:Copying training dataset
2023-02-15 11:44:03,347:INFO:Defining folds
2023-02-15 11:44:03,347:INFO:Declaring metric variables
2023-02-15 11:44:03,350:INFO:Importing untrained model
2023-02-15 11:44:03,353:INFO:Huber Regressor Imported succesfully
2023-02-15 11:44:03,359:INFO:Starting cross validation
2023-02-15 11:44:03,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:44:20,053:INFO:Calculating mean and std
2023-02-15 11:44:20,053:INFO:Creating metrics dataframe
2023-02-15 11:44:20,057:INFO:Uploading results into container
2023-02-15 11:44:20,057:INFO:Uploading model into container now
2023-02-15 11:44:20,057:INFO:create_model_container: 9
2023-02-15 11:44:20,057:INFO:master_model_container: 9
2023-02-15 11:44:20,057:INFO:display_container: 2
2023-02-15 11:44:20,057:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-15 11:44:20,057:INFO:create_model() succesfully completed......................................
2023-02-15 11:44:20,171:INFO:SubProcess create_model() end ==================================
2023-02-15 11:44:20,171:INFO:Creating metrics dataframe
2023-02-15 11:44:20,178:INFO:Initializing K Neighbors Regressor
2023-02-15 11:44:20,178:INFO:Total runtime is 0.3766039252281189 minutes
2023-02-15 11:44:20,181:INFO:SubProcess create_model() called ==================================
2023-02-15 11:44:20,181:INFO:Initializing create_model()
2023-02-15 11:44:20,181:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:44:20,181:INFO:Checking exceptions
2023-02-15 11:44:20,181:INFO:Importing libraries
2023-02-15 11:44:20,181:INFO:Copying training dataset
2023-02-15 11:44:20,182:INFO:Defining folds
2023-02-15 11:44:20,182:INFO:Declaring metric variables
2023-02-15 11:44:20,185:INFO:Importing untrained model
2023-02-15 11:44:20,188:INFO:K Neighbors Regressor Imported succesfully
2023-02-15 11:44:20,195:INFO:Starting cross validation
2023-02-15 11:44:20,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:44:25,570:INFO:Calculating mean and std
2023-02-15 11:44:25,571:INFO:Creating metrics dataframe
2023-02-15 11:44:25,574:INFO:Uploading results into container
2023-02-15 11:44:25,574:INFO:Uploading model into container now
2023-02-15 11:44:25,574:INFO:create_model_container: 10
2023-02-15 11:44:25,574:INFO:master_model_container: 10
2023-02-15 11:44:25,574:INFO:display_container: 2
2023-02-15 11:44:25,574:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-15 11:44:25,574:INFO:create_model() succesfully completed......................................
2023-02-15 11:44:25,699:INFO:SubProcess create_model() end ==================================
2023-02-15 11:44:25,699:INFO:Creating metrics dataframe
2023-02-15 11:44:25,707:INFO:Initializing Decision Tree Regressor
2023-02-15 11:44:25,707:INFO:Total runtime is 0.4687583565711975 minutes
2023-02-15 11:44:25,711:INFO:SubProcess create_model() called ==================================
2023-02-15 11:44:25,711:INFO:Initializing create_model()
2023-02-15 11:44:25,711:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:44:25,711:INFO:Checking exceptions
2023-02-15 11:44:25,711:INFO:Importing libraries
2023-02-15 11:44:25,711:INFO:Copying training dataset
2023-02-15 11:44:25,712:INFO:Defining folds
2023-02-15 11:44:25,712:INFO:Declaring metric variables
2023-02-15 11:44:25,715:INFO:Importing untrained model
2023-02-15 11:44:25,718:INFO:Decision Tree Regressor Imported succesfully
2023-02-15 11:44:25,725:INFO:Starting cross validation
2023-02-15 11:44:25,725:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:44:48,006:INFO:Calculating mean and std
2023-02-15 11:44:48,007:INFO:Creating metrics dataframe
2023-02-15 11:44:48,009:INFO:Uploading results into container
2023-02-15 11:44:48,009:INFO:Uploading model into container now
2023-02-15 11:44:48,009:INFO:create_model_container: 11
2023-02-15 11:44:48,009:INFO:master_model_container: 11
2023-02-15 11:44:48,009:INFO:display_container: 2
2023-02-15 11:44:48,009:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-15 11:44:48,009:INFO:create_model() succesfully completed......................................
2023-02-15 11:44:48,117:INFO:SubProcess create_model() end ==================================
2023-02-15 11:44:48,117:INFO:Creating metrics dataframe
2023-02-15 11:44:48,124:INFO:Initializing Random Forest Regressor
2023-02-15 11:44:48,124:INFO:Total runtime is 0.8423756321271261 minutes
2023-02-15 11:44:48,128:INFO:SubProcess create_model() called ==================================
2023-02-15 11:44:48,128:INFO:Initializing create_model()
2023-02-15 11:44:48,128:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:44:48,128:INFO:Checking exceptions
2023-02-15 11:44:48,128:INFO:Importing libraries
2023-02-15 11:44:48,128:INFO:Copying training dataset
2023-02-15 11:44:48,129:INFO:Defining folds
2023-02-15 11:44:48,129:INFO:Declaring metric variables
2023-02-15 11:44:48,132:INFO:Importing untrained model
2023-02-15 11:44:48,135:INFO:Random Forest Regressor Imported succesfully
2023-02-15 11:44:48,141:INFO:Starting cross validation
2023-02-15 11:44:48,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:46:15,247:INFO:Calculating mean and std
2023-02-15 11:46:15,248:INFO:Creating metrics dataframe
2023-02-15 11:46:15,250:INFO:Uploading results into container
2023-02-15 11:46:15,250:INFO:Uploading model into container now
2023-02-15 11:46:15,250:INFO:create_model_container: 12
2023-02-15 11:46:15,250:INFO:master_model_container: 12
2023-02-15 11:46:15,250:INFO:display_container: 2
2023-02-15 11:46:15,250:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-15 11:46:15,250:INFO:create_model() succesfully completed......................................
2023-02-15 11:46:15,362:INFO:SubProcess create_model() end ==================================
2023-02-15 11:46:15,363:INFO:Creating metrics dataframe
2023-02-15 11:46:15,370:INFO:Initializing Extra Trees Regressor
2023-02-15 11:46:15,370:INFO:Total runtime is 2.296475617090861 minutes
2023-02-15 11:46:15,374:INFO:SubProcess create_model() called ==================================
2023-02-15 11:46:15,374:INFO:Initializing create_model()
2023-02-15 11:46:15,374:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:46:15,374:INFO:Checking exceptions
2023-02-15 11:46:15,374:INFO:Importing libraries
2023-02-15 11:46:15,374:INFO:Copying training dataset
2023-02-15 11:46:15,375:INFO:Defining folds
2023-02-15 11:46:15,375:INFO:Declaring metric variables
2023-02-15 11:46:15,378:INFO:Importing untrained model
2023-02-15 11:46:15,381:INFO:Extra Trees Regressor Imported succesfully
2023-02-15 11:46:15,387:INFO:Starting cross validation
2023-02-15 11:46:15,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:46:40,982:INFO:Calculating mean and std
2023-02-15 11:46:40,983:INFO:Creating metrics dataframe
2023-02-15 11:46:40,985:INFO:Uploading results into container
2023-02-15 11:46:40,985:INFO:Uploading model into container now
2023-02-15 11:46:40,985:INFO:create_model_container: 13
2023-02-15 11:46:40,985:INFO:master_model_container: 13
2023-02-15 11:46:40,985:INFO:display_container: 2
2023-02-15 11:46:40,986:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-15 11:46:40,986:INFO:create_model() succesfully completed......................................
2023-02-15 11:46:41,093:INFO:SubProcess create_model() end ==================================
2023-02-15 11:46:41,093:INFO:Creating metrics dataframe
2023-02-15 11:46:41,101:INFO:Initializing AdaBoost Regressor
2023-02-15 11:46:41,101:INFO:Total runtime is 2.7253254055976868 minutes
2023-02-15 11:46:41,106:INFO:SubProcess create_model() called ==================================
2023-02-15 11:46:41,107:INFO:Initializing create_model()
2023-02-15 11:46:41,107:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:46:41,107:INFO:Checking exceptions
2023-02-15 11:46:41,107:INFO:Importing libraries
2023-02-15 11:46:41,107:INFO:Copying training dataset
2023-02-15 11:46:41,108:INFO:Defining folds
2023-02-15 11:46:41,108:INFO:Declaring metric variables
2023-02-15 11:46:41,112:INFO:Importing untrained model
2023-02-15 11:46:41,116:INFO:AdaBoost Regressor Imported succesfully
2023-02-15 11:46:41,123:INFO:Starting cross validation
2023-02-15 11:46:41,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:47:54,726:INFO:Calculating mean and std
2023-02-15 11:47:54,726:INFO:Creating metrics dataframe
2023-02-15 11:47:54,729:INFO:Uploading results into container
2023-02-15 11:47:54,729:INFO:Uploading model into container now
2023-02-15 11:47:54,729:INFO:create_model_container: 14
2023-02-15 11:47:54,729:INFO:master_model_container: 14
2023-02-15 11:47:54,729:INFO:display_container: 2
2023-02-15 11:47:54,729:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-15 11:47:54,729:INFO:create_model() succesfully completed......................................
2023-02-15 11:47:54,834:INFO:SubProcess create_model() end ==================================
2023-02-15 11:47:54,834:INFO:Creating metrics dataframe
2023-02-15 11:47:54,842:INFO:Initializing Gradient Boosting Regressor
2023-02-15 11:47:54,842:INFO:Total runtime is 3.9543366233507795 minutes
2023-02-15 11:47:54,845:INFO:SubProcess create_model() called ==================================
2023-02-15 11:47:54,845:INFO:Initializing create_model()
2023-02-15 11:47:54,845:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:47:54,846:INFO:Checking exceptions
2023-02-15 11:47:54,846:INFO:Importing libraries
2023-02-15 11:47:54,846:INFO:Copying training dataset
2023-02-15 11:47:54,846:INFO:Defining folds
2023-02-15 11:47:54,846:INFO:Declaring metric variables
2023-02-15 11:47:54,849:INFO:Importing untrained model
2023-02-15 11:47:54,853:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-15 11:47:54,859:INFO:Starting cross validation
2023-02-15 11:47:54,859:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:54:19,075:INFO:Calculating mean and std
2023-02-15 11:54:19,076:INFO:Creating metrics dataframe
2023-02-15 11:54:19,078:INFO:Uploading results into container
2023-02-15 11:54:19,078:INFO:Uploading model into container now
2023-02-15 11:54:19,078:INFO:create_model_container: 15
2023-02-15 11:54:19,078:INFO:master_model_container: 15
2023-02-15 11:54:19,078:INFO:display_container: 2
2023-02-15 11:54:19,078:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-15 11:54:19,078:INFO:create_model() succesfully completed......................................
2023-02-15 11:54:19,180:INFO:SubProcess create_model() end ==================================
2023-02-15 11:54:19,181:INFO:Creating metrics dataframe
2023-02-15 11:54:19,188:INFO:Initializing Extreme Gradient Boosting
2023-02-15 11:54:19,188:INFO:Total runtime is 10.360111924012502 minutes
2023-02-15 11:54:19,192:INFO:SubProcess create_model() called ==================================
2023-02-15 11:54:19,192:INFO:Initializing create_model()
2023-02-15 11:54:19,192:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:54:19,192:INFO:Checking exceptions
2023-02-15 11:54:19,192:INFO:Importing libraries
2023-02-15 11:54:19,192:INFO:Copying training dataset
2023-02-15 11:54:19,193:INFO:Defining folds
2023-02-15 11:54:19,193:INFO:Declaring metric variables
2023-02-15 11:54:19,196:INFO:Importing untrained model
2023-02-15 11:54:19,199:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-15 11:54:19,205:INFO:Starting cross validation
2023-02-15 11:54:19,206:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:54:19,704:INFO:Calculating mean and std
2023-02-15 11:54:19,705:INFO:Creating metrics dataframe
2023-02-15 11:54:19,707:INFO:Uploading results into container
2023-02-15 11:54:19,707:INFO:Uploading model into container now
2023-02-15 11:54:19,707:INFO:create_model_container: 16
2023-02-15 11:54:19,707:INFO:master_model_container: 16
2023-02-15 11:54:19,707:INFO:display_container: 2
2023-02-15 11:54:19,708:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-15 11:54:19,708:INFO:create_model() succesfully completed......................................
2023-02-15 11:54:19,809:WARNING:create_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:54:19,809:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2205, in compare_models
    assert np.sum(model_results.iloc[0]) != 0.0
AssertionError

2023-02-15 11:54:19,809:INFO:Initializing create_model()
2023-02-15 11:54:19,809:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:54:19,809:INFO:Checking exceptions
2023-02-15 11:54:19,809:INFO:Importing libraries
2023-02-15 11:54:19,809:INFO:Copying training dataset
2023-02-15 11:54:19,810:INFO:Defining folds
2023-02-15 11:54:19,810:INFO:Declaring metric variables
2023-02-15 11:54:19,813:INFO:Importing untrained model
2023-02-15 11:54:19,816:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-15 11:54:19,822:INFO:Starting cross validation
2023-02-15 11:54:19,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:54:20,241:INFO:Calculating mean and std
2023-02-15 11:54:20,242:INFO:Creating metrics dataframe
2023-02-15 11:54:20,244:INFO:Uploading results into container
2023-02-15 11:54:20,244:INFO:Uploading model into container now
2023-02-15 11:54:20,245:INFO:create_model_container: 17
2023-02-15 11:54:20,245:INFO:master_model_container: 17
2023-02-15 11:54:20,245:INFO:display_container: 2
2023-02-15 11:54:20,245:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-15 11:54:20,245:INFO:create_model() succesfully completed......................................
2023-02-15 11:54:20,347:ERROR:create_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...) raised an exception or returned all 0.0:
2023-02-15 11:54:20,347:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2205, in compare_models
    assert np.sum(model_results.iloc[0]) != 0.0
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2214, in compare_models
    assert np.sum(model_results.iloc[0]) != 0.0
AssertionError

2023-02-15 11:54:20,347:INFO:Initializing Light Gradient Boosting Machine
2023-02-15 11:54:20,347:INFO:Total runtime is 10.37942642768224 minutes
2023-02-15 11:54:20,351:INFO:SubProcess create_model() called ==================================
2023-02-15 11:54:20,351:INFO:Initializing create_model()
2023-02-15 11:54:20,351:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:54:20,351:INFO:Checking exceptions
2023-02-15 11:54:20,351:INFO:Importing libraries
2023-02-15 11:54:20,351:INFO:Copying training dataset
2023-02-15 11:54:20,352:INFO:Defining folds
2023-02-15 11:54:20,352:INFO:Declaring metric variables
2023-02-15 11:54:20,355:INFO:Importing untrained model
2023-02-15 11:54:20,358:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-15 11:54:20,363:INFO:Starting cross validation
2023-02-15 11:54:20,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:54:25,181:INFO:Calculating mean and std
2023-02-15 11:54:25,182:INFO:Creating metrics dataframe
2023-02-15 11:54:25,185:INFO:Uploading results into container
2023-02-15 11:54:25,185:INFO:Uploading model into container now
2023-02-15 11:54:25,185:INFO:create_model_container: 18
2023-02-15 11:54:25,185:INFO:master_model_container: 18
2023-02-15 11:54:25,185:INFO:display_container: 2
2023-02-15 11:54:25,186:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:54:25,186:INFO:create_model() succesfully completed......................................
2023-02-15 11:54:25,306:INFO:SubProcess create_model() end ==================================
2023-02-15 11:54:25,306:INFO:Creating metrics dataframe
2023-02-15 11:54:25,316:INFO:Initializing CatBoost Regressor
2023-02-15 11:54:25,316:INFO:Total runtime is 10.462237850824991 minutes
2023-02-15 11:54:25,322:INFO:SubProcess create_model() called ==================================
2023-02-15 11:54:25,322:INFO:Initializing create_model()
2023-02-15 11:54:25,322:INFO:create_model(estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:54:25,322:INFO:Checking exceptions
2023-02-15 11:54:25,322:INFO:Importing libraries
2023-02-15 11:54:25,322:INFO:Copying training dataset
2023-02-15 11:54:25,324:INFO:Defining folds
2023-02-15 11:54:25,324:INFO:Declaring metric variables
2023-02-15 11:54:25,329:INFO:Importing untrained model
2023-02-15 11:54:25,341:INFO:CatBoost Regressor Imported succesfully
2023-02-15 11:54:25,353:INFO:Starting cross validation
2023-02-15 11:54:25,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:54:54,258:INFO:Calculating mean and std
2023-02-15 11:54:54,258:INFO:Creating metrics dataframe
2023-02-15 11:54:54,261:INFO:Uploading results into container
2023-02-15 11:54:54,261:INFO:Uploading model into container now
2023-02-15 11:54:54,261:INFO:create_model_container: 19
2023-02-15 11:54:54,261:INFO:master_model_container: 19
2023-02-15 11:54:54,261:INFO:display_container: 2
2023-02-15 11:54:54,261:INFO:<catboost.core.CatBoostRegressor object at 0x7f97e8ff55e0>
2023-02-15 11:54:54,261:INFO:create_model() succesfully completed......................................
2023-02-15 11:54:54,355:INFO:SubProcess create_model() end ==================================
2023-02-15 11:54:54,356:INFO:Creating metrics dataframe
2023-02-15 11:54:54,363:INFO:Initializing Dummy Regressor
2023-02-15 11:54:54,363:INFO:Total runtime is 10.9463614265124 minutes
2023-02-15 11:54:54,366:INFO:SubProcess create_model() called ==================================
2023-02-15 11:54:54,367:INFO:Initializing create_model()
2023-02-15 11:54:54,367:INFO:create_model(estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f978ba6adc0>, return_train_score=False, kwargs={})
2023-02-15 11:54:54,367:INFO:Checking exceptions
2023-02-15 11:54:54,367:INFO:Importing libraries
2023-02-15 11:54:54,367:INFO:Copying training dataset
2023-02-15 11:54:54,367:INFO:Defining folds
2023-02-15 11:54:54,367:INFO:Declaring metric variables
2023-02-15 11:54:54,370:INFO:Importing untrained model
2023-02-15 11:54:54,373:INFO:Dummy Regressor Imported succesfully
2023-02-15 11:54:54,379:INFO:Starting cross validation
2023-02-15 11:54:54,379:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:54:54,407:INFO:Calculating mean and std
2023-02-15 11:54:54,407:INFO:Creating metrics dataframe
2023-02-15 11:54:54,409:INFO:Uploading results into container
2023-02-15 11:54:54,409:INFO:Uploading model into container now
2023-02-15 11:54:54,409:INFO:create_model_container: 20
2023-02-15 11:54:54,409:INFO:master_model_container: 20
2023-02-15 11:54:54,409:INFO:display_container: 2
2023-02-15 11:54:54,409:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-02-15 11:54:54,409:INFO:create_model() succesfully completed......................................
2023-02-15 11:54:54,504:INFO:SubProcess create_model() end ==================================
2023-02-15 11:54:54,504:INFO:Creating metrics dataframe
2023-02-15 11:54:54,519:INFO:Initializing create_model()
2023-02-15 11:54:54,519:INFO:create_model(estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-15 11:54:54,519:INFO:Checking exceptions
2023-02-15 11:54:54,519:INFO:Importing libraries
2023-02-15 11:54:54,519:INFO:Copying training dataset
2023-02-15 11:54:54,519:INFO:Defining folds
2023-02-15 11:54:54,519:INFO:Declaring metric variables
2023-02-15 11:54:54,520:INFO:Importing untrained model
2023-02-15 11:54:54,520:INFO:Declaring custom model
2023-02-15 11:54:54,520:INFO:Extra Trees Regressor Imported succesfully
2023-02-15 11:54:54,520:INFO:Cross validation set to False
2023-02-15 11:54:54,520:INFO:Fitting Model
2023-02-15 11:54:56,132:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-15 11:54:56,132:INFO:create_models() succesfully completed......................................
2023-02-15 11:54:56,258:INFO:create_model_container: 20
2023-02-15 11:54:56,258:INFO:master_model_container: 20
2023-02-15 11:54:56,258:INFO:display_container: 2
2023-02-15 11:54:56,259:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-15 11:54:56,259:INFO:compare_models() succesfully completed......................................
2023-02-15 11:56:14,257:INFO:PyCaret Supervised Module
2023-02-15 11:56:14,257:INFO:ML Usecase: regression
2023-02-15 11:56:14,257:INFO:version 2.3.10
2023-02-15 11:56:14,257:INFO:Initializing setup()
2023-02-15 11:56:14,257:INFO:setup(target=closeChg%_forward24HR, ml_usecase=regression, available_plots={'parameter': 'Hyperparameters', 'residuals': 'Residuals', 'error': 'Prediction Error', 'cooks': 'Cooks Distance', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'vc': 'Validation Curve', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'tree': 'Decision Tree', 'residuals_interactive': 'Interactive Residuals'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR'], normalize=True, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=True, custom_pipeline=None, html=True, session_id=11, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-02-15 11:56:14,257:INFO:Checking environment
2023-02-15 11:56:14,257:INFO:python_version: 3.9.16
2023-02-15 11:56:14,257:INFO:python_build: ('main', 'Jan 11 2023 16:05:54')
2023-02-15 11:56:14,257:INFO:machine: x86_64
2023-02-15 11:56:14,257:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.31
2023-02-15 11:56:14,258:INFO:Memory: svmem(total=134979592192, available=122743758848, percent=9.1, used=10544873472, free=102561484800, active=3821604864, inactive=26075451392, buffers=1428484096, cached=20444749824, shared=428601344, slab=1940004864)
2023-02-15 11:56:14,259:INFO:Physical Core: 16
2023-02-15 11:56:14,259:INFO:Logical Core: 32
2023-02-15 11:56:14,259:INFO:Checking libraries
2023-02-15 11:56:14,259:INFO:pd==1.5.2
2023-02-15 11:56:14,259:INFO:numpy==1.20.3
2023-02-15 11:56:14,259:INFO:sklearn==0.23.2
2023-02-15 11:56:14,259:INFO:lightgbm==3.3.5.99
2023-02-15 11:56:14,280:INFO:catboost==1.1.1
2023-02-15 11:56:14,280:INFO:xgboost==1.7.3
2023-02-15 11:56:14,280:INFO:mlflow==2.1.1
2023-02-15 11:56:14,280:INFO:Checking Exceptions
2023-02-15 11:56:14,280:INFO:Declaring global variables
2023-02-15 11:56:14,280:INFO:USI: d5b6
2023-02-15 11:56:14,280:INFO:pycaret_globals: {'logging_param', '_ml_usecase', '_all_models_internal', 'y', 'imputation_regressor', 'X', 'fix_imbalance_param', 'gpu_param', 'fold_param', 'fold_groups_param', 'X_train', 'fold_generator', 'html_param', 'imputation_classifier', 'exp_name_log', 'pycaret_globals', 'log_plots_param', '_gpu_n_jobs_param', 'y_train', '_all_models', 'y_test', '_available_plots', 'transform_target_method_param', 'n_jobs_param', 'data_before_preprocess', 'iterative_imputation_iters_param', 'X_test', 'master_model_container', 'prep_pipe', 'experiment__', 'create_model_container', 'transform_target_param', 'display_container', 'fix_imbalance_method_param', 'fold_groups_param_full', '_all_metrics', 'USI', 'target_param', 'dashboard_logger', 'fold_shuffle_param', '_internal_pipeline', 'stratify_param', 'seed'}
2023-02-15 11:56:14,280:INFO:Preparing display monitor
2023-02-15 11:56:14,281:INFO:Preparing display monitor
2023-02-15 11:56:14,288:INFO:Importing libraries
2023-02-15 11:56:14,288:INFO:Copying data for preprocessing
2023-02-15 11:56:14,297:INFO:Declaring preprocessing parameters
2023-02-15 11:56:14,297:WARNING:cuML not found
2023-02-15 11:56:14,297:WARNING:cuML is outdated or not found. Required version is >=0.15, got 1.7.3
2023-02-15 11:56:14,308:INFO:Creating preprocessing pipeline
2023-02-15 11:56:14,531:INFO:Preprocessing pipeline created successfully
2023-02-15 11:56:14,532:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-02-15 11:56:14,532:INFO:Creating global containers
2023-02-15 11:56:14,532:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-02-15 11:56:16,049:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:56:16,049:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:56:16,052:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:56:16,055:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:56:16,087:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:56:16,113:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:56:16,113:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:56:16,168:WARNING:Couldn't import cuml.linear_model.LinearRegression
2023-02-15 11:56:16,168:WARNING:Couldn't import cuml.linear_model.Lasso
2023-02-15 11:56:16,173:WARNING:Couldn't import cuml.linear_model.Ridge
2023-02-15 11:56:16,178:WARNING:Couldn't import cuml.linear_model.ElasticNet
2023-02-15 11:56:16,233:WARNING:Couldn't import cuml.svm.SVR
2023-02-15 11:56:16,277:WARNING:Couldn't import cuml.neighbors.KNeighborsRegressor
2023-02-15 11:56:16,278:WARNING:Couldn't import cuml.ensemble
2023-02-15 11:56:16,283:INFO:Creating grid variables
2023-02-15 11:56:16,303:INFO:create_model_container: 0
2023-02-15 11:56:16,304:INFO:master_model_container: 0
2023-02-15 11:56:16,304:INFO:display_container: 1
2023-02-15 11:56:16,307:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=False,
                                      features_todrop=['dt', 'exchange',
                                                       'timestamp',
                                                       'instrument',
                                                       'closeChg%_forward1HR'],
                                      id_columns=[], ml_usecase='regression',
                                      numerical_features=[],
                                      target='closeChg%_forward24HR',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_ava...
                ('P_transform', 'passthrough'), ('binn', 'passthrough'),
                ('rem_outliers', 'passthrough'), ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='closeChg%_forward24HR')),
                ('fix_perfect', Remove_100(target='closeChg%_forward24HR')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-02-15 11:56:16,307:INFO:setup() succesfully completed......................................
2023-02-15 11:56:16,415:INFO:Initializing compare_models()
2023-02-15 11:56:16,415:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=['tr'])
2023-02-15 11:56:16,415:INFO:Checking exceptions
2023-02-15 11:56:16,415:INFO:Preparing display monitor
2023-02-15 11:56:16,415:INFO:Preparing display monitor
2023-02-15 11:56:16,426:INFO:Initializing Linear Regression
2023-02-15 11:56:16,426:INFO:Total runtime is 8.742014567057291e-07 minutes
2023-02-15 11:56:16,430:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:16,430:INFO:Initializing create_model()
2023-02-15 11:56:16,430:INFO:create_model(estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:16,430:INFO:Checking exceptions
2023-02-15 11:56:16,430:INFO:Importing libraries
2023-02-15 11:56:16,430:INFO:Copying training dataset
2023-02-15 11:56:16,431:INFO:Defining folds
2023-02-15 11:56:16,431:INFO:Declaring metric variables
2023-02-15 11:56:16,434:INFO:Importing untrained model
2023-02-15 11:56:16,438:INFO:Linear Regression Imported succesfully
2023-02-15 11:56:16,447:INFO:Starting cross validation
2023-02-15 11:56:16,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:17,339:INFO:Calculating mean and std
2023-02-15 11:56:17,340:INFO:Creating metrics dataframe
2023-02-15 11:56:17,353:INFO:Uploading results into container
2023-02-15 11:56:17,355:INFO:Uploading model into container now
2023-02-15 11:56:17,355:INFO:create_model_container: 1
2023-02-15 11:56:17,355:INFO:master_model_container: 1
2023-02-15 11:56:17,355:INFO:display_container: 2
2023-02-15 11:56:17,355:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)
2023-02-15 11:56:17,355:INFO:create_model() succesfully completed......................................
2023-02-15 11:56:17,482:INFO:SubProcess create_model() end ==================================
2023-02-15 11:56:17,482:INFO:Creating metrics dataframe
2023-02-15 11:56:17,487:INFO:Initializing Lasso Regression
2023-02-15 11:56:17,488:INFO:Total runtime is 0.0176889181137085 minutes
2023-02-15 11:56:17,491:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:17,492:INFO:Initializing create_model()
2023-02-15 11:56:17,492:INFO:create_model(estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:17,492:INFO:Checking exceptions
2023-02-15 11:56:17,492:INFO:Importing libraries
2023-02-15 11:56:17,492:INFO:Copying training dataset
2023-02-15 11:56:17,492:INFO:Defining folds
2023-02-15 11:56:17,492:INFO:Declaring metric variables
2023-02-15 11:56:17,495:INFO:Importing untrained model
2023-02-15 11:56:17,498:INFO:Lasso Regression Imported succesfully
2023-02-15 11:56:17,505:INFO:Starting cross validation
2023-02-15 11:56:17,505:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:17,741:INFO:Calculating mean and std
2023-02-15 11:56:17,743:INFO:Creating metrics dataframe
2023-02-15 11:56:17,747:INFO:Uploading results into container
2023-02-15 11:56:17,747:INFO:Uploading model into container now
2023-02-15 11:56:17,747:INFO:create_model_container: 2
2023-02-15 11:56:17,747:INFO:master_model_container: 2
2023-02-15 11:56:17,747:INFO:display_container: 2
2023-02-15 11:56:17,748:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize=False, positive=False, precompute=False, random_state=11,
      selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:56:17,748:INFO:create_model() succesfully completed......................................
2023-02-15 11:56:17,888:INFO:SubProcess create_model() end ==================================
2023-02-15 11:56:17,888:INFO:Creating metrics dataframe
2023-02-15 11:56:17,894:INFO:Initializing Ridge Regression
2023-02-15 11:56:17,894:INFO:Total runtime is 0.024469014008839926 minutes
2023-02-15 11:56:17,898:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:17,898:INFO:Initializing create_model()
2023-02-15 11:56:17,898:INFO:create_model(estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:17,898:INFO:Checking exceptions
2023-02-15 11:56:17,898:INFO:Importing libraries
2023-02-15 11:56:17,898:INFO:Copying training dataset
2023-02-15 11:56:17,899:INFO:Defining folds
2023-02-15 11:56:17,899:INFO:Declaring metric variables
2023-02-15 11:56:17,903:INFO:Importing untrained model
2023-02-15 11:56:17,907:INFO:Ridge Regression Imported succesfully
2023-02-15 11:56:17,913:INFO:Starting cross validation
2023-02-15 11:56:17,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:18,127:INFO:Calculating mean and std
2023-02-15 11:56:18,129:INFO:Creating metrics dataframe
2023-02-15 11:56:18,132:INFO:Uploading results into container
2023-02-15 11:56:18,132:INFO:Uploading model into container now
2023-02-15 11:56:18,132:INFO:create_model_container: 3
2023-02-15 11:56:18,132:INFO:master_model_container: 3
2023-02-15 11:56:18,132:INFO:display_container: 2
2023-02-15 11:56:18,133:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=11, solver='auto', tol=0.001)
2023-02-15 11:56:18,133:INFO:create_model() succesfully completed......................................
2023-02-15 11:56:18,258:INFO:SubProcess create_model() end ==================================
2023-02-15 11:56:18,258:INFO:Creating metrics dataframe
2023-02-15 11:56:18,265:INFO:Initializing Elastic Net
2023-02-15 11:56:18,265:INFO:Total runtime is 0.03064045508702596 minutes
2023-02-15 11:56:18,269:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:18,269:INFO:Initializing create_model()
2023-02-15 11:56:18,269:INFO:create_model(estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:18,269:INFO:Checking exceptions
2023-02-15 11:56:18,269:INFO:Importing libraries
2023-02-15 11:56:18,269:INFO:Copying training dataset
2023-02-15 11:56:18,270:INFO:Defining folds
2023-02-15 11:56:18,270:INFO:Declaring metric variables
2023-02-15 11:56:18,273:INFO:Importing untrained model
2023-02-15 11:56:18,276:INFO:Elastic Net Imported succesfully
2023-02-15 11:56:18,281:INFO:Starting cross validation
2023-02-15 11:56:18,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:18,461:INFO:Calculating mean and std
2023-02-15 11:56:18,461:INFO:Creating metrics dataframe
2023-02-15 11:56:18,465:INFO:Uploading results into container
2023-02-15 11:56:18,465:INFO:Uploading model into container now
2023-02-15 11:56:18,465:INFO:create_model_container: 4
2023-02-15 11:56:18,465:INFO:master_model_container: 4
2023-02-15 11:56:18,465:INFO:display_container: 2
2023-02-15 11:56:18,465:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize=False, positive=False, precompute=False,
           random_state=11, selection='cyclic', tol=0.0001, warm_start=False)
2023-02-15 11:56:18,465:INFO:create_model() succesfully completed......................................
2023-02-15 11:56:18,589:INFO:SubProcess create_model() end ==================================
2023-02-15 11:56:18,589:INFO:Creating metrics dataframe
2023-02-15 11:56:18,595:INFO:Initializing Least Angle Regression
2023-02-15 11:56:18,595:INFO:Total runtime is 0.036151790618896486 minutes
2023-02-15 11:56:18,599:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:18,599:INFO:Initializing create_model()
2023-02-15 11:56:18,599:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:18,599:INFO:Checking exceptions
2023-02-15 11:56:18,600:INFO:Importing libraries
2023-02-15 11:56:18,600:INFO:Copying training dataset
2023-02-15 11:56:18,600:INFO:Defining folds
2023-02-15 11:56:18,600:INFO:Declaring metric variables
2023-02-15 11:56:18,603:INFO:Importing untrained model
2023-02-15 11:56:18,607:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:56:18,613:INFO:Starting cross validation
2023-02-15 11:56:18,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:18,949:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 11:56:18,951:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:56:18,952:INFO:Initializing create_model()
2023-02-15 11:56:18,952:INFO:create_model(estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:18,952:INFO:Checking exceptions
2023-02-15 11:56:18,952:INFO:Importing libraries
2023-02-15 11:56:18,952:INFO:Copying training dataset
2023-02-15 11:56:18,953:INFO:Defining folds
2023-02-15 11:56:18,953:INFO:Declaring metric variables
2023-02-15 11:56:18,959:INFO:Importing untrained model
2023-02-15 11:56:18,965:INFO:Least Angle Regression Imported succesfully
2023-02-15 11:56:18,976:INFO:Starting cross validation
2023-02-15 11:56:18,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:19,339:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-02-15 11:56:19,340:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2203, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2212, in compare_models
    model, model_fit_time = create_model_supervised(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 3200, in create_model_supervised
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 1051, in __call__
    while self.dispatch_one_batch(iterator):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 864, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 782, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
    result = ImmediateResult(func)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
    self.results = batch()
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/joblib/parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 560, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 607, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 87, in __call__
    score = scorer._score(cached_call, estimator,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 212, in _score
    return self._sign * self._score_func(y_true, y_pred,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 178, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 86, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 644, in check_array
    _assert_all_finite(array,
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/sklearn/utils/validation.py", line 96, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

2023-02-15 11:56:19,340:INFO:Initializing Lasso Least Angle Regression
2023-02-15 11:56:19,340:INFO:Total runtime is 0.048557507991790774 minutes
2023-02-15 11:56:19,346:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:19,347:INFO:Initializing create_model()
2023-02-15 11:56:19,347:INFO:create_model(estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:19,347:INFO:Checking exceptions
2023-02-15 11:56:19,347:INFO:Importing libraries
2023-02-15 11:56:19,347:INFO:Copying training dataset
2023-02-15 11:56:19,348:INFO:Defining folds
2023-02-15 11:56:19,348:INFO:Declaring metric variables
2023-02-15 11:56:19,353:INFO:Importing untrained model
2023-02-15 11:56:19,358:INFO:Lasso Least Angle Regression Imported succesfully
2023-02-15 11:56:19,368:INFO:Starting cross validation
2023-02-15 11:56:19,368:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:19,537:INFO:Calculating mean and std
2023-02-15 11:56:19,537:INFO:Creating metrics dataframe
2023-02-15 11:56:19,541:INFO:Uploading results into container
2023-02-15 11:56:19,541:INFO:Uploading model into container now
2023-02-15 11:56:19,541:INFO:create_model_container: 5
2023-02-15 11:56:19,541:INFO:master_model_container: 5
2023-02-15 11:56:19,541:INFO:display_container: 2
2023-02-15 11:56:19,542:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize=True,
          positive=False, precompute='auto', random_state=11, verbose=False)
2023-02-15 11:56:19,542:INFO:create_model() succesfully completed......................................
2023-02-15 11:56:19,662:INFO:SubProcess create_model() end ==================================
2023-02-15 11:56:19,662:INFO:Creating metrics dataframe
2023-02-15 11:56:19,669:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 11:56:19,669:INFO:Total runtime is 0.054040686289469404 minutes
2023-02-15 11:56:19,672:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:19,672:INFO:Initializing create_model()
2023-02-15 11:56:19,672:INFO:create_model(estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:19,672:INFO:Checking exceptions
2023-02-15 11:56:19,672:INFO:Importing libraries
2023-02-15 11:56:19,672:INFO:Copying training dataset
2023-02-15 11:56:19,673:INFO:Defining folds
2023-02-15 11:56:19,673:INFO:Declaring metric variables
2023-02-15 11:56:19,676:INFO:Importing untrained model
2023-02-15 11:56:19,679:INFO:Orthogonal Matching Pursuit Imported succesfully
2023-02-15 11:56:19,685:INFO:Starting cross validation
2023-02-15 11:56:19,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:19,842:INFO:Calculating mean and std
2023-02-15 11:56:19,843:INFO:Creating metrics dataframe
2023-02-15 11:56:19,846:INFO:Uploading results into container
2023-02-15 11:56:19,846:INFO:Uploading model into container now
2023-02-15 11:56:19,846:INFO:create_model_container: 6
2023-02-15 11:56:19,846:INFO:master_model_container: 6
2023-02-15 11:56:19,846:INFO:display_container: 2
2023-02-15 11:56:19,846:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize=True, precompute='auto', tol=None)
2023-02-15 11:56:19,846:INFO:create_model() succesfully completed......................................
2023-02-15 11:56:19,966:INFO:SubProcess create_model() end ==================================
2023-02-15 11:56:19,966:INFO:Creating metrics dataframe
2023-02-15 11:56:19,972:INFO:Initializing Bayesian Ridge
2023-02-15 11:56:19,972:INFO:Total runtime is 0.05910143852233887 minutes
2023-02-15 11:56:19,976:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:19,976:INFO:Initializing create_model()
2023-02-15 11:56:19,976:INFO:create_model(estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:19,976:INFO:Checking exceptions
2023-02-15 11:56:19,976:INFO:Importing libraries
2023-02-15 11:56:19,976:INFO:Copying training dataset
2023-02-15 11:56:19,977:INFO:Defining folds
2023-02-15 11:56:19,977:INFO:Declaring metric variables
2023-02-15 11:56:19,980:INFO:Importing untrained model
2023-02-15 11:56:19,983:INFO:Bayesian Ridge Imported succesfully
2023-02-15 11:56:19,989:INFO:Starting cross validation
2023-02-15 11:56:19,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:21,469:INFO:Calculating mean and std
2023-02-15 11:56:21,472:INFO:Creating metrics dataframe
2023-02-15 11:56:21,478:INFO:Uploading results into container
2023-02-15 11:56:21,479:INFO:Uploading model into container now
2023-02-15 11:56:21,479:INFO:create_model_container: 7
2023-02-15 11:56:21,479:INFO:master_model_container: 7
2023-02-15 11:56:21,479:INFO:display_container: 2
2023-02-15 11:56:21,479:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize=False, tol=0.001, verbose=False)
2023-02-15 11:56:21,479:INFO:create_model() succesfully completed......................................
2023-02-15 11:56:21,613:INFO:SubProcess create_model() end ==================================
2023-02-15 11:56:21,613:INFO:Creating metrics dataframe
2023-02-15 11:56:21,619:INFO:Initializing Passive Aggressive Regressor
2023-02-15 11:56:21,619:INFO:Total runtime is 0.08654760917027791 minutes
2023-02-15 11:56:21,622:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:21,623:INFO:Initializing create_model()
2023-02-15 11:56:21,623:INFO:create_model(estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:21,623:INFO:Checking exceptions
2023-02-15 11:56:21,623:INFO:Importing libraries
2023-02-15 11:56:21,623:INFO:Copying training dataset
2023-02-15 11:56:21,623:INFO:Defining folds
2023-02-15 11:56:21,623:INFO:Declaring metric variables
2023-02-15 11:56:21,627:INFO:Importing untrained model
2023-02-15 11:56:21,632:INFO:Passive Aggressive Regressor Imported succesfully
2023-02-15 11:56:21,640:INFO:Starting cross validation
2023-02-15 11:56:21,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:21,985:INFO:Calculating mean and std
2023-02-15 11:56:21,986:INFO:Creating metrics dataframe
2023-02-15 11:56:21,989:INFO:Uploading results into container
2023-02-15 11:56:21,990:INFO:Uploading model into container now
2023-02-15 11:56:21,990:INFO:create_model_container: 8
2023-02-15 11:56:21,990:INFO:master_model_container: 8
2023-02-15 11:56:21,990:INFO:display_container: 2
2023-02-15 11:56:21,990:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=11, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-15 11:56:21,990:INFO:create_model() succesfully completed......................................
2023-02-15 11:56:22,114:INFO:SubProcess create_model() end ==================================
2023-02-15 11:56:22,114:INFO:Creating metrics dataframe
2023-02-15 11:56:22,121:INFO:Initializing Huber Regressor
2023-02-15 11:56:22,121:INFO:Total runtime is 0.09492040475209554 minutes
2023-02-15 11:56:22,125:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:22,125:INFO:Initializing create_model()
2023-02-15 11:56:22,125:INFO:create_model(estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:22,125:INFO:Checking exceptions
2023-02-15 11:56:22,125:INFO:Importing libraries
2023-02-15 11:56:22,125:INFO:Copying training dataset
2023-02-15 11:56:22,126:INFO:Defining folds
2023-02-15 11:56:22,126:INFO:Declaring metric variables
2023-02-15 11:56:22,129:INFO:Importing untrained model
2023-02-15 11:56:22,132:INFO:Huber Regressor Imported succesfully
2023-02-15 11:56:22,138:INFO:Starting cross validation
2023-02-15 11:56:22,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:38,694:INFO:Calculating mean and std
2023-02-15 11:56:38,695:INFO:Creating metrics dataframe
2023-02-15 11:56:38,698:INFO:Uploading results into container
2023-02-15 11:56:38,698:INFO:Uploading model into container now
2023-02-15 11:56:38,698:INFO:create_model_container: 9
2023-02-15 11:56:38,698:INFO:master_model_container: 9
2023-02-15 11:56:38,698:INFO:display_container: 2
2023-02-15 11:56:38,699:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-02-15 11:56:38,699:INFO:create_model() succesfully completed......................................
2023-02-15 11:56:38,824:INFO:SubProcess create_model() end ==================================
2023-02-15 11:56:38,824:INFO:Creating metrics dataframe
2023-02-15 11:56:38,831:INFO:Initializing K Neighbors Regressor
2023-02-15 11:56:38,831:INFO:Total runtime is 0.37341187000274656 minutes
2023-02-15 11:56:38,834:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:38,835:INFO:Initializing create_model()
2023-02-15 11:56:38,835:INFO:create_model(estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:38,835:INFO:Checking exceptions
2023-02-15 11:56:38,835:INFO:Importing libraries
2023-02-15 11:56:38,835:INFO:Copying training dataset
2023-02-15 11:56:38,835:INFO:Defining folds
2023-02-15 11:56:38,835:INFO:Declaring metric variables
2023-02-15 11:56:38,839:INFO:Importing untrained model
2023-02-15 11:56:38,842:INFO:K Neighbors Regressor Imported succesfully
2023-02-15 11:56:38,848:INFO:Starting cross validation
2023-02-15 11:56:38,848:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:56:44,371:INFO:Calculating mean and std
2023-02-15 11:56:44,372:INFO:Creating metrics dataframe
2023-02-15 11:56:44,377:INFO:Uploading results into container
2023-02-15 11:56:44,377:INFO:Uploading model into container now
2023-02-15 11:56:44,377:INFO:create_model_container: 10
2023-02-15 11:56:44,377:INFO:master_model_container: 10
2023-02-15 11:56:44,377:INFO:display_container: 2
2023-02-15 11:56:44,377:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-02-15 11:56:44,377:INFO:create_model() succesfully completed......................................
2023-02-15 11:56:44,490:INFO:SubProcess create_model() end ==================================
2023-02-15 11:56:44,490:INFO:Creating metrics dataframe
2023-02-15 11:56:44,497:INFO:Initializing Decision Tree Regressor
2023-02-15 11:56:44,497:INFO:Total runtime is 0.46785362164179484 minutes
2023-02-15 11:56:44,501:INFO:SubProcess create_model() called ==================================
2023-02-15 11:56:44,501:INFO:Initializing create_model()
2023-02-15 11:56:44,501:INFO:create_model(estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:56:44,501:INFO:Checking exceptions
2023-02-15 11:56:44,501:INFO:Importing libraries
2023-02-15 11:56:44,501:INFO:Copying training dataset
2023-02-15 11:56:44,502:INFO:Defining folds
2023-02-15 11:56:44,502:INFO:Declaring metric variables
2023-02-15 11:56:44,505:INFO:Importing untrained model
2023-02-15 11:56:44,508:INFO:Decision Tree Regressor Imported succesfully
2023-02-15 11:56:44,515:INFO:Starting cross validation
2023-02-15 11:56:44,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:57:06,232:INFO:Calculating mean and std
2023-02-15 11:57:06,232:INFO:Creating metrics dataframe
2023-02-15 11:57:06,235:INFO:Uploading results into container
2023-02-15 11:57:06,235:INFO:Uploading model into container now
2023-02-15 11:57:06,235:INFO:create_model_container: 11
2023-02-15 11:57:06,235:INFO:master_model_container: 11
2023-02-15 11:57:06,235:INFO:display_container: 2
2023-02-15 11:57:06,235:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=11, splitter='best')
2023-02-15 11:57:06,235:INFO:create_model() succesfully completed......................................
2023-02-15 11:57:06,335:INFO:SubProcess create_model() end ==================================
2023-02-15 11:57:06,335:INFO:Creating metrics dataframe
2023-02-15 11:57:06,342:INFO:Initializing Random Forest Regressor
2023-02-15 11:57:06,342:INFO:Total runtime is 0.8319366733233133 minutes
2023-02-15 11:57:06,346:INFO:SubProcess create_model() called ==================================
2023-02-15 11:57:06,346:INFO:Initializing create_model()
2023-02-15 11:57:06,346:INFO:create_model(estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:57:06,346:INFO:Checking exceptions
2023-02-15 11:57:06,346:INFO:Importing libraries
2023-02-15 11:57:06,346:INFO:Copying training dataset
2023-02-15 11:57:06,347:INFO:Defining folds
2023-02-15 11:57:06,347:INFO:Declaring metric variables
2023-02-15 11:57:06,350:INFO:Importing untrained model
2023-02-15 11:57:06,353:INFO:Random Forest Regressor Imported succesfully
2023-02-15 11:57:06,360:INFO:Starting cross validation
2023-02-15 11:57:06,360:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:58:33,575:INFO:Calculating mean and std
2023-02-15 11:58:33,576:INFO:Creating metrics dataframe
2023-02-15 11:58:33,578:INFO:Uploading results into container
2023-02-15 11:58:33,579:INFO:Uploading model into container now
2023-02-15 11:58:33,579:INFO:create_model_container: 12
2023-02-15 11:58:33,579:INFO:master_model_container: 12
2023-02-15 11:58:33,579:INFO:display_container: 2
2023-02-15 11:58:33,579:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=11, verbose=0, warm_start=False)
2023-02-15 11:58:33,579:INFO:create_model() succesfully completed......................................
2023-02-15 11:58:33,689:INFO:SubProcess create_model() end ==================================
2023-02-15 11:58:33,689:INFO:Creating metrics dataframe
2023-02-15 11:58:33,698:INFO:Initializing Extra Trees Regressor
2023-02-15 11:58:33,698:INFO:Total runtime is 2.2878700256347653 minutes
2023-02-15 11:58:33,702:INFO:SubProcess create_model() called ==================================
2023-02-15 11:58:33,702:INFO:Initializing create_model()
2023-02-15 11:58:33,702:INFO:create_model(estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:58:33,702:INFO:Checking exceptions
2023-02-15 11:58:33,702:INFO:Importing libraries
2023-02-15 11:58:33,702:INFO:Copying training dataset
2023-02-15 11:58:33,703:INFO:Defining folds
2023-02-15 11:58:33,703:INFO:Declaring metric variables
2023-02-15 11:58:33,706:INFO:Importing untrained model
2023-02-15 11:58:33,709:INFO:Extra Trees Regressor Imported succesfully
2023-02-15 11:58:33,715:INFO:Starting cross validation
2023-02-15 11:58:33,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 11:58:59,642:INFO:Calculating mean and std
2023-02-15 11:58:59,643:INFO:Creating metrics dataframe
2023-02-15 11:58:59,645:INFO:Uploading results into container
2023-02-15 11:58:59,645:INFO:Uploading model into container now
2023-02-15 11:58:59,645:INFO:create_model_container: 13
2023-02-15 11:58:59,645:INFO:master_model_container: 13
2023-02-15 11:58:59,645:INFO:display_container: 2
2023-02-15 11:58:59,646:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-15 11:58:59,646:INFO:create_model() succesfully completed......................................
2023-02-15 11:58:59,757:INFO:SubProcess create_model() end ==================================
2023-02-15 11:58:59,757:INFO:Creating metrics dataframe
2023-02-15 11:58:59,764:INFO:Initializing AdaBoost Regressor
2023-02-15 11:58:59,765:INFO:Total runtime is 2.7223049084345496 minutes
2023-02-15 11:58:59,768:INFO:SubProcess create_model() called ==================================
2023-02-15 11:58:59,769:INFO:Initializing create_model()
2023-02-15 11:58:59,769:INFO:create_model(estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 11:58:59,769:INFO:Checking exceptions
2023-02-15 11:58:59,769:INFO:Importing libraries
2023-02-15 11:58:59,769:INFO:Copying training dataset
2023-02-15 11:58:59,769:INFO:Defining folds
2023-02-15 11:58:59,769:INFO:Declaring metric variables
2023-02-15 11:58:59,772:INFO:Importing untrained model
2023-02-15 11:58:59,775:INFO:AdaBoost Regressor Imported succesfully
2023-02-15 11:58:59,781:INFO:Starting cross validation
2023-02-15 11:58:59,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:00:13,212:INFO:Calculating mean and std
2023-02-15 12:00:13,212:INFO:Creating metrics dataframe
2023-02-15 12:00:13,215:INFO:Uploading results into container
2023-02-15 12:00:13,215:INFO:Uploading model into container now
2023-02-15 12:00:13,215:INFO:create_model_container: 14
2023-02-15 12:00:13,215:INFO:master_model_container: 14
2023-02-15 12:00:13,215:INFO:display_container: 2
2023-02-15 12:00:13,215:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=11)
2023-02-15 12:00:13,215:INFO:create_model() succesfully completed......................................
2023-02-15 12:00:13,325:INFO:SubProcess create_model() end ==================================
2023-02-15 12:00:13,325:INFO:Creating metrics dataframe
2023-02-15 12:00:13,333:INFO:Initializing Gradient Boosting Regressor
2023-02-15 12:00:13,334:INFO:Total runtime is 3.9484563867251072 minutes
2023-02-15 12:00:13,338:INFO:SubProcess create_model() called ==================================
2023-02-15 12:00:13,338:INFO:Initializing create_model()
2023-02-15 12:00:13,338:INFO:create_model(estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 12:00:13,338:INFO:Checking exceptions
2023-02-15 12:00:13,338:INFO:Importing libraries
2023-02-15 12:00:13,338:INFO:Copying training dataset
2023-02-15 12:00:13,339:INFO:Defining folds
2023-02-15 12:00:13,339:INFO:Declaring metric variables
2023-02-15 12:00:13,343:INFO:Importing untrained model
2023-02-15 12:00:13,346:INFO:Gradient Boosting Regressor Imported succesfully
2023-02-15 12:00:13,353:INFO:Starting cross validation
2023-02-15 12:00:13,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:06:35,343:INFO:Calculating mean and std
2023-02-15 12:06:35,343:INFO:Creating metrics dataframe
2023-02-15 12:06:35,346:INFO:Uploading results into container
2023-02-15 12:06:35,346:INFO:Uploading model into container now
2023-02-15 12:06:35,346:INFO:create_model_container: 15
2023-02-15 12:06:35,346:INFO:master_model_container: 15
2023-02-15 12:06:35,346:INFO:display_container: 2
2023-02-15 12:06:35,346:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='ls', max_depth=3,
                          max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=100,
                          n_iter_no_change=None, presort='deprecated',
                          random_state=11, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-15 12:06:35,346:INFO:create_model() succesfully completed......................................
2023-02-15 12:06:35,445:INFO:SubProcess create_model() end ==================================
2023-02-15 12:06:35,445:INFO:Creating metrics dataframe
2023-02-15 12:06:35,452:INFO:Initializing Extreme Gradient Boosting
2023-02-15 12:06:35,453:INFO:Total runtime is 10.317105392615 minutes
2023-02-15 12:06:35,456:INFO:SubProcess create_model() called ==================================
2023-02-15 12:06:35,456:INFO:Initializing create_model()
2023-02-15 12:06:35,456:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 12:06:35,456:INFO:Checking exceptions
2023-02-15 12:06:35,456:INFO:Importing libraries
2023-02-15 12:06:35,456:INFO:Copying training dataset
2023-02-15 12:06:35,457:INFO:Defining folds
2023-02-15 12:06:35,457:INFO:Declaring metric variables
2023-02-15 12:06:35,460:INFO:Importing untrained model
2023-02-15 12:06:35,464:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-15 12:06:35,469:INFO:Starting cross validation
2023-02-15 12:06:35,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:06:36,078:INFO:Calculating mean and std
2023-02-15 12:06:36,079:INFO:Creating metrics dataframe
2023-02-15 12:06:36,081:INFO:Uploading results into container
2023-02-15 12:06:36,081:INFO:Uploading model into container now
2023-02-15 12:06:36,081:INFO:create_model_container: 16
2023-02-15 12:06:36,081:INFO:master_model_container: 16
2023-02-15 12:06:36,081:INFO:display_container: 2
2023-02-15 12:06:36,082:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-15 12:06:36,082:INFO:create_model() succesfully completed......................................
2023-02-15 12:06:36,188:WARNING:create_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 12:06:36,188:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2205, in compare_models
    assert np.sum(model_results.iloc[0]) != 0.0
AssertionError

2023-02-15 12:06:36,189:INFO:Initializing create_model()
2023-02-15 12:06:36,189:INFO:create_model(estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 12:06:36,189:INFO:Checking exceptions
2023-02-15 12:06:36,189:INFO:Importing libraries
2023-02-15 12:06:36,189:INFO:Copying training dataset
2023-02-15 12:06:36,189:INFO:Defining folds
2023-02-15 12:06:36,190:INFO:Declaring metric variables
2023-02-15 12:06:36,193:INFO:Importing untrained model
2023-02-15 12:06:36,196:INFO:Extreme Gradient Boosting Imported succesfully
2023-02-15 12:06:36,202:INFO:Starting cross validation
2023-02-15 12:06:36,202:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:06:36,718:INFO:Calculating mean and std
2023-02-15 12:06:36,719:INFO:Creating metrics dataframe
2023-02-15 12:06:36,722:INFO:Uploading results into container
2023-02-15 12:06:36,722:INFO:Uploading model into container now
2023-02-15 12:06:36,722:INFO:create_model_container: 17
2023-02-15 12:06:36,722:INFO:master_model_container: 17
2023-02-15 12:06:36,722:INFO:display_container: 2
2023-02-15 12:06:36,722:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-02-15 12:06:36,722:INFO:create_model() succesfully completed......................................
2023-02-15 12:06:36,833:ERROR:create_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...) raised an exception or returned all 0.0:
2023-02-15 12:06:36,833:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2205, in compare_models
    assert np.sum(model_results.iloc[0]) != 0.0
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.9/site-packages/pycaret/internal/tabular.py", line 2214, in compare_models
    assert np.sum(model_results.iloc[0]) != 0.0
AssertionError

2023-02-15 12:06:36,833:INFO:Initializing Light Gradient Boosting Machine
2023-02-15 12:06:36,833:INFO:Total runtime is 10.340111227830251 minutes
2023-02-15 12:06:36,838:INFO:SubProcess create_model() called ==================================
2023-02-15 12:06:36,838:INFO:Initializing create_model()
2023-02-15 12:06:36,838:INFO:create_model(estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 12:06:36,838:INFO:Checking exceptions
2023-02-15 12:06:36,838:INFO:Importing libraries
2023-02-15 12:06:36,838:INFO:Copying training dataset
2023-02-15 12:06:36,839:INFO:Defining folds
2023-02-15 12:06:36,839:INFO:Declaring metric variables
2023-02-15 12:06:36,842:INFO:Importing untrained model
2023-02-15 12:06:36,845:INFO:Light Gradient Boosting Machine Imported succesfully
2023-02-15 12:06:36,852:INFO:Starting cross validation
2023-02-15 12:06:36,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:06:41,530:INFO:Calculating mean and std
2023-02-15 12:06:41,531:INFO:Creating metrics dataframe
2023-02-15 12:06:41,534:INFO:Uploading results into container
2023-02-15 12:06:41,534:INFO:Uploading model into container now
2023-02-15 12:06:41,534:INFO:create_model_container: 18
2023-02-15 12:06:41,534:INFO:master_model_container: 18
2023-02-15 12:06:41,534:INFO:display_container: 2
2023-02-15 12:06:41,534:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=11, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2023-02-15 12:06:41,534:INFO:create_model() succesfully completed......................................
2023-02-15 12:06:41,647:INFO:SubProcess create_model() end ==================================
2023-02-15 12:06:41,647:INFO:Creating metrics dataframe
2023-02-15 12:06:41,657:INFO:Initializing CatBoost Regressor
2023-02-15 12:06:41,657:INFO:Total runtime is 10.420518147945405 minutes
2023-02-15 12:06:41,662:INFO:SubProcess create_model() called ==================================
2023-02-15 12:06:41,662:INFO:Initializing create_model()
2023-02-15 12:06:41,662:INFO:create_model(estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 12:06:41,662:INFO:Checking exceptions
2023-02-15 12:06:41,662:INFO:Importing libraries
2023-02-15 12:06:41,662:INFO:Copying training dataset
2023-02-15 12:06:41,663:INFO:Defining folds
2023-02-15 12:06:41,663:INFO:Declaring metric variables
2023-02-15 12:06:41,666:INFO:Importing untrained model
2023-02-15 12:06:41,670:INFO:CatBoost Regressor Imported succesfully
2023-02-15 12:06:41,678:INFO:Starting cross validation
2023-02-15 12:06:41,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:07:10,542:INFO:Calculating mean and std
2023-02-15 12:07:10,542:INFO:Creating metrics dataframe
2023-02-15 12:07:10,544:INFO:Uploading results into container
2023-02-15 12:07:10,544:INFO:Uploading model into container now
2023-02-15 12:07:10,544:INFO:create_model_container: 19
2023-02-15 12:07:10,544:INFO:master_model_container: 19
2023-02-15 12:07:10,544:INFO:display_container: 2
2023-02-15 12:07:10,544:INFO:<catboost.core.CatBoostRegressor object at 0x7f79581de040>
2023-02-15 12:07:10,544:INFO:create_model() succesfully completed......................................
2023-02-15 12:07:10,641:INFO:SubProcess create_model() end ==================================
2023-02-15 12:07:10,641:INFO:Creating metrics dataframe
2023-02-15 12:07:10,649:INFO:Initializing Dummy Regressor
2023-02-15 12:07:10,649:INFO:Total runtime is 10.90371212164561 minutes
2023-02-15 12:07:10,652:INFO:SubProcess create_model() called ==================================
2023-02-15 12:07:10,652:INFO:Initializing create_model()
2023-02-15 12:07:10,652:INFO:create_model(estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x7f79c10c0100>, return_train_score=False, kwargs={})
2023-02-15 12:07:10,652:INFO:Checking exceptions
2023-02-15 12:07:10,652:INFO:Importing libraries
2023-02-15 12:07:10,652:INFO:Copying training dataset
2023-02-15 12:07:10,653:INFO:Defining folds
2023-02-15 12:07:10,653:INFO:Declaring metric variables
2023-02-15 12:07:10,656:INFO:Importing untrained model
2023-02-15 12:07:10,659:INFO:Dummy Regressor Imported succesfully
2023-02-15 12:07:10,666:INFO:Starting cross validation
2023-02-15 12:07:10,666:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:07:10,694:INFO:Calculating mean and std
2023-02-15 12:07:10,694:INFO:Creating metrics dataframe
2023-02-15 12:07:10,696:INFO:Uploading results into container
2023-02-15 12:07:10,696:INFO:Uploading model into container now
2023-02-15 12:07:10,696:INFO:create_model_container: 20
2023-02-15 12:07:10,696:INFO:master_model_container: 20
2023-02-15 12:07:10,696:INFO:display_container: 2
2023-02-15 12:07:10,696:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-02-15 12:07:10,696:INFO:create_model() succesfully completed......................................
2023-02-15 12:07:10,790:INFO:SubProcess create_model() end ==================================
2023-02-15 12:07:10,790:INFO:Creating metrics dataframe
2023-02-15 12:07:10,805:INFO:Initializing create_model()
2023-02-15 12:07:10,805:INFO:create_model(estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-02-15 12:07:10,805:INFO:Checking exceptions
2023-02-15 12:07:10,805:INFO:Importing libraries
2023-02-15 12:07:10,805:INFO:Copying training dataset
2023-02-15 12:07:10,805:INFO:Defining folds
2023-02-15 12:07:10,806:INFO:Declaring metric variables
2023-02-15 12:07:10,806:INFO:Importing untrained model
2023-02-15 12:07:10,806:INFO:Declaring custom model
2023-02-15 12:07:10,806:INFO:Extra Trees Regressor Imported succesfully
2023-02-15 12:07:10,806:INFO:Cross validation set to False
2023-02-15 12:07:10,806:INFO:Fitting Model
2023-02-15 12:07:12,411:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-15 12:07:12,411:INFO:create_models() succesfully completed......................................
2023-02-15 12:07:12,523:INFO:create_model_container: 20
2023-02-15 12:07:12,523:INFO:master_model_container: 20
2023-02-15 12:07:12,523:INFO:display_container: 2
2023-02-15 12:07:12,523:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',
                    max_depth=None, max_features='auto', max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_impurity_split=None, min_samples_leaf=1,
                    min_samples_split=2, min_weight_fraction_leaf=0.0,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=11, verbose=0, warm_start=False)
2023-02-15 12:07:12,523:INFO:compare_models() succesfully completed......................................
2023-02-15 12:43:46,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:43:46,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:43:46,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:43:46,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:43:46,296:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 12:44:02,942:INFO:PyCaret RegressionExperiment
2023-02-15 12:44:02,943:INFO:Logging name: reg-default-name
2023-02-15 12:44:02,943:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 12:44:02,943:INFO:version 3.0.0.rc9
2023-02-15 12:44:02,943:INFO:Initializing setup()
2023-02-15 12:44:02,943:INFO:self.USI: a748
2023-02-15 12:44:02,943:INFO:self._variable_keys: {'idx', 'X_train', 'y_test', 'target_param', 'exp_name_log', 'seed', 'y_train', 'X_test', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'fold_generator', 'n_jobs_param', 'transform_target_param', '_ml_usecase', 'logging_param', 'y', '_available_plots', 'html_param', 'fold_groups_param', 'USI', 'gpu_param', 'data', 'X', 'exp_id', 'log_plots_param', 'memory'}
2023-02-15 12:44:02,943:INFO:Checking environment
2023-02-15 12:44:02,943:INFO:python_version: 3.8.16
2023-02-15 12:44:02,943:INFO:python_build: ('default', 'Jan 17 2023 23:13:24')
2023-02-15 12:44:02,943:INFO:machine: x86_64
2023-02-15 12:44:02,943:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 12:44:02,943:INFO:Memory: svmem(total=134979592192, available=121149751296, percent=10.2, used=12064428032, free=91840167936, active=5148844032, inactive=34865082368, buffers=1642778624, cached=29432217600, shared=503029760, slab=2521853952)
2023-02-15 12:44:02,944:INFO:Physical Core: 16
2023-02-15 12:44:02,944:INFO:Logical Core: 32
2023-02-15 12:44:02,944:INFO:Checking libraries
2023-02-15 12:44:02,944:INFO:System:
2023-02-15 12:44:02,944:INFO:    python: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0]
2023-02-15 12:44:02,944:INFO:executable: /home/moussa/anaconda3/envs/research2/bin/python
2023-02-15 12:44:02,944:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 12:44:02,944:INFO:PyCaret required dependencies:
2023-02-15 12:44:02,944:INFO:                 pip: 22.3.1
2023-02-15 12:44:02,944:INFO:          setuptools: 60.10.0
2023-02-15 12:44:02,944:INFO:             pycaret: 3.0.0rc9
2023-02-15 12:44:02,944:INFO:             IPython: 7.31.1
2023-02-15 12:44:02,944:INFO:          ipywidgets: 7.7.3
2023-02-15 12:44:02,944:INFO:                tqdm: 4.64.1
2023-02-15 12:44:02,944:INFO:               numpy: 1.23.5
2023-02-15 12:44:02,944:INFO:              pandas: 1.5.3
2023-02-15 12:44:02,944:INFO:              jinja2: 3.1.2
2023-02-15 12:44:02,944:INFO:               scipy: 1.9.1
2023-02-15 12:44:02,944:INFO:              joblib: 1.2.0
2023-02-15 12:44:02,944:INFO:             sklearn: 1.2.1
2023-02-15 12:44:02,944:INFO:                pyod: 1.0.7
2023-02-15 12:44:02,944:INFO:            imblearn: 0.10.1
2023-02-15 12:44:02,944:INFO:   category_encoders: 2.6.0
2023-02-15 12:44:02,944:INFO:            lightgbm: 3.3.5
2023-02-15 12:44:02,944:INFO:               numba: 0.56.4
2023-02-15 12:44:02,944:INFO:            requests: 2.28.1
2023-02-15 12:44:02,945:INFO:          matplotlib: 3.6.3
2023-02-15 12:44:02,945:INFO:          scikitplot: 0.3.7
2023-02-15 12:44:02,945:INFO:         yellowbrick: 1.5
2023-02-15 12:44:02,945:INFO:              plotly: 5.13.0
2023-02-15 12:44:02,945:INFO:             kaleido: 0.2.1
2023-02-15 12:44:02,945:INFO:         statsmodels: 0.13.5
2023-02-15 12:44:02,945:INFO:              sktime: 0.16.1
2023-02-15 12:44:02,945:INFO:               tbats: 1.1.2
2023-02-15 12:44:02,945:INFO:            pmdarima: 2.0.2
2023-02-15 12:44:02,945:INFO:              psutil: 5.9.0
2023-02-15 12:44:02,945:INFO:PyCaret optional dependencies:
2023-02-15 12:44:03,247:INFO:                shap: 0.41.0
2023-02-15 12:44:03,247:INFO:           interpret: 0.3.0
2023-02-15 12:44:03,247:INFO:                umap: 0.5.3
2023-02-15 12:44:03,247:INFO:    pandas_profiling: 4.0.0
2023-02-15 12:44:03,247:INFO:  explainerdashboard: 0.4.2
2023-02-15 12:44:03,247:INFO:             autoviz: 0.1.58
2023-02-15 12:44:03,247:INFO:           fairlearn: 0.7.0
2023-02-15 12:44:03,247:INFO:             xgboost: 1.7.3
2023-02-15 12:44:03,247:INFO:            catboost: 1.1.1
2023-02-15 12:44:03,247:INFO:              kmodes: 0.12.2
2023-02-15 12:44:03,248:INFO:             mlxtend: 0.21.0
2023-02-15 12:44:03,248:INFO:       statsforecast: 1.4.0
2023-02-15 12:44:03,248:INFO:        tune_sklearn: 0.4.5
2023-02-15 12:44:03,248:INFO:                 ray: 2.2.0
2023-02-15 12:44:03,248:INFO:            hyperopt: 0.2.7
2023-02-15 12:44:03,248:INFO:              optuna: 3.1.0
2023-02-15 12:44:03,248:INFO:               skopt: 0.9.0
2023-02-15 12:44:03,248:INFO:              mlflow: 1.30.0
2023-02-15 12:44:03,248:INFO:              gradio: 3.18.0
2023-02-15 12:44:03,248:INFO:             fastapi: 0.92.0
2023-02-15 12:44:03,248:INFO:             uvicorn: 0.20.0
2023-02-15 12:44:03,248:INFO:              m2cgen: 0.10.0
2023-02-15 12:44:03,248:INFO:           evidently: 0.2.4
2023-02-15 12:44:03,248:INFO:               fugue: 0.8.1.dev4
2023-02-15 12:44:03,248:INFO:           streamlit: Not installed
2023-02-15 12:44:03,248:INFO:             prophet: Not installed
2023-02-15 12:44:03,248:INFO:None
2023-02-15 12:44:03,248:INFO:Set up GPU usage.
2023-02-15 12:44:03,248:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,248:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 12:44:03,248:INFO:Set up data.
2023-02-15 12:44:03,306:INFO:Set up train/test split.
2023-02-15 12:44:03,335:INFO:Set up index.
2023-02-15 12:44:03,341:INFO:Set up folding strategy.
2023-02-15 12:44:03,341:INFO:Assigning column types.
2023-02-15 12:44:03,352:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 12:44:03,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,353:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,355:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,358:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,399:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,426:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,427:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:03,506:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:03,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,521:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,523:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,523:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,526:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,596:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,596:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:03,601:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:03,606:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 12:44:03,606:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,606:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,609:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,611:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,678:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:03,681:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:03,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,689:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,691:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,763:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,764:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:03,767:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:03,772:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 12:44:03,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,778:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,820:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,847:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,847:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,847:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:03,850:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:03,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,859:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,861:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,903:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,903:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,930:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,930:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,930:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,930:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:03,933:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:03,938:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 12:44:03,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,941:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:03,986:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:03,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,013:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:04,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,014:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:04,017:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:04,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,068:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:04,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:04,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,096:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:04,099:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:04,104:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 12:44:04,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,151:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:04,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,178:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:04,181:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:04,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:04,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,270:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:04,273:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:04,278:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 12:44:04,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,324:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,352:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:04,356:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:04,361:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,361:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,434:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,434:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,435:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:04,438:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:04,443:INFO:Preparing preprocessing pipeline...
2023-02-15 12:44:04,444:INFO:Set up column name cleaning.
2023-02-15 12:44:04,444:INFO:Set up simple imputation.
2023-02-15 12:44:04,444:INFO:Set up feature normalization.
2023-02-15 12:44:04,505:INFO:Finished creating preprocessing pipeline.
2023-02-15 12:44:04,509:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 12:44:04,509:INFO:Creating final display dataframe.
2023-02-15 12:44:04,804:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28657, 164)
4        Transformed data shape           (28657, 159)
5   Transformed train set shape           (20059, 159)
6    Transformed test set shape            (8598, 159)
7               Ignore features                      5
8              Numeric features                    158
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   a748
2023-02-15 12:44:04,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,883:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,883:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,883:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:04,887:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:04,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:04,966:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:04,969:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:04,974:INFO:setup() successfully completed in 2.03s...............
2023-02-15 12:44:04,974:INFO:Initializing compare_models()
2023-02-15 12:44:04,974:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f473bdb2280>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f473bdb2280>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 12:44:04,974:INFO:Checking exceptions
2023-02-15 12:44:04,977:INFO:Preparing display monitor
2023-02-15 12:44:04,991:INFO:Initializing Linear Regression
2023-02-15 12:44:04,991:INFO:Total runtime is 1.7841657002766927e-06 minutes
2023-02-15 12:44:04,993:INFO:SubProcess create_model() called ==================================
2023-02-15 12:44:04,993:INFO:Initializing create_model()
2023-02-15 12:44:04,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f473bdb2280>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4695ae4b50>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:44:04,993:INFO:Checking exceptions
2023-02-15 12:44:04,993:INFO:Importing libraries
2023-02-15 12:44:04,993:INFO:Copying training dataset
2023-02-15 12:44:05,006:INFO:Defining folds
2023-02-15 12:44:05,006:INFO:Declaring metric variables
2023-02-15 12:44:05,008:INFO:Importing untrained model
2023-02-15 12:44:05,009:INFO:Linear Regression Imported successfully
2023-02-15 12:44:05,013:INFO:Starting cross validation
2023-02-15 12:44:05,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:44:06,677:INFO:Calculating mean and std
2023-02-15 12:44:06,678:INFO:Creating metrics dataframe
2023-02-15 12:44:06,681:INFO:Uploading results into container
2023-02-15 12:44:06,681:INFO:Uploading model into container now
2023-02-15 12:44:06,681:INFO:_master_model_container: 1
2023-02-15 12:44:06,681:INFO:_display_container: 2
2023-02-15 12:44:06,682:INFO:LinearRegression(n_jobs=-1)
2023-02-15 12:44:06,682:INFO:create_model() successfully completed......................................
2023-02-15 12:44:06,803:INFO:SubProcess create_model() end ==================================
2023-02-15 12:44:06,803:INFO:Creating metrics dataframe
2023-02-15 12:44:06,808:INFO:Initializing Lasso Regression
2023-02-15 12:44:06,808:INFO:Total runtime is 0.030281424522399902 minutes
2023-02-15 12:44:06,810:INFO:SubProcess create_model() called ==================================
2023-02-15 12:44:06,810:INFO:Initializing create_model()
2023-02-15 12:44:06,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f473bdb2280>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4695ae4b50>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:44:06,810:INFO:Checking exceptions
2023-02-15 12:44:06,810:INFO:Importing libraries
2023-02-15 12:44:06,810:INFO:Copying training dataset
2023-02-15 12:44:06,825:INFO:Defining folds
2023-02-15 12:44:06,825:INFO:Declaring metric variables
2023-02-15 12:44:06,827:INFO:Importing untrained model
2023-02-15 12:44:06,829:INFO:Lasso Regression Imported successfully
2023-02-15 12:44:06,831:INFO:Starting cross validation
2023-02-15 12:44:06,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:44:08,088:INFO:Calculating mean and std
2023-02-15 12:44:08,090:INFO:Creating metrics dataframe
2023-02-15 12:44:08,092:INFO:Uploading results into container
2023-02-15 12:44:08,093:INFO:Uploading model into container now
2023-02-15 12:44:08,093:INFO:_master_model_container: 2
2023-02-15 12:44:08,093:INFO:_display_container: 2
2023-02-15 12:44:08,093:INFO:Lasso(random_state=11)
2023-02-15 12:44:08,093:INFO:create_model() successfully completed......................................
2023-02-15 12:44:08,228:INFO:SubProcess create_model() end ==================================
2023-02-15 12:44:08,228:INFO:Creating metrics dataframe
2023-02-15 12:44:08,234:INFO:Initializing Ridge Regression
2023-02-15 12:44:08,234:INFO:Total runtime is 0.054039414723714194 minutes
2023-02-15 12:44:08,235:INFO:SubProcess create_model() called ==================================
2023-02-15 12:44:08,235:INFO:Initializing create_model()
2023-02-15 12:44:08,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f473bdb2280>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4695ae4b50>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:44:08,236:INFO:Checking exceptions
2023-02-15 12:44:08,236:INFO:Importing libraries
2023-02-15 12:44:08,236:INFO:Copying training dataset
2023-02-15 12:44:08,250:INFO:Defining folds
2023-02-15 12:44:08,250:INFO:Declaring metric variables
2023-02-15 12:44:08,252:INFO:Importing untrained model
2023-02-15 12:44:08,254:INFO:Ridge Regression Imported successfully
2023-02-15 12:44:08,257:INFO:Starting cross validation
2023-02-15 12:44:08,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:44:46,645:INFO:PyCaret RegressionExperiment
2023-02-15 12:44:46,645:INFO:Logging name: reg-default-name
2023-02-15 12:44:46,645:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 12:44:46,645:INFO:version 3.0.0.rc9
2023-02-15 12:44:46,645:INFO:Initializing setup()
2023-02-15 12:44:46,645:INFO:self.USI: faac
2023-02-15 12:44:46,646:INFO:self._variable_keys: {'idx', 'X_train', 'y_test', 'target_param', 'exp_name_log', 'seed', 'y_train', 'X_test', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'fold_generator', 'n_jobs_param', 'transform_target_param', '_ml_usecase', 'logging_param', 'y', '_available_plots', 'html_param', 'fold_groups_param', 'USI', 'gpu_param', 'data', 'X', 'exp_id', 'log_plots_param', 'memory'}
2023-02-15 12:44:46,646:INFO:Checking environment
2023-02-15 12:44:46,646:INFO:python_version: 3.8.16
2023-02-15 12:44:46,646:INFO:python_build: ('default', 'Jan 17 2023 23:13:24')
2023-02-15 12:44:46,646:INFO:machine: x86_64
2023-02-15 12:44:46,646:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 12:44:46,646:INFO:Memory: svmem(total=134979592192, available=120961564672, percent=10.4, used=12251025408, free=91651723264, active=5152251904, inactive=35042189312, buffers=1643012096, cached=29433831424, shared=504639488, slab=2522374144)
2023-02-15 12:44:46,647:INFO:Physical Core: 16
2023-02-15 12:44:46,647:INFO:Logical Core: 32
2023-02-15 12:44:46,647:INFO:Checking libraries
2023-02-15 12:44:46,647:INFO:System:
2023-02-15 12:44:46,647:INFO:    python: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0]
2023-02-15 12:44:46,647:INFO:executable: /home/moussa/anaconda3/envs/research2/bin/python
2023-02-15 12:44:46,647:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 12:44:46,647:INFO:PyCaret required dependencies:
2023-02-15 12:44:46,647:INFO:                 pip: 22.3.1
2023-02-15 12:44:46,647:INFO:          setuptools: 60.10.0
2023-02-15 12:44:46,647:INFO:             pycaret: 3.0.0rc9
2023-02-15 12:44:46,647:INFO:             IPython: 7.31.1
2023-02-15 12:44:46,647:INFO:          ipywidgets: 7.7.3
2023-02-15 12:44:46,647:INFO:                tqdm: 4.64.1
2023-02-15 12:44:46,647:INFO:               numpy: 1.23.5
2023-02-15 12:44:46,647:INFO:              pandas: 1.5.3
2023-02-15 12:44:46,647:INFO:              jinja2: 3.1.2
2023-02-15 12:44:46,647:INFO:               scipy: 1.9.1
2023-02-15 12:44:46,647:INFO:              joblib: 1.2.0
2023-02-15 12:44:46,647:INFO:             sklearn: 1.2.1
2023-02-15 12:44:46,647:INFO:                pyod: 1.0.7
2023-02-15 12:44:46,647:INFO:            imblearn: 0.10.1
2023-02-15 12:44:46,647:INFO:   category_encoders: 2.6.0
2023-02-15 12:44:46,647:INFO:            lightgbm: 3.3.5
2023-02-15 12:44:46,647:INFO:               numba: 0.56.4
2023-02-15 12:44:46,647:INFO:            requests: 2.28.1
2023-02-15 12:44:46,647:INFO:          matplotlib: 3.6.3
2023-02-15 12:44:46,647:INFO:          scikitplot: 0.3.7
2023-02-15 12:44:46,648:INFO:         yellowbrick: 1.5
2023-02-15 12:44:46,648:INFO:              plotly: 5.13.0
2023-02-15 12:44:46,648:INFO:             kaleido: 0.2.1
2023-02-15 12:44:46,648:INFO:         statsmodels: 0.13.5
2023-02-15 12:44:46,648:INFO:              sktime: 0.16.1
2023-02-15 12:44:46,648:INFO:               tbats: 1.1.2
2023-02-15 12:44:46,648:INFO:            pmdarima: 2.0.2
2023-02-15 12:44:46,648:INFO:              psutil: 5.9.0
2023-02-15 12:44:46,648:INFO:PyCaret optional dependencies:
2023-02-15 12:44:46,648:INFO:                shap: 0.41.0
2023-02-15 12:44:46,648:INFO:           interpret: 0.3.0
2023-02-15 12:44:46,648:INFO:                umap: 0.5.3
2023-02-15 12:44:46,648:INFO:    pandas_profiling: 4.0.0
2023-02-15 12:44:46,648:INFO:  explainerdashboard: 0.4.2
2023-02-15 12:44:46,648:INFO:             autoviz: 0.1.58
2023-02-15 12:44:46,648:INFO:           fairlearn: 0.7.0
2023-02-15 12:44:46,648:INFO:             xgboost: 1.7.3
2023-02-15 12:44:46,648:INFO:            catboost: 1.1.1
2023-02-15 12:44:46,648:INFO:              kmodes: 0.12.2
2023-02-15 12:44:46,648:INFO:             mlxtend: 0.21.0
2023-02-15 12:44:46,648:INFO:       statsforecast: 1.4.0
2023-02-15 12:44:46,648:INFO:        tune_sklearn: 0.4.5
2023-02-15 12:44:46,648:INFO:                 ray: 2.2.0
2023-02-15 12:44:46,648:INFO:            hyperopt: 0.2.7
2023-02-15 12:44:46,648:INFO:              optuna: 3.1.0
2023-02-15 12:44:46,648:INFO:               skopt: 0.9.0
2023-02-15 12:44:46,648:INFO:              mlflow: 1.30.0
2023-02-15 12:44:46,648:INFO:              gradio: 3.18.0
2023-02-15 12:44:46,648:INFO:             fastapi: 0.92.0
2023-02-15 12:44:46,648:INFO:             uvicorn: 0.20.0
2023-02-15 12:44:46,648:INFO:              m2cgen: 0.10.0
2023-02-15 12:44:46,648:INFO:           evidently: 0.2.4
2023-02-15 12:44:46,648:INFO:               fugue: 0.8.1.dev4
2023-02-15 12:44:46,648:INFO:           streamlit: Not installed
2023-02-15 12:44:46,648:INFO:             prophet: Not installed
2023-02-15 12:44:46,648:INFO:None
2023-02-15 12:44:46,648:INFO:Set up GPU usage.
2023-02-15 12:44:46,648:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,648:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 12:44:46,649:INFO:Set up data.
2023-02-15 12:44:46,696:INFO:Set up train/test split.
2023-02-15 12:44:46,719:INFO:Set up index.
2023-02-15 12:44:46,725:INFO:Set up folding strategy.
2023-02-15 12:44:46,725:INFO:Assigning column types.
2023-02-15 12:44:46,734:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 12:44:46,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,734:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,737:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,779:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,779:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,805:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,805:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:46,818:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:46,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,823:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,825:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,828:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,867:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,893:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:46,896:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:46,901:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 12:44:46,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,904:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,906:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,971:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,971:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:46,974:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:46,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,982:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:46,984:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:46,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,024:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,050:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,051:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:47,054:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:47,058:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 12:44:47,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,064:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,129:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,129:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:47,132:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:47,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,139:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,142:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,207:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,207:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:47,210:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:47,215:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 12:44:47,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,290:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,290:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,290:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,290:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:47,293:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:47,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,303:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,368:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,368:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:47,371:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:47,376:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 12:44:47,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,381:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,420:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,447:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:47,450:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:47,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,498:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:44:47,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,525:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:47,528:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:47,532:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 12:44:47,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,537:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,603:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:47,605:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:47,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:47,681:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:47,683:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:47,688:INFO:Preparing preprocessing pipeline...
2023-02-15 12:44:47,689:INFO:Set up column name cleaning.
2023-02-15 12:44:47,689:INFO:Set up simple imputation.
2023-02-15 12:44:47,689:INFO:Set up feature normalization.
2023-02-15 12:44:47,744:INFO:Finished creating preprocessing pipeline.
2023-02-15 12:44:47,747:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 12:44:47,747:INFO:Creating final display dataframe.
2023-02-15 12:44:48,027:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28657, 164)
4        Transformed data shape           (28657, 159)
5   Transformed train set shape           (20059, 159)
6    Transformed test set shape            (8598, 159)
7               Ignore features                      5
8              Numeric features                    158
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   faac
2023-02-15 12:44:48,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,076:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,103:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:48,112:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:48,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,122:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:44:48,188:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:44:48,202:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:44:48,207:INFO:setup() successfully completed in 1.56s...............
2023-02-15 12:44:48,207:INFO:Initializing compare_models()
2023-02-15 12:44:48,208:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f47677ee760>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f47677ee760>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 12:44:48,208:INFO:Checking exceptions
2023-02-15 12:44:48,211:INFO:Preparing display monitor
2023-02-15 12:44:48,224:INFO:Initializing Linear Regression
2023-02-15 12:44:48,224:INFO:Total runtime is 1.700719197591146e-06 minutes
2023-02-15 12:44:48,226:INFO:SubProcess create_model() called ==================================
2023-02-15 12:44:48,226:INFO:Initializing create_model()
2023-02-15 12:44:48,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f47677ee760>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4695bee490>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:44:48,226:INFO:Checking exceptions
2023-02-15 12:44:48,226:INFO:Importing libraries
2023-02-15 12:44:48,226:INFO:Copying training dataset
2023-02-15 12:44:48,237:INFO:Defining folds
2023-02-15 12:44:48,237:INFO:Declaring metric variables
2023-02-15 12:44:48,239:INFO:Importing untrained model
2023-02-15 12:44:48,241:INFO:Linear Regression Imported successfully
2023-02-15 12:44:48,244:INFO:Starting cross validation
2023-02-15 12:44:48,245:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:44:49,910:INFO:Calculating mean and std
2023-02-15 12:44:49,911:INFO:Creating metrics dataframe
2023-02-15 12:44:49,915:INFO:Uploading results into container
2023-02-15 12:44:49,916:INFO:Uploading model into container now
2023-02-15 12:44:49,916:INFO:_master_model_container: 1
2023-02-15 12:44:49,916:INFO:_display_container: 2
2023-02-15 12:44:49,916:INFO:LinearRegression(n_jobs=-1)
2023-02-15 12:44:49,916:INFO:create_model() successfully completed......................................
2023-02-15 12:44:50,044:INFO:SubProcess create_model() end ==================================
2023-02-15 12:44:50,044:INFO:Creating metrics dataframe
2023-02-15 12:44:50,049:INFO:Initializing Lasso Regression
2023-02-15 12:44:50,049:INFO:Total runtime is 0.03041757345199585 minutes
2023-02-15 12:44:50,051:INFO:SubProcess create_model() called ==================================
2023-02-15 12:44:50,051:INFO:Initializing create_model()
2023-02-15 12:44:50,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f47677ee760>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4695bee490>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:44:50,051:INFO:Checking exceptions
2023-02-15 12:44:50,051:INFO:Importing libraries
2023-02-15 12:44:50,051:INFO:Copying training dataset
2023-02-15 12:44:50,064:INFO:Defining folds
2023-02-15 12:44:50,064:INFO:Declaring metric variables
2023-02-15 12:44:50,066:INFO:Importing untrained model
2023-02-15 12:44:50,068:INFO:Lasso Regression Imported successfully
2023-02-15 12:44:50,071:INFO:Starting cross validation
2023-02-15 12:44:50,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:44:51,329:INFO:Calculating mean and std
2023-02-15 12:44:51,331:INFO:Creating metrics dataframe
2023-02-15 12:44:51,333:INFO:Uploading results into container
2023-02-15 12:44:51,334:INFO:Uploading model into container now
2023-02-15 12:44:51,334:INFO:_master_model_container: 2
2023-02-15 12:44:51,334:INFO:_display_container: 2
2023-02-15 12:44:51,334:INFO:Lasso(random_state=11)
2023-02-15 12:44:51,334:INFO:create_model() successfully completed......................................
2023-02-15 12:44:51,453:INFO:SubProcess create_model() end ==================================
2023-02-15 12:44:51,453:INFO:Creating metrics dataframe
2023-02-15 12:44:51,458:INFO:Initializing Ridge Regression
2023-02-15 12:44:51,458:INFO:Total runtime is 0.05390445788701376 minutes
2023-02-15 12:44:51,460:INFO:SubProcess create_model() called ==================================
2023-02-15 12:44:51,460:INFO:Initializing create_model()
2023-02-15 12:44:51,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f47677ee760>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4695bee490>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:44:51,460:INFO:Checking exceptions
2023-02-15 12:44:51,460:INFO:Importing libraries
2023-02-15 12:44:51,460:INFO:Copying training dataset
2023-02-15 12:44:51,473:INFO:Defining folds
2023-02-15 12:44:51,473:INFO:Declaring metric variables
2023-02-15 12:44:51,475:INFO:Importing untrained model
2023-02-15 12:44:51,477:INFO:Ridge Regression Imported successfully
2023-02-15 12:44:51,480:INFO:Starting cross validation
2023-02-15 12:44:51,481:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:44:53,051:INFO:Calculating mean and std
2023-02-15 12:44:53,052:INFO:Creating metrics dataframe
2023-02-15 12:44:53,054:INFO:Uploading results into container
2023-02-15 12:44:53,056:INFO:Uploading model into container now
2023-02-15 12:44:53,057:INFO:_master_model_container: 3
2023-02-15 12:44:53,057:INFO:_display_container: 2
2023-02-15 12:44:53,057:INFO:Ridge(random_state=11)
2023-02-15 12:44:53,057:INFO:create_model() successfully completed......................................
2023-02-15 12:44:53,179:INFO:SubProcess create_model() end ==================================
2023-02-15 12:44:53,180:INFO:Creating metrics dataframe
2023-02-15 12:44:53,185:INFO:Initializing Elastic Net
2023-02-15 12:44:53,185:INFO:Total runtime is 0.08268063465754191 minutes
2023-02-15 12:44:53,186:INFO:SubProcess create_model() called ==================================
2023-02-15 12:44:53,186:INFO:Initializing create_model()
2023-02-15 12:44:53,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f47677ee760>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4695bee490>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:44:53,187:INFO:Checking exceptions
2023-02-15 12:44:53,187:INFO:Importing libraries
2023-02-15 12:44:53,187:INFO:Copying training dataset
2023-02-15 12:44:53,200:INFO:Defining folds
2023-02-15 12:44:53,200:INFO:Declaring metric variables
2023-02-15 12:44:53,202:INFO:Importing untrained model
2023-02-15 12:44:53,204:INFO:Elastic Net Imported successfully
2023-02-15 12:44:53,206:INFO:Starting cross validation
2023-02-15 12:44:53,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:45:08,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,195:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 12:45:08,270:INFO:PyCaret RegressionExperiment
2023-02-15 12:45:08,270:INFO:Logging name: reg-default-name
2023-02-15 12:45:08,270:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 12:45:08,270:INFO:version 3.0.0.rc9
2023-02-15 12:45:08,270:INFO:Initializing setup()
2023-02-15 12:45:08,270:INFO:self.USI: ea29
2023-02-15 12:45:08,271:INFO:self._variable_keys: {'exp_name_log', 'exp_id', 'fold_groups_param', 'data', 'y', '_ml_usecase', 'fold_shuffle_param', 'memory', 'log_plots_param', 'y_train', 'fold_generator', 'X_test', 'html_param', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', '_available_plots', 'gpu_param', 'X', 'n_jobs_param', 'X_train', 'transform_target_param', 'y_test', 'target_param', 'pipeline'}
2023-02-15 12:45:08,271:INFO:Checking environment
2023-02-15 12:45:08,271:INFO:python_version: 3.8.16
2023-02-15 12:45:08,271:INFO:python_build: ('default', 'Jan 17 2023 23:13:24')
2023-02-15 12:45:08,271:INFO:machine: x86_64
2023-02-15 12:45:08,271:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 12:45:08,271:INFO:Memory: svmem(total=134979592192, available=121160933376, percent=10.2, used=12060872704, free=91851161600, active=5212958720, inactive=34793029632, buffers=1643130880, cached=29424427008, shared=495427584, slab=2521825280)
2023-02-15 12:45:08,271:INFO:Physical Core: 16
2023-02-15 12:45:08,271:INFO:Logical Core: 32
2023-02-15 12:45:08,271:INFO:Checking libraries
2023-02-15 12:45:08,271:INFO:System:
2023-02-15 12:45:08,271:INFO:    python: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0]
2023-02-15 12:45:08,271:INFO:executable: /home/moussa/anaconda3/envs/research2/bin/python
2023-02-15 12:45:08,271:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 12:45:08,271:INFO:PyCaret required dependencies:
2023-02-15 12:45:08,271:INFO:                 pip: 22.3.1
2023-02-15 12:45:08,272:INFO:          setuptools: 60.10.0
2023-02-15 12:45:08,272:INFO:             pycaret: 3.0.0rc9
2023-02-15 12:45:08,272:INFO:             IPython: 7.31.1
2023-02-15 12:45:08,272:INFO:          ipywidgets: 7.7.3
2023-02-15 12:45:08,272:INFO:                tqdm: 4.64.1
2023-02-15 12:45:08,272:INFO:               numpy: 1.23.5
2023-02-15 12:45:08,272:INFO:              pandas: 1.5.3
2023-02-15 12:45:08,272:INFO:              jinja2: 3.1.2
2023-02-15 12:45:08,272:INFO:               scipy: 1.9.1
2023-02-15 12:45:08,272:INFO:              joblib: 1.2.0
2023-02-15 12:45:08,272:INFO:             sklearn: 1.2.1
2023-02-15 12:45:08,272:INFO:                pyod: 1.0.7
2023-02-15 12:45:08,272:INFO:            imblearn: 0.10.1
2023-02-15 12:45:08,272:INFO:   category_encoders: 2.6.0
2023-02-15 12:45:08,272:INFO:            lightgbm: 3.3.5
2023-02-15 12:45:08,272:INFO:               numba: 0.56.4
2023-02-15 12:45:08,272:INFO:            requests: 2.28.1
2023-02-15 12:45:08,272:INFO:          matplotlib: 3.6.3
2023-02-15 12:45:08,272:INFO:          scikitplot: 0.3.7
2023-02-15 12:45:08,272:INFO:         yellowbrick: 1.5
2023-02-15 12:45:08,272:INFO:              plotly: 5.13.0
2023-02-15 12:45:08,272:INFO:             kaleido: 0.2.1
2023-02-15 12:45:08,272:INFO:         statsmodels: 0.13.5
2023-02-15 12:45:08,272:INFO:              sktime: 0.16.1
2023-02-15 12:45:08,272:INFO:               tbats: 1.1.2
2023-02-15 12:45:08,272:INFO:            pmdarima: 2.0.2
2023-02-15 12:45:08,272:INFO:              psutil: 5.9.0
2023-02-15 12:45:08,272:INFO:PyCaret optional dependencies:
2023-02-15 12:45:08,549:INFO:                shap: 0.41.0
2023-02-15 12:45:08,549:INFO:           interpret: 0.3.0
2023-02-15 12:45:08,549:INFO:                umap: 0.5.3
2023-02-15 12:45:08,549:INFO:    pandas_profiling: 4.0.0
2023-02-15 12:45:08,549:INFO:  explainerdashboard: 0.4.2
2023-02-15 12:45:08,549:INFO:             autoviz: 0.1.58
2023-02-15 12:45:08,549:INFO:           fairlearn: 0.7.0
2023-02-15 12:45:08,549:INFO:             xgboost: 1.7.3
2023-02-15 12:45:08,549:INFO:            catboost: 1.1.1
2023-02-15 12:45:08,549:INFO:              kmodes: 0.12.2
2023-02-15 12:45:08,549:INFO:             mlxtend: 0.21.0
2023-02-15 12:45:08,549:INFO:       statsforecast: 1.4.0
2023-02-15 12:45:08,549:INFO:        tune_sklearn: 0.4.5
2023-02-15 12:45:08,549:INFO:                 ray: 2.2.0
2023-02-15 12:45:08,549:INFO:            hyperopt: 0.2.7
2023-02-15 12:45:08,549:INFO:              optuna: 3.1.0
2023-02-15 12:45:08,549:INFO:               skopt: 0.9.0
2023-02-15 12:45:08,549:INFO:              mlflow: 1.30.0
2023-02-15 12:45:08,549:INFO:              gradio: 3.18.0
2023-02-15 12:45:08,549:INFO:             fastapi: 0.92.0
2023-02-15 12:45:08,549:INFO:             uvicorn: 0.20.0
2023-02-15 12:45:08,549:INFO:              m2cgen: 0.10.0
2023-02-15 12:45:08,549:INFO:           evidently: 0.2.4
2023-02-15 12:45:08,549:INFO:               fugue: 0.8.1.dev4
2023-02-15 12:45:08,549:INFO:           streamlit: Not installed
2023-02-15 12:45:08,549:INFO:             prophet: Not installed
2023-02-15 12:45:08,549:INFO:None
2023-02-15 12:45:08,549:INFO:Set up GPU usage.
2023-02-15 12:45:08,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,549:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 12:45:08,549:INFO:Set up data.
2023-02-15 12:45:08,606:INFO:Set up train/test split.
2023-02-15 12:45:08,634:INFO:Set up index.
2023-02-15 12:45:08,640:INFO:Set up folding strategy.
2023-02-15 12:45:08,640:INFO:Assigning column types.
2023-02-15 12:45:08,650:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 12:45:08,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,650:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,653:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,655:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,695:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,721:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:08,796:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:08,810:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,810:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,810:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,813:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,815:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,857:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,883:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,883:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,883:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:08,894:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:08,899:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 12:45:08,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,902:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,902:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,943:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,969:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,969:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:08,973:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:08,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,981:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,981:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:08,983:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:45:08,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,048:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:09,052:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:09,057:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 12:45:09,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,060:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,062:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,101:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,101:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,127:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:09,131:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:09,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,139:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,142:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,180:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,205:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,206:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:09,209:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:09,213:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 12:45:09,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,259:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,259:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,285:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:09,289:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:09,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,297:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,338:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,363:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,364:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:09,367:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:09,373:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 12:45:09,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,445:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:09,448:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:09,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,499:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:45:09,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,529:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:09,534:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:09,540:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 12:45:09,540:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,540:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,546:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,611:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:09,616:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:09,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:09,692:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:09,698:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:09,703:INFO:Preparing preprocessing pipeline...
2023-02-15 12:45:09,704:INFO:Set up column name cleaning.
2023-02-15 12:45:09,704:INFO:Set up simple imputation.
2023-02-15 12:45:09,704:INFO:Set up feature normalization.
2023-02-15 12:45:09,764:INFO:Finished creating preprocessing pipeline.
2023-02-15 12:45:09,768:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 12:45:09,768:INFO:Creating final display dataframe.
2023-02-15 12:45:10,058:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28657, 164)
4        Transformed data shape           (28657, 159)
5   Transformed train set shape           (20059, 159)
6    Transformed test set shape            (8598, 159)
7               Ignore features                      5
8              Numeric features                    158
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   ea29
2023-02-15 12:45:10,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,134:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:10,138:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:10,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:45:10,222:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:45:10,233:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:45:10,239:INFO:setup() successfully completed in 1.97s...............
2023-02-15 12:45:10,239:INFO:Initializing compare_models()
2023-02-15 12:45:10,239:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5e6eb67760>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f5e6eb67760>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 12:45:10,239:INFO:Checking exceptions
2023-02-15 12:45:10,243:INFO:Preparing display monitor
2023-02-15 12:45:10,257:INFO:Initializing Linear Regression
2023-02-15 12:45:10,257:INFO:Total runtime is 1.6967455546061197e-06 minutes
2023-02-15 12:45:10,258:INFO:SubProcess create_model() called ==================================
2023-02-15 12:45:10,259:INFO:Initializing create_model()
2023-02-15 12:45:10,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5e6eb67760>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5da46a3cd0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:45:10,259:INFO:Checking exceptions
2023-02-15 12:45:10,259:INFO:Importing libraries
2023-02-15 12:45:10,259:INFO:Copying training dataset
2023-02-15 12:45:10,271:INFO:Defining folds
2023-02-15 12:45:10,271:INFO:Declaring metric variables
2023-02-15 12:45:10,273:INFO:Importing untrained model
2023-02-15 12:45:10,274:INFO:Linear Regression Imported successfully
2023-02-15 12:45:10,277:INFO:Starting cross validation
2023-02-15 12:45:10,280:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:45:11,955:INFO:Calculating mean and std
2023-02-15 12:45:11,956:INFO:Creating metrics dataframe
2023-02-15 12:45:11,959:INFO:Uploading results into container
2023-02-15 12:45:11,959:INFO:Uploading model into container now
2023-02-15 12:45:11,959:INFO:_master_model_container: 1
2023-02-15 12:45:11,959:INFO:_display_container: 2
2023-02-15 12:45:11,960:INFO:LinearRegression(n_jobs=-1)
2023-02-15 12:45:11,960:INFO:create_model() successfully completed......................................
2023-02-15 12:45:12,077:INFO:SubProcess create_model() end ==================================
2023-02-15 12:45:12,078:INFO:Creating metrics dataframe
2023-02-15 12:45:12,083:INFO:Initializing Lasso Regression
2023-02-15 12:45:12,083:INFO:Total runtime is 0.030433142185211183 minutes
2023-02-15 12:45:12,085:INFO:SubProcess create_model() called ==================================
2023-02-15 12:45:12,085:INFO:Initializing create_model()
2023-02-15 12:45:12,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5e6eb67760>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5da46a3cd0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:45:12,085:INFO:Checking exceptions
2023-02-15 12:45:12,085:INFO:Importing libraries
2023-02-15 12:45:12,085:INFO:Copying training dataset
2023-02-15 12:45:12,099:INFO:Defining folds
2023-02-15 12:45:12,099:INFO:Declaring metric variables
2023-02-15 12:45:12,101:INFO:Importing untrained model
2023-02-15 12:45:12,102:INFO:Lasso Regression Imported successfully
2023-02-15 12:45:12,105:INFO:Starting cross validation
2023-02-15 12:45:12,106:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:45:13,478:INFO:Calculating mean and std
2023-02-15 12:45:13,479:INFO:Creating metrics dataframe
2023-02-15 12:45:13,482:INFO:Uploading results into container
2023-02-15 12:45:13,482:INFO:Uploading model into container now
2023-02-15 12:45:13,482:INFO:_master_model_container: 2
2023-02-15 12:45:13,482:INFO:_display_container: 2
2023-02-15 12:45:13,482:INFO:Lasso(random_state=11)
2023-02-15 12:45:13,482:INFO:create_model() successfully completed......................................
2023-02-15 12:45:13,592:INFO:SubProcess create_model() end ==================================
2023-02-15 12:45:13,592:INFO:Creating metrics dataframe
2023-02-15 12:45:13,597:INFO:Initializing Ridge Regression
2023-02-15 12:45:13,597:INFO:Total runtime is 0.05567512512207032 minutes
2023-02-15 12:45:13,599:INFO:SubProcess create_model() called ==================================
2023-02-15 12:45:13,599:INFO:Initializing create_model()
2023-02-15 12:45:13,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5e6eb67760>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5da46a3cd0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:45:13,599:INFO:Checking exceptions
2023-02-15 12:45:13,599:INFO:Importing libraries
2023-02-15 12:45:13,599:INFO:Copying training dataset
2023-02-15 12:45:13,613:INFO:Defining folds
2023-02-15 12:45:13,613:INFO:Declaring metric variables
2023-02-15 12:45:13,615:INFO:Importing untrained model
2023-02-15 12:45:13,617:INFO:Ridge Regression Imported successfully
2023-02-15 12:45:13,619:INFO:Starting cross validation
2023-02-15 12:45:13,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:45:15,291:INFO:Calculating mean and std
2023-02-15 12:45:15,292:INFO:Creating metrics dataframe
2023-02-15 12:45:15,294:INFO:Uploading results into container
2023-02-15 12:45:15,295:INFO:Uploading model into container now
2023-02-15 12:45:15,295:INFO:_master_model_container: 3
2023-02-15 12:45:15,295:INFO:_display_container: 2
2023-02-15 12:45:15,295:INFO:Ridge(random_state=11)
2023-02-15 12:45:15,295:INFO:create_model() successfully completed......................................
2023-02-15 12:45:15,415:INFO:SubProcess create_model() end ==================================
2023-02-15 12:45:15,415:INFO:Creating metrics dataframe
2023-02-15 12:45:15,421:INFO:Initializing Elastic Net
2023-02-15 12:45:15,421:INFO:Total runtime is 0.08607064485549927 minutes
2023-02-15 12:45:15,423:INFO:SubProcess create_model() called ==================================
2023-02-15 12:45:15,423:INFO:Initializing create_model()
2023-02-15 12:45:15,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5e6eb67760>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5da46a3cd0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:45:15,423:INFO:Checking exceptions
2023-02-15 12:45:15,423:INFO:Importing libraries
2023-02-15 12:45:15,423:INFO:Copying training dataset
2023-02-15 12:45:15,438:INFO:Defining folds
2023-02-15 12:45:15,438:INFO:Declaring metric variables
2023-02-15 12:45:15,440:INFO:Importing untrained model
2023-02-15 12:45:15,441:INFO:Elastic Net Imported successfully
2023-02-15 12:45:15,444:INFO:Starting cross validation
2023-02-15 12:45:15,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:45:16,811:INFO:Calculating mean and std
2023-02-15 12:45:16,814:INFO:Creating metrics dataframe
2023-02-15 12:45:16,820:INFO:Uploading results into container
2023-02-15 12:45:16,820:INFO:Uploading model into container now
2023-02-15 12:45:16,821:INFO:_master_model_container: 4
2023-02-15 12:45:16,821:INFO:_display_container: 2
2023-02-15 12:45:16,821:INFO:ElasticNet(random_state=11)
2023-02-15 12:45:16,821:INFO:create_model() successfully completed......................................
2023-02-15 12:45:16,947:INFO:SubProcess create_model() end ==================================
2023-02-15 12:45:16,947:INFO:Creating metrics dataframe
2023-02-15 12:45:16,953:INFO:Initializing Least Angle Regression
2023-02-15 12:45:16,953:INFO:Total runtime is 0.11160472631454468 minutes
2023-02-15 12:45:16,955:INFO:SubProcess create_model() called ==================================
2023-02-15 12:45:16,955:INFO:Initializing create_model()
2023-02-15 12:45:16,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5e6eb67760>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5da46a3cd0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:45:16,955:INFO:Checking exceptions
2023-02-15 12:45:16,955:INFO:Importing libraries
2023-02-15 12:45:16,955:INFO:Copying training dataset
2023-02-15 12:45:16,969:INFO:Defining folds
2023-02-15 12:45:16,969:INFO:Declaring metric variables
2023-02-15 12:45:16,971:INFO:Importing untrained model
2023-02-15 12:45:16,973:INFO:Least Angle Regression Imported successfully
2023-02-15 12:45:16,976:INFO:Starting cross validation
2023-02-15 12:45:16,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:45:17,123:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:17,123:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:17,124:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:45:17,231:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.484e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,232:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.116e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,299:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:17,299:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:17,299:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:45:17,406:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.094e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,406:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 12:45:17,406:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.933e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,407:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.485e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,407:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.827e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,413:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=1.246e-02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,416:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.621e-02, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,478:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:17,478:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:17,479:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:45:17,586:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.534e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,586:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.542e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,591:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.618e-04, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,657:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:17,657:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:17,657:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:45:17,765:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.397e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,765:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 12:45:17,765:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.786e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,765:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.506e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,765:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.100e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,766:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.597e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,780:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:713: RuntimeWarning: invalid value encountered in multiply
  least_squares *= AA

2023-02-15 12:45:17,780:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:736: RuntimeWarning: divide by zero encountered in double_scalars
  gamma_ = min(g1, g2, C / AA)

2023-02-15 12:45:17,780:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-02-15 12:45:17,860:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 12:45:17,860:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 12:45:17,860:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 12:45:17,964:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.418e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,965:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 12:45:17,965:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.113e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,965:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.817e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,966:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.548e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:17,985:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 12:45:18,056:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 12:45:18,057:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:18,057:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:18,057:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:45:18,058:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/pycaret/containers/metrics/regression.py:243: RuntimeWarning: overflow encountered in divide
  mape = np.abs(y_pred - y_true) / np.abs(y_true)

2023-02-15 12:45:18,058:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 12:45:18,163:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.373e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,163:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.749e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,163:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.593e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,164:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.337e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,178:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 12:45:18,240:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 12:45:18,347:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.828e-04, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,414:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:18,414:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:18,415:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:45:18,526:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.090e-03, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,590:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:18,590:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:18,590:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:45:18,696:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.094e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,697:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.279e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,697:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.160e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,697:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 12:45:18,700:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.121e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,704:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.198e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:45:18,766:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:18,767:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:45:18,767:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:45:18,768:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:45:18,768:INFO:Calculating mean and std
2023-02-15 12:45:18,769:INFO:Creating metrics dataframe
2023-02-15 12:45:18,772:INFO:Uploading results into container
2023-02-15 12:45:18,772:INFO:Uploading model into container now
2023-02-15 12:45:18,773:INFO:_master_model_container: 5
2023-02-15 12:45:18,773:INFO:_display_container: 2
2023-02-15 12:45:18,773:INFO:Lars(random_state=11)
2023-02-15 12:45:18,773:INFO:create_model() successfully completed......................................
2023-02-15 12:45:18,889:INFO:SubProcess create_model() end ==================================
2023-02-15 12:45:18,889:INFO:Creating metrics dataframe
2023-02-15 12:45:18,895:INFO:Initializing Lasso Least Angle Regression
2023-02-15 12:45:18,895:INFO:Total runtime is 0.14397355715433757 minutes
2023-02-15 12:45:18,897:INFO:SubProcess create_model() called ==================================
2023-02-15 12:45:18,897:INFO:Initializing create_model()
2023-02-15 12:45:18,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5e6eb67760>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5da46a3cd0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:45:18,897:INFO:Checking exceptions
2023-02-15 12:45:18,897:INFO:Importing libraries
2023-02-15 12:45:18,897:INFO:Copying training dataset
2023-02-15 12:45:18,910:INFO:Defining folds
2023-02-15 12:45:18,911:INFO:Declaring metric variables
2023-02-15 12:45:18,912:INFO:Importing untrained model
2023-02-15 12:45:18,914:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 12:45:18,917:INFO:Starting cross validation
2023-02-15 12:45:18,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:45:20,279:INFO:Calculating mean and std
2023-02-15 12:45:20,280:INFO:Creating metrics dataframe
2023-02-15 12:45:20,283:INFO:Uploading results into container
2023-02-15 12:45:20,283:INFO:Uploading model into container now
2023-02-15 12:45:20,283:INFO:_master_model_container: 6
2023-02-15 12:45:20,283:INFO:_display_container: 2
2023-02-15 12:45:20,284:INFO:LassoLars(random_state=11)
2023-02-15 12:45:20,284:INFO:create_model() successfully completed......................................
2023-02-15 12:45:20,407:INFO:SubProcess create_model() end ==================================
2023-02-15 12:45:20,408:INFO:Creating metrics dataframe
2023-02-15 12:45:20,414:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 12:45:20,414:INFO:Total runtime is 0.1692817767461141 minutes
2023-02-15 12:45:20,416:INFO:SubProcess create_model() called ==================================
2023-02-15 12:45:20,416:INFO:Initializing create_model()
2023-02-15 12:45:20,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5e6eb67760>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5da46a3cd0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:45:20,416:INFO:Checking exceptions
2023-02-15 12:45:20,416:INFO:Importing libraries
2023-02-15 12:45:20,416:INFO:Copying training dataset
2023-02-15 12:45:20,429:INFO:Defining folds
2023-02-15 12:45:20,429:INFO:Declaring metric variables
2023-02-15 12:45:20,431:INFO:Importing untrained model
2023-02-15 12:45:20,433:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 12:45:20,436:INFO:Starting cross validation
2023-02-15 12:45:20,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:50:57,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:57,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:57,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:57,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:57,515:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 12:50:57,592:INFO:PyCaret RegressionExperiment
2023-02-15 12:50:57,593:INFO:Logging name: reg-default-name
2023-02-15 12:50:57,593:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 12:50:57,593:INFO:version 3.0.0.rc9
2023-02-15 12:50:57,593:INFO:Initializing setup()
2023-02-15 12:50:57,593:INFO:self.USI: 78d6
2023-02-15 12:50:57,593:INFO:self._variable_keys: {'seed', 'gpu_param', 'log_plots_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_generator', 'X', 'transform_target_param', 'y_train', 'fold_shuffle_param', 'idx', '_ml_usecase', 'y', 'logging_param', 'memory', 'target_param', 'exp_name_log', 'exp_id', 'html_param', 'X_train', 'X_test', 'USI', 'data', '_available_plots', 'y_test', 'pipeline', 'fold_groups_param'}
2023-02-15 12:50:57,593:INFO:Checking environment
2023-02-15 12:50:57,593:INFO:python_version: 3.8.16
2023-02-15 12:50:57,593:INFO:python_build: ('default', 'Jan 17 2023 23:13:24')
2023-02-15 12:50:57,593:INFO:machine: x86_64
2023-02-15 12:50:57,593:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 12:50:57,593:INFO:Memory: svmem(total=134979592192, available=120951226368, percent=10.4, used=12274446336, free=91175260160, active=5337636864, inactive=35332030464, buffers=1644851200, cached=29885034496, shared=491511808, slab=2529181696)
2023-02-15 12:50:57,593:INFO:Physical Core: 16
2023-02-15 12:50:57,593:INFO:Logical Core: 32
2023-02-15 12:50:57,593:INFO:Checking libraries
2023-02-15 12:50:57,594:INFO:System:
2023-02-15 12:50:57,594:INFO:    python: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0]
2023-02-15 12:50:57,594:INFO:executable: /home/moussa/anaconda3/envs/research2/bin/python
2023-02-15 12:50:57,594:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 12:50:57,594:INFO:PyCaret required dependencies:
2023-02-15 12:50:57,594:INFO:                 pip: 22.3.1
2023-02-15 12:50:57,594:INFO:          setuptools: 60.10.0
2023-02-15 12:50:57,594:INFO:             pycaret: 3.0.0rc9
2023-02-15 12:50:57,594:INFO:             IPython: 7.31.1
2023-02-15 12:50:57,594:INFO:          ipywidgets: 7.7.3
2023-02-15 12:50:57,594:INFO:                tqdm: 4.64.1
2023-02-15 12:50:57,594:INFO:               numpy: 1.23.5
2023-02-15 12:50:57,594:INFO:              pandas: 1.5.3
2023-02-15 12:50:57,594:INFO:              jinja2: 3.1.2
2023-02-15 12:50:57,594:INFO:               scipy: 1.9.1
2023-02-15 12:50:57,594:INFO:              joblib: 1.2.0
2023-02-15 12:50:57,594:INFO:             sklearn: 1.2.1
2023-02-15 12:50:57,594:INFO:                pyod: 1.0.7
2023-02-15 12:50:57,594:INFO:            imblearn: 0.10.1
2023-02-15 12:50:57,594:INFO:   category_encoders: 2.6.0
2023-02-15 12:50:57,594:INFO:            lightgbm: 3.3.5
2023-02-15 12:50:57,594:INFO:               numba: 0.56.4
2023-02-15 12:50:57,594:INFO:            requests: 2.28.1
2023-02-15 12:50:57,594:INFO:          matplotlib: 3.6.3
2023-02-15 12:50:57,594:INFO:          scikitplot: 0.3.7
2023-02-15 12:50:57,594:INFO:         yellowbrick: 1.5
2023-02-15 12:50:57,594:INFO:              plotly: 5.13.0
2023-02-15 12:50:57,594:INFO:             kaleido: 0.2.1
2023-02-15 12:50:57,594:INFO:         statsmodels: 0.13.5
2023-02-15 12:50:57,594:INFO:              sktime: 0.16.1
2023-02-15 12:50:57,594:INFO:               tbats: 1.1.2
2023-02-15 12:50:57,594:INFO:            pmdarima: 2.0.2
2023-02-15 12:50:57,594:INFO:              psutil: 5.9.0
2023-02-15 12:50:57,594:INFO:PyCaret optional dependencies:
2023-02-15 12:50:57,887:INFO:                shap: 0.41.0
2023-02-15 12:50:57,887:INFO:           interpret: 0.3.0
2023-02-15 12:50:57,887:INFO:                umap: 0.5.3
2023-02-15 12:50:57,887:INFO:    pandas_profiling: 4.0.0
2023-02-15 12:50:57,887:INFO:  explainerdashboard: 0.4.2
2023-02-15 12:50:57,887:INFO:             autoviz: 0.1.58
2023-02-15 12:50:57,887:INFO:           fairlearn: 0.7.0
2023-02-15 12:50:57,887:INFO:             xgboost: 1.7.3
2023-02-15 12:50:57,887:INFO:            catboost: 1.1.1
2023-02-15 12:50:57,887:INFO:              kmodes: 0.12.2
2023-02-15 12:50:57,887:INFO:             mlxtend: 0.21.0
2023-02-15 12:50:57,887:INFO:       statsforecast: 1.4.0
2023-02-15 12:50:57,887:INFO:        tune_sklearn: 0.4.5
2023-02-15 12:50:57,887:INFO:                 ray: 2.2.0
2023-02-15 12:50:57,887:INFO:            hyperopt: 0.2.7
2023-02-15 12:50:57,887:INFO:              optuna: 3.1.0
2023-02-15 12:50:57,887:INFO:               skopt: 0.9.0
2023-02-15 12:50:57,887:INFO:              mlflow: 1.30.0
2023-02-15 12:50:57,887:INFO:              gradio: 3.18.0
2023-02-15 12:50:57,887:INFO:             fastapi: 0.92.0
2023-02-15 12:50:57,887:INFO:             uvicorn: 0.20.0
2023-02-15 12:50:57,887:INFO:              m2cgen: 0.10.0
2023-02-15 12:50:57,887:INFO:           evidently: 0.2.4
2023-02-15 12:50:57,887:INFO:               fugue: 0.8.1.dev4
2023-02-15 12:50:57,887:INFO:           streamlit: Not installed
2023-02-15 12:50:57,887:INFO:             prophet: Not installed
2023-02-15 12:50:57,887:INFO:None
2023-02-15 12:50:57,887:INFO:Set up GPU usage.
2023-02-15 12:50:57,887:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:57,887:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 12:50:57,887:INFO:Set up data.
2023-02-15 12:50:57,947:INFO:Set up train/test split.
2023-02-15 12:50:57,975:INFO:Set up index.
2023-02-15 12:50:57,981:INFO:Set up folding strategy.
2023-02-15 12:50:57,981:INFO:Assigning column types.
2023-02-15 12:50:57,992:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 12:50:57,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:57,992:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 12:50:57,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:57,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:50:57,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:57,997:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:50:57,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,039:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,039:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,066:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,067:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:58,170:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:58,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,185:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,188:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,237:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,263:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,264:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,264:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:58,267:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:58,274:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 12:50:58,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,277:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,279:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,320:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,347:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:58,350:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:58,357:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,357:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,360:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,362:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,403:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,430:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,430:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,430:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,430:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:58,433:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:58,442:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 12:50:58,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,447:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,488:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,514:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,515:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:58,535:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:58,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,547:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,587:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,614:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:58,617:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:58,623:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 12:50:58,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,669:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,696:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:58,699:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:58,708:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,708:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,781:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:58,783:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:58,789:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 12:50:58,789:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,789:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,862:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:58,865:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:58,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,876:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 12:50:58,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,943:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:58,947:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:58,952:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 12:50:58,952:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,955:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:58,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,027:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:59,030:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:59,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,039:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,109:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,109:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,109:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:59,112:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:59,118:INFO:Preparing preprocessing pipeline...
2023-02-15 12:50:59,120:INFO:Set up column name cleaning.
2023-02-15 12:50:59,120:INFO:Set up simple imputation.
2023-02-15 12:50:59,120:INFO:Set up feature normalization.
2023-02-15 12:50:59,179:INFO:Finished creating preprocessing pipeline.
2023-02-15 12:50:59,183:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 12:50:59,183:INFO:Creating final display dataframe.
2023-02-15 12:50:59,477:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28657, 164)
4        Transformed data shape           (28657, 159)
5   Transformed train set shape           (20059, 159)
6    Transformed test set shape            (8598, 159)
7               Ignore features                      5
8              Numeric features                    158
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   78d6
2023-02-15 12:50:59,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,482:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,558:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:59,561:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:59,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,569:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 12:50:59,642:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 12:50:59,645:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 12:50:59,651:INFO:setup() successfully completed in 2.06s...............
2023-02-15 12:50:59,651:INFO:Initializing compare_models()
2023-02-15 12:50:59,651:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 12:50:59,651:INFO:Checking exceptions
2023-02-15 12:50:59,654:INFO:Preparing display monitor
2023-02-15 12:50:59,668:INFO:Initializing Linear Regression
2023-02-15 12:50:59,668:INFO:Total runtime is 1.434485117594401e-06 minutes
2023-02-15 12:50:59,669:INFO:SubProcess create_model() called ==================================
2023-02-15 12:50:59,669:INFO:Initializing create_model()
2023-02-15 12:50:59,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:50:59,669:INFO:Checking exceptions
2023-02-15 12:50:59,669:INFO:Importing libraries
2023-02-15 12:50:59,669:INFO:Copying training dataset
2023-02-15 12:50:59,681:INFO:Defining folds
2023-02-15 12:50:59,681:INFO:Declaring metric variables
2023-02-15 12:50:59,683:INFO:Importing untrained model
2023-02-15 12:50:59,685:INFO:Linear Regression Imported successfully
2023-02-15 12:50:59,688:INFO:Starting cross validation
2023-02-15 12:50:59,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:01,396:INFO:Calculating mean and std
2023-02-15 12:51:01,397:INFO:Creating metrics dataframe
2023-02-15 12:51:01,403:INFO:Uploading results into container
2023-02-15 12:51:01,403:INFO:Uploading model into container now
2023-02-15 12:51:01,403:INFO:_master_model_container: 1
2023-02-15 12:51:01,403:INFO:_display_container: 2
2023-02-15 12:51:01,403:INFO:LinearRegression(n_jobs=-1)
2023-02-15 12:51:01,403:INFO:create_model() successfully completed......................................
2023-02-15 12:51:01,540:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:01,541:INFO:Creating metrics dataframe
2023-02-15 12:51:01,546:INFO:Initializing Lasso Regression
2023-02-15 12:51:01,546:INFO:Total runtime is 0.03130397399266561 minutes
2023-02-15 12:51:01,548:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:01,548:INFO:Initializing create_model()
2023-02-15 12:51:01,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:01,548:INFO:Checking exceptions
2023-02-15 12:51:01,548:INFO:Importing libraries
2023-02-15 12:51:01,548:INFO:Copying training dataset
2023-02-15 12:51:01,560:INFO:Defining folds
2023-02-15 12:51:01,561:INFO:Declaring metric variables
2023-02-15 12:51:01,563:INFO:Importing untrained model
2023-02-15 12:51:01,564:INFO:Lasso Regression Imported successfully
2023-02-15 12:51:01,567:INFO:Starting cross validation
2023-02-15 12:51:01,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:02,851:INFO:Calculating mean and std
2023-02-15 12:51:02,852:INFO:Creating metrics dataframe
2023-02-15 12:51:02,855:INFO:Uploading results into container
2023-02-15 12:51:02,855:INFO:Uploading model into container now
2023-02-15 12:51:02,855:INFO:_master_model_container: 2
2023-02-15 12:51:02,855:INFO:_display_container: 2
2023-02-15 12:51:02,856:INFO:Lasso(random_state=11)
2023-02-15 12:51:02,856:INFO:create_model() successfully completed......................................
2023-02-15 12:51:02,973:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:02,973:INFO:Creating metrics dataframe
2023-02-15 12:51:02,979:INFO:Initializing Ridge Regression
2023-02-15 12:51:02,979:INFO:Total runtime is 0.055186955134073894 minutes
2023-02-15 12:51:02,981:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:02,981:INFO:Initializing create_model()
2023-02-15 12:51:02,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:02,981:INFO:Checking exceptions
2023-02-15 12:51:02,981:INFO:Importing libraries
2023-02-15 12:51:02,981:INFO:Copying training dataset
2023-02-15 12:51:02,994:INFO:Defining folds
2023-02-15 12:51:02,994:INFO:Declaring metric variables
2023-02-15 12:51:02,996:INFO:Importing untrained model
2023-02-15 12:51:02,998:INFO:Ridge Regression Imported successfully
2023-02-15 12:51:03,001:INFO:Starting cross validation
2023-02-15 12:51:03,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:04,323:INFO:Calculating mean and std
2023-02-15 12:51:04,325:INFO:Creating metrics dataframe
2023-02-15 12:51:04,327:INFO:Uploading results into container
2023-02-15 12:51:04,327:INFO:Uploading model into container now
2023-02-15 12:51:04,328:INFO:_master_model_container: 3
2023-02-15 12:51:04,328:INFO:_display_container: 2
2023-02-15 12:51:04,328:INFO:Ridge(random_state=11)
2023-02-15 12:51:04,328:INFO:create_model() successfully completed......................................
2023-02-15 12:51:04,444:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:04,444:INFO:Creating metrics dataframe
2023-02-15 12:51:04,450:INFO:Initializing Elastic Net
2023-02-15 12:51:04,450:INFO:Total runtime is 0.07971057891845704 minutes
2023-02-15 12:51:04,452:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:04,452:INFO:Initializing create_model()
2023-02-15 12:51:04,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:04,452:INFO:Checking exceptions
2023-02-15 12:51:04,452:INFO:Importing libraries
2023-02-15 12:51:04,452:INFO:Copying training dataset
2023-02-15 12:51:04,466:INFO:Defining folds
2023-02-15 12:51:04,466:INFO:Declaring metric variables
2023-02-15 12:51:04,468:INFO:Importing untrained model
2023-02-15 12:51:04,470:INFO:Elastic Net Imported successfully
2023-02-15 12:51:04,473:INFO:Starting cross validation
2023-02-15 12:51:04,474:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:05,748:INFO:Calculating mean and std
2023-02-15 12:51:05,749:INFO:Creating metrics dataframe
2023-02-15 12:51:05,754:INFO:Uploading results into container
2023-02-15 12:51:05,755:INFO:Uploading model into container now
2023-02-15 12:51:05,755:INFO:_master_model_container: 4
2023-02-15 12:51:05,755:INFO:_display_container: 2
2023-02-15 12:51:05,755:INFO:ElasticNet(random_state=11)
2023-02-15 12:51:05,755:INFO:create_model() successfully completed......................................
2023-02-15 12:51:05,868:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:05,868:INFO:Creating metrics dataframe
2023-02-15 12:51:05,874:INFO:Initializing Least Angle Regression
2023-02-15 12:51:05,874:INFO:Total runtime is 0.10344421068827311 minutes
2023-02-15 12:51:05,876:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:05,876:INFO:Initializing create_model()
2023-02-15 12:51:05,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:05,876:INFO:Checking exceptions
2023-02-15 12:51:05,876:INFO:Importing libraries
2023-02-15 12:51:05,876:INFO:Copying training dataset
2023-02-15 12:51:05,891:INFO:Defining folds
2023-02-15 12:51:05,891:INFO:Declaring metric variables
2023-02-15 12:51:05,893:INFO:Importing untrained model
2023-02-15 12:51:05,894:INFO:Least Angle Regression Imported successfully
2023-02-15 12:51:05,897:INFO:Starting cross validation
2023-02-15 12:51:05,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:06,041:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:06,041:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:06,041:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:51:06,140:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.484e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,141:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.116e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,207:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:06,208:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:06,208:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:51:06,308:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.094e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,308:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 12:51:06,308:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.933e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,308:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.485e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,309:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.827e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,315:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=1.246e-02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,317:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.621e-02, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,379:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:06,379:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:06,380:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:51:06,480:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.534e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,481:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.542e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,486:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.618e-04, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,550:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:06,551:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:06,551:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:51:06,650:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.397e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,650:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 12:51:06,650:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.786e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,651:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.506e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,651:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.100e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,651:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.597e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,665:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:713: RuntimeWarning: invalid value encountered in multiply
  least_squares *= AA

2023-02-15 12:51:06,665:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:736: RuntimeWarning: divide by zero encountered in double_scalars
  gamma_ = min(g1, g2, C / AA)

2023-02-15 12:51:06,665:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-02-15 12:51:06,745:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 12:51:06,745:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 12:51:06,745:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 12:51:06,843:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.418e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,844:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 12:51:06,844:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.113e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,844:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.817e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,845:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.548e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:06,863:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 12:51:06,934:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 12:51:06,935:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:06,935:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:06,935:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:51:06,936:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/pycaret/containers/metrics/regression.py:243: RuntimeWarning: overflow encountered in divide
  mape = np.abs(y_pred - y_true) / np.abs(y_true)

2023-02-15 12:51:06,936:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 12:51:07,033:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.373e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,034:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.749e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,034:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.593e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,035:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.337e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,049:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 12:51:07,112:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 12:51:07,213:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.828e-04, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,280:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:07,281:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:07,281:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:51:07,387:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.090e-03, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,449:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:07,449:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:07,450:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:51:07,549:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.094e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,549:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.279e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,550:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.160e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,550:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 12:51:07,553:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.121e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,557:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.198e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 12:51:07,617:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:07,618:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 12:51:07,618:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 12:51:07,619:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:51:07,619:INFO:Calculating mean and std
2023-02-15 12:51:07,620:INFO:Creating metrics dataframe
2023-02-15 12:51:07,623:INFO:Uploading results into container
2023-02-15 12:51:07,623:INFO:Uploading model into container now
2023-02-15 12:51:07,623:INFO:_master_model_container: 5
2023-02-15 12:51:07,623:INFO:_display_container: 2
2023-02-15 12:51:07,623:INFO:Lars(random_state=11)
2023-02-15 12:51:07,624:INFO:create_model() successfully completed......................................
2023-02-15 12:51:07,750:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:07,750:INFO:Creating metrics dataframe
2023-02-15 12:51:07,756:INFO:Initializing Lasso Least Angle Regression
2023-02-15 12:51:07,756:INFO:Total runtime is 0.13481299082438153 minutes
2023-02-15 12:51:07,758:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:07,758:INFO:Initializing create_model()
2023-02-15 12:51:07,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:07,758:INFO:Checking exceptions
2023-02-15 12:51:07,758:INFO:Importing libraries
2023-02-15 12:51:07,758:INFO:Copying training dataset
2023-02-15 12:51:07,772:INFO:Defining folds
2023-02-15 12:51:07,772:INFO:Declaring metric variables
2023-02-15 12:51:07,774:INFO:Importing untrained model
2023-02-15 12:51:07,775:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 12:51:07,778:INFO:Starting cross validation
2023-02-15 12:51:07,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:09,081:INFO:Calculating mean and std
2023-02-15 12:51:09,082:INFO:Creating metrics dataframe
2023-02-15 12:51:09,085:INFO:Uploading results into container
2023-02-15 12:51:09,085:INFO:Uploading model into container now
2023-02-15 12:51:09,086:INFO:_master_model_container: 6
2023-02-15 12:51:09,086:INFO:_display_container: 2
2023-02-15 12:51:09,086:INFO:LassoLars(random_state=11)
2023-02-15 12:51:09,086:INFO:create_model() successfully completed......................................
2023-02-15 12:51:09,206:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:09,206:INFO:Creating metrics dataframe
2023-02-15 12:51:09,212:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 12:51:09,212:INFO:Total runtime is 0.1590809226036072 minutes
2023-02-15 12:51:09,214:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:09,214:INFO:Initializing create_model()
2023-02-15 12:51:09,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:09,214:INFO:Checking exceptions
2023-02-15 12:51:09,214:INFO:Importing libraries
2023-02-15 12:51:09,215:INFO:Copying training dataset
2023-02-15 12:51:09,229:INFO:Defining folds
2023-02-15 12:51:09,229:INFO:Declaring metric variables
2023-02-15 12:51:09,231:INFO:Importing untrained model
2023-02-15 12:51:09,233:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 12:51:09,236:INFO:Starting cross validation
2023-02-15 12:51:09,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:10,538:INFO:Calculating mean and std
2023-02-15 12:51:10,539:INFO:Creating metrics dataframe
2023-02-15 12:51:10,542:INFO:Uploading results into container
2023-02-15 12:51:10,542:INFO:Uploading model into container now
2023-02-15 12:51:10,542:INFO:_master_model_container: 7
2023-02-15 12:51:10,542:INFO:_display_container: 2
2023-02-15 12:51:10,543:INFO:OrthogonalMatchingPursuit()
2023-02-15 12:51:10,543:INFO:create_model() successfully completed......................................
2023-02-15 12:51:10,659:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:10,659:INFO:Creating metrics dataframe
2023-02-15 12:51:10,666:INFO:Initializing Bayesian Ridge
2023-02-15 12:51:10,666:INFO:Total runtime is 0.18330207268397017 minutes
2023-02-15 12:51:10,667:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:10,668:INFO:Initializing create_model()
2023-02-15 12:51:10,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:10,668:INFO:Checking exceptions
2023-02-15 12:51:10,668:INFO:Importing libraries
2023-02-15 12:51:10,668:INFO:Copying training dataset
2023-02-15 12:51:10,681:INFO:Defining folds
2023-02-15 12:51:10,682:INFO:Declaring metric variables
2023-02-15 12:51:10,684:INFO:Importing untrained model
2023-02-15 12:51:10,685:INFO:Bayesian Ridge Imported successfully
2023-02-15 12:51:10,688:INFO:Starting cross validation
2023-02-15 12:51:10,689:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:13,469:INFO:Calculating mean and std
2023-02-15 12:51:13,470:INFO:Creating metrics dataframe
2023-02-15 12:51:13,475:INFO:Uploading results into container
2023-02-15 12:51:13,475:INFO:Uploading model into container now
2023-02-15 12:51:13,475:INFO:_master_model_container: 8
2023-02-15 12:51:13,475:INFO:_display_container: 2
2023-02-15 12:51:13,476:INFO:BayesianRidge()
2023-02-15 12:51:13,476:INFO:create_model() successfully completed......................................
2023-02-15 12:51:13,600:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:13,600:INFO:Creating metrics dataframe
2023-02-15 12:51:13,607:INFO:Initializing Passive Aggressive Regressor
2023-02-15 12:51:13,607:INFO:Total runtime is 0.23232526779174809 minutes
2023-02-15 12:51:13,609:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:13,609:INFO:Initializing create_model()
2023-02-15 12:51:13,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:13,609:INFO:Checking exceptions
2023-02-15 12:51:13,609:INFO:Importing libraries
2023-02-15 12:51:13,609:INFO:Copying training dataset
2023-02-15 12:51:13,623:INFO:Defining folds
2023-02-15 12:51:13,623:INFO:Declaring metric variables
2023-02-15 12:51:13,625:INFO:Importing untrained model
2023-02-15 12:51:13,627:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 12:51:13,630:INFO:Starting cross validation
2023-02-15 12:51:13,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:15,114:INFO:Calculating mean and std
2023-02-15 12:51:15,114:INFO:Creating metrics dataframe
2023-02-15 12:51:15,117:INFO:Uploading results into container
2023-02-15 12:51:15,117:INFO:Uploading model into container now
2023-02-15 12:51:15,118:INFO:_master_model_container: 9
2023-02-15 12:51:15,118:INFO:_display_container: 2
2023-02-15 12:51:15,118:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 12:51:15,118:INFO:create_model() successfully completed......................................
2023-02-15 12:51:15,258:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:15,258:INFO:Creating metrics dataframe
2023-02-15 12:51:15,264:INFO:Initializing Huber Regressor
2023-02-15 12:51:15,264:INFO:Total runtime is 0.2599467794100444 minutes
2023-02-15 12:51:15,266:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:15,266:INFO:Initializing create_model()
2023-02-15 12:51:15,266:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:15,266:INFO:Checking exceptions
2023-02-15 12:51:15,266:INFO:Importing libraries
2023-02-15 12:51:15,266:INFO:Copying training dataset
2023-02-15 12:51:15,280:INFO:Defining folds
2023-02-15 12:51:15,280:INFO:Declaring metric variables
2023-02-15 12:51:15,282:INFO:Importing untrained model
2023-02-15 12:51:15,283:INFO:Huber Regressor Imported successfully
2023-02-15 12:51:15,287:INFO:Starting cross validation
2023-02-15 12:51:15,287:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:17,423:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 12:51:19,551:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 12:51:22,125:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 12:51:24,580:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 12:51:26,907:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 12:51:29,242:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 12:51:31,578:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 12:51:33,880:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 12:51:36,253:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 12:51:38,759:WARNING:/home/moussa/anaconda3/envs/research2/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 12:51:38,863:INFO:Calculating mean and std
2023-02-15 12:51:38,863:INFO:Creating metrics dataframe
2023-02-15 12:51:38,868:INFO:Uploading results into container
2023-02-15 12:51:38,869:INFO:Uploading model into container now
2023-02-15 12:51:38,869:INFO:_master_model_container: 10
2023-02-15 12:51:38,869:INFO:_display_container: 2
2023-02-15 12:51:38,869:INFO:HuberRegressor()
2023-02-15 12:51:38,869:INFO:create_model() successfully completed......................................
2023-02-15 12:51:38,992:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:38,992:INFO:Creating metrics dataframe
2023-02-15 12:51:38,999:INFO:Initializing K Neighbors Regressor
2023-02-15 12:51:38,999:INFO:Total runtime is 0.6555167555809022 minutes
2023-02-15 12:51:39,001:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:39,001:INFO:Initializing create_model()
2023-02-15 12:51:39,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:39,001:INFO:Checking exceptions
2023-02-15 12:51:39,001:INFO:Importing libraries
2023-02-15 12:51:39,001:INFO:Copying training dataset
2023-02-15 12:51:39,014:INFO:Defining folds
2023-02-15 12:51:39,014:INFO:Declaring metric variables
2023-02-15 12:51:39,016:INFO:Importing untrained model
2023-02-15 12:51:39,018:INFO:K Neighbors Regressor Imported successfully
2023-02-15 12:51:39,021:INFO:Starting cross validation
2023-02-15 12:51:39,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:51:40,617:INFO:Calculating mean and std
2023-02-15 12:51:40,618:INFO:Creating metrics dataframe
2023-02-15 12:51:40,621:INFO:Uploading results into container
2023-02-15 12:51:40,621:INFO:Uploading model into container now
2023-02-15 12:51:40,621:INFO:_master_model_container: 11
2023-02-15 12:51:40,621:INFO:_display_container: 2
2023-02-15 12:51:40,622:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-15 12:51:40,622:INFO:create_model() successfully completed......................................
2023-02-15 12:51:40,727:INFO:SubProcess create_model() end ==================================
2023-02-15 12:51:40,727:INFO:Creating metrics dataframe
2023-02-15 12:51:40,733:INFO:Initializing Decision Tree Regressor
2023-02-15 12:51:40,733:INFO:Total runtime is 0.6844284296035767 minutes
2023-02-15 12:51:40,735:INFO:SubProcess create_model() called ==================================
2023-02-15 12:51:40,735:INFO:Initializing create_model()
2023-02-15 12:51:40,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:51:40,735:INFO:Checking exceptions
2023-02-15 12:51:40,735:INFO:Importing libraries
2023-02-15 12:51:40,735:INFO:Copying training dataset
2023-02-15 12:51:40,749:INFO:Defining folds
2023-02-15 12:51:40,749:INFO:Declaring metric variables
2023-02-15 12:51:40,751:INFO:Importing untrained model
2023-02-15 12:51:40,753:INFO:Decision Tree Regressor Imported successfully
2023-02-15 12:51:40,756:INFO:Starting cross validation
2023-02-15 12:51:40,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:52:18,048:INFO:Calculating mean and std
2023-02-15 12:52:18,049:INFO:Creating metrics dataframe
2023-02-15 12:52:18,051:INFO:Uploading results into container
2023-02-15 12:52:18,051:INFO:Uploading model into container now
2023-02-15 12:52:18,051:INFO:_master_model_container: 12
2023-02-15 12:52:18,051:INFO:_display_container: 2
2023-02-15 12:52:18,052:INFO:DecisionTreeRegressor(random_state=11)
2023-02-15 12:52:18,052:INFO:create_model() successfully completed......................................
2023-02-15 12:52:18,152:INFO:SubProcess create_model() end ==================================
2023-02-15 12:52:18,152:INFO:Creating metrics dataframe
2023-02-15 12:52:18,159:INFO:Initializing Random Forest Regressor
2023-02-15 12:52:18,159:INFO:Total runtime is 1.3081963936487835 minutes
2023-02-15 12:52:18,161:INFO:SubProcess create_model() called ==================================
2023-02-15 12:52:18,161:INFO:Initializing create_model()
2023-02-15 12:52:18,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:52:18,161:INFO:Checking exceptions
2023-02-15 12:52:18,161:INFO:Importing libraries
2023-02-15 12:52:18,161:INFO:Copying training dataset
2023-02-15 12:52:18,175:INFO:Defining folds
2023-02-15 12:52:18,175:INFO:Declaring metric variables
2023-02-15 12:52:18,177:INFO:Importing untrained model
2023-02-15 12:52:18,178:INFO:Random Forest Regressor Imported successfully
2023-02-15 12:52:18,181:INFO:Starting cross validation
2023-02-15 12:52:18,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:54:38,218:INFO:Calculating mean and std
2023-02-15 12:54:38,218:INFO:Creating metrics dataframe
2023-02-15 12:54:38,221:INFO:Uploading results into container
2023-02-15 12:54:38,221:INFO:Uploading model into container now
2023-02-15 12:54:38,221:INFO:_master_model_container: 13
2023-02-15 12:54:38,221:INFO:_display_container: 2
2023-02-15 12:54:38,222:INFO:RandomForestRegressor(n_jobs=-1, random_state=11)
2023-02-15 12:54:38,222:INFO:create_model() successfully completed......................................
2023-02-15 12:54:38,335:INFO:SubProcess create_model() end ==================================
2023-02-15 12:54:38,336:INFO:Creating metrics dataframe
2023-02-15 12:54:38,343:INFO:Initializing Extra Trees Regressor
2023-02-15 12:54:38,343:INFO:Total runtime is 3.6445886135101317 minutes
2023-02-15 12:54:38,345:INFO:SubProcess create_model() called ==================================
2023-02-15 12:54:38,345:INFO:Initializing create_model()
2023-02-15 12:54:38,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:54:38,345:INFO:Checking exceptions
2023-02-15 12:54:38,345:INFO:Importing libraries
2023-02-15 12:54:38,345:INFO:Copying training dataset
2023-02-15 12:54:38,359:INFO:Defining folds
2023-02-15 12:54:38,359:INFO:Declaring metric variables
2023-02-15 12:54:38,361:INFO:Importing untrained model
2023-02-15 12:54:38,363:INFO:Extra Trees Regressor Imported successfully
2023-02-15 12:54:38,366:INFO:Starting cross validation
2023-02-15 12:54:38,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:55:06,479:INFO:Calculating mean and std
2023-02-15 12:55:06,480:INFO:Creating metrics dataframe
2023-02-15 12:55:06,482:INFO:Uploading results into container
2023-02-15 12:55:06,482:INFO:Uploading model into container now
2023-02-15 12:55:06,482:INFO:_master_model_container: 14
2023-02-15 12:55:06,482:INFO:_display_container: 2
2023-02-15 12:55:06,482:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=11)
2023-02-15 12:55:06,482:INFO:create_model() successfully completed......................................
2023-02-15 12:55:06,590:INFO:SubProcess create_model() end ==================================
2023-02-15 12:55:06,591:INFO:Creating metrics dataframe
2023-02-15 12:55:06,603:INFO:Initializing AdaBoost Regressor
2023-02-15 12:55:06,604:INFO:Total runtime is 4.115599044164021 minutes
2023-02-15 12:55:06,605:INFO:SubProcess create_model() called ==================================
2023-02-15 12:55:06,606:INFO:Initializing create_model()
2023-02-15 12:55:06,606:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:55:06,606:INFO:Checking exceptions
2023-02-15 12:55:06,606:INFO:Importing libraries
2023-02-15 12:55:06,606:INFO:Copying training dataset
2023-02-15 12:55:06,620:INFO:Defining folds
2023-02-15 12:55:06,620:INFO:Declaring metric variables
2023-02-15 12:55:06,622:INFO:Importing untrained model
2023-02-15 12:55:06,624:INFO:AdaBoost Regressor Imported successfully
2023-02-15 12:55:06,628:INFO:Starting cross validation
2023-02-15 12:55:06,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 12:57:15,589:INFO:Calculating mean and std
2023-02-15 12:57:15,590:INFO:Creating metrics dataframe
2023-02-15 12:57:15,592:INFO:Uploading results into container
2023-02-15 12:57:15,592:INFO:Uploading model into container now
2023-02-15 12:57:15,592:INFO:_master_model_container: 15
2023-02-15 12:57:15,592:INFO:_display_container: 2
2023-02-15 12:57:15,592:INFO:AdaBoostRegressor(random_state=11)
2023-02-15 12:57:15,592:INFO:create_model() successfully completed......................................
2023-02-15 12:57:15,709:INFO:SubProcess create_model() end ==================================
2023-02-15 12:57:15,709:INFO:Creating metrics dataframe
2023-02-15 12:57:15,717:INFO:Initializing Gradient Boosting Regressor
2023-02-15 12:57:15,717:INFO:Total runtime is 6.26749259630839 minutes
2023-02-15 12:57:15,719:INFO:SubProcess create_model() called ==================================
2023-02-15 12:57:15,719:INFO:Initializing create_model()
2023-02-15 12:57:15,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4a1e2fbfa0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495463bf10>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:57:15,719:INFO:Checking exceptions
2023-02-15 12:57:15,719:INFO:Importing libraries
2023-02-15 12:57:15,719:INFO:Copying training dataset
2023-02-15 12:57:15,735:INFO:Defining folds
2023-02-15 12:57:15,735:INFO:Declaring metric variables
2023-02-15 12:57:15,737:INFO:Importing untrained model
2023-02-15 12:57:15,739:INFO:Gradient Boosting Regressor Imported successfully
2023-02-15 12:57:15,742:INFO:Starting cross validation
2023-02-15 12:57:15,743:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 13:03:15,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:15,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:15,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:15,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:15,678:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 13:03:15,755:INFO:PyCaret RegressionExperiment
2023-02-15 13:03:15,755:INFO:Logging name: reg-default-name
2023-02-15 13:03:15,755:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 13:03:15,755:INFO:version 3.0.0.rc9
2023-02-15 13:03:15,755:INFO:Initializing setup()
2023-02-15 13:03:15,755:INFO:self.USI: 6090
2023-02-15 13:03:15,755:INFO:self._variable_keys: {'transform_target_param', 'fold_generator', 'USI', 'fold_shuffle_param', '_ml_usecase', 'y', 'idx', 'seed', 'data', 'target_param', 'logging_param', '_available_plots', 'X_train', 'fold_groups_param', 'n_jobs_param', 'log_plots_param', 'gpu_n_jobs_param', 'y_test', 'y_train', 'exp_name_log', 'exp_id', 'X', 'gpu_param', 'pipeline', 'X_test', 'memory', 'html_param'}
2023-02-15 13:03:15,755:INFO:Checking environment
2023-02-15 13:03:15,755:INFO:python_version: 3.8.16
2023-02-15 13:03:15,755:INFO:python_build: ('default', 'Jan 17 2023 23:13:24')
2023-02-15 13:03:15,755:INFO:machine: x86_64
2023-02-15 13:03:15,755:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 13:03:15,756:INFO:Memory: svmem(total=134979592192, available=119091933184, percent=11.8, used=14067355648, free=84587614208, active=5645996032, inactive=41377120256, buffers=1719013376, cached=34605608960, shared=557944832, slab=2739171328)
2023-02-15 13:03:15,756:INFO:Physical Core: 16
2023-02-15 13:03:15,756:INFO:Logical Core: 32
2023-02-15 13:03:15,756:INFO:Checking libraries
2023-02-15 13:03:15,756:INFO:System:
2023-02-15 13:03:15,756:INFO:    python: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0]
2023-02-15 13:03:15,756:INFO:executable: /home/moussa/anaconda3/envs/research2/bin/python
2023-02-15 13:03:15,756:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 13:03:15,756:INFO:PyCaret required dependencies:
2023-02-15 13:03:15,756:INFO:                 pip: 22.3.1
2023-02-15 13:03:15,756:INFO:          setuptools: 60.10.0
2023-02-15 13:03:15,756:INFO:             pycaret: 3.0.0rc9
2023-02-15 13:03:15,756:INFO:             IPython: 7.31.1
2023-02-15 13:03:15,756:INFO:          ipywidgets: 7.7.3
2023-02-15 13:03:15,756:INFO:                tqdm: 4.64.1
2023-02-15 13:03:15,756:INFO:               numpy: 1.23.5
2023-02-15 13:03:15,756:INFO:              pandas: 1.5.3
2023-02-15 13:03:15,756:INFO:              jinja2: 3.1.2
2023-02-15 13:03:15,756:INFO:               scipy: 1.9.1
2023-02-15 13:03:15,757:INFO:              joblib: 1.2.0
2023-02-15 13:03:15,757:INFO:             sklearn: 1.2.1
2023-02-15 13:03:15,757:INFO:                pyod: 1.0.7
2023-02-15 13:03:15,757:INFO:            imblearn: 0.10.1
2023-02-15 13:03:15,757:INFO:   category_encoders: 2.6.0
2023-02-15 13:03:15,757:INFO:            lightgbm: 3.3.5
2023-02-15 13:03:15,757:INFO:               numba: 0.56.4
2023-02-15 13:03:15,757:INFO:            requests: 2.28.1
2023-02-15 13:03:15,757:INFO:          matplotlib: 3.6.3
2023-02-15 13:03:15,757:INFO:          scikitplot: 0.3.7
2023-02-15 13:03:15,757:INFO:         yellowbrick: 1.5
2023-02-15 13:03:15,757:INFO:              plotly: 5.13.0
2023-02-15 13:03:15,757:INFO:             kaleido: 0.2.1
2023-02-15 13:03:15,757:INFO:         statsmodels: 0.13.5
2023-02-15 13:03:15,757:INFO:              sktime: 0.16.1
2023-02-15 13:03:15,757:INFO:               tbats: 1.1.2
2023-02-15 13:03:15,757:INFO:            pmdarima: 2.0.2
2023-02-15 13:03:15,757:INFO:              psutil: 5.9.0
2023-02-15 13:03:15,757:INFO:PyCaret optional dependencies:
2023-02-15 13:03:16,060:INFO:                shap: 0.41.0
2023-02-15 13:03:16,060:INFO:           interpret: 0.3.0
2023-02-15 13:03:16,060:INFO:                umap: 0.5.3
2023-02-15 13:03:16,060:INFO:    pandas_profiling: 4.0.0
2023-02-15 13:03:16,060:INFO:  explainerdashboard: 0.4.2
2023-02-15 13:03:16,060:INFO:             autoviz: 0.1.58
2023-02-15 13:03:16,060:INFO:           fairlearn: 0.7.0
2023-02-15 13:03:16,060:INFO:             xgboost: 1.7.3
2023-02-15 13:03:16,060:INFO:            catboost: 1.1.1
2023-02-15 13:03:16,060:INFO:              kmodes: 0.12.2
2023-02-15 13:03:16,060:INFO:             mlxtend: 0.21.0
2023-02-15 13:03:16,060:INFO:       statsforecast: 1.4.0
2023-02-15 13:03:16,060:INFO:        tune_sklearn: 0.4.5
2023-02-15 13:03:16,060:INFO:                 ray: 2.2.0
2023-02-15 13:03:16,060:INFO:            hyperopt: 0.2.7
2023-02-15 13:03:16,060:INFO:              optuna: 3.1.0
2023-02-15 13:03:16,060:INFO:               skopt: 0.9.0
2023-02-15 13:03:16,060:INFO:              mlflow: 1.30.0
2023-02-15 13:03:16,060:INFO:              gradio: 3.18.0
2023-02-15 13:03:16,060:INFO:             fastapi: 0.92.0
2023-02-15 13:03:16,060:INFO:             uvicorn: 0.20.0
2023-02-15 13:03:16,060:INFO:              m2cgen: 0.10.0
2023-02-15 13:03:16,060:INFO:           evidently: 0.2.4
2023-02-15 13:03:16,060:INFO:               fugue: 0.8.1.dev4
2023-02-15 13:03:16,060:INFO:           streamlit: Not installed
2023-02-15 13:03:16,060:INFO:             prophet: Not installed
2023-02-15 13:03:16,060:INFO:None
2023-02-15 13:03:16,060:INFO:Set up GPU usage.
2023-02-15 13:03:16,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:16,061:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 13:03:16,061:INFO:Set up data.
2023-02-15 13:03:16,120:INFO:Set up train/test split.
2023-02-15 13:03:16,149:INFO:Set up index.
2023-02-15 13:03:16,155:INFO:Set up folding strategy.
2023-02-15 13:03:16,155:INFO:Assigning column types.
2023-02-15 13:03:16,166:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 13:03:16,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:16,166:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 13:03:16,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:16,169:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 13:03:16,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:16,172:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 13:03:16,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:16,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 13:03:16,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:16,240:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 13:03:16,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:16,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:03:16,240:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 13:04:52,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,246:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 13:04:52,322:INFO:PyCaret RegressionExperiment
2023-02-15 13:04:52,322:INFO:Logging name: reg-default-name
2023-02-15 13:04:52,322:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 13:04:52,322:INFO:version 3.0.0.rc9
2023-02-15 13:04:52,322:INFO:Initializing setup()
2023-02-15 13:04:52,322:INFO:self.USI: f012
2023-02-15 13:04:52,322:INFO:self._variable_keys: {'gpu_param', 'seed', '_ml_usecase', 'USI', 'transform_target_param', 'gpu_n_jobs_param', 'X_test', 'n_jobs_param', 'exp_id', 'logging_param', 'fold_shuffle_param', 'X_train', '_available_plots', 'memory', 'idx', 'y_train', 'exp_name_log', 'y_test', 'target_param', 'y', 'fold_groups_param', 'log_plots_param', 'fold_generator', 'pipeline', 'html_param', 'data', 'X'}
2023-02-15 13:04:52,322:INFO:Checking environment
2023-02-15 13:04:52,322:INFO:python_version: 3.8.16
2023-02-15 13:04:52,322:INFO:python_build: ('default', 'Jan 17 2023 23:13:24')
2023-02-15 13:04:52,322:INFO:machine: x86_64
2023-02-15 13:04:52,322:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 13:04:52,323:INFO:Memory: svmem(total=134979592192, available=119618838528, percent=11.4, used=13532823552, free=85114773504, active=5652045824, inactive=40849166336, buffers=1719463936, cached=34612531200, shared=565571584, slab=2737246208)
2023-02-15 13:04:52,323:INFO:Physical Core: 16
2023-02-15 13:04:52,323:INFO:Logical Core: 32
2023-02-15 13:04:52,323:INFO:Checking libraries
2023-02-15 13:04:52,323:INFO:System:
2023-02-15 13:04:52,323:INFO:    python: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0]
2023-02-15 13:04:52,323:INFO:executable: /home/moussa/anaconda3/envs/research2/bin/python
2023-02-15 13:04:52,323:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 13:04:52,323:INFO:PyCaret required dependencies:
2023-02-15 13:04:52,323:INFO:                 pip: 22.3.1
2023-02-15 13:04:52,323:INFO:          setuptools: 60.10.0
2023-02-15 13:04:52,323:INFO:             pycaret: 3.0.0rc9
2023-02-15 13:04:52,323:INFO:             IPython: 7.31.1
2023-02-15 13:04:52,323:INFO:          ipywidgets: 7.7.3
2023-02-15 13:04:52,323:INFO:                tqdm: 4.64.1
2023-02-15 13:04:52,323:INFO:               numpy: 1.23.5
2023-02-15 13:04:52,323:INFO:              pandas: 1.5.3
2023-02-15 13:04:52,323:INFO:              jinja2: 3.1.2
2023-02-15 13:04:52,323:INFO:               scipy: 1.9.1
2023-02-15 13:04:52,323:INFO:              joblib: 1.2.0
2023-02-15 13:04:52,323:INFO:             sklearn: 1.2.1
2023-02-15 13:04:52,323:INFO:                pyod: 1.0.7
2023-02-15 13:04:52,324:INFO:            imblearn: 0.10.1
2023-02-15 13:04:52,324:INFO:   category_encoders: 2.6.0
2023-02-15 13:04:52,324:INFO:            lightgbm: 3.3.5
2023-02-15 13:04:52,324:INFO:               numba: 0.56.4
2023-02-15 13:04:52,324:INFO:            requests: 2.28.1
2023-02-15 13:04:52,324:INFO:          matplotlib: 3.6.3
2023-02-15 13:04:52,324:INFO:          scikitplot: 0.3.7
2023-02-15 13:04:52,324:INFO:         yellowbrick: 1.5
2023-02-15 13:04:52,324:INFO:              plotly: 5.13.0
2023-02-15 13:04:52,324:INFO:             kaleido: 0.2.1
2023-02-15 13:04:52,324:INFO:         statsmodels: 0.13.5
2023-02-15 13:04:52,324:INFO:              sktime: 0.16.1
2023-02-15 13:04:52,324:INFO:               tbats: 1.1.2
2023-02-15 13:04:52,324:INFO:            pmdarima: 2.0.2
2023-02-15 13:04:52,324:INFO:              psutil: 5.9.0
2023-02-15 13:04:52,324:INFO:PyCaret optional dependencies:
2023-02-15 13:04:52,617:INFO:                shap: 0.41.0
2023-02-15 13:04:52,617:INFO:           interpret: 0.3.0
2023-02-15 13:04:52,617:INFO:                umap: 0.5.3
2023-02-15 13:04:52,617:INFO:    pandas_profiling: 4.0.0
2023-02-15 13:04:52,617:INFO:  explainerdashboard: 0.4.2
2023-02-15 13:04:52,617:INFO:             autoviz: 0.1.58
2023-02-15 13:04:52,617:INFO:           fairlearn: 0.7.0
2023-02-15 13:04:52,617:INFO:             xgboost: 1.7.3
2023-02-15 13:04:52,617:INFO:            catboost: 1.1.1
2023-02-15 13:04:52,617:INFO:              kmodes: 0.12.2
2023-02-15 13:04:52,617:INFO:             mlxtend: 0.21.0
2023-02-15 13:04:52,617:INFO:       statsforecast: 1.4.0
2023-02-15 13:04:52,617:INFO:        tune_sklearn: 0.4.5
2023-02-15 13:04:52,617:INFO:                 ray: 2.2.0
2023-02-15 13:04:52,617:INFO:            hyperopt: 0.2.7
2023-02-15 13:04:52,617:INFO:              optuna: 3.1.0
2023-02-15 13:04:52,617:INFO:               skopt: 0.9.0
2023-02-15 13:04:52,617:INFO:              mlflow: 1.30.0
2023-02-15 13:04:52,617:INFO:              gradio: 3.18.0
2023-02-15 13:04:52,617:INFO:             fastapi: 0.92.0
2023-02-15 13:04:52,617:INFO:             uvicorn: 0.20.0
2023-02-15 13:04:52,617:INFO:              m2cgen: 0.10.0
2023-02-15 13:04:52,617:INFO:           evidently: 0.2.4
2023-02-15 13:04:52,617:INFO:               fugue: 0.8.1.dev4
2023-02-15 13:04:52,617:INFO:           streamlit: Not installed
2023-02-15 13:04:52,617:INFO:             prophet: Not installed
2023-02-15 13:04:52,618:INFO:None
2023-02-15 13:04:52,618:INFO:Set up GPU usage.
2023-02-15 13:04:52,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,618:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 13:04:52,618:INFO:Set up data.
2023-02-15 13:04:52,676:INFO:Set up train/test split.
2023-02-15 13:04:52,705:INFO:Set up index.
2023-02-15 13:04:52,711:INFO:Set up folding strategy.
2023-02-15 13:04:52,711:INFO:Assigning column types.
2023-02-15 13:04:52,723:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 13:04:52,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,723:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 13:04:52,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,725:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 13:04:52,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,728:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 13:04:52,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,771:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 13:04:52,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,798:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 13:04:52,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:04:52,799:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 13:06:01,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:01,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:01,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:01,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:02,119:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 13:06:02,195:INFO:PyCaret RegressionExperiment
2023-02-15 13:06:02,195:INFO:Logging name: reg-default-name
2023-02-15 13:06:02,195:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 13:06:02,195:INFO:version 3.0.0.rc9
2023-02-15 13:06:02,195:INFO:Initializing setup()
2023-02-15 13:06:02,195:INFO:self.USI: 4912
2023-02-15 13:06:02,195:INFO:self._variable_keys: {'seed', 'fold_generator', 'transform_target_param', 'gpu_n_jobs_param', '_available_plots', 'exp_id', 'log_plots_param', 'USI', 'y_train', 'fold_groups_param', 'logging_param', 'pipeline', 'exp_name_log', 'target_param', 'memory', 'idx', 'X_test', '_ml_usecase', 'html_param', 'data', 'fold_shuffle_param', 'y', 'n_jobs_param', 'y_test', 'X_train', 'gpu_param', 'X'}
2023-02-15 13:06:02,195:INFO:Checking environment
2023-02-15 13:06:02,195:INFO:python_version: 3.8.16
2023-02-15 13:06:02,195:INFO:python_build: ('default', 'Jan 17 2023 23:13:24')
2023-02-15 13:06:02,195:INFO:machine: x86_64
2023-02-15 13:06:02,195:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 13:06:02,195:INFO:Memory: svmem(total=134979592192, available=119587753984, percent=11.4, used=13559529472, free=85141839872, active=5655687168, inactive=40821420032, buffers=1719861248, cached=34558361600, shared=569950208, slab=2735075328)
2023-02-15 13:06:02,196:INFO:Physical Core: 16
2023-02-15 13:06:02,196:INFO:Logical Core: 32
2023-02-15 13:06:02,196:INFO:Checking libraries
2023-02-15 13:06:02,196:INFO:System:
2023-02-15 13:06:02,196:INFO:    python: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0]
2023-02-15 13:06:02,196:INFO:executable: /home/moussa/anaconda3/envs/research2/bin/python
2023-02-15 13:06:02,196:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 13:06:02,196:INFO:PyCaret required dependencies:
2023-02-15 13:06:02,196:INFO:                 pip: 22.3.1
2023-02-15 13:06:02,196:INFO:          setuptools: 60.10.0
2023-02-15 13:06:02,196:INFO:             pycaret: 3.0.0rc9
2023-02-15 13:06:02,196:INFO:             IPython: 7.31.1
2023-02-15 13:06:02,196:INFO:          ipywidgets: 7.7.3
2023-02-15 13:06:02,196:INFO:                tqdm: 4.64.1
2023-02-15 13:06:02,196:INFO:               numpy: 1.23.5
2023-02-15 13:06:02,196:INFO:              pandas: 1.5.3
2023-02-15 13:06:02,196:INFO:              jinja2: 3.1.2
2023-02-15 13:06:02,196:INFO:               scipy: 1.9.1
2023-02-15 13:06:02,196:INFO:              joblib: 1.2.0
2023-02-15 13:06:02,196:INFO:             sklearn: 1.2.1
2023-02-15 13:06:02,196:INFO:                pyod: 1.0.7
2023-02-15 13:06:02,196:INFO:            imblearn: 0.10.1
2023-02-15 13:06:02,196:INFO:   category_encoders: 2.6.0
2023-02-15 13:06:02,196:INFO:            lightgbm: 3.3.5
2023-02-15 13:06:02,196:INFO:               numba: 0.56.4
2023-02-15 13:06:02,196:INFO:            requests: 2.28.1
2023-02-15 13:06:02,196:INFO:          matplotlib: 3.6.3
2023-02-15 13:06:02,196:INFO:          scikitplot: 0.3.7
2023-02-15 13:06:02,196:INFO:         yellowbrick: 1.5
2023-02-15 13:06:02,196:INFO:              plotly: 5.13.0
2023-02-15 13:06:02,196:INFO:             kaleido: 0.2.1
2023-02-15 13:06:02,196:INFO:         statsmodels: 0.13.5
2023-02-15 13:06:02,196:INFO:              sktime: 0.16.1
2023-02-15 13:06:02,196:INFO:               tbats: 1.1.2
2023-02-15 13:06:02,196:INFO:            pmdarima: 2.0.2
2023-02-15 13:06:02,196:INFO:              psutil: 5.9.0
2023-02-15 13:06:02,196:INFO:PyCaret optional dependencies:
2023-02-15 13:06:02,490:INFO:                shap: 0.41.0
2023-02-15 13:06:02,490:INFO:           interpret: 0.3.0
2023-02-15 13:06:02,490:INFO:                umap: 0.5.3
2023-02-15 13:06:02,490:INFO:    pandas_profiling: 4.0.0
2023-02-15 13:06:02,490:INFO:  explainerdashboard: 0.4.2
2023-02-15 13:06:02,490:INFO:             autoviz: 0.1.58
2023-02-15 13:06:02,490:INFO:           fairlearn: 0.7.0
2023-02-15 13:06:02,490:INFO:             xgboost: 1.7.3
2023-02-15 13:06:02,490:INFO:            catboost: 1.1.1
2023-02-15 13:06:02,490:INFO:              kmodes: 0.12.2
2023-02-15 13:06:02,490:INFO:             mlxtend: 0.21.0
2023-02-15 13:06:02,491:INFO:       statsforecast: 1.4.0
2023-02-15 13:06:02,491:INFO:        tune_sklearn: 0.4.5
2023-02-15 13:06:02,491:INFO:                 ray: 2.2.0
2023-02-15 13:06:02,491:INFO:            hyperopt: 0.2.7
2023-02-15 13:06:02,491:INFO:              optuna: 3.1.0
2023-02-15 13:06:02,491:INFO:               skopt: 0.9.0
2023-02-15 13:06:02,491:INFO:              mlflow: 1.30.0
2023-02-15 13:06:02,491:INFO:              gradio: 3.18.0
2023-02-15 13:06:02,491:INFO:             fastapi: 0.92.0
2023-02-15 13:06:02,491:INFO:             uvicorn: 0.20.0
2023-02-15 13:06:02,491:INFO:              m2cgen: 0.10.0
2023-02-15 13:06:02,491:INFO:           evidently: 0.2.4
2023-02-15 13:06:02,491:INFO:               fugue: 0.8.1.dev4
2023-02-15 13:06:02,491:INFO:           streamlit: Not installed
2023-02-15 13:06:02,491:INFO:             prophet: Not installed
2023-02-15 13:06:02,491:INFO:None
2023-02-15 13:06:02,491:INFO:Set up GPU usage.
2023-02-15 13:06:02,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:02,491:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 13:06:02,491:INFO:Set up data.
2023-02-15 13:06:02,551:INFO:Set up train/test split.
2023-02-15 13:06:02,580:INFO:Set up index.
2023-02-15 13:06:02,586:INFO:Set up folding strategy.
2023-02-15 13:06:02,586:INFO:Assigning column types.
2023-02-15 13:06:02,598:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 13:06:02,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:02,598:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 13:06:02,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:02,601:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 13:06:02,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:02,603:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 13:06:02,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:02,647:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 13:06:02,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:02,675:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 13:06:02,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:02,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:06:02,675:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 13:08:22,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,369:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 13:08:22,451:INFO:PyCaret RegressionExperiment
2023-02-15 13:08:22,451:INFO:Logging name: reg-default-name
2023-02-15 13:08:22,451:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 13:08:22,451:INFO:version 3.0.0.rc9
2023-02-15 13:08:22,451:INFO:Initializing setup()
2023-02-15 13:08:22,451:INFO:self.USI: 7aa3
2023-02-15 13:08:22,451:INFO:self._variable_keys: {'idx', 'X_test', 'exp_id', 'y', 'USI', '_ml_usecase', 'memory', 'y_test', 'logging_param', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param', 'y_train', 'X_train', 'fold_groups_param', 'data', 'exp_name_log', 'transform_target_param', 'gpu_param', 'log_plots_param', '_available_plots', 'seed', 'n_jobs_param', 'target_param', 'pipeline', 'html_param', 'fold_generator'}
2023-02-15 13:08:22,451:INFO:Checking environment
2023-02-15 13:08:22,451:INFO:python_version: 3.8.16
2023-02-15 13:08:22,451:INFO:python_build: ('default', 'Jan 17 2023 23:13:24')
2023-02-15 13:08:22,451:INFO:machine: x86_64
2023-02-15 13:08:22,451:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 13:08:22,451:INFO:Memory: svmem(total=134979592192, available=119183237120, percent=11.7, used=13946253312, free=84717461504, active=5660258304, inactive=41233010688, buffers=1720827904, cached=34595049472, shared=587743232, slab=2735742976)
2023-02-15 13:08:22,452:INFO:Physical Core: 16
2023-02-15 13:08:22,452:INFO:Logical Core: 32
2023-02-15 13:08:22,452:INFO:Checking libraries
2023-02-15 13:08:22,452:INFO:System:
2023-02-15 13:08:22,452:INFO:    python: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0]
2023-02-15 13:08:22,452:INFO:executable: /home/moussa/anaconda3/envs/research2/bin/python
2023-02-15 13:08:22,452:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 13:08:22,452:INFO:PyCaret required dependencies:
2023-02-15 13:08:22,452:INFO:                 pip: 22.3.1
2023-02-15 13:08:22,452:INFO:          setuptools: 60.10.0
2023-02-15 13:08:22,452:INFO:             pycaret: 3.0.0rc9
2023-02-15 13:08:22,452:INFO:             IPython: 7.31.1
2023-02-15 13:08:22,452:INFO:          ipywidgets: 7.7.3
2023-02-15 13:08:22,452:INFO:                tqdm: 4.64.1
2023-02-15 13:08:22,452:INFO:               numpy: 1.23.5
2023-02-15 13:08:22,452:INFO:              pandas: 1.5.3
2023-02-15 13:08:22,452:INFO:              jinja2: 3.1.2
2023-02-15 13:08:22,452:INFO:               scipy: 1.9.1
2023-02-15 13:08:22,452:INFO:              joblib: 1.2.0
2023-02-15 13:08:22,452:INFO:             sklearn: 1.2.1
2023-02-15 13:08:22,453:INFO:                pyod: 1.0.7
2023-02-15 13:08:22,453:INFO:            imblearn: 0.10.1
2023-02-15 13:08:22,453:INFO:   category_encoders: 2.6.0
2023-02-15 13:08:22,453:INFO:            lightgbm: 3.3.5
2023-02-15 13:08:22,453:INFO:               numba: 0.56.4
2023-02-15 13:08:22,453:INFO:            requests: 2.28.1
2023-02-15 13:08:22,453:INFO:          matplotlib: 3.6.3
2023-02-15 13:08:22,453:INFO:          scikitplot: 0.3.7
2023-02-15 13:08:22,453:INFO:         yellowbrick: 1.5
2023-02-15 13:08:22,453:INFO:              plotly: 5.13.0
2023-02-15 13:08:22,453:INFO:             kaleido: 0.2.1
2023-02-15 13:08:22,453:INFO:         statsmodels: 0.13.5
2023-02-15 13:08:22,453:INFO:              sktime: 0.16.1
2023-02-15 13:08:22,453:INFO:               tbats: 1.1.2
2023-02-15 13:08:22,453:INFO:            pmdarima: 2.0.2
2023-02-15 13:08:22,453:INFO:              psutil: 5.9.0
2023-02-15 13:08:22,453:INFO:PyCaret optional dependencies:
2023-02-15 13:08:22,767:INFO:                shap: 0.41.0
2023-02-15 13:08:22,767:INFO:           interpret: 0.3.0
2023-02-15 13:08:22,767:INFO:                umap: 0.5.3
2023-02-15 13:08:22,767:INFO:    pandas_profiling: 4.0.0
2023-02-15 13:08:22,767:INFO:  explainerdashboard: 0.4.2
2023-02-15 13:08:22,767:INFO:             autoviz: 0.1.58
2023-02-15 13:08:22,767:INFO:           fairlearn: 0.7.0
2023-02-15 13:08:22,767:INFO:             xgboost: 1.7.3
2023-02-15 13:08:22,767:INFO:            catboost: 1.1.1
2023-02-15 13:08:22,767:INFO:              kmodes: 0.12.2
2023-02-15 13:08:22,767:INFO:             mlxtend: 0.21.0
2023-02-15 13:08:22,767:INFO:       statsforecast: 1.4.0
2023-02-15 13:08:22,767:INFO:        tune_sklearn: 0.4.5
2023-02-15 13:08:22,767:INFO:                 ray: 2.2.0
2023-02-15 13:08:22,767:INFO:            hyperopt: 0.2.7
2023-02-15 13:08:22,767:INFO:              optuna: 3.1.0
2023-02-15 13:08:22,767:INFO:               skopt: 0.9.0
2023-02-15 13:08:22,767:INFO:              mlflow: 1.30.0
2023-02-15 13:08:22,767:INFO:              gradio: 3.18.0
2023-02-15 13:08:22,767:INFO:             fastapi: 0.92.0
2023-02-15 13:08:22,767:INFO:             uvicorn: 0.20.0
2023-02-15 13:08:22,767:INFO:              m2cgen: 0.10.0
2023-02-15 13:08:22,767:INFO:           evidently: 0.2.4
2023-02-15 13:08:22,767:INFO:               fugue: 0.8.1.dev4
2023-02-15 13:08:22,767:INFO:           streamlit: Not installed
2023-02-15 13:08:22,767:INFO:             prophet: Not installed
2023-02-15 13:08:22,767:INFO:None
2023-02-15 13:08:22,767:INFO:Set up GPU usage.
2023-02-15 13:08:22,767:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,767:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 13:08:22,767:INFO:Set up data.
2023-02-15 13:08:22,828:INFO:Set up train/test split.
2023-02-15 13:08:22,860:INFO:Set up index.
2023-02-15 13:08:22,867:INFO:Set up folding strategy.
2023-02-15 13:08:22,867:INFO:Assigning column types.
2023-02-15 13:08:22,881:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 13:08:22,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,881:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 13:08:22,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,884:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 13:08:22,884:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,888:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 13:08:22,888:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 13:08:22,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,977:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 13:08:22,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:08:22,978:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 13:09:44,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:44,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:44,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:44,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:44,515:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 13:09:44,591:INFO:PyCaret RegressionExperiment
2023-02-15 13:09:44,591:INFO:Logging name: reg-default-name
2023-02-15 13:09:44,591:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 13:09:44,591:INFO:version 3.0.0.rc9
2023-02-15 13:09:44,591:INFO:Initializing setup()
2023-02-15 13:09:44,591:INFO:self.USI: c084
2023-02-15 13:09:44,591:INFO:self._variable_keys: {'html_param', 'y_test', '_ml_usecase', 'exp_id', 'target_param', 'logging_param', 'transform_target_param', 'idx', 'fold_shuffle_param', 'fold_groups_param', 'X_train', 'data', 'gpu_n_jobs_param', 'gpu_param', '_available_plots', 'memory', 'y', 'fold_generator', 'X', 'X_test', 'seed', 'pipeline', 'n_jobs_param', 'y_train', 'USI', 'log_plots_param', 'exp_name_log'}
2023-02-15 13:09:44,591:INFO:Checking environment
2023-02-15 13:09:44,591:INFO:python_version: 3.8.16
2023-02-15 13:09:44,591:INFO:python_build: ('default', 'Jan 17 2023 23:13:24')
2023-02-15 13:09:44,591:INFO:machine: x86_64
2023-02-15 13:09:44,591:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 13:09:44,591:INFO:Memory: svmem(total=134979592192, available=119216173056, percent=11.7, used=13921873920, free=84748484608, active=5661511680, inactive=41199837184, buffers=1721180160, cached=34588053504, shared=579186688, slab=2735792128)
2023-02-15 13:09:44,592:INFO:Physical Core: 16
2023-02-15 13:09:44,592:INFO:Logical Core: 32
2023-02-15 13:09:44,592:INFO:Checking libraries
2023-02-15 13:09:44,592:INFO:System:
2023-02-15 13:09:44,592:INFO:    python: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0]
2023-02-15 13:09:44,592:INFO:executable: /home/moussa/anaconda3/envs/research2/bin/python
2023-02-15 13:09:44,592:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 13:09:44,592:INFO:PyCaret required dependencies:
2023-02-15 13:09:44,592:INFO:                 pip: 22.3.1
2023-02-15 13:09:44,592:INFO:          setuptools: 60.10.0
2023-02-15 13:09:44,592:INFO:             pycaret: 3.0.0rc9
2023-02-15 13:09:44,592:INFO:             IPython: 7.31.1
2023-02-15 13:09:44,592:INFO:          ipywidgets: 7.7.3
2023-02-15 13:09:44,592:INFO:                tqdm: 4.64.1
2023-02-15 13:09:44,592:INFO:               numpy: 1.23.5
2023-02-15 13:09:44,592:INFO:              pandas: 1.5.3
2023-02-15 13:09:44,592:INFO:              jinja2: 3.1.2
2023-02-15 13:09:44,592:INFO:               scipy: 1.9.1
2023-02-15 13:09:44,592:INFO:              joblib: 1.2.0
2023-02-15 13:09:44,592:INFO:             sklearn: 1.2.1
2023-02-15 13:09:44,592:INFO:                pyod: 1.0.7
2023-02-15 13:09:44,592:INFO:            imblearn: 0.10.1
2023-02-15 13:09:44,592:INFO:   category_encoders: 2.6.0
2023-02-15 13:09:44,592:INFO:            lightgbm: 3.3.5
2023-02-15 13:09:44,592:INFO:               numba: 0.56.4
2023-02-15 13:09:44,592:INFO:            requests: 2.28.1
2023-02-15 13:09:44,592:INFO:          matplotlib: 3.6.3
2023-02-15 13:09:44,592:INFO:          scikitplot: 0.3.7
2023-02-15 13:09:44,592:INFO:         yellowbrick: 1.5
2023-02-15 13:09:44,592:INFO:              plotly: 5.13.0
2023-02-15 13:09:44,592:INFO:             kaleido: 0.2.1
2023-02-15 13:09:44,592:INFO:         statsmodels: 0.13.5
2023-02-15 13:09:44,592:INFO:              sktime: 0.16.1
2023-02-15 13:09:44,592:INFO:               tbats: 1.1.2
2023-02-15 13:09:44,592:INFO:            pmdarima: 2.0.2
2023-02-15 13:09:44,592:INFO:              psutil: 5.9.0
2023-02-15 13:09:44,592:INFO:PyCaret optional dependencies:
2023-02-15 13:09:44,881:INFO:                shap: 0.41.0
2023-02-15 13:09:44,881:INFO:           interpret: 0.3.0
2023-02-15 13:09:44,881:INFO:                umap: 0.5.3
2023-02-15 13:09:44,881:INFO:    pandas_profiling: 4.0.0
2023-02-15 13:09:44,881:INFO:  explainerdashboard: 0.4.2
2023-02-15 13:09:44,881:INFO:             autoviz: 0.1.58
2023-02-15 13:09:44,881:INFO:           fairlearn: 0.7.0
2023-02-15 13:09:44,881:INFO:             xgboost: 1.7.3
2023-02-15 13:09:44,881:INFO:            catboost: 1.1.1
2023-02-15 13:09:44,881:INFO:              kmodes: 0.12.2
2023-02-15 13:09:44,881:INFO:             mlxtend: 0.21.0
2023-02-15 13:09:44,881:INFO:       statsforecast: 1.4.0
2023-02-15 13:09:44,881:INFO:        tune_sklearn: 0.4.5
2023-02-15 13:09:44,881:INFO:                 ray: 2.2.0
2023-02-15 13:09:44,881:INFO:            hyperopt: 0.2.7
2023-02-15 13:09:44,881:INFO:              optuna: 3.1.0
2023-02-15 13:09:44,881:INFO:               skopt: 0.9.0
2023-02-15 13:09:44,881:INFO:              mlflow: 1.30.0
2023-02-15 13:09:44,882:INFO:              gradio: 3.18.0
2023-02-15 13:09:44,882:INFO:             fastapi: 0.92.0
2023-02-15 13:09:44,882:INFO:             uvicorn: 0.20.0
2023-02-15 13:09:44,882:INFO:              m2cgen: 0.10.0
2023-02-15 13:09:44,882:INFO:           evidently: 0.2.4
2023-02-15 13:09:44,882:INFO:               fugue: 0.8.1.dev4
2023-02-15 13:09:44,882:INFO:           streamlit: Not installed
2023-02-15 13:09:44,882:INFO:             prophet: Not installed
2023-02-15 13:09:44,882:INFO:None
2023-02-15 13:09:44,882:INFO:Set up GPU usage.
2023-02-15 13:09:44,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:44,882:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 13:09:44,882:INFO:Set up data.
2023-02-15 13:09:44,940:INFO:Set up train/test split.
2023-02-15 13:09:44,969:INFO:Set up index.
2023-02-15 13:09:44,975:INFO:Set up folding strategy.
2023-02-15 13:09:44,975:INFO:Assigning column types.
2023-02-15 13:09:44,985:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 13:09:44,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:44,986:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 13:09:44,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:44,988:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 13:09:44,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:44,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 13:09:44,991:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:45,031:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 13:09:45,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:45,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 13:09:45,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:45,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 13:09:45,057:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:48,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:48,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:48,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:48,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,039:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 14:56:49,119:INFO:PyCaret RegressionExperiment
2023-02-15 14:56:49,119:INFO:Logging name: reg-default-name
2023-02-15 14:56:49,119:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 14:56:49,119:INFO:version 3.0.0.rc9
2023-02-15 14:56:49,119:INFO:Initializing setup()
2023-02-15 14:56:49,119:INFO:self.USI: d717
2023-02-15 14:56:49,119:INFO:self._variable_keys: {'gpu_n_jobs_param', 'log_plots_param', '_available_plots', 'X_train', 'y_test', 'memory', 'fold_generator', 'target_param', 'X_test', 'fold_groups_param', 'gpu_param', 'seed', 'pipeline', 'y_train', 'exp_name_log', 'n_jobs_param', '_ml_usecase', 'X', 'fold_shuffle_param', 'y', 'exp_id', 'USI', 'html_param', 'logging_param', 'transform_target_param', 'data', 'idx'}
2023-02-15 14:56:49,119:INFO:Checking environment
2023-02-15 14:56:49,119:INFO:python_version: 3.8.16
2023-02-15 14:56:49,119:INFO:python_build: ('default', 'Jan 17 2023 23:13:24')
2023-02-15 14:56:49,119:INFO:machine: x86_64
2023-02-15 14:56:49,119:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 14:56:49,119:INFO:Memory: svmem(total=134979592192, available=120164757504, percent=11.0, used=13071302656, free=74585104384, active=9314852864, inactive=47314399232, buffers=1879191552, cached=45443993600, shared=481181696, slab=3158548480)
2023-02-15 14:56:49,120:INFO:Physical Core: 16
2023-02-15 14:56:49,120:INFO:Logical Core: 32
2023-02-15 14:56:49,120:INFO:Checking libraries
2023-02-15 14:56:49,120:INFO:System:
2023-02-15 14:56:49,120:INFO:    python: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0]
2023-02-15 14:56:49,120:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 14:56:49,120:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.17
2023-02-15 14:56:49,120:INFO:PyCaret required dependencies:
2023-02-15 14:56:49,120:INFO:                 pip: 22.3.1
2023-02-15 14:56:49,120:INFO:          setuptools: 60.10.0
2023-02-15 14:56:49,120:INFO:             pycaret: 3.0.0rc9
2023-02-15 14:56:49,120:INFO:             IPython: 7.31.1
2023-02-15 14:56:49,120:INFO:          ipywidgets: 7.7.3
2023-02-15 14:56:49,120:INFO:                tqdm: 4.64.1
2023-02-15 14:56:49,120:INFO:               numpy: 1.23.5
2023-02-15 14:56:49,120:INFO:              pandas: 1.5.3
2023-02-15 14:56:49,120:INFO:              jinja2: 3.1.2
2023-02-15 14:56:49,120:INFO:               scipy: 1.9.1
2023-02-15 14:56:49,120:INFO:              joblib: 1.2.0
2023-02-15 14:56:49,120:INFO:             sklearn: 1.2.1
2023-02-15 14:56:49,120:INFO:                pyod: 1.0.7
2023-02-15 14:56:49,120:INFO:            imblearn: 0.10.1
2023-02-15 14:56:49,120:INFO:   category_encoders: 2.6.0
2023-02-15 14:56:49,120:INFO:            lightgbm: 3.3.5
2023-02-15 14:56:49,120:INFO:               numba: 0.56.4
2023-02-15 14:56:49,120:INFO:            requests: 2.28.1
2023-02-15 14:56:49,120:INFO:          matplotlib: 3.6.3
2023-02-15 14:56:49,121:INFO:          scikitplot: 0.3.7
2023-02-15 14:56:49,121:INFO:         yellowbrick: 1.5
2023-02-15 14:56:49,121:INFO:              plotly: 5.13.0
2023-02-15 14:56:49,121:INFO:             kaleido: 0.2.1
2023-02-15 14:56:49,121:INFO:         statsmodels: 0.13.5
2023-02-15 14:56:49,121:INFO:              sktime: 0.16.1
2023-02-15 14:56:49,121:INFO:               tbats: 1.1.2
2023-02-15 14:56:49,121:INFO:            pmdarima: 2.0.2
2023-02-15 14:56:49,121:INFO:              psutil: 5.9.0
2023-02-15 14:56:49,121:INFO:PyCaret optional dependencies:
2023-02-15 14:56:49,418:INFO:                shap: 0.41.0
2023-02-15 14:56:49,418:INFO:           interpret: 0.3.0
2023-02-15 14:56:49,418:INFO:                umap: 0.5.3
2023-02-15 14:56:49,418:INFO:    pandas_profiling: 4.0.0
2023-02-15 14:56:49,418:INFO:  explainerdashboard: 0.4.2
2023-02-15 14:56:49,418:INFO:             autoviz: 0.1.58
2023-02-15 14:56:49,418:INFO:           fairlearn: 0.7.0
2023-02-15 14:56:49,418:INFO:             xgboost: 1.7.3
2023-02-15 14:56:49,418:INFO:            catboost: 1.1.1
2023-02-15 14:56:49,418:INFO:              kmodes: 0.12.2
2023-02-15 14:56:49,418:INFO:             mlxtend: 0.21.0
2023-02-15 14:56:49,418:INFO:       statsforecast: 1.4.0
2023-02-15 14:56:49,418:INFO:        tune_sklearn: 0.4.5
2023-02-15 14:56:49,418:INFO:                 ray: 2.2.0
2023-02-15 14:56:49,418:INFO:            hyperopt: 0.2.7
2023-02-15 14:56:49,418:INFO:              optuna: 3.1.0
2023-02-15 14:56:49,418:INFO:               skopt: 0.9.0
2023-02-15 14:56:49,418:INFO:              mlflow: 1.30.0
2023-02-15 14:56:49,418:INFO:              gradio: 3.18.0
2023-02-15 14:56:49,418:INFO:             fastapi: 0.92.0
2023-02-15 14:56:49,419:INFO:             uvicorn: 0.20.0
2023-02-15 14:56:49,419:INFO:              m2cgen: 0.10.0
2023-02-15 14:56:49,419:INFO:           evidently: 0.2.4
2023-02-15 14:56:49,419:INFO:               fugue: 0.8.1.dev4
2023-02-15 14:56:49,419:INFO:           streamlit: Not installed
2023-02-15 14:56:49,419:INFO:             prophet: Not installed
2023-02-15 14:56:49,419:INFO:None
2023-02-15 14:56:49,419:INFO:Set up GPU usage.
2023-02-15 14:56:49,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,419:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 14:56:49,419:INFO:Set up data.
2023-02-15 14:56:49,476:INFO:Set up train/test split.
2023-02-15 14:56:49,506:INFO:Set up index.
2023-02-15 14:56:49,511:INFO:Set up folding strategy.
2023-02-15 14:56:49,511:INFO:Assigning column types.
2023-02-15 14:56:49,521:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 14:56:49,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,521:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,524:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,527:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,527:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,566:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,592:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:49,672:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:49,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,686:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,688:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,691:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,756:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:49,760:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:49,765:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 14:56:49,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,768:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,770:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,833:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,834:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:49,838:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:49,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,845:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,848:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,886:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,912:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:49,916:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:49,921:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 14:56:49,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,927:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 14:56:49,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:49,990:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:49,997:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:50,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,008:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 14:56:50,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,046:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 14:56:50,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 14:56:50,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,072:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:50,076:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:50,081:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 14:56:50,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,126:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 14:56:50,126:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 14:56:50,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,152:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:50,156:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:50,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,165:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 14:56:50,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 14:56:50,232:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,232:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,232:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:50,239:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:50,244:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 14:56:50,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,247:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,249:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 14:56:50,288:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,314:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:50,317:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:50,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,366:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 14:56:50,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,392:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:50,396:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:50,401:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 14:56:50,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,470:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:50,474:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:50,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,482:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,551:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:50,593:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:50,600:INFO:Preparing preprocessing pipeline...
2023-02-15 14:56:50,601:INFO:Set up column name cleaning.
2023-02-15 14:56:50,601:INFO:Set up simple imputation.
2023-02-15 14:56:50,601:INFO:Set up feature normalization.
2023-02-15 14:56:50,664:INFO:Finished creating preprocessing pipeline.
2023-02-15 14:56:50,668:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 14:56:50,668:INFO:Creating final display dataframe.
2023-02-15 14:56:50,960:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28659, 164)
4        Transformed data shape           (28659, 159)
5   Transformed train set shape           (20061, 159)
6    Transformed test set shape            (8598, 159)
7               Ignore features                      5
8              Numeric features                    158
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   d717
2023-02-15 14:56:50,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,967:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:50,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,035:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:51,044:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:51,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,124:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,124:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 14:56:51,124:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 14:56:51,128:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 14:56:51,133:INFO:setup() successfully completed in 2.02s...............
2023-02-15 14:56:51,133:INFO:Initializing compare_models()
2023-02-15 14:56:51,133:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 14:56:51,133:INFO:Checking exceptions
2023-02-15 14:56:51,137:INFO:Preparing display monitor
2023-02-15 14:56:51,153:INFO:Initializing Linear Regression
2023-02-15 14:56:51,153:INFO:Total runtime is 1.9113222757975262e-06 minutes
2023-02-15 14:56:51,155:INFO:SubProcess create_model() called ==================================
2023-02-15 14:56:51,155:INFO:Initializing create_model()
2023-02-15 14:56:51,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:56:51,155:INFO:Checking exceptions
2023-02-15 14:56:51,155:INFO:Importing libraries
2023-02-15 14:56:51,155:INFO:Copying training dataset
2023-02-15 14:56:51,167:INFO:Defining folds
2023-02-15 14:56:51,167:INFO:Declaring metric variables
2023-02-15 14:56:51,169:INFO:Importing untrained model
2023-02-15 14:56:51,171:INFO:Linear Regression Imported successfully
2023-02-15 14:56:51,174:INFO:Starting cross validation
2023-02-15 14:56:51,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:56:52,848:INFO:Calculating mean and std
2023-02-15 14:56:52,849:INFO:Creating metrics dataframe
2023-02-15 14:56:52,852:INFO:Uploading results into container
2023-02-15 14:56:52,852:INFO:Uploading model into container now
2023-02-15 14:56:52,852:INFO:_master_model_container: 1
2023-02-15 14:56:52,852:INFO:_display_container: 2
2023-02-15 14:56:52,852:INFO:LinearRegression(n_jobs=-1)
2023-02-15 14:56:52,852:INFO:create_model() successfully completed......................................
2023-02-15 14:56:52,974:INFO:SubProcess create_model() end ==================================
2023-02-15 14:56:52,974:INFO:Creating metrics dataframe
2023-02-15 14:56:52,979:INFO:Initializing Lasso Regression
2023-02-15 14:56:52,980:INFO:Total runtime is 0.030447928110758464 minutes
2023-02-15 14:56:52,981:INFO:SubProcess create_model() called ==================================
2023-02-15 14:56:52,981:INFO:Initializing create_model()
2023-02-15 14:56:52,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:56:52,981:INFO:Checking exceptions
2023-02-15 14:56:52,982:INFO:Importing libraries
2023-02-15 14:56:52,982:INFO:Copying training dataset
2023-02-15 14:56:52,995:INFO:Defining folds
2023-02-15 14:56:52,995:INFO:Declaring metric variables
2023-02-15 14:56:52,997:INFO:Importing untrained model
2023-02-15 14:56:52,998:INFO:Lasso Regression Imported successfully
2023-02-15 14:56:53,002:INFO:Starting cross validation
2023-02-15 14:56:53,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:56:54,329:INFO:Calculating mean and std
2023-02-15 14:56:54,330:INFO:Creating metrics dataframe
2023-02-15 14:56:54,333:INFO:Uploading results into container
2023-02-15 14:56:54,333:INFO:Uploading model into container now
2023-02-15 14:56:54,333:INFO:_master_model_container: 2
2023-02-15 14:56:54,333:INFO:_display_container: 2
2023-02-15 14:56:54,334:INFO:Lasso(random_state=11)
2023-02-15 14:56:54,334:INFO:create_model() successfully completed......................................
2023-02-15 14:56:54,469:INFO:SubProcess create_model() end ==================================
2023-02-15 14:56:54,469:INFO:Creating metrics dataframe
2023-02-15 14:56:54,475:INFO:Initializing Ridge Regression
2023-02-15 14:56:54,475:INFO:Total runtime is 0.05537168582280477 minutes
2023-02-15 14:56:54,477:INFO:SubProcess create_model() called ==================================
2023-02-15 14:56:54,477:INFO:Initializing create_model()
2023-02-15 14:56:54,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:56:54,477:INFO:Checking exceptions
2023-02-15 14:56:54,477:INFO:Importing libraries
2023-02-15 14:56:54,477:INFO:Copying training dataset
2023-02-15 14:56:54,491:INFO:Defining folds
2023-02-15 14:56:54,492:INFO:Declaring metric variables
2023-02-15 14:56:54,494:INFO:Importing untrained model
2023-02-15 14:56:54,496:INFO:Ridge Regression Imported successfully
2023-02-15 14:56:54,499:INFO:Starting cross validation
2023-02-15 14:56:54,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:56:55,992:INFO:Calculating mean and std
2023-02-15 14:56:55,993:INFO:Creating metrics dataframe
2023-02-15 14:56:55,996:INFO:Uploading results into container
2023-02-15 14:56:55,996:INFO:Uploading model into container now
2023-02-15 14:56:55,997:INFO:_master_model_container: 3
2023-02-15 14:56:55,997:INFO:_display_container: 2
2023-02-15 14:56:55,997:INFO:Ridge(random_state=11)
2023-02-15 14:56:55,997:INFO:create_model() successfully completed......................................
2023-02-15 14:56:56,127:INFO:SubProcess create_model() end ==================================
2023-02-15 14:56:56,127:INFO:Creating metrics dataframe
2023-02-15 14:56:56,133:INFO:Initializing Elastic Net
2023-02-15 14:56:56,133:INFO:Total runtime is 0.083007017771403 minutes
2023-02-15 14:56:56,135:INFO:SubProcess create_model() called ==================================
2023-02-15 14:56:56,135:INFO:Initializing create_model()
2023-02-15 14:56:56,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:56:56,135:INFO:Checking exceptions
2023-02-15 14:56:56,135:INFO:Importing libraries
2023-02-15 14:56:56,135:INFO:Copying training dataset
2023-02-15 14:56:56,149:INFO:Defining folds
2023-02-15 14:56:56,149:INFO:Declaring metric variables
2023-02-15 14:56:56,151:INFO:Importing untrained model
2023-02-15 14:56:56,152:INFO:Elastic Net Imported successfully
2023-02-15 14:56:56,155:INFO:Starting cross validation
2023-02-15 14:56:56,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:56:57,479:INFO:Calculating mean and std
2023-02-15 14:56:57,480:INFO:Creating metrics dataframe
2023-02-15 14:56:57,483:INFO:Uploading results into container
2023-02-15 14:56:57,483:INFO:Uploading model into container now
2023-02-15 14:56:57,483:INFO:_master_model_container: 4
2023-02-15 14:56:57,483:INFO:_display_container: 2
2023-02-15 14:56:57,483:INFO:ElasticNet(random_state=11)
2023-02-15 14:56:57,483:INFO:create_model() successfully completed......................................
2023-02-15 14:56:57,607:INFO:SubProcess create_model() end ==================================
2023-02-15 14:56:57,607:INFO:Creating metrics dataframe
2023-02-15 14:56:57,613:INFO:Initializing Least Angle Regression
2023-02-15 14:56:57,613:INFO:Total runtime is 0.10767602523167928 minutes
2023-02-15 14:56:57,615:INFO:SubProcess create_model() called ==================================
2023-02-15 14:56:57,615:INFO:Initializing create_model()
2023-02-15 14:56:57,615:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:56:57,615:INFO:Checking exceptions
2023-02-15 14:56:57,615:INFO:Importing libraries
2023-02-15 14:56:57,615:INFO:Copying training dataset
2023-02-15 14:56:57,628:INFO:Defining folds
2023-02-15 14:56:57,628:INFO:Declaring metric variables
2023-02-15 14:56:57,630:INFO:Importing untrained model
2023-02-15 14:56:57,631:INFO:Least Angle Regression Imported successfully
2023-02-15 14:56:57,634:INFO:Starting cross validation
2023-02-15 14:56:57,635:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:56:57,714:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.461e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:57,779:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: overflow encountered in matmul
  ret = a @ b

2023-02-15 14:56:57,779:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2023-02-15 14:56:57,781:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:57,781:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:57,781:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:57,885:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.957e-04, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:57,886:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=7.237e-04, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:57,887:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=6.791e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:57,947:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:57,948:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:57,948:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:56:58,062:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:713: RuntimeWarning: invalid value encountered in multiply
  least_squares *= AA

2023-02-15 14:56:58,062:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:736: RuntimeWarning: divide by zero encountered in double_scalars
  gamma_ = min(g1, g2, C / AA)

2023-02-15 14:56:58,062:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-02-15 14:56:58,145:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:58,145:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:58,145:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:58,247:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.259e-04, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,415:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.361e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,416:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.407e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,416:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.388e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,417:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.027e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,417:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.838e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,419:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.580e-04, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,423:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.041e-04, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,481:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:58,481:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 14:56:58,482:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:58,482:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 14:56:58,482:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:56:58,581:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.031e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,581:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 14:56:58,582:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.100e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,582:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.997e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,582:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.668e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,584:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.805e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,584:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.745e-04, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,584:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.710e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,584:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.571e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,585:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.469e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,589:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.731e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,590:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.672e-04, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,590:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.653e-04, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,591:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.620e-04, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,591:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.588e-04, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,651:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:58,651:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:58,651:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:56:58,750:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.285e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,752:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.940e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,752:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.767e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,756:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=8.502e-04, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,826:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:58,826:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:58,826:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:56:58,931:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=6.650e-04, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:58,995:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:58,996:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:58,996:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:56:59,097:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.957e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:59,097:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.657e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:59,104:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=9.413e-03, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:59,175:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:59,175:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:59,176:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:56:59,278:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=2.229e-03, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:59,338:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:59,339:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:59,339:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:56:59,340:INFO:Calculating mean and std
2023-02-15 14:56:59,341:INFO:Creating metrics dataframe
2023-02-15 14:56:59,344:INFO:Uploading results into container
2023-02-15 14:56:59,344:INFO:Uploading model into container now
2023-02-15 14:56:59,344:INFO:_master_model_container: 5
2023-02-15 14:56:59,344:INFO:_display_container: 2
2023-02-15 14:56:59,345:INFO:Lars(random_state=11)
2023-02-15 14:56:59,345:INFO:create_model() successfully completed......................................
2023-02-15 14:56:59,465:WARNING:create_model() for Lars(random_state=11) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 14:56:59,466:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2023-02-15 14:56:59,466:INFO:Initializing create_model()
2023-02-15 14:56:59,466:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:56:59,466:INFO:Checking exceptions
2023-02-15 14:56:59,466:INFO:Importing libraries
2023-02-15 14:56:59,466:INFO:Copying training dataset
2023-02-15 14:56:59,479:INFO:Defining folds
2023-02-15 14:56:59,479:INFO:Declaring metric variables
2023-02-15 14:56:59,481:INFO:Importing untrained model
2023-02-15 14:56:59,483:INFO:Least Angle Regression Imported successfully
2023-02-15 14:56:59,486:INFO:Starting cross validation
2023-02-15 14:56:59,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:56:59,559:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.461e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:59,625:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: overflow encountered in matmul
  ret = a @ b

2023-02-15 14:56:59,625:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2023-02-15 14:56:59,626:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:59,626:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:59,626:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:59,731:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.957e-04, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:59,732:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=7.237e-04, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:59,733:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=6.791e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:56:59,796:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:59,796:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:56:59,796:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:56:59,910:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:713: RuntimeWarning: invalid value encountered in multiply
  least_squares *= AA

2023-02-15 14:56:59,910:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:736: RuntimeWarning: divide by zero encountered in double_scalars
  gamma_ = min(g1, g2, C / AA)

2023-02-15 14:56:59,910:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-02-15 14:56:59,993:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:59,993:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:56:59,994:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 14:57:00,095:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.259e-04, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,262:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.361e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,263:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.407e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,263:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.388e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,264:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.027e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,265:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.838e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,266:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.580e-04, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,271:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.041e-04, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,329:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:00,329:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 14:57:00,329:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:00,329:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 14:57:00,329:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:57:00,428:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.031e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,428:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 14:57:00,429:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.100e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,429:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.997e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,430:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.668e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,431:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.805e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,432:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.745e-04, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,432:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.710e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,432:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.571e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,432:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.469e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,436:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.731e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,438:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.672e-04, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,438:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.653e-04, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,438:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.620e-04, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,438:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.588e-04, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,498:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:00,498:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:00,498:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:57:00,597:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.285e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,598:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.940e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,599:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.767e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,603:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=8.502e-04, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,665:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:00,665:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:00,665:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:57:00,771:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=6.650e-04, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,834:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:00,834:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:00,834:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:57:00,935:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.957e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,935:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.657e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:00,942:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=9.413e-03, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:01,002:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:01,002:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:01,002:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:57:01,108:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=2.229e-03, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 14:57:01,174:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:01,175:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 14:57:01,175:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 14:57:01,176:INFO:Calculating mean and std
2023-02-15 14:57:01,177:INFO:Creating metrics dataframe
2023-02-15 14:57:01,180:INFO:Uploading results into container
2023-02-15 14:57:01,180:INFO:Uploading model into container now
2023-02-15 14:57:01,186:INFO:_master_model_container: 6
2023-02-15 14:57:01,186:INFO:_display_container: 2
2023-02-15 14:57:01,187:INFO:Lars(random_state=11)
2023-02-15 14:57:01,187:INFO:create_model() successfully completed......................................
2023-02-15 14:57:01,315:ERROR:create_model() for Lars(random_state=11) raised an exception or returned all 0.0:
2023-02-15 14:57:01,315:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2023-02-15 14:57:01,315:INFO:Initializing Lasso Least Angle Regression
2023-02-15 14:57:01,315:INFO:Total runtime is 0.16938026348749796 minutes
2023-02-15 14:57:01,318:INFO:SubProcess create_model() called ==================================
2023-02-15 14:57:01,318:INFO:Initializing create_model()
2023-02-15 14:57:01,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:57:01,318:INFO:Checking exceptions
2023-02-15 14:57:01,318:INFO:Importing libraries
2023-02-15 14:57:01,318:INFO:Copying training dataset
2023-02-15 14:57:01,331:INFO:Defining folds
2023-02-15 14:57:01,331:INFO:Declaring metric variables
2023-02-15 14:57:01,333:INFO:Importing untrained model
2023-02-15 14:57:01,335:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 14:57:01,338:INFO:Starting cross validation
2023-02-15 14:57:01,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:57:02,633:INFO:Calculating mean and std
2023-02-15 14:57:02,634:INFO:Creating metrics dataframe
2023-02-15 14:57:02,636:INFO:Uploading results into container
2023-02-15 14:57:02,637:INFO:Uploading model into container now
2023-02-15 14:57:02,637:INFO:_master_model_container: 7
2023-02-15 14:57:02,637:INFO:_display_container: 2
2023-02-15 14:57:02,637:INFO:LassoLars(random_state=11)
2023-02-15 14:57:02,637:INFO:create_model() successfully completed......................................
2023-02-15 14:57:02,755:INFO:SubProcess create_model() end ==================================
2023-02-15 14:57:02,756:INFO:Creating metrics dataframe
2023-02-15 14:57:02,762:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 14:57:02,762:INFO:Total runtime is 0.19348299105962116 minutes
2023-02-15 14:57:02,763:INFO:SubProcess create_model() called ==================================
2023-02-15 14:57:02,763:INFO:Initializing create_model()
2023-02-15 14:57:02,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:57:02,763:INFO:Checking exceptions
2023-02-15 14:57:02,763:INFO:Importing libraries
2023-02-15 14:57:02,764:INFO:Copying training dataset
2023-02-15 14:57:02,776:INFO:Defining folds
2023-02-15 14:57:02,777:INFO:Declaring metric variables
2023-02-15 14:57:02,778:INFO:Importing untrained model
2023-02-15 14:57:02,780:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 14:57:02,783:INFO:Starting cross validation
2023-02-15 14:57:02,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:57:04,007:INFO:Calculating mean and std
2023-02-15 14:57:04,008:INFO:Creating metrics dataframe
2023-02-15 14:57:04,011:INFO:Uploading results into container
2023-02-15 14:57:04,011:INFO:Uploading model into container now
2023-02-15 14:57:04,011:INFO:_master_model_container: 8
2023-02-15 14:57:04,012:INFO:_display_container: 2
2023-02-15 14:57:04,012:INFO:OrthogonalMatchingPursuit()
2023-02-15 14:57:04,012:INFO:create_model() successfully completed......................................
2023-02-15 14:57:04,133:INFO:SubProcess create_model() end ==================================
2023-02-15 14:57:04,133:INFO:Creating metrics dataframe
2023-02-15 14:57:04,139:INFO:Initializing Bayesian Ridge
2023-02-15 14:57:04,139:INFO:Total runtime is 0.21643700997034707 minutes
2023-02-15 14:57:04,140:INFO:SubProcess create_model() called ==================================
2023-02-15 14:57:04,141:INFO:Initializing create_model()
2023-02-15 14:57:04,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:57:04,141:INFO:Checking exceptions
2023-02-15 14:57:04,141:INFO:Importing libraries
2023-02-15 14:57:04,141:INFO:Copying training dataset
2023-02-15 14:57:04,154:INFO:Defining folds
2023-02-15 14:57:04,154:INFO:Declaring metric variables
2023-02-15 14:57:04,156:INFO:Importing untrained model
2023-02-15 14:57:04,158:INFO:Bayesian Ridge Imported successfully
2023-02-15 14:57:04,161:INFO:Starting cross validation
2023-02-15 14:57:04,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:57:06,894:INFO:Calculating mean and std
2023-02-15 14:57:06,897:INFO:Creating metrics dataframe
2023-02-15 14:57:06,899:INFO:Uploading results into container
2023-02-15 14:57:06,899:INFO:Uploading model into container now
2023-02-15 14:57:06,900:INFO:_master_model_container: 9
2023-02-15 14:57:06,900:INFO:_display_container: 2
2023-02-15 14:57:06,900:INFO:BayesianRidge()
2023-02-15 14:57:06,900:INFO:create_model() successfully completed......................................
2023-02-15 14:57:07,023:INFO:SubProcess create_model() end ==================================
2023-02-15 14:57:07,023:INFO:Creating metrics dataframe
2023-02-15 14:57:07,029:INFO:Initializing Passive Aggressive Regressor
2023-02-15 14:57:07,029:INFO:Total runtime is 0.26460858980814617 minutes
2023-02-15 14:57:07,031:INFO:SubProcess create_model() called ==================================
2023-02-15 14:57:07,031:INFO:Initializing create_model()
2023-02-15 14:57:07,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:57:07,031:INFO:Checking exceptions
2023-02-15 14:57:07,031:INFO:Importing libraries
2023-02-15 14:57:07,031:INFO:Copying training dataset
2023-02-15 14:57:07,047:INFO:Defining folds
2023-02-15 14:57:07,047:INFO:Declaring metric variables
2023-02-15 14:57:07,050:INFO:Importing untrained model
2023-02-15 14:57:07,051:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 14:57:07,054:INFO:Starting cross validation
2023-02-15 14:57:07,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:57:08,502:INFO:Calculating mean and std
2023-02-15 14:57:08,503:INFO:Creating metrics dataframe
2023-02-15 14:57:08,506:INFO:Uploading results into container
2023-02-15 14:57:08,506:INFO:Uploading model into container now
2023-02-15 14:57:08,506:INFO:_master_model_container: 10
2023-02-15 14:57:08,506:INFO:_display_container: 2
2023-02-15 14:57:08,507:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 14:57:08,507:INFO:create_model() successfully completed......................................
2023-02-15 14:57:08,628:INFO:SubProcess create_model() end ==================================
2023-02-15 14:57:08,628:INFO:Creating metrics dataframe
2023-02-15 14:57:08,635:INFO:Initializing Huber Regressor
2023-02-15 14:57:08,635:INFO:Total runtime is 0.29137824376424154 minutes
2023-02-15 14:57:08,637:INFO:SubProcess create_model() called ==================================
2023-02-15 14:57:08,637:INFO:Initializing create_model()
2023-02-15 14:57:08,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f69ee43d790>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f69e4ef7640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 14:57:08,637:INFO:Checking exceptions
2023-02-15 14:57:08,637:INFO:Importing libraries
2023-02-15 14:57:08,637:INFO:Copying training dataset
2023-02-15 14:57:08,650:INFO:Defining folds
2023-02-15 14:57:08,650:INFO:Declaring metric variables
2023-02-15 14:57:08,652:INFO:Importing untrained model
2023-02-15 14:57:08,654:INFO:Huber Regressor Imported successfully
2023-02-15 14:57:08,657:INFO:Starting cross validation
2023-02-15 14:57:08,657:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 14:57:10,666:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:28:22,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:22,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:22,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:22,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:22,476:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 15:28:22,551:INFO:PyCaret RegressionExperiment
2023-02-15 15:28:22,551:INFO:Logging name: reg-default-name
2023-02-15 15:28:22,551:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 15:28:22,551:INFO:version 3.0.0.rc9
2023-02-15 15:28:22,551:INFO:Initializing setup()
2023-02-15 15:28:22,551:INFO:self.USI: b512
2023-02-15 15:28:22,551:INFO:self._variable_keys: {'data', 'logging_param', '_ml_usecase', 'X', 'target_param', 'fold_generator', 'transform_target_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'exp_name_log', 'html_param', 'pipeline', 'log_plots_param', 'exp_id', 'idx', 'fold_shuffle_param', 'y_test', 'USI', 'X_train', 'y', 'y_train', 'gpu_n_jobs_param', 'gpu_param', 'memory', 'seed', '_available_plots'}
2023-02-15 15:28:22,551:INFO:Checking environment
2023-02-15 15:28:22,551:INFO:python_version: 3.8.16
2023-02-15 15:28:22,551:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-15 15:28:22,551:INFO:machine: x86_64
2023-02-15 15:28:22,551:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 15:28:22,551:INFO:Memory: svmem(total=134979592192, available=119051689984, percent=11.8, used=14122295296, free=63955804160, active=9455579136, inactive=57437503488, buffers=1950588928, cached=54950903808, shared=543256576, slab=3506032640)
2023-02-15 15:28:22,552:INFO:Physical Core: 16
2023-02-15 15:28:22,552:INFO:Logical Core: 32
2023-02-15 15:28:22,552:INFO:Checking libraries
2023-02-15 15:28:22,552:INFO:System:
2023-02-15 15:28:22,552:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-15 15:28:22,552:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 15:28:22,552:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 15:28:22,552:INFO:PyCaret required dependencies:
2023-02-15 15:28:22,552:INFO:                 pip: 23.0
2023-02-15 15:28:22,552:INFO:          setuptools: 60.10.0
2023-02-15 15:28:22,552:INFO:             pycaret: 3.0.0rc9
2023-02-15 15:28:22,552:INFO:             IPython: 8.10.0
2023-02-15 15:28:22,552:INFO:          ipywidgets: 7.7.3
2023-02-15 15:28:22,552:INFO:                tqdm: 4.64.1
2023-02-15 15:28:22,552:INFO:               numpy: 1.23.5
2023-02-15 15:28:22,552:INFO:              pandas: 1.5.3
2023-02-15 15:28:22,552:INFO:              jinja2: 3.1.2
2023-02-15 15:28:22,552:INFO:               scipy: 1.9.1
2023-02-15 15:28:22,552:INFO:              joblib: 1.2.0
2023-02-15 15:28:22,552:INFO:             sklearn: 1.2.1
2023-02-15 15:28:22,552:INFO:                pyod: 1.0.7
2023-02-15 15:28:22,552:INFO:            imblearn: 0.10.1
2023-02-15 15:28:22,552:INFO:   category_encoders: 2.6.0
2023-02-15 15:28:22,552:INFO:            lightgbm: 3.3.5.99
2023-02-15 15:28:22,552:INFO:               numba: 0.56.4
2023-02-15 15:28:22,552:INFO:            requests: 2.28.2
2023-02-15 15:28:22,552:INFO:          matplotlib: 3.6.3
2023-02-15 15:28:22,552:INFO:          scikitplot: 0.3.7
2023-02-15 15:28:22,552:INFO:         yellowbrick: 1.5
2023-02-15 15:28:22,552:INFO:              plotly: 5.13.0
2023-02-15 15:28:22,552:INFO:             kaleido: 0.2.1
2023-02-15 15:28:22,552:INFO:         statsmodels: 0.13.5
2023-02-15 15:28:22,552:INFO:              sktime: 0.16.1
2023-02-15 15:28:22,552:INFO:               tbats: 1.1.2
2023-02-15 15:28:22,552:INFO:            pmdarima: 2.0.2
2023-02-15 15:28:22,552:INFO:              psutil: 5.9.4
2023-02-15 15:28:22,552:INFO:PyCaret optional dependencies:
2023-02-15 15:28:22,858:INFO:                shap: 0.41.0
2023-02-15 15:28:22,858:INFO:           interpret: 0.3.0
2023-02-15 15:28:22,858:INFO:                umap: 0.5.3
2023-02-15 15:28:22,858:INFO:    pandas_profiling: 4.0.0
2023-02-15 15:28:22,858:INFO:  explainerdashboard: 0.4.2
2023-02-15 15:28:22,858:INFO:             autoviz: 0.1.58
2023-02-15 15:28:22,858:INFO:           fairlearn: 0.7.0
2023-02-15 15:28:22,858:INFO:             xgboost: 1.7.3
2023-02-15 15:28:22,858:INFO:            catboost: 1.1.1
2023-02-15 15:28:22,858:INFO:              kmodes: 0.12.2
2023-02-15 15:28:22,858:INFO:             mlxtend: 0.21.0
2023-02-15 15:28:22,858:INFO:       statsforecast: 1.4.0
2023-02-15 15:28:22,859:INFO:        tune_sklearn: 0.4.5
2023-02-15 15:28:22,859:INFO:                 ray: 2.2.0
2023-02-15 15:28:22,859:INFO:            hyperopt: 0.2.7
2023-02-15 15:28:22,859:INFO:              optuna: 3.1.0
2023-02-15 15:28:22,859:INFO:               skopt: 0.9.0
2023-02-15 15:28:22,859:INFO:              mlflow: 1.30.0
2023-02-15 15:28:22,859:INFO:              gradio: 3.18.0
2023-02-15 15:28:22,859:INFO:             fastapi: 0.92.0
2023-02-15 15:28:22,859:INFO:             uvicorn: 0.20.0
2023-02-15 15:28:22,859:INFO:              m2cgen: 0.10.0
2023-02-15 15:28:22,859:INFO:           evidently: 0.2.4
2023-02-15 15:28:22,859:INFO:               fugue: 0.8.1.dev4
2023-02-15 15:28:22,859:INFO:           streamlit: Not installed
2023-02-15 15:28:22,859:INFO:             prophet: Not installed
2023-02-15 15:28:22,859:INFO:None
2023-02-15 15:28:22,859:INFO:Set up GPU usage.
2023-02-15 15:28:22,859:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:22,859:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 15:28:22,859:INFO:Set up data.
2023-02-15 15:28:22,916:INFO:Set up train/test split.
2023-02-15 15:28:22,945:INFO:Set up index.
2023-02-15 15:28:22,952:INFO:Set up folding strategy.
2023-02-15 15:28:22,952:INFO:Assigning column types.
2023-02-15 15:28:22,962:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 15:28:22,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:22,963:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 15:28:22,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:22,965:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 15:28:22,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:22,968:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 15:28:22,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,007:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,033:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:23,191:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:23,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,210:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,213:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,215:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,259:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,259:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,286:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:23,289:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:23,295:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 15:28:23,296:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,296:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,298:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,301:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,369:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,369:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:23,372:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:23,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,382:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,385:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,453:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,453:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:23,457:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:23,463:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 15:28:23,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,510:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,537:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:23,540:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:23,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,553:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,621:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:23,624:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:23,630:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 15:28:23,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,704:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:23,707:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:23,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,719:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,787:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:23,790:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:23,796:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 15:28:23,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,842:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,869:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:23,873:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:23,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,884:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,925:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 15:28:23,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,952:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,952:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,952:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:23,956:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:23,962:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 15:28:23,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:23,967:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,035:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:24,038:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:24,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,118:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:24,121:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:24,128:INFO:Preparing preprocessing pipeline...
2023-02-15 15:28:24,129:INFO:Set up column name cleaning.
2023-02-15 15:28:24,129:INFO:Set up simple imputation.
2023-02-15 15:28:24,129:INFO:Set up feature normalization.
2023-02-15 15:28:24,193:INFO:Finished creating preprocessing pipeline.
2023-02-15 15:28:24,198:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 15:28:24,198:INFO:Creating final display dataframe.
2023-02-15 15:28:24,507:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28660, 164)
4        Transformed data shape           (28660, 159)
5   Transformed train set shape           (20062, 159)
6    Transformed test set shape            (8598, 159)
7               Ignore features                      5
8              Numeric features                    158
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   b512
2023-02-15 15:28:24,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,586:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,587:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,587:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:24,590:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:24,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,645:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 15:28:24,672:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 15:28:24,675:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 15:28:24,682:INFO:setup() successfully completed in 2.13s...............
2023-02-15 15:28:24,682:INFO:Initializing compare_models()
2023-02-15 15:28:24,682:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 15:28:24,682:INFO:Checking exceptions
2023-02-15 15:28:24,685:INFO:Preparing display monitor
2023-02-15 15:28:24,699:INFO:Initializing Linear Regression
2023-02-15 15:28:24,699:INFO:Total runtime is 1.6013781229654948e-06 minutes
2023-02-15 15:28:24,700:INFO:SubProcess create_model() called ==================================
2023-02-15 15:28:24,700:INFO:Initializing create_model()
2023-02-15 15:28:24,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:28:24,700:INFO:Checking exceptions
2023-02-15 15:28:24,700:INFO:Importing libraries
2023-02-15 15:28:24,700:INFO:Copying training dataset
2023-02-15 15:28:24,715:INFO:Defining folds
2023-02-15 15:28:24,715:INFO:Declaring metric variables
2023-02-15 15:28:24,718:INFO:Importing untrained model
2023-02-15 15:28:24,719:INFO:Linear Regression Imported successfully
2023-02-15 15:28:24,723:INFO:Starting cross validation
2023-02-15 15:28:24,725:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:28:26,390:INFO:Calculating mean and std
2023-02-15 15:28:26,391:INFO:Creating metrics dataframe
2023-02-15 15:28:26,394:INFO:Uploading results into container
2023-02-15 15:28:26,394:INFO:Uploading model into container now
2023-02-15 15:28:26,394:INFO:_master_model_container: 1
2023-02-15 15:28:26,394:INFO:_display_container: 2
2023-02-15 15:28:26,395:INFO:LinearRegression(n_jobs=-1)
2023-02-15 15:28:26,395:INFO:create_model() successfully completed......................................
2023-02-15 15:28:26,522:INFO:SubProcess create_model() end ==================================
2023-02-15 15:28:26,523:INFO:Creating metrics dataframe
2023-02-15 15:28:26,528:INFO:Initializing Lasso Regression
2023-02-15 15:28:26,528:INFO:Total runtime is 0.03049173355102539 minutes
2023-02-15 15:28:26,530:INFO:SubProcess create_model() called ==================================
2023-02-15 15:28:26,530:INFO:Initializing create_model()
2023-02-15 15:28:26,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:28:26,530:INFO:Checking exceptions
2023-02-15 15:28:26,530:INFO:Importing libraries
2023-02-15 15:28:26,530:INFO:Copying training dataset
2023-02-15 15:28:26,544:INFO:Defining folds
2023-02-15 15:28:26,544:INFO:Declaring metric variables
2023-02-15 15:28:26,546:INFO:Importing untrained model
2023-02-15 15:28:26,548:INFO:Lasso Regression Imported successfully
2023-02-15 15:28:26,551:INFO:Starting cross validation
2023-02-15 15:28:26,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:28:27,878:INFO:Calculating mean and std
2023-02-15 15:28:27,879:INFO:Creating metrics dataframe
2023-02-15 15:28:27,881:INFO:Uploading results into container
2023-02-15 15:28:27,882:INFO:Uploading model into container now
2023-02-15 15:28:27,882:INFO:_master_model_container: 2
2023-02-15 15:28:27,882:INFO:_display_container: 2
2023-02-15 15:28:27,882:INFO:Lasso(random_state=11)
2023-02-15 15:28:27,882:INFO:create_model() successfully completed......................................
2023-02-15 15:28:28,004:INFO:SubProcess create_model() end ==================================
2023-02-15 15:28:28,005:INFO:Creating metrics dataframe
2023-02-15 15:28:28,010:INFO:Initializing Ridge Regression
2023-02-15 15:28:28,011:INFO:Total runtime is 0.05520057280858358 minutes
2023-02-15 15:28:28,012:INFO:SubProcess create_model() called ==================================
2023-02-15 15:28:28,012:INFO:Initializing create_model()
2023-02-15 15:28:28,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:28:28,013:INFO:Checking exceptions
2023-02-15 15:28:28,013:INFO:Importing libraries
2023-02-15 15:28:28,013:INFO:Copying training dataset
2023-02-15 15:28:28,027:INFO:Defining folds
2023-02-15 15:28:28,027:INFO:Declaring metric variables
2023-02-15 15:28:28,029:INFO:Importing untrained model
2023-02-15 15:28:28,030:INFO:Ridge Regression Imported successfully
2023-02-15 15:28:28,033:INFO:Starting cross validation
2023-02-15 15:28:28,034:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:28:29,403:INFO:Calculating mean and std
2023-02-15 15:28:29,405:INFO:Creating metrics dataframe
2023-02-15 15:28:29,407:INFO:Uploading results into container
2023-02-15 15:28:29,407:INFO:Uploading model into container now
2023-02-15 15:28:29,407:INFO:_master_model_container: 3
2023-02-15 15:28:29,407:INFO:_display_container: 2
2023-02-15 15:28:29,408:INFO:Ridge(random_state=11)
2023-02-15 15:28:29,408:INFO:create_model() successfully completed......................................
2023-02-15 15:28:29,530:INFO:SubProcess create_model() end ==================================
2023-02-15 15:28:29,530:INFO:Creating metrics dataframe
2023-02-15 15:28:29,536:INFO:Initializing Elastic Net
2023-02-15 15:28:29,536:INFO:Total runtime is 0.08062153259913127 minutes
2023-02-15 15:28:29,538:INFO:SubProcess create_model() called ==================================
2023-02-15 15:28:29,538:INFO:Initializing create_model()
2023-02-15 15:28:29,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:28:29,538:INFO:Checking exceptions
2023-02-15 15:28:29,538:INFO:Importing libraries
2023-02-15 15:28:29,538:INFO:Copying training dataset
2023-02-15 15:28:29,551:INFO:Defining folds
2023-02-15 15:28:29,551:INFO:Declaring metric variables
2023-02-15 15:28:29,553:INFO:Importing untrained model
2023-02-15 15:28:29,555:INFO:Elastic Net Imported successfully
2023-02-15 15:28:29,558:INFO:Starting cross validation
2023-02-15 15:28:29,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:28:30,875:INFO:Calculating mean and std
2023-02-15 15:28:30,876:INFO:Creating metrics dataframe
2023-02-15 15:28:30,879:INFO:Uploading results into container
2023-02-15 15:28:30,879:INFO:Uploading model into container now
2023-02-15 15:28:30,879:INFO:_master_model_container: 4
2023-02-15 15:28:30,879:INFO:_display_container: 2
2023-02-15 15:28:30,880:INFO:ElasticNet(random_state=11)
2023-02-15 15:28:30,880:INFO:create_model() successfully completed......................................
2023-02-15 15:28:30,995:INFO:SubProcess create_model() end ==================================
2023-02-15 15:28:30,995:INFO:Creating metrics dataframe
2023-02-15 15:28:31,000:INFO:Initializing Least Angle Regression
2023-02-15 15:28:31,001:INFO:Total runtime is 0.10503372351328533 minutes
2023-02-15 15:28:31,002:INFO:SubProcess create_model() called ==================================
2023-02-15 15:28:31,002:INFO:Initializing create_model()
2023-02-15 15:28:31,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:28:31,002:INFO:Checking exceptions
2023-02-15 15:28:31,002:INFO:Importing libraries
2023-02-15 15:28:31,002:INFO:Copying training dataset
2023-02-15 15:28:31,016:INFO:Defining folds
2023-02-15 15:28:31,016:INFO:Declaring metric variables
2023-02-15 15:28:31,018:INFO:Importing untrained model
2023-02-15 15:28:31,019:INFO:Least Angle Regression Imported successfully
2023-02-15 15:28:31,022:INFO:Starting cross validation
2023-02-15 15:28:31,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:28:31,093:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.681e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,094:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.940e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,094:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 15:28:31,098:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=5.427e-04, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,099:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.113e-04, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,100:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.110e-04, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,163:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:31,163:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 15:28:31,164:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:31,164:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 15:28:31,164:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 15:28:31,343:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:31,343:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:31,344:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 15:28:31,464:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:699: RuntimeWarning: invalid value encountered in sqrt
  AA = 1.0 / np.sqrt(np.sum(least_squares * sign_active[:n_active]))

2023-02-15 15:28:31,464:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:713: RuntimeWarning: overflow encountered in multiply
  least_squares *= AA

2023-02-15 15:28:31,561:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.982e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,564:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.331e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,568:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=3.061e-04, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,627:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:31,627:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:31,627:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 15:28:31,727:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.534e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,728:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.770e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,732:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.094e-03, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,740:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=6.372e-03, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:31,794:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:31,795:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:31,795:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 15:28:31,964:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:31,964:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 15:28:31,964:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:31,964:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 15:28:31,965:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 15:28:32,064:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.193e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,064:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 15:28:32,066:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.337e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,066:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.298e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,067:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.522e-04, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,070:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.782e-04, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,070:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=2.746e-04, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,071:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.695e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,138:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:32,138:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 15:28:32,138:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:32,138:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 15:28:32,139:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 15:28:32,239:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.225e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,322:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:32,323:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:32,326:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 15:28:32,471:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.076e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,471:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.746e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,471:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.742e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,473:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=8.844e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,487:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 15:28:32,506:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 15:28:32,550:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 15:28:32,658:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.224e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,659:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.816e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 15:28:32,678:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 15:28:32,753:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 15:28:32,753:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:32,753:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 15:28:32,754:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 15:28:32,754:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/containers/metrics/regression.py:243: RuntimeWarning: overflow encountered in divide
  mape = np.abs(y_pred - y_true) / np.abs(y_true)

2023-02-15 15:28:32,754:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 15:28:32,755:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 603, in _lars_path_solver
    sign_active[n_active] = np.sign(C_)
ValueError: cannot convert float NaN to integer

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 15:28:32,755:INFO:Calculating mean and std
2023-02-15 15:28:32,756:INFO:Creating metrics dataframe
2023-02-15 15:28:32,758:INFO:Uploading results into container
2023-02-15 15:28:32,758:INFO:Uploading model into container now
2023-02-15 15:28:32,759:INFO:_master_model_container: 5
2023-02-15 15:28:32,759:INFO:_display_container: 2
2023-02-15 15:28:32,759:INFO:Lars(random_state=11)
2023-02-15 15:28:32,759:INFO:create_model() successfully completed......................................
2023-02-15 15:28:32,875:INFO:SubProcess create_model() end ==================================
2023-02-15 15:28:32,875:INFO:Creating metrics dataframe
2023-02-15 15:28:32,881:INFO:Initializing Lasso Least Angle Regression
2023-02-15 15:28:32,881:INFO:Total runtime is 0.13637840350468955 minutes
2023-02-15 15:28:32,883:INFO:SubProcess create_model() called ==================================
2023-02-15 15:28:32,883:INFO:Initializing create_model()
2023-02-15 15:28:32,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:28:32,883:INFO:Checking exceptions
2023-02-15 15:28:32,883:INFO:Importing libraries
2023-02-15 15:28:32,883:INFO:Copying training dataset
2023-02-15 15:28:32,897:INFO:Defining folds
2023-02-15 15:28:32,897:INFO:Declaring metric variables
2023-02-15 15:28:32,899:INFO:Importing untrained model
2023-02-15 15:28:32,901:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 15:28:32,904:INFO:Starting cross validation
2023-02-15 15:28:32,905:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:28:34,209:INFO:Calculating mean and std
2023-02-15 15:28:34,210:INFO:Creating metrics dataframe
2023-02-15 15:28:34,213:INFO:Uploading results into container
2023-02-15 15:28:34,213:INFO:Uploading model into container now
2023-02-15 15:28:34,213:INFO:_master_model_container: 6
2023-02-15 15:28:34,213:INFO:_display_container: 2
2023-02-15 15:28:34,214:INFO:LassoLars(random_state=11)
2023-02-15 15:28:34,214:INFO:create_model() successfully completed......................................
2023-02-15 15:28:34,331:INFO:SubProcess create_model() end ==================================
2023-02-15 15:28:34,331:INFO:Creating metrics dataframe
2023-02-15 15:28:34,338:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 15:28:34,338:INFO:Total runtime is 0.16065314610799156 minutes
2023-02-15 15:28:34,339:INFO:SubProcess create_model() called ==================================
2023-02-15 15:28:34,340:INFO:Initializing create_model()
2023-02-15 15:28:34,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:28:34,340:INFO:Checking exceptions
2023-02-15 15:28:34,340:INFO:Importing libraries
2023-02-15 15:28:34,340:INFO:Copying training dataset
2023-02-15 15:28:34,353:INFO:Defining folds
2023-02-15 15:28:34,353:INFO:Declaring metric variables
2023-02-15 15:28:34,355:INFO:Importing untrained model
2023-02-15 15:28:34,357:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 15:28:34,360:INFO:Starting cross validation
2023-02-15 15:28:34,360:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:28:35,666:INFO:Calculating mean and std
2023-02-15 15:28:35,667:INFO:Creating metrics dataframe
2023-02-15 15:28:35,670:INFO:Uploading results into container
2023-02-15 15:28:35,670:INFO:Uploading model into container now
2023-02-15 15:28:35,671:INFO:_master_model_container: 7
2023-02-15 15:28:35,671:INFO:_display_container: 2
2023-02-15 15:28:35,671:INFO:OrthogonalMatchingPursuit()
2023-02-15 15:28:35,671:INFO:create_model() successfully completed......................................
2023-02-15 15:28:35,798:INFO:SubProcess create_model() end ==================================
2023-02-15 15:28:35,798:INFO:Creating metrics dataframe
2023-02-15 15:28:35,805:INFO:Initializing Bayesian Ridge
2023-02-15 15:28:35,805:INFO:Total runtime is 0.18510285218556724 minutes
2023-02-15 15:28:35,806:INFO:SubProcess create_model() called ==================================
2023-02-15 15:28:35,807:INFO:Initializing create_model()
2023-02-15 15:28:35,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:28:35,807:INFO:Checking exceptions
2023-02-15 15:28:35,807:INFO:Importing libraries
2023-02-15 15:28:35,807:INFO:Copying training dataset
2023-02-15 15:28:35,821:INFO:Defining folds
2023-02-15 15:28:35,821:INFO:Declaring metric variables
2023-02-15 15:28:35,823:INFO:Importing untrained model
2023-02-15 15:28:35,825:INFO:Bayesian Ridge Imported successfully
2023-02-15 15:28:35,828:INFO:Starting cross validation
2023-02-15 15:28:35,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:28:38,381:INFO:Calculating mean and std
2023-02-15 15:28:38,382:INFO:Creating metrics dataframe
2023-02-15 15:28:38,384:INFO:Uploading results into container
2023-02-15 15:28:38,385:INFO:Uploading model into container now
2023-02-15 15:28:38,385:INFO:_master_model_container: 8
2023-02-15 15:28:38,385:INFO:_display_container: 2
2023-02-15 15:28:38,385:INFO:BayesianRidge()
2023-02-15 15:28:38,385:INFO:create_model() successfully completed......................................
2023-02-15 15:28:38,503:INFO:SubProcess create_model() end ==================================
2023-02-15 15:28:38,503:INFO:Creating metrics dataframe
2023-02-15 15:28:38,509:INFO:Initializing Passive Aggressive Regressor
2023-02-15 15:28:38,509:INFO:Total runtime is 0.2301791071891785 minutes
2023-02-15 15:28:38,511:INFO:SubProcess create_model() called ==================================
2023-02-15 15:28:38,511:INFO:Initializing create_model()
2023-02-15 15:28:38,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:28:38,511:INFO:Checking exceptions
2023-02-15 15:28:38,511:INFO:Importing libraries
2023-02-15 15:28:38,511:INFO:Copying training dataset
2023-02-15 15:28:38,525:INFO:Defining folds
2023-02-15 15:28:38,525:INFO:Declaring metric variables
2023-02-15 15:28:38,527:INFO:Importing untrained model
2023-02-15 15:28:38,529:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 15:28:38,532:INFO:Starting cross validation
2023-02-15 15:28:38,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:28:39,969:INFO:Calculating mean and std
2023-02-15 15:28:39,970:INFO:Creating metrics dataframe
2023-02-15 15:28:39,972:INFO:Uploading results into container
2023-02-15 15:28:39,973:INFO:Uploading model into container now
2023-02-15 15:28:39,973:INFO:_master_model_container: 9
2023-02-15 15:28:39,973:INFO:_display_container: 2
2023-02-15 15:28:39,973:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 15:28:39,973:INFO:create_model() successfully completed......................................
2023-02-15 15:28:40,100:INFO:SubProcess create_model() end ==================================
2023-02-15 15:28:40,100:INFO:Creating metrics dataframe
2023-02-15 15:28:40,106:INFO:Initializing Huber Regressor
2023-02-15 15:28:40,106:INFO:Total runtime is 0.2567940433820089 minutes
2023-02-15 15:28:40,108:INFO:SubProcess create_model() called ==================================
2023-02-15 15:28:40,108:INFO:Initializing create_model()
2023-02-15 15:28:40,108:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:28:40,108:INFO:Checking exceptions
2023-02-15 15:28:40,108:INFO:Importing libraries
2023-02-15 15:28:40,108:INFO:Copying training dataset
2023-02-15 15:28:40,120:INFO:Defining folds
2023-02-15 15:28:40,120:INFO:Declaring metric variables
2023-02-15 15:28:40,122:INFO:Importing untrained model
2023-02-15 15:28:40,124:INFO:Huber Regressor Imported successfully
2023-02-15 15:28:40,126:INFO:Starting cross validation
2023-02-15 15:28:40,127:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:28:42,357:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:28:44,627:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:28:46,865:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:28:49,117:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:28:51,244:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:28:53,394:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:28:55,785:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:28:57,894:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:29:00,066:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:29:02,126:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 15:29:02,213:INFO:Calculating mean and std
2023-02-15 15:29:02,214:INFO:Creating metrics dataframe
2023-02-15 15:29:02,216:INFO:Uploading results into container
2023-02-15 15:29:02,217:INFO:Uploading model into container now
2023-02-15 15:29:02,217:INFO:_master_model_container: 10
2023-02-15 15:29:02,217:INFO:_display_container: 2
2023-02-15 15:29:02,217:INFO:HuberRegressor()
2023-02-15 15:29:02,217:INFO:create_model() successfully completed......................................
2023-02-15 15:29:02,337:INFO:SubProcess create_model() end ==================================
2023-02-15 15:29:02,337:INFO:Creating metrics dataframe
2023-02-15 15:29:02,344:INFO:Initializing K Neighbors Regressor
2023-02-15 15:29:02,344:INFO:Total runtime is 0.6274182875951131 minutes
2023-02-15 15:29:02,345:INFO:SubProcess create_model() called ==================================
2023-02-15 15:29:02,345:INFO:Initializing create_model()
2023-02-15 15:29:02,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:29:02,346:INFO:Checking exceptions
2023-02-15 15:29:02,346:INFO:Importing libraries
2023-02-15 15:29:02,346:INFO:Copying training dataset
2023-02-15 15:29:02,358:INFO:Defining folds
2023-02-15 15:29:02,359:INFO:Declaring metric variables
2023-02-15 15:29:02,360:INFO:Importing untrained model
2023-02-15 15:29:02,362:INFO:K Neighbors Regressor Imported successfully
2023-02-15 15:29:02,365:INFO:Starting cross validation
2023-02-15 15:29:02,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:29:04,632:INFO:Calculating mean and std
2023-02-15 15:29:04,633:INFO:Creating metrics dataframe
2023-02-15 15:29:04,636:INFO:Uploading results into container
2023-02-15 15:29:04,636:INFO:Uploading model into container now
2023-02-15 15:29:04,636:INFO:_master_model_container: 11
2023-02-15 15:29:04,636:INFO:_display_container: 2
2023-02-15 15:29:04,636:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-15 15:29:04,636:INFO:create_model() successfully completed......................................
2023-02-15 15:29:04,741:INFO:SubProcess create_model() end ==================================
2023-02-15 15:29:04,741:INFO:Creating metrics dataframe
2023-02-15 15:29:04,747:INFO:Initializing Decision Tree Regressor
2023-02-15 15:29:04,747:INFO:Total runtime is 0.6674759745597839 minutes
2023-02-15 15:29:04,749:INFO:SubProcess create_model() called ==================================
2023-02-15 15:29:04,749:INFO:Initializing create_model()
2023-02-15 15:29:04,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:29:04,749:INFO:Checking exceptions
2023-02-15 15:29:04,749:INFO:Importing libraries
2023-02-15 15:29:04,749:INFO:Copying training dataset
2023-02-15 15:29:04,764:INFO:Defining folds
2023-02-15 15:29:04,765:INFO:Declaring metric variables
2023-02-15 15:29:04,767:INFO:Importing untrained model
2023-02-15 15:29:04,768:INFO:Decision Tree Regressor Imported successfully
2023-02-15 15:29:04,771:INFO:Starting cross validation
2023-02-15 15:29:04,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:29:42,533:INFO:Calculating mean and std
2023-02-15 15:29:42,534:INFO:Creating metrics dataframe
2023-02-15 15:29:42,536:INFO:Uploading results into container
2023-02-15 15:29:42,536:INFO:Uploading model into container now
2023-02-15 15:29:42,536:INFO:_master_model_container: 12
2023-02-15 15:29:42,536:INFO:_display_container: 2
2023-02-15 15:29:42,536:INFO:DecisionTreeRegressor(random_state=11)
2023-02-15 15:29:42,536:INFO:create_model() successfully completed......................................
2023-02-15 15:29:42,641:INFO:SubProcess create_model() end ==================================
2023-02-15 15:29:42,641:INFO:Creating metrics dataframe
2023-02-15 15:29:42,648:INFO:Initializing Random Forest Regressor
2023-02-15 15:29:42,648:INFO:Total runtime is 1.2991514603296914 minutes
2023-02-15 15:29:42,649:INFO:SubProcess create_model() called ==================================
2023-02-15 15:29:42,650:INFO:Initializing create_model()
2023-02-15 15:29:42,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:29:42,650:INFO:Checking exceptions
2023-02-15 15:29:42,650:INFO:Importing libraries
2023-02-15 15:29:42,650:INFO:Copying training dataset
2023-02-15 15:29:42,662:INFO:Defining folds
2023-02-15 15:29:42,662:INFO:Declaring metric variables
2023-02-15 15:29:42,665:INFO:Importing untrained model
2023-02-15 15:29:42,667:INFO:Random Forest Regressor Imported successfully
2023-02-15 15:29:42,672:INFO:Starting cross validation
2023-02-15 15:29:42,673:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:32:04,738:INFO:Calculating mean and std
2023-02-15 15:32:04,739:INFO:Creating metrics dataframe
2023-02-15 15:32:04,742:INFO:Uploading results into container
2023-02-15 15:32:04,742:INFO:Uploading model into container now
2023-02-15 15:32:04,743:INFO:_master_model_container: 13
2023-02-15 15:32:04,743:INFO:_display_container: 2
2023-02-15 15:32:04,744:INFO:RandomForestRegressor(n_jobs=-1, random_state=11)
2023-02-15 15:32:04,744:INFO:create_model() successfully completed......................................
2023-02-15 15:32:04,855:INFO:SubProcess create_model() end ==================================
2023-02-15 15:32:04,855:INFO:Creating metrics dataframe
2023-02-15 15:32:04,862:INFO:Initializing Extra Trees Regressor
2023-02-15 15:32:04,862:INFO:Total runtime is 3.669395609696706 minutes
2023-02-15 15:32:04,864:INFO:SubProcess create_model() called ==================================
2023-02-15 15:32:04,864:INFO:Initializing create_model()
2023-02-15 15:32:04,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:32:04,864:INFO:Checking exceptions
2023-02-15 15:32:04,865:INFO:Importing libraries
2023-02-15 15:32:04,865:INFO:Copying training dataset
2023-02-15 15:32:04,878:INFO:Defining folds
2023-02-15 15:32:04,878:INFO:Declaring metric variables
2023-02-15 15:32:04,880:INFO:Importing untrained model
2023-02-15 15:32:04,882:INFO:Extra Trees Regressor Imported successfully
2023-02-15 15:32:04,885:INFO:Starting cross validation
2023-02-15 15:32:04,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:32:33,374:INFO:Calculating mean and std
2023-02-15 15:32:33,375:INFO:Creating metrics dataframe
2023-02-15 15:32:33,376:INFO:Uploading results into container
2023-02-15 15:32:33,377:INFO:Uploading model into container now
2023-02-15 15:32:33,377:INFO:_master_model_container: 14
2023-02-15 15:32:33,377:INFO:_display_container: 2
2023-02-15 15:32:33,377:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=11)
2023-02-15 15:32:33,377:INFO:create_model() successfully completed......................................
2023-02-15 15:32:33,483:INFO:SubProcess create_model() end ==================================
2023-02-15 15:32:33,483:INFO:Creating metrics dataframe
2023-02-15 15:32:33,490:INFO:Initializing AdaBoost Regressor
2023-02-15 15:32:33,490:INFO:Total runtime is 4.146527115503947 minutes
2023-02-15 15:32:33,493:INFO:SubProcess create_model() called ==================================
2023-02-15 15:32:33,493:INFO:Initializing create_model()
2023-02-15 15:32:33,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:32:33,493:INFO:Checking exceptions
2023-02-15 15:32:33,493:INFO:Importing libraries
2023-02-15 15:32:33,493:INFO:Copying training dataset
2023-02-15 15:32:33,508:INFO:Defining folds
2023-02-15 15:32:33,508:INFO:Declaring metric variables
2023-02-15 15:32:33,510:INFO:Importing untrained model
2023-02-15 15:32:33,511:INFO:AdaBoost Regressor Imported successfully
2023-02-15 15:32:33,514:INFO:Starting cross validation
2023-02-15 15:32:33,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:34:39,244:INFO:Calculating mean and std
2023-02-15 15:34:39,244:INFO:Creating metrics dataframe
2023-02-15 15:34:39,246:INFO:Uploading results into container
2023-02-15 15:34:39,246:INFO:Uploading model into container now
2023-02-15 15:34:39,247:INFO:_master_model_container: 15
2023-02-15 15:34:39,247:INFO:_display_container: 2
2023-02-15 15:34:39,247:INFO:AdaBoostRegressor(random_state=11)
2023-02-15 15:34:39,247:INFO:create_model() successfully completed......................................
2023-02-15 15:34:39,356:INFO:SubProcess create_model() end ==================================
2023-02-15 15:34:39,356:INFO:Creating metrics dataframe
2023-02-15 15:34:39,364:INFO:Initializing Gradient Boosting Regressor
2023-02-15 15:34:39,364:INFO:Total runtime is 6.244422717889149 minutes
2023-02-15 15:34:39,366:INFO:SubProcess create_model() called ==================================
2023-02-15 15:34:39,366:INFO:Initializing create_model()
2023-02-15 15:34:39,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:34:39,366:INFO:Checking exceptions
2023-02-15 15:34:39,366:INFO:Importing libraries
2023-02-15 15:34:39,366:INFO:Copying training dataset
2023-02-15 15:34:39,379:INFO:Defining folds
2023-02-15 15:34:39,379:INFO:Declaring metric variables
2023-02-15 15:34:39,382:INFO:Importing untrained model
2023-02-15 15:34:39,383:INFO:Gradient Boosting Regressor Imported successfully
2023-02-15 15:34:39,387:INFO:Starting cross validation
2023-02-15 15:34:39,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:45:27,990:INFO:Calculating mean and std
2023-02-15 15:45:27,996:INFO:Creating metrics dataframe
2023-02-15 15:45:27,998:INFO:Uploading results into container
2023-02-15 15:45:27,998:INFO:Uploading model into container now
2023-02-15 15:45:27,999:INFO:_master_model_container: 16
2023-02-15 15:45:27,999:INFO:_display_container: 2
2023-02-15 15:45:27,999:INFO:GradientBoostingRegressor(random_state=11)
2023-02-15 15:45:27,999:INFO:create_model() successfully completed......................................
2023-02-15 15:45:28,104:INFO:SubProcess create_model() end ==================================
2023-02-15 15:45:28,104:INFO:Creating metrics dataframe
2023-02-15 15:45:28,111:INFO:Initializing Extreme Gradient Boosting
2023-02-15 15:45:28,111:INFO:Total runtime is 17.056882747014363 minutes
2023-02-15 15:45:28,113:INFO:SubProcess create_model() called ==================================
2023-02-15 15:45:28,113:INFO:Initializing create_model()
2023-02-15 15:45:28,113:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:45:28,113:INFO:Checking exceptions
2023-02-15 15:45:28,113:INFO:Importing libraries
2023-02-15 15:45:28,114:INFO:Copying training dataset
2023-02-15 15:45:28,127:INFO:Defining folds
2023-02-15 15:45:28,127:INFO:Declaring metric variables
2023-02-15 15:45:28,129:INFO:Importing untrained model
2023-02-15 15:45:28,131:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 15:45:28,134:INFO:Starting cross validation
2023-02-15 15:45:28,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:45:29,224:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 15:45:29,230:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
7 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/sklearn.py", line 1025, in fit
    self._Booster = train(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/training.py", line 185, in train
    bst.update(dtrain, i, obj)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 1918, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 279, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [15:45:28] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.
Stack trace:
  [bt] (0) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29d959) [0x7f5b8037d959]
  [bt] (1) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29ec02) [0x7f5b8037ec02]
  [bt] (2) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29efba) [0x7f5b8037efba]
  [bt] (3) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2dddad) [0x7f5b803bddad]
  [bt] (4) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f5b8020dfb0]
  [bt] (5) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f5c81fc1a4a]
  [bt] (6) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f5c81fc0fea]
  [bt] (7) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f5c81fda48f]
  [bt] (8) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x8ff3) [0x7f5c81fcfff3]



--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/sklearn.py", line 1025, in fit
    self._Booster = train(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/training.py", line 185, in train
    bst.update(dtrain, i, obj)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 1918, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 279, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [15:45:29] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.
Stack trace:
  [bt] (0) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29d959) [0x7f5b8037d959]
  [bt] (1) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29ec02) [0x7f5b8037ec02]
  [bt] (2) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29efba) [0x7f5b8037efba]
  [bt] (3) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2dddad) [0x7f5b803bddad]
  [bt] (4) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f5b8020dfb0]
  [bt] (5) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f5c81fc1a4a]
  [bt] (6) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f5c81fc0fea]
  [bt] (7) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f5c81fda48f]
  [bt] (8) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x8ff3) [0x7f5c81fcfff3]




2023-02-15 15:45:29,230:INFO:Initializing create_model()
2023-02-15 15:45:29,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:45:29,230:INFO:Checking exceptions
2023-02-15 15:45:29,230:INFO:Importing libraries
2023-02-15 15:45:29,230:INFO:Copying training dataset
2023-02-15 15:45:29,244:INFO:Defining folds
2023-02-15 15:45:29,244:INFO:Declaring metric variables
2023-02-15 15:45:29,246:INFO:Importing untrained model
2023-02-15 15:45:29,248:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 15:45:29,251:INFO:Starting cross validation
2023-02-15 15:45:29,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:45:30,285:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2023-02-15 15:45:30,285:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
7 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/sklearn.py", line 1025, in fit
    self._Booster = train(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/training.py", line 185, in train
    bst.update(dtrain, i, obj)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 1918, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 279, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [15:45:28] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.
Stack trace:
  [bt] (0) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29d959) [0x7f5b8037d959]
  [bt] (1) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29ec02) [0x7f5b8037ec02]
  [bt] (2) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29efba) [0x7f5b8037efba]
  [bt] (3) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2dddad) [0x7f5b803bddad]
  [bt] (4) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f5b8020dfb0]
  [bt] (5) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f5c81fc1a4a]
  [bt] (6) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f5c81fc0fea]
  [bt] (7) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f5c81fda48f]
  [bt] (8) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x8ff3) [0x7f5c81fcfff3]



--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/sklearn.py", line 1025, in fit
    self._Booster = train(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/training.py", line 185, in train
    bst.update(dtrain, i, obj)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 1918, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 279, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [15:45:29] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.
Stack trace:
  [bt] (0) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29d959) [0x7f5b8037d959]
  [bt] (1) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29ec02) [0x7f5b8037ec02]
  [bt] (2) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29efba) [0x7f5b8037efba]
  [bt] (3) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2dddad) [0x7f5b803bddad]
  [bt] (4) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f5b8020dfb0]
  [bt] (5) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f5c81fc1a4a]
  [bt] (6) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f5c81fc0fea]
  [bt] (7) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f5c81fda48f]
  [bt] (8) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x8ff3) [0x7f5c81fcfff3]




During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
7 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
7 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/sklearn.py", line 1025, in fit
    self._Booster = train(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/training.py", line 185, in train
    bst.update(dtrain, i, obj)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 1918, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 279, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [15:45:28] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.
Stack trace:
  [bt] (0) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29d959) [0x7f5b8037d959]
  [bt] (1) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29ec02) [0x7f5b8037ec02]
  [bt] (2) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29efba) [0x7f5b8037efba]
  [bt] (3) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2dddad) [0x7f5b803bddad]
  [bt] (4) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f5b8020dfb0]
  [bt] (5) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f5c81fc1a4a]
  [bt] (6) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f5c81fc0fea]
  [bt] (7) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f5c81fda48f]
  [bt] (8) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x8ff3) [0x7f5c81fcfff3]



--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/sklearn.py", line 1025, in fit
    self._Booster = train(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/training.py", line 185, in train
    bst.update(dtrain, i, obj)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 1918, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 279, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [15:45:29] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.
Stack trace:
  [bt] (0) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29d959) [0x7f5b8037d959]
  [bt] (1) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29ec02) [0x7f5b8037ec02]
  [bt] (2) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29efba) [0x7f5b8037efba]
  [bt] (3) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2dddad) [0x7f5b803bddad]
  [bt] (4) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f5b8020dfb0]
  [bt] (5) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f5c81fc1a4a]
  [bt] (6) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f5c81fc0fea]
  [bt] (7) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f5c81fda48f]
  [bt] (8) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x8ff3) [0x7f5c81fcfff3]




During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/sklearn.py", line 1025, in fit
    self._Booster = train(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/training.py", line 185, in train
    bst.update(dtrain, i, obj)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 1918, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 279, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [15:45:29] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.
Stack trace:
  [bt] (0) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29d959) [0x7f5b8037d959]
  [bt] (1) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29ec02) [0x7f5b8037ec02]
  [bt] (2) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29efba) [0x7f5b8037efba]
  [bt] (3) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2dddad) [0x7f5b803bddad]
  [bt] (4) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f5b8020dfb0]
  [bt] (5) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f5c81fc1a4a]
  [bt] (6) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f5c81fc0fea]
  [bt] (7) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f5c81fda48f]
  [bt] (8) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x8ff3) [0x7f5c81fcfff3]



--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
7 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/sklearn.py", line 1025, in fit
    self._Booster = train(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/training.py", line 185, in train
    bst.update(dtrain, i, obj)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 1918, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 279, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [15:45:28] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.
Stack trace:
  [bt] (0) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29d959) [0x7f5b8037d959]
  [bt] (1) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29ec02) [0x7f5b8037ec02]
  [bt] (2) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29efba) [0x7f5b8037efba]
  [bt] (3) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2dddad) [0x7f5b803bddad]
  [bt] (4) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f5b8020dfb0]
  [bt] (5) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f5c81fc1a4a]
  [bt] (6) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f5c81fc0fea]
  [bt] (7) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f5c81fda48f]
  [bt] (8) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x8ff3) [0x7f5c81fcfff3]



--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/sklearn.py", line 1025, in fit
    self._Booster = train(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/training.py", line 185, in train
    bst.update(dtrain, i, obj)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 1918, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 279, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [15:45:29] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.
Stack trace:
  [bt] (0) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29d959) [0x7f5b8037d959]
  [bt] (1) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29ec02) [0x7f5b8037ec02]
  [bt] (2) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29efba) [0x7f5b8037efba]
  [bt] (3) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2dddad) [0x7f5b803bddad]
  [bt] (4) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f5b8020dfb0]
  [bt] (5) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f5c81fc1a4a]
  [bt] (6) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f5c81fc0fea]
  [bt] (7) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f5c81fda48f]
  [bt] (8) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x8ff3) [0x7f5c81fcfff3]




During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/sklearn.py", line 1025, in fit
    self._Booster = train(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 620, in inner_f
    return func(**kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/training.py", line 185, in train
    bst.update(dtrain, i, obj)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 1918, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/core.py", line 279, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [15:45:30] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.
Stack trace:
  [bt] (0) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29d959) [0x7f5b8037d959]
  [bt] (1) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29ec02) [0x7f5b8037ec02]
  [bt] (2) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x29efba) [0x7f5b8037efba]
  [bt] (3) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2dddad) [0x7f5b803bddad]
  [bt] (4) /home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f5b8020dfb0]
  [bt] (5) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f5c81fc1a4a]
  [bt] (6) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f5c81fc0fea]
  [bt] (7) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f5c81fda48f]
  [bt] (8) /home/moussa/anaconda3/envs/research/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x8ff3) [0x7f5c81fcfff3]




2023-02-15 15:45:30,285:INFO:Initializing Light Gradient Boosting Machine
2023-02-15 15:45:30,285:INFO:Total runtime is 17.09310944477717 minutes
2023-02-15 15:45:30,288:INFO:SubProcess create_model() called ==================================
2023-02-15 15:45:30,288:INFO:Initializing create_model()
2023-02-15 15:45:30,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:45:30,288:INFO:Checking exceptions
2023-02-15 15:45:30,288:INFO:Importing libraries
2023-02-15 15:45:30,288:INFO:Copying training dataset
2023-02-15 15:45:30,302:INFO:Defining folds
2023-02-15 15:45:30,302:INFO:Declaring metric variables
2023-02-15 15:45:30,304:INFO:Importing untrained model
2023-02-15 15:45:30,306:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 15:45:30,309:INFO:Starting cross validation
2023-02-15 15:45:30,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:45:30,463:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006866 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-15 15:45:30,464:INFO:[LightGBM] [Info] Total Bins 40290
2023-02-15 15:45:30,465:INFO:[LightGBM] [Info] Number of data points in the train set: 18055, number of used features: 158
2023-02-15 15:45:30,466:INFO:[LightGBM] [Info] Start training from score 0.001473
2023-02-15 15:45:30,965:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013885 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-15 15:45:30,966:INFO:[LightGBM] [Info] Total Bins 40290
2023-02-15 15:45:30,967:INFO:[LightGBM] [Info] Number of data points in the train set: 18055, number of used features: 158
2023-02-15 15:45:30,967:INFO:[LightGBM] [Info] Start training from score 0.001360
2023-02-15 15:45:31,442:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-15 15:45:31,443:INFO:[LightGBM] [Info] Total Bins 40290
2023-02-15 15:45:31,448:INFO:[LightGBM] [Info] Number of data points in the train set: 18056, number of used features: 158
2023-02-15 15:45:31,451:INFO:[LightGBM] [Info] Start training from score 0.001364
2023-02-15 15:45:31,869:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005567 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-15 15:45:31,870:INFO:[LightGBM] [Info] Total Bins 40290
2023-02-15 15:45:31,871:INFO:[LightGBM] [Info] Number of data points in the train set: 18056, number of used features: 158
2023-02-15 15:45:31,871:INFO:[LightGBM] [Info] Start training from score 0.001495
2023-02-15 15:45:32,278:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007154 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-15 15:45:32,278:INFO:[LightGBM] [Info] Total Bins 40290
2023-02-15 15:45:32,280:INFO:[LightGBM] [Info] Number of data points in the train set: 18056, number of used features: 158
2023-02-15 15:45:32,280:INFO:[LightGBM] [Info] Start training from score 0.001352
2023-02-15 15:45:32,668:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005397 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-15 15:45:32,669:INFO:[LightGBM] [Info] Total Bins 40290
2023-02-15 15:45:32,670:INFO:[LightGBM] [Info] Number of data points in the train set: 18056, number of used features: 158
2023-02-15 15:45:32,671:INFO:[LightGBM] [Info] Start training from score 0.001420
2023-02-15 15:45:33,052:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005366 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-15 15:45:33,053:INFO:[LightGBM] [Info] Total Bins 40290
2023-02-15 15:45:33,054:INFO:[LightGBM] [Info] Number of data points in the train set: 18056, number of used features: 158
2023-02-15 15:45:33,055:INFO:[LightGBM] [Info] Start training from score 0.001310
2023-02-15 15:45:33,464:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005372 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-15 15:45:33,465:INFO:[LightGBM] [Info] Total Bins 40290
2023-02-15 15:45:33,466:INFO:[LightGBM] [Info] Number of data points in the train set: 18056, number of used features: 158
2023-02-15 15:45:33,466:INFO:[LightGBM] [Info] Start training from score 0.001370
2023-02-15 15:45:33,867:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005643 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-15 15:45:33,867:INFO:[LightGBM] [Info] Total Bins 40290
2023-02-15 15:45:33,869:INFO:[LightGBM] [Info] Number of data points in the train set: 18056, number of used features: 158
2023-02-15 15:45:33,869:INFO:[LightGBM] [Info] Start training from score 0.001436
2023-02-15 15:45:34,308:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-15 15:45:34,309:INFO:[LightGBM] [Info] Total Bins 40290
2023-02-15 15:45:34,312:INFO:[LightGBM] [Info] Number of data points in the train set: 18056, number of used features: 158
2023-02-15 15:45:34,312:INFO:[LightGBM] [Info] Start training from score 0.001391
2023-02-15 15:45:34,605:INFO:Calculating mean and std
2023-02-15 15:45:34,605:INFO:Creating metrics dataframe
2023-02-15 15:45:34,607:INFO:Uploading results into container
2023-02-15 15:45:34,608:INFO:Uploading model into container now
2023-02-15 15:45:34,608:INFO:_master_model_container: 17
2023-02-15 15:45:34,608:INFO:_display_container: 2
2023-02-15 15:45:34,608:INFO:LGBMRegressor(n_jobs=-1, random_state=11)
2023-02-15 15:45:34,608:INFO:create_model() successfully completed......................................
2023-02-15 15:45:34,716:INFO:SubProcess create_model() end ==================================
2023-02-15 15:45:34,716:INFO:Creating metrics dataframe
2023-02-15 15:45:34,724:INFO:Initializing CatBoost Regressor
2023-02-15 15:45:34,724:INFO:Total runtime is 17.167095581690468 minutes
2023-02-15 15:45:34,726:INFO:SubProcess create_model() called ==================================
2023-02-15 15:45:34,726:INFO:Initializing create_model()
2023-02-15 15:45:34,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:45:34,726:INFO:Checking exceptions
2023-02-15 15:45:34,726:INFO:Importing libraries
2023-02-15 15:45:34,726:INFO:Copying training dataset
2023-02-15 15:45:34,741:INFO:Defining folds
2023-02-15 15:45:34,741:INFO:Declaring metric variables
2023-02-15 15:45:34,743:INFO:Importing untrained model
2023-02-15 15:45:34,752:INFO:CatBoost Regressor Imported successfully
2023-02-15 15:45:34,755:INFO:Starting cross validation
2023-02-15 15:45:34,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:46:15,299:INFO:Calculating mean and std
2023-02-15 15:46:15,300:INFO:Creating metrics dataframe
2023-02-15 15:46:15,301:INFO:Uploading results into container
2023-02-15 15:46:15,302:INFO:Uploading model into container now
2023-02-15 15:46:15,302:INFO:_master_model_container: 18
2023-02-15 15:46:15,302:INFO:_display_container: 2
2023-02-15 15:46:15,302:INFO:<catboost.core.CatBoostRegressor object at 0x7f5bb9126d60>
2023-02-15 15:46:15,302:INFO:create_model() successfully completed......................................
2023-02-15 15:46:15,412:INFO:SubProcess create_model() end ==================================
2023-02-15 15:46:15,412:INFO:Creating metrics dataframe
2023-02-15 15:46:15,421:INFO:Initializing Dummy Regressor
2023-02-15 15:46:15,421:INFO:Total runtime is 17.845367678006486 minutes
2023-02-15 15:46:15,422:INFO:SubProcess create_model() called ==================================
2023-02-15 15:46:15,423:INFO:Initializing create_model()
2023-02-15 15:46:15,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5bb92917f0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:46:15,423:INFO:Checking exceptions
2023-02-15 15:46:15,423:INFO:Importing libraries
2023-02-15 15:46:15,423:INFO:Copying training dataset
2023-02-15 15:46:15,437:INFO:Defining folds
2023-02-15 15:46:15,438:INFO:Declaring metric variables
2023-02-15 15:46:15,440:INFO:Importing untrained model
2023-02-15 15:46:15,442:INFO:Dummy Regressor Imported successfully
2023-02-15 15:46:15,445:INFO:Starting cross validation
2023-02-15 15:46:15,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 15:46:16,267:INFO:Calculating mean and std
2023-02-15 15:46:16,270:INFO:Creating metrics dataframe
2023-02-15 15:46:16,272:INFO:Uploading results into container
2023-02-15 15:46:16,272:INFO:Uploading model into container now
2023-02-15 15:46:16,272:INFO:_master_model_container: 19
2023-02-15 15:46:16,272:INFO:_display_container: 2
2023-02-15 15:46:16,272:INFO:DummyRegressor()
2023-02-15 15:46:16,272:INFO:create_model() successfully completed......................................
2023-02-15 15:46:16,388:INFO:SubProcess create_model() end ==================================
2023-02-15 15:46:16,388:INFO:Creating metrics dataframe
2023-02-15 15:46:16,401:INFO:Initializing create_model()
2023-02-15 15:46:16,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5c72405ac0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=11), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 15:46:16,401:INFO:Checking exceptions
2023-02-15 15:46:16,402:INFO:Importing libraries
2023-02-15 15:46:16,402:INFO:Copying training dataset
2023-02-15 15:46:16,417:INFO:Defining folds
2023-02-15 15:46:16,417:INFO:Declaring metric variables
2023-02-15 15:46:16,417:INFO:Importing untrained model
2023-02-15 15:46:16,417:INFO:Declaring custom model
2023-02-15 15:46:16,417:INFO:Extra Trees Regressor Imported successfully
2023-02-15 15:46:16,418:INFO:Cross validation set to False
2023-02-15 15:46:16,418:INFO:Fitting Model
2023-02-15 15:46:19,385:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=11)
2023-02-15 15:46:19,386:INFO:create_model() successfully completed......................................
2023-02-15 15:46:19,513:INFO:_master_model_container: 19
2023-02-15 15:46:19,514:INFO:_display_container: 2
2023-02-15 15:46:19,514:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=11)
2023-02-15 15:46:19,514:INFO:compare_models() successfully completed......................................
2023-02-15 16:39:22,662:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:22,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:22,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:22,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:23,966:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 16:39:24,080:INFO:PyCaret RegressionExperiment
2023-02-15 16:39:24,080:INFO:Logging name: reg-default-name
2023-02-15 16:39:24,080:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 16:39:24,080:INFO:version 3.0.0.rc9
2023-02-15 16:39:24,080:INFO:Initializing setup()
2023-02-15 16:39:24,080:INFO:self.USI: 7aa9
2023-02-15 16:39:24,080:INFO:self._variable_keys: {'idx', 'gpu_n_jobs_param', 'exp_name_log', 'y_train', '_available_plots', 'data', 'gpu_param', 'pipeline', 'fold_shuffle_param', 'html_param', 'USI', 'X_test', 'X_train', 'y_test', 'memory', 'y', 'exp_id', 'n_jobs_param', '_ml_usecase', 'logging_param', 'target_param', 'fold_generator', 'seed', 'fold_groups_param', 'log_plots_param', 'transform_target_param', 'X'}
2023-02-15 16:39:24,080:INFO:Checking environment
2023-02-15 16:39:24,080:INFO:python_version: 3.8.16
2023-02-15 16:39:24,080:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-15 16:39:24,080:INFO:machine: x86_64
2023-02-15 16:39:24,081:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 16:39:24,081:INFO:Memory: svmem(total=134979592192, available=122790535168, percent=9.0, used=10572898304, free=41573752832, active=1903882240, inactive=82447196160, buffers=59714912256, cached=23118028800, shared=345391104, slab=8459948032)
2023-02-15 16:39:24,081:INFO:Physical Core: 16
2023-02-15 16:39:24,081:INFO:Logical Core: 32
2023-02-15 16:39:24,081:INFO:Checking libraries
2023-02-15 16:39:24,081:INFO:System:
2023-02-15 16:39:24,081:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-15 16:39:24,081:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 16:39:24,081:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 16:39:24,081:INFO:PyCaret required dependencies:
2023-02-15 16:39:24,082:INFO:                 pip: 23.0
2023-02-15 16:39:24,082:INFO:          setuptools: 60.10.0
2023-02-15 16:39:24,082:INFO:             pycaret: 3.0.0rc9
2023-02-15 16:39:24,082:INFO:             IPython: 8.10.0
2023-02-15 16:39:24,082:INFO:          ipywidgets: 7.7.3
2023-02-15 16:39:24,082:INFO:                tqdm: 4.64.1
2023-02-15 16:39:24,082:INFO:               numpy: 1.23.5
2023-02-15 16:39:24,082:INFO:              pandas: 1.5.3
2023-02-15 16:39:24,082:INFO:              jinja2: 3.1.2
2023-02-15 16:39:24,082:INFO:               scipy: 1.9.1
2023-02-15 16:39:24,082:INFO:              joblib: 1.2.0
2023-02-15 16:39:24,082:INFO:             sklearn: 1.2.1
2023-02-15 16:39:24,082:INFO:                pyod: 1.0.7
2023-02-15 16:39:24,082:INFO:            imblearn: 0.10.1
2023-02-15 16:39:24,082:INFO:   category_encoders: 2.6.0
2023-02-15 16:39:24,082:INFO:            lightgbm: 3.3.5.99
2023-02-15 16:39:24,082:INFO:               numba: 0.56.4
2023-02-15 16:39:24,082:INFO:            requests: 2.28.2
2023-02-15 16:39:24,082:INFO:          matplotlib: 3.6.3
2023-02-15 16:39:24,082:INFO:          scikitplot: 0.3.7
2023-02-15 16:39:24,082:INFO:         yellowbrick: 1.5
2023-02-15 16:39:24,082:INFO:              plotly: 5.13.0
2023-02-15 16:39:24,082:INFO:             kaleido: 0.2.1
2023-02-15 16:39:24,082:INFO:         statsmodels: 0.13.5
2023-02-15 16:39:24,082:INFO:              sktime: 0.16.1
2023-02-15 16:39:24,082:INFO:               tbats: 1.1.2
2023-02-15 16:39:24,082:INFO:            pmdarima: 2.0.2
2023-02-15 16:39:24,082:INFO:              psutil: 5.9.4
2023-02-15 16:39:24,082:INFO:PyCaret optional dependencies:
2023-02-15 16:39:24,542:INFO:                shap: 0.41.0
2023-02-15 16:39:24,542:INFO:           interpret: 0.3.0
2023-02-15 16:39:24,542:INFO:                umap: 0.5.3
2023-02-15 16:39:24,542:INFO:    pandas_profiling: 4.0.0
2023-02-15 16:39:24,542:INFO:  explainerdashboard: 0.4.2
2023-02-15 16:39:24,542:INFO:             autoviz: 0.1.58
2023-02-15 16:39:24,542:INFO:           fairlearn: 0.7.0
2023-02-15 16:39:24,542:INFO:             xgboost: 1.7.3
2023-02-15 16:39:24,542:INFO:            catboost: 1.1.1
2023-02-15 16:39:24,542:INFO:              kmodes: 0.12.2
2023-02-15 16:39:24,542:INFO:             mlxtend: 0.21.0
2023-02-15 16:39:24,542:INFO:       statsforecast: 1.4.0
2023-02-15 16:39:24,542:INFO:        tune_sklearn: 0.4.5
2023-02-15 16:39:24,542:INFO:                 ray: 2.2.0
2023-02-15 16:39:24,542:INFO:            hyperopt: 0.2.7
2023-02-15 16:39:24,542:INFO:              optuna: 3.1.0
2023-02-15 16:39:24,542:INFO:               skopt: 0.9.0
2023-02-15 16:39:24,542:INFO:              mlflow: 1.30.0
2023-02-15 16:39:24,542:INFO:              gradio: 3.18.0
2023-02-15 16:39:24,542:INFO:             fastapi: 0.92.0
2023-02-15 16:39:24,542:INFO:             uvicorn: 0.20.0
2023-02-15 16:39:24,542:INFO:              m2cgen: 0.10.0
2023-02-15 16:39:24,542:INFO:           evidently: 0.2.4
2023-02-15 16:39:24,542:INFO:               fugue: 0.8.1.dev4
2023-02-15 16:39:24,542:INFO:           streamlit: Not installed
2023-02-15 16:39:24,542:INFO:             prophet: Not installed
2023-02-15 16:39:24,542:INFO:None
2023-02-15 16:39:24,542:INFO:Set up GPU usage.
2023-02-15 16:39:24,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:24,542:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 16:39:24,542:INFO:Set up data.
2023-02-15 16:39:24,602:INFO:Set up train/test split.
2023-02-15 16:39:24,630:INFO:Set up index.
2023-02-15 16:39:24,637:INFO:Set up folding strategy.
2023-02-15 16:39:24,637:INFO:Assigning column types.
2023-02-15 16:39:24,648:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 16:39:24,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:24,649:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 16:39:24,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:24,651:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 16:39:24,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:24,654:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 16:39:24,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:24,697:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 16:39:24,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:24,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 16:39:24,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:24,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:39:24,725:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:11,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:11,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:11,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:11,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:12,136:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 18:14:12,217:INFO:PyCaret RegressionExperiment
2023-02-15 18:14:12,217:INFO:Logging name: reg-default-name
2023-02-15 18:14:12,217:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 18:14:12,217:INFO:version 3.0.0.rc9
2023-02-15 18:14:12,217:INFO:Initializing setup()
2023-02-15 18:14:12,217:INFO:self.USI: 3594
2023-02-15 18:14:12,217:INFO:self._variable_keys: {'pipeline', 'y', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_groups_param', 'y_test', 'html_param', 'log_plots_param', 'transform_target_param', 'exp_name_log', 'n_jobs_param', 'logging_param', 'memory', 'X_train', 'exp_id', 'data', 'fold_shuffle_param', 'seed', 'USI', '_available_plots', 'y_train', '_ml_usecase', 'idx', 'gpu_param', 'X', 'X_test'}
2023-02-15 18:14:12,217:INFO:Checking environment
2023-02-15 18:14:12,217:INFO:python_version: 3.8.16
2023-02-15 18:14:12,217:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-15 18:14:12,217:INFO:machine: x86_64
2023-02-15 18:14:12,217:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 18:14:12,217:INFO:Memory: svmem(total=134979592192, available=117845274624, percent=12.7, used=14900105216, free=987258880, active=5112967168, inactive=122762526720, buffers=1776140288, cached=117316087808, shared=962203648, slab=5400514560)
2023-02-15 18:14:12,218:INFO:Physical Core: 16
2023-02-15 18:14:12,218:INFO:Logical Core: 32
2023-02-15 18:14:12,218:INFO:Checking libraries
2023-02-15 18:14:12,218:INFO:System:
2023-02-15 18:14:12,218:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-15 18:14:12,218:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 18:14:12,218:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 18:14:12,218:INFO:PyCaret required dependencies:
2023-02-15 18:14:12,218:INFO:                 pip: 23.0
2023-02-15 18:14:12,218:INFO:          setuptools: 60.10.0
2023-02-15 18:14:12,218:INFO:             pycaret: 3.0.0rc9
2023-02-15 18:14:12,218:INFO:             IPython: 8.10.0
2023-02-15 18:14:12,218:INFO:          ipywidgets: 7.7.3
2023-02-15 18:14:12,218:INFO:                tqdm: 4.64.1
2023-02-15 18:14:12,218:INFO:               numpy: 1.23.5
2023-02-15 18:14:12,218:INFO:              pandas: 1.5.3
2023-02-15 18:14:12,218:INFO:              jinja2: 3.1.2
2023-02-15 18:14:12,218:INFO:               scipy: 1.9.1
2023-02-15 18:14:12,218:INFO:              joblib: 1.2.0
2023-02-15 18:14:12,218:INFO:             sklearn: 1.2.1
2023-02-15 18:14:12,218:INFO:                pyod: 1.0.7
2023-02-15 18:14:12,218:INFO:            imblearn: 0.10.1
2023-02-15 18:14:12,218:INFO:   category_encoders: 2.6.0
2023-02-15 18:14:12,218:INFO:            lightgbm: 3.3.5.99
2023-02-15 18:14:12,218:INFO:               numba: 0.56.4
2023-02-15 18:14:12,218:INFO:            requests: 2.28.2
2023-02-15 18:14:12,218:INFO:          matplotlib: 3.6.3
2023-02-15 18:14:12,218:INFO:          scikitplot: 0.3.7
2023-02-15 18:14:12,218:INFO:         yellowbrick: 1.5
2023-02-15 18:14:12,218:INFO:              plotly: 5.13.0
2023-02-15 18:14:12,218:INFO:             kaleido: 0.2.1
2023-02-15 18:14:12,218:INFO:         statsmodels: 0.13.5
2023-02-15 18:14:12,218:INFO:              sktime: 0.16.1
2023-02-15 18:14:12,218:INFO:               tbats: 1.1.2
2023-02-15 18:14:12,218:INFO:            pmdarima: 2.0.2
2023-02-15 18:14:12,218:INFO:              psutil: 5.9.4
2023-02-15 18:14:12,218:INFO:PyCaret optional dependencies:
2023-02-15 18:14:12,555:INFO:                shap: 0.41.0
2023-02-15 18:14:12,555:INFO:           interpret: 0.3.0
2023-02-15 18:14:12,555:INFO:                umap: 0.5.3
2023-02-15 18:14:12,556:INFO:    pandas_profiling: 4.0.0
2023-02-15 18:14:12,556:INFO:  explainerdashboard: 0.4.2
2023-02-15 18:14:12,556:INFO:             autoviz: 0.1.58
2023-02-15 18:14:12,556:INFO:           fairlearn: 0.7.0
2023-02-15 18:14:12,556:INFO:             xgboost: 1.7.3
2023-02-15 18:14:12,556:INFO:            catboost: 1.1.1
2023-02-15 18:14:12,556:INFO:              kmodes: 0.12.2
2023-02-15 18:14:12,556:INFO:             mlxtend: 0.21.0
2023-02-15 18:14:12,556:INFO:       statsforecast: 1.4.0
2023-02-15 18:14:12,556:INFO:        tune_sklearn: 0.4.5
2023-02-15 18:14:12,556:INFO:                 ray: 2.2.0
2023-02-15 18:14:12,556:INFO:            hyperopt: 0.2.7
2023-02-15 18:14:12,556:INFO:              optuna: 3.1.0
2023-02-15 18:14:12,556:INFO:               skopt: 0.9.0
2023-02-15 18:14:12,556:INFO:              mlflow: 1.30.0
2023-02-15 18:14:12,556:INFO:              gradio: 3.18.0
2023-02-15 18:14:12,556:INFO:             fastapi: 0.92.0
2023-02-15 18:14:12,556:INFO:             uvicorn: 0.20.0
2023-02-15 18:14:12,556:INFO:              m2cgen: 0.10.0
2023-02-15 18:14:12,556:INFO:           evidently: 0.2.4
2023-02-15 18:14:12,556:INFO:               fugue: 0.8.1.dev4
2023-02-15 18:14:12,556:INFO:           streamlit: Not installed
2023-02-15 18:14:12,556:INFO:             prophet: Not installed
2023-02-15 18:14:12,556:INFO:None
2023-02-15 18:14:12,556:INFO:Set up GPU usage.
2023-02-15 18:14:12,556:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:12,556:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc9
2023-02-15 18:14:12,556:INFO:Set up data.
2023-02-15 18:14:12,820:INFO:Set up train/test split.
2023-02-15 18:14:12,948:INFO:Set up index.
2023-02-15 18:14:12,979:INFO:Set up folding strategy.
2023-02-15 18:14:12,980:INFO:Assigning column types.
2023-02-15 18:14:13,052:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 18:14:13,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:13,053:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 18:14:13,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:13,055:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:14:13,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:13,058:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:14:13,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:13,151:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:14:13,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:13,177:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:14:13,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:13,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:13,177:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:15,685:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:15,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:15,730:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 18:14:15,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:15,733:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:14:15,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:15,736:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:14:15,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:15,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:14:15,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:15,854:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:14:15,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:15,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:15,855:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:15,943:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:15,973:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 18:14:15,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:15,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:15,976:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:14:15,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:15,979:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:14:15,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,070:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,097:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:16,176:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:16,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,210:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,213:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,308:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,308:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,336:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:16,423:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:16,454:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 18:14:16,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,460:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,555:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,555:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,583:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:16,673:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:16,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,708:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,710:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,803:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:14:16,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,830:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:16,912:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:16,943:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 18:14:16,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:16,950:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,048:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:14:17,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,078:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:14:17,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,079:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:17,160:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:17,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,301:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:14:17,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:14:17,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,329:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:17,413:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:17,449:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 18:14:17,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,551:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:14:17,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,581:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,581:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:17,674:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:17,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,708:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:14:17,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,849:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:17,940:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:17,971:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 18:14:17,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:17,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,070:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,097:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:18,191:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:18,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,363:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,363:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:18,363:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:18,464:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:18,497:INFO:Preparing preprocessing pipeline...
2023-02-15 18:14:18,510:INFO:Set up column name cleaning.
2023-02-15 18:14:18,510:INFO:Set up simple imputation.
2023-02-15 18:14:18,510:INFO:Set up feature normalization.
2023-02-15 18:14:18,848:INFO:Finished creating preprocessing pipeline.
2023-02-15 18:14:18,854:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 18:14:18,854:INFO:Creating final display dataframe.
2023-02-15 18:14:20,001:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28569, 780)
4        Transformed data shape           (28569, 775)
5   Transformed train set shape           (19998, 775)
6    Transformed test set shape            (8571, 775)
7               Ignore features                      5
8              Numeric features                    774
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   3594
2023-02-15 18:14:20,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,012:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,134:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:20,225:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:20,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,391:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,391:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 18:14:20,391:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:14:20,480:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:14:20,513:INFO:setup() successfully completed in 8.3s...............
2023-02-15 18:14:20,513:INFO:Initializing compare_models()
2023-02-15 18:14:20,513:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 18:14:20,513:INFO:Checking exceptions
2023-02-15 18:14:20,545:INFO:Preparing display monitor
2023-02-15 18:14:20,559:INFO:Initializing Linear Regression
2023-02-15 18:14:20,559:INFO:Total runtime is 1.8715858459472655e-06 minutes
2023-02-15 18:14:20,561:INFO:SubProcess create_model() called ==================================
2023-02-15 18:14:20,561:INFO:Initializing create_model()
2023-02-15 18:14:20,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:14:20,561:INFO:Checking exceptions
2023-02-15 18:14:20,561:INFO:Importing libraries
2023-02-15 18:14:20,561:INFO:Copying training dataset
2023-02-15 18:14:20,650:INFO:Defining folds
2023-02-15 18:14:20,651:INFO:Declaring metric variables
2023-02-15 18:14:20,653:INFO:Importing untrained model
2023-02-15 18:14:20,655:INFO:Linear Regression Imported successfully
2023-02-15 18:14:20,658:INFO:Starting cross validation
2023-02-15 18:14:20,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:14:29,360:INFO:Calculating mean and std
2023-02-15 18:14:29,361:INFO:Creating metrics dataframe
2023-02-15 18:14:29,363:INFO:Uploading results into container
2023-02-15 18:14:29,363:INFO:Uploading model into container now
2023-02-15 18:14:29,364:INFO:_master_model_container: 1
2023-02-15 18:14:29,364:INFO:_display_container: 2
2023-02-15 18:14:29,364:INFO:LinearRegression(n_jobs=-1)
2023-02-15 18:14:29,364:INFO:create_model() successfully completed......................................
2023-02-15 18:14:29,498:INFO:SubProcess create_model() end ==================================
2023-02-15 18:14:29,498:INFO:Creating metrics dataframe
2023-02-15 18:14:29,504:INFO:Initializing Lasso Regression
2023-02-15 18:14:29,504:INFO:Total runtime is 0.14908169905344645 minutes
2023-02-15 18:14:29,506:INFO:SubProcess create_model() called ==================================
2023-02-15 18:14:29,506:INFO:Initializing create_model()
2023-02-15 18:14:29,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:14:29,506:INFO:Checking exceptions
2023-02-15 18:14:29,506:INFO:Importing libraries
2023-02-15 18:14:29,506:INFO:Copying training dataset
2023-02-15 18:14:29,589:INFO:Defining folds
2023-02-15 18:14:29,590:INFO:Declaring metric variables
2023-02-15 18:14:29,592:INFO:Importing untrained model
2023-02-15 18:14:29,593:INFO:Lasso Regression Imported successfully
2023-02-15 18:14:29,597:INFO:Starting cross validation
2023-02-15 18:14:29,599:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:14:34,309:INFO:Calculating mean and std
2023-02-15 18:14:34,310:INFO:Creating metrics dataframe
2023-02-15 18:14:34,312:INFO:Uploading results into container
2023-02-15 18:14:34,313:INFO:Uploading model into container now
2023-02-15 18:14:34,313:INFO:_master_model_container: 2
2023-02-15 18:14:34,313:INFO:_display_container: 2
2023-02-15 18:14:34,313:INFO:Lasso(random_state=11)
2023-02-15 18:14:34,313:INFO:create_model() successfully completed......................................
2023-02-15 18:14:34,438:INFO:SubProcess create_model() end ==================================
2023-02-15 18:14:34,438:INFO:Creating metrics dataframe
2023-02-15 18:14:34,444:INFO:Initializing Ridge Regression
2023-02-15 18:14:34,444:INFO:Total runtime is 0.23141649564107258 minutes
2023-02-15 18:14:34,446:INFO:SubProcess create_model() called ==================================
2023-02-15 18:14:34,446:INFO:Initializing create_model()
2023-02-15 18:14:34,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:14:34,446:INFO:Checking exceptions
2023-02-15 18:14:34,446:INFO:Importing libraries
2023-02-15 18:14:34,446:INFO:Copying training dataset
2023-02-15 18:14:34,532:INFO:Defining folds
2023-02-15 18:14:34,532:INFO:Declaring metric variables
2023-02-15 18:14:34,534:INFO:Importing untrained model
2023-02-15 18:14:34,536:INFO:Ridge Regression Imported successfully
2023-02-15 18:14:34,539:INFO:Starting cross validation
2023-02-15 18:14:34,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:14:34,916:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.72431e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 18:14:35,417:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.66177e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 18:14:35,919:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.68476e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 18:14:36,414:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.71488e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 18:14:36,909:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.67865e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 18:14:37,401:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.68254e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 18:14:37,890:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.64299e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 18:14:38,359:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.68977e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 18:14:38,833:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.71862e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 18:14:39,315:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.67823e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 18:14:39,417:INFO:Calculating mean and std
2023-02-15 18:14:39,418:INFO:Creating metrics dataframe
2023-02-15 18:14:39,420:INFO:Uploading results into container
2023-02-15 18:14:39,421:INFO:Uploading model into container now
2023-02-15 18:14:39,421:INFO:_master_model_container: 3
2023-02-15 18:14:39,421:INFO:_display_container: 2
2023-02-15 18:14:39,421:INFO:Ridge(random_state=11)
2023-02-15 18:14:39,421:INFO:create_model() successfully completed......................................
2023-02-15 18:14:39,541:INFO:SubProcess create_model() end ==================================
2023-02-15 18:14:39,541:INFO:Creating metrics dataframe
2023-02-15 18:14:39,547:INFO:Initializing Elastic Net
2023-02-15 18:14:39,547:INFO:Total runtime is 0.31647046009699503 minutes
2023-02-15 18:14:39,549:INFO:SubProcess create_model() called ==================================
2023-02-15 18:14:39,549:INFO:Initializing create_model()
2023-02-15 18:14:39,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:14:39,549:INFO:Checking exceptions
2023-02-15 18:14:39,549:INFO:Importing libraries
2023-02-15 18:14:39,549:INFO:Copying training dataset
2023-02-15 18:14:39,633:INFO:Defining folds
2023-02-15 18:14:39,633:INFO:Declaring metric variables
2023-02-15 18:14:39,636:INFO:Importing untrained model
2023-02-15 18:14:39,637:INFO:Elastic Net Imported successfully
2023-02-15 18:14:39,640:INFO:Starting cross validation
2023-02-15 18:14:39,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:14:44,222:INFO:Calculating mean and std
2023-02-15 18:14:44,223:INFO:Creating metrics dataframe
2023-02-15 18:14:44,225:INFO:Uploading results into container
2023-02-15 18:14:44,225:INFO:Uploading model into container now
2023-02-15 18:14:44,225:INFO:_master_model_container: 4
2023-02-15 18:14:44,225:INFO:_display_container: 2
2023-02-15 18:14:44,226:INFO:ElasticNet(random_state=11)
2023-02-15 18:14:44,226:INFO:create_model() successfully completed......................................
2023-02-15 18:14:44,343:INFO:SubProcess create_model() end ==================================
2023-02-15 18:14:44,343:INFO:Creating metrics dataframe
2023-02-15 18:14:44,349:INFO:Initializing Least Angle Regression
2023-02-15 18:14:44,349:INFO:Total runtime is 0.39649154742558795 minutes
2023-02-15 18:14:44,350:INFO:SubProcess create_model() called ==================================
2023-02-15 18:14:44,350:INFO:Initializing create_model()
2023-02-15 18:14:44,350:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:14:44,350:INFO:Checking exceptions
2023-02-15 18:14:44,350:INFO:Importing libraries
2023-02-15 18:14:44,350:INFO:Copying training dataset
2023-02-15 18:14:44,432:INFO:Defining folds
2023-02-15 18:14:44,432:INFO:Declaring metric variables
2023-02-15 18:14:44,434:INFO:Importing untrained model
2023-02-15 18:14:44,435:INFO:Least Angle Regression Imported successfully
2023-02-15 18:14:44,438:INFO:Starting cross validation
2023-02-15 18:14:44,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:14:44,778:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.365e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:44,779:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 18:14:44,779:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.345e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:45,553:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=1.315e-03, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:45,579:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=2.013e-03, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:46,255:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.277e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:46,256:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 18:14:46,257:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.066e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:46,300:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=4.772e-03, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:46,300:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=4.771e-03, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:46,400:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:14:46,511:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:14:46,670:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 18:14:47,894:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.223e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:47,895:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 18:14:47,895:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.851e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:48,013:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:713: RuntimeWarning: invalid value encountered in multiply
  least_squares *= AA

2023-02-15 18:14:48,014:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:736: RuntimeWarning: divide by zero encountered in double_scalars
  gamma_ = min(g1, g2, C / AA)

2023-02-15 18:14:48,014:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-02-15 18:14:48,273:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 18:14:48,273:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 18:14:48,273:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 18:14:49,438:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.570e-03, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:49,541:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:14:49,587:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 18:14:50,783:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.635e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:50,806:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.470e-03, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:50,809:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=2.868e-03, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:50,825:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=3.370e-03, with an active set of 138 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:14:51,029:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:14:51,095:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:14:51,234:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 18:14:52,130:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 18:14:52,130:INFO:Calculating mean and std
2023-02-15 18:14:52,131:INFO:Creating metrics dataframe
2023-02-15 18:14:52,133:INFO:Uploading results into container
2023-02-15 18:14:52,134:INFO:Uploading model into container now
2023-02-15 18:14:52,134:INFO:_master_model_container: 5
2023-02-15 18:14:52,134:INFO:_display_container: 2
2023-02-15 18:14:52,134:INFO:Lars(random_state=11)
2023-02-15 18:14:52,134:INFO:create_model() successfully completed......................................
2023-02-15 18:14:52,256:INFO:SubProcess create_model() end ==================================
2023-02-15 18:14:52,256:INFO:Creating metrics dataframe
2023-02-15 18:14:52,264:INFO:Initializing Lasso Least Angle Regression
2023-02-15 18:14:52,264:INFO:Total runtime is 0.5284210602442423 minutes
2023-02-15 18:14:52,267:INFO:SubProcess create_model() called ==================================
2023-02-15 18:14:52,267:INFO:Initializing create_model()
2023-02-15 18:14:52,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:14:52,267:INFO:Checking exceptions
2023-02-15 18:14:52,267:INFO:Importing libraries
2023-02-15 18:14:52,267:INFO:Copying training dataset
2023-02-15 18:14:52,352:INFO:Defining folds
2023-02-15 18:14:52,353:INFO:Declaring metric variables
2023-02-15 18:14:52,355:INFO:Importing untrained model
2023-02-15 18:14:52,356:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 18:14:52,359:INFO:Starting cross validation
2023-02-15 18:14:52,362:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:14:57,081:INFO:Calculating mean and std
2023-02-15 18:14:57,082:INFO:Creating metrics dataframe
2023-02-15 18:14:57,084:INFO:Uploading results into container
2023-02-15 18:14:57,085:INFO:Uploading model into container now
2023-02-15 18:14:57,085:INFO:_master_model_container: 6
2023-02-15 18:14:57,085:INFO:_display_container: 2
2023-02-15 18:14:57,085:INFO:LassoLars(random_state=11)
2023-02-15 18:14:57,085:INFO:create_model() successfully completed......................................
2023-02-15 18:14:57,205:INFO:SubProcess create_model() end ==================================
2023-02-15 18:14:57,205:INFO:Creating metrics dataframe
2023-02-15 18:14:57,211:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 18:14:57,211:INFO:Total runtime is 0.6108693440755207 minutes
2023-02-15 18:14:57,213:INFO:SubProcess create_model() called ==================================
2023-02-15 18:14:57,213:INFO:Initializing create_model()
2023-02-15 18:14:57,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:14:57,213:INFO:Checking exceptions
2023-02-15 18:14:57,213:INFO:Importing libraries
2023-02-15 18:14:57,213:INFO:Copying training dataset
2023-02-15 18:14:57,297:INFO:Defining folds
2023-02-15 18:14:57,297:INFO:Declaring metric variables
2023-02-15 18:14:57,299:INFO:Importing untrained model
2023-02-15 18:14:57,301:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 18:14:57,304:INFO:Starting cross validation
2023-02-15 18:14:57,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:15:02,030:INFO:Calculating mean and std
2023-02-15 18:15:02,031:INFO:Creating metrics dataframe
2023-02-15 18:15:02,033:INFO:Uploading results into container
2023-02-15 18:15:02,034:INFO:Uploading model into container now
2023-02-15 18:15:02,034:INFO:_master_model_container: 7
2023-02-15 18:15:02,034:INFO:_display_container: 2
2023-02-15 18:15:02,034:INFO:OrthogonalMatchingPursuit()
2023-02-15 18:15:02,034:INFO:create_model() successfully completed......................................
2023-02-15 18:15:02,154:INFO:SubProcess create_model() end ==================================
2023-02-15 18:15:02,154:INFO:Creating metrics dataframe
2023-02-15 18:15:02,160:INFO:Initializing Bayesian Ridge
2023-02-15 18:15:02,160:INFO:Total runtime is 0.6933508396148681 minutes
2023-02-15 18:15:02,162:INFO:SubProcess create_model() called ==================================
2023-02-15 18:15:02,162:INFO:Initializing create_model()
2023-02-15 18:15:02,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:15:02,162:INFO:Checking exceptions
2023-02-15 18:15:02,162:INFO:Importing libraries
2023-02-15 18:15:02,162:INFO:Copying training dataset
2023-02-15 18:15:02,247:INFO:Defining folds
2023-02-15 18:15:02,247:INFO:Declaring metric variables
2023-02-15 18:15:02,249:INFO:Importing untrained model
2023-02-15 18:15:02,251:INFO:Bayesian Ridge Imported successfully
2023-02-15 18:15:02,254:INFO:Starting cross validation
2023-02-15 18:15:02,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:15:13,451:INFO:Calculating mean and std
2023-02-15 18:15:13,451:INFO:Creating metrics dataframe
2023-02-15 18:15:13,454:INFO:Uploading results into container
2023-02-15 18:15:13,454:INFO:Uploading model into container now
2023-02-15 18:15:13,455:INFO:_master_model_container: 8
2023-02-15 18:15:13,455:INFO:_display_container: 2
2023-02-15 18:15:13,455:INFO:BayesianRidge()
2023-02-15 18:15:13,455:INFO:create_model() successfully completed......................................
2023-02-15 18:15:13,576:INFO:SubProcess create_model() end ==================================
2023-02-15 18:15:13,576:INFO:Creating metrics dataframe
2023-02-15 18:15:13,582:INFO:Initializing Passive Aggressive Regressor
2023-02-15 18:15:13,582:INFO:Total runtime is 0.8837221304575602 minutes
2023-02-15 18:15:13,584:INFO:SubProcess create_model() called ==================================
2023-02-15 18:15:13,584:INFO:Initializing create_model()
2023-02-15 18:15:13,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:15:13,584:INFO:Checking exceptions
2023-02-15 18:15:13,584:INFO:Importing libraries
2023-02-15 18:15:13,584:INFO:Copying training dataset
2023-02-15 18:15:13,667:INFO:Defining folds
2023-02-15 18:15:13,668:INFO:Declaring metric variables
2023-02-15 18:15:13,670:INFO:Importing untrained model
2023-02-15 18:15:13,671:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 18:15:13,675:INFO:Starting cross validation
2023-02-15 18:15:13,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:15:20,090:INFO:Calculating mean and std
2023-02-15 18:15:20,090:INFO:Creating metrics dataframe
2023-02-15 18:15:20,093:INFO:Uploading results into container
2023-02-15 18:15:20,093:INFO:Uploading model into container now
2023-02-15 18:15:20,093:INFO:_master_model_container: 9
2023-02-15 18:15:20,093:INFO:_display_container: 2
2023-02-15 18:15:20,093:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 18:15:20,093:INFO:create_model() successfully completed......................................
2023-02-15 18:15:20,213:INFO:SubProcess create_model() end ==================================
2023-02-15 18:15:20,213:INFO:Creating metrics dataframe
2023-02-15 18:15:20,220:INFO:Initializing Huber Regressor
2023-02-15 18:15:20,220:INFO:Total runtime is 0.9943440238634745 minutes
2023-02-15 18:15:20,221:INFO:SubProcess create_model() called ==================================
2023-02-15 18:15:20,222:INFO:Initializing create_model()
2023-02-15 18:15:20,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:15:20,222:INFO:Checking exceptions
2023-02-15 18:15:20,222:INFO:Importing libraries
2023-02-15 18:15:20,222:INFO:Copying training dataset
2023-02-15 18:15:20,305:INFO:Defining folds
2023-02-15 18:15:20,305:INFO:Declaring metric variables
2023-02-15 18:15:20,308:INFO:Importing untrained model
2023-02-15 18:15:20,309:INFO:Huber Regressor Imported successfully
2023-02-15 18:15:20,313:INFO:Starting cross validation
2023-02-15 18:15:20,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:15:30,583:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 18:15:41,332:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 18:15:52,027:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 18:16:03,087:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 18:16:14,143:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 18:16:25,472:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 18:16:36,061:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 18:16:46,566:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 18:16:58,129:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 18:17:09,940:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 18:17:10,179:INFO:Calculating mean and std
2023-02-15 18:17:10,180:INFO:Creating metrics dataframe
2023-02-15 18:17:10,182:INFO:Uploading results into container
2023-02-15 18:17:10,182:INFO:Uploading model into container now
2023-02-15 18:17:10,183:INFO:_master_model_container: 10
2023-02-15 18:17:10,183:INFO:_display_container: 2
2023-02-15 18:17:10,183:INFO:HuberRegressor()
2023-02-15 18:17:10,183:INFO:create_model() successfully completed......................................
2023-02-15 18:17:10,306:INFO:SubProcess create_model() end ==================================
2023-02-15 18:17:10,306:INFO:Creating metrics dataframe
2023-02-15 18:17:10,313:INFO:Initializing K Neighbors Regressor
2023-02-15 18:17:10,313:INFO:Total runtime is 2.8292376438776654 minutes
2023-02-15 18:17:10,315:INFO:SubProcess create_model() called ==================================
2023-02-15 18:17:10,315:INFO:Initializing create_model()
2023-02-15 18:17:10,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:17:10,315:INFO:Checking exceptions
2023-02-15 18:17:10,315:INFO:Importing libraries
2023-02-15 18:17:10,315:INFO:Copying training dataset
2023-02-15 18:17:10,400:INFO:Defining folds
2023-02-15 18:17:10,400:INFO:Declaring metric variables
2023-02-15 18:17:10,402:INFO:Importing untrained model
2023-02-15 18:17:10,404:INFO:K Neighbors Regressor Imported successfully
2023-02-15 18:17:10,407:INFO:Starting cross validation
2023-02-15 18:17:10,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:17:18,363:INFO:Calculating mean and std
2023-02-15 18:17:18,364:INFO:Creating metrics dataframe
2023-02-15 18:17:18,366:INFO:Uploading results into container
2023-02-15 18:17:18,366:INFO:Uploading model into container now
2023-02-15 18:17:18,366:INFO:_master_model_container: 11
2023-02-15 18:17:18,366:INFO:_display_container: 2
2023-02-15 18:17:18,366:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-15 18:17:18,366:INFO:create_model() successfully completed......................................
2023-02-15 18:17:18,487:INFO:SubProcess create_model() end ==================================
2023-02-15 18:17:18,488:INFO:Creating metrics dataframe
2023-02-15 18:17:18,496:INFO:Initializing Decision Tree Regressor
2023-02-15 18:17:18,496:INFO:Total runtime is 2.9656233191490173 minutes
2023-02-15 18:17:18,498:INFO:SubProcess create_model() called ==================================
2023-02-15 18:17:18,498:INFO:Initializing create_model()
2023-02-15 18:17:18,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:17:18,499:INFO:Checking exceptions
2023-02-15 18:17:18,499:INFO:Importing libraries
2023-02-15 18:17:18,499:INFO:Copying training dataset
2023-02-15 18:17:18,587:INFO:Defining folds
2023-02-15 18:17:18,587:INFO:Declaring metric variables
2023-02-15 18:17:18,590:INFO:Importing untrained model
2023-02-15 18:17:18,591:INFO:Decision Tree Regressor Imported successfully
2023-02-15 18:17:18,594:INFO:Starting cross validation
2023-02-15 18:17:18,597:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:21:00,759:INFO:Calculating mean and std
2023-02-15 18:21:00,760:INFO:Creating metrics dataframe
2023-02-15 18:21:00,762:INFO:Uploading results into container
2023-02-15 18:21:00,762:INFO:Uploading model into container now
2023-02-15 18:21:00,762:INFO:_master_model_container: 12
2023-02-15 18:21:00,762:INFO:_display_container: 2
2023-02-15 18:21:00,762:INFO:DecisionTreeRegressor(random_state=11)
2023-02-15 18:21:00,763:INFO:create_model() successfully completed......................................
2023-02-15 18:21:00,862:INFO:SubProcess create_model() end ==================================
2023-02-15 18:21:00,862:INFO:Creating metrics dataframe
2023-02-15 18:21:00,869:INFO:Initializing Random Forest Regressor
2023-02-15 18:21:00,869:INFO:Total runtime is 6.671825516223907 minutes
2023-02-15 18:21:00,870:INFO:SubProcess create_model() called ==================================
2023-02-15 18:21:00,870:INFO:Initializing create_model()
2023-02-15 18:21:00,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f15165c4910>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f14518be7c0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:21:00,870:INFO:Checking exceptions
2023-02-15 18:21:00,870:INFO:Importing libraries
2023-02-15 18:21:00,870:INFO:Copying training dataset
2023-02-15 18:21:00,951:INFO:Defining folds
2023-02-15 18:21:00,951:INFO:Declaring metric variables
2023-02-15 18:21:00,953:INFO:Importing untrained model
2023-02-15 18:21:00,955:INFO:Random Forest Regressor Imported successfully
2023-02-15 18:21:00,958:INFO:Starting cross validation
2023-02-15 18:21:00,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:34:25,370:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:26,252:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:26,252:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:26,252:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:26,402:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 18:34:26,582:INFO:PyCaret RegressionExperiment
2023-02-15 18:34:26,582:INFO:Logging name: reg-default-name
2023-02-15 18:34:26,582:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 18:34:26,582:INFO:version 3.0.0.rc9
2023-02-15 18:34:26,582:INFO:Initializing setup()
2023-02-15 18:34:26,582:INFO:self.USI: 7fa0
2023-02-15 18:34:26,582:INFO:self._variable_keys: {'USI', 'target_param', 'X_train', 'memory', '_ml_usecase', 'html_param', 'seed', 'fold_shuffle_param', 'exp_name_log', 'exp_id', 'gpu_param', 'y', 'log_plots_param', 'X_test', 'data', 'idx', 'y_train', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'transform_target_param', 'n_jobs_param', '_available_plots', 'logging_param', 'fold_groups_param', 'pipeline', 'X'}
2023-02-15 18:34:26,582:INFO:Checking environment
2023-02-15 18:34:26,582:INFO:python_version: 3.8.16
2023-02-15 18:34:26,582:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-15 18:34:26,582:INFO:machine: x86_64
2023-02-15 18:34:26,582:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 18:34:26,582:INFO:Memory: svmem(total=134979592192, available=122224316416, percent=9.4, used=10759172096, free=48080801792, active=4818300928, inactive=78450212864, buffers=1215528960, cached=74924089344, shared=724094976, slab=2890604544)
2023-02-15 18:34:26,583:INFO:Physical Core: 16
2023-02-15 18:34:26,583:INFO:Logical Core: 32
2023-02-15 18:34:26,583:INFO:Checking libraries
2023-02-15 18:34:26,583:INFO:System:
2023-02-15 18:34:26,583:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-15 18:34:26,583:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 18:34:26,583:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 18:34:26,583:INFO:PyCaret required dependencies:
2023-02-15 18:34:26,583:INFO:                 pip: 23.0
2023-02-15 18:34:26,583:INFO:          setuptools: 60.10.0
2023-02-15 18:34:26,583:INFO:             pycaret: 3.0.0rc9
2023-02-15 18:34:26,583:INFO:             IPython: 8.10.0
2023-02-15 18:34:26,583:INFO:          ipywidgets: 7.7.3
2023-02-15 18:34:26,583:INFO:                tqdm: 4.64.1
2023-02-15 18:34:26,583:INFO:               numpy: 1.23.5
2023-02-15 18:34:26,583:INFO:              pandas: 1.5.3
2023-02-15 18:34:26,583:INFO:              jinja2: 3.1.2
2023-02-15 18:34:26,583:INFO:               scipy: 1.9.1
2023-02-15 18:34:26,583:INFO:              joblib: 1.2.0
2023-02-15 18:34:26,583:INFO:             sklearn: 1.2.1
2023-02-15 18:34:26,583:INFO:                pyod: 1.0.7
2023-02-15 18:34:26,583:INFO:            imblearn: 0.10.1
2023-02-15 18:34:26,584:INFO:   category_encoders: 2.6.0
2023-02-15 18:34:26,584:INFO:            lightgbm: 3.3.5.99
2023-02-15 18:34:26,584:INFO:               numba: 0.56.4
2023-02-15 18:34:26,584:INFO:            requests: 2.28.2
2023-02-15 18:34:26,584:INFO:          matplotlib: 3.6.3
2023-02-15 18:34:26,584:INFO:          scikitplot: 0.3.7
2023-02-15 18:34:26,584:INFO:         yellowbrick: 1.5
2023-02-15 18:34:26,584:INFO:              plotly: 5.13.0
2023-02-15 18:34:26,584:INFO:             kaleido: 0.2.1
2023-02-15 18:34:26,584:INFO:         statsmodels: 0.13.5
2023-02-15 18:34:26,584:INFO:              sktime: 0.16.1
2023-02-15 18:34:26,584:INFO:               tbats: 1.1.2
2023-02-15 18:34:26,584:INFO:            pmdarima: 2.0.2
2023-02-15 18:34:26,584:INFO:              psutil: 5.9.4
2023-02-15 18:34:26,584:INFO:PyCaret optional dependencies:
2023-02-15 18:34:26,810:INFO:                shap: 0.41.0
2023-02-15 18:34:26,811:INFO:           interpret: 0.3.0
2023-02-15 18:34:26,811:INFO:                umap: 0.5.3
2023-02-15 18:34:26,811:INFO:    pandas_profiling: 4.0.0
2023-02-15 18:34:26,811:INFO:  explainerdashboard: 0.4.2
2023-02-15 18:34:26,811:INFO:             autoviz: 0.1.58
2023-02-15 18:34:26,811:INFO:           fairlearn: 0.7.0
2023-02-15 18:34:26,811:INFO:             xgboost: 1.7.3
2023-02-15 18:34:26,811:INFO:            catboost: 1.1.1
2023-02-15 18:34:26,811:INFO:              kmodes: 0.12.2
2023-02-15 18:34:26,811:INFO:             mlxtend: 0.21.0
2023-02-15 18:34:26,811:INFO:       statsforecast: 1.4.0
2023-02-15 18:34:26,811:INFO:        tune_sklearn: 0.4.5
2023-02-15 18:34:26,811:INFO:                 ray: 2.2.0
2023-02-15 18:34:26,811:INFO:            hyperopt: 0.2.7
2023-02-15 18:34:26,811:INFO:              optuna: 3.1.0
2023-02-15 18:34:26,811:INFO:               skopt: 0.9.0
2023-02-15 18:34:26,811:INFO:              mlflow: 1.30.0
2023-02-15 18:34:26,811:INFO:              gradio: 3.18.0
2023-02-15 18:34:26,811:INFO:             fastapi: 0.92.0
2023-02-15 18:34:26,811:INFO:             uvicorn: 0.20.0
2023-02-15 18:34:26,811:INFO:              m2cgen: 0.10.0
2023-02-15 18:34:26,811:INFO:           evidently: 0.2.4
2023-02-15 18:34:26,811:INFO:               fugue: 0.8.1.dev4
2023-02-15 18:34:26,811:INFO:           streamlit: Not installed
2023-02-15 18:34:26,811:INFO:             prophet: Not installed
2023-02-15 18:34:26,811:INFO:None
2023-02-15 18:34:26,811:INFO:Set up GPU usage.
2023-02-15 18:34:26,811:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:26,811:INFO:cuml==23.2.0
2023-02-15 18:34:26,811:ERROR:Couldn't set cuML global output type
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/tabular_experiment.py", line 351, in _initialize_setup
    import cuml.common.memory_utils
ModuleNotFoundError: No module named 'cuml.common.memory_utils'
2023-02-15 18:34:26,811:INFO:Set up data.
2023-02-15 18:34:27,084:INFO:Set up train/test split.
2023-02-15 18:34:27,208:INFO:Set up index.
2023-02-15 18:34:27,240:INFO:Set up folding strategy.
2023-02-15 18:34:27,240:INFO:Assigning column types.
2023-02-15 18:34:27,314:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 18:34:27,314:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,314:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:27,314:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,314:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,314:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:27,317:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,317:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,317:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:27,320:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,320:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,320:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:27,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,404:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,404:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:27,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,431:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,431:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:27,431:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,431:INFO:Imported cuml.ensemble
2023-02-15 18:34:27,431:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:27,711:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:27,755:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,755:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:27,755:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,755:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,755:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:27,758:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,758:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,758:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:27,761:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,761:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,761:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:27,843:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,844:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,844:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:27,870:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,870:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,870:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:27,870:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,870:INFO:Imported cuml.ensemble
2023-02-15 18:34:27,870:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:27,937:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:27,963:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 18:34:27,964:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,964:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:27,964:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,964:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:27,966:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,966:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,966:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:27,969:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:34:27,969:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:27,969:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:28,051:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,052:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,052:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:28,078:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,078:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,078:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:28,078:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,078:INFO:Imported cuml.ensemble
2023-02-15 18:34:28,078:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:28,143:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:28,171:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,171:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:28,171:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,171:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:28,174:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,174:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,174:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:28,176:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,176:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,176:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:28,258:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,258:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,258:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:28,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,285:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,285:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:28,285:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,285:INFO:Imported cuml.ensemble
2023-02-15 18:34:28,285:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:28,350:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:28,376:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 18:34:28,376:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,377:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:28,377:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,377:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:28,379:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,379:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:28,382:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,382:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,382:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:28,464:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,465:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,465:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:28,491:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,491:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,491:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:28,491:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,491:INFO:Imported cuml.ensemble
2023-02-15 18:34:28,491:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:28,554:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:28,581:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,581:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:28,581:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,581:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:28,584:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,584:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:28,586:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,586:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,586:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:28,669:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,669:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,669:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:28,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,696:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,696:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:28,696:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,696:INFO:Imported cuml.ensemble
2023-02-15 18:34:28,696:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:28,762:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:28,788:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 18:34:28,788:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,788:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:28,788:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,788:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:28,791:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,791:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:28,794:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,794:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:28,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,876:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,876:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:28,903:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:34:28,903:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,903:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:28,903:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,903:INFO:Imported cuml.ensemble
2023-02-15 18:34:28,903:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:28,970:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:28,998:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,998:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:28,998:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:28,998:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:29,001:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,001:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:29,005:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,005:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:29,088:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:34:29,088:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,088:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:29,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:34:29,114:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,114:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:29,114:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,115:INFO:Imported cuml.ensemble
2023-02-15 18:34:29,115:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:29,181:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:29,208:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 18:34:29,208:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,208:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:29,208:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,208:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:29,211:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,211:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:29,214:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,214:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:29,296:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:34:29,296:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,296:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:29,322:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,322:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:29,322:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,322:INFO:Imported cuml.ensemble
2023-02-15 18:34:29,322:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:29,387:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:29,415:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,415:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:29,415:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,415:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:29,418:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,418:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:29,421:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,421:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:29,506:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:34:29,507:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,507:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:29,532:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,532:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:29,533:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,533:INFO:Imported cuml.ensemble
2023-02-15 18:34:29,533:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:29,599:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:29,626:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 18:34:29,626:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,626:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:29,626:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,626:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:29,629:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,629:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:29,632:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,632:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:29,714:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,714:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:29,740:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,740:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:29,740:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,740:INFO:Imported cuml.ensemble
2023-02-15 18:34:29,740:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:29,809:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:29,836:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,836:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:29,836:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,836:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:29,839:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,839:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:29,841:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,841:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:29,923:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,924:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:29,950:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,950:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:29,950:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:29,950:INFO:Imported cuml.ensemble
2023-02-15 18:34:29,950:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:30,018:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:30,046:INFO:Preparing preprocessing pipeline...
2023-02-15 18:34:30,055:INFO:Set up column name cleaning.
2023-02-15 18:34:30,055:INFO:Set up simple imputation.
2023-02-15 18:34:30,055:INFO:Set up feature normalization.
2023-02-15 18:34:30,345:INFO:Finished creating preprocessing pipeline.
2023-02-15 18:34:30,351:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 18:34:30,352:INFO:Creating final display dataframe.
2023-02-15 18:34:30,877:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28569, 780)
4        Transformed data shape           (28569, 775)
5   Transformed train set shape           (19998, 775)
6    Transformed test set shape            (8571, 775)
7               Ignore features                      5
8              Numeric features                    774
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   7fa0
2023-02-15 18:34:30,882:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:30,882:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:30,882:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:30,882:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:30,886:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:30,886:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:30,890:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:30,890:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:30,976:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:30,976:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:31,002:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:31,002:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:31,002:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:31,002:INFO:Imported cuml.ensemble
2023-02-15 18:34:31,002:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:31,070:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:31,105:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:31,105:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:34:31,105:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:31,105:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:34:31,108:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:31,108:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:34:31,110:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:31,110:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:34:31,195:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:31,195:INFO:Imported cuml.svm.SVR
2023-02-15 18:34:31,221:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:31,221:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:34:31,221:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:34:31,221:INFO:Imported cuml.ensemble
2023-02-15 18:34:31,222:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:34:31,283:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:34:31,310:INFO:setup() successfully completed in 4.73s...............
2023-02-15 18:34:31,311:INFO:Initializing compare_models()
2023-02-15 18:34:31,311:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 18:34:31,311:INFO:Checking exceptions
2023-02-15 18:34:31,336:INFO:Preparing display monitor
2023-02-15 18:34:31,350:INFO:Initializing Linear Regression
2023-02-15 18:34:31,350:INFO:Total runtime is 1.899401346842448e-06 minutes
2023-02-15 18:34:31,352:INFO:SubProcess create_model() called ==================================
2023-02-15 18:34:31,352:INFO:Initializing create_model()
2023-02-15 18:34:31,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:34:31,352:INFO:Checking exceptions
2023-02-15 18:34:31,352:INFO:Importing libraries
2023-02-15 18:34:31,352:INFO:Copying training dataset
2023-02-15 18:34:31,421:INFO:Defining folds
2023-02-15 18:34:31,421:INFO:Declaring metric variables
2023-02-15 18:34:31,424:INFO:Importing untrained model
2023-02-15 18:34:31,426:INFO:Linear Regression Imported successfully
2023-02-15 18:34:31,429:INFO:Starting cross validation
2023-02-15 18:34:31,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:34:37,089:INFO:Calculating mean and std
2023-02-15 18:34:37,090:INFO:Creating metrics dataframe
2023-02-15 18:34:37,092:INFO:Uploading results into container
2023-02-15 18:34:37,092:INFO:Uploading model into container now
2023-02-15 18:34:37,092:INFO:_master_model_container: 1
2023-02-15 18:34:37,092:INFO:_display_container: 2
2023-02-15 18:34:37,092:INFO:LinearRegression()
2023-02-15 18:34:37,092:INFO:create_model() successfully completed......................................
2023-02-15 18:34:37,240:INFO:SubProcess create_model() end ==================================
2023-02-15 18:34:37,240:INFO:Creating metrics dataframe
2023-02-15 18:34:37,245:INFO:Initializing Lasso Regression
2023-02-15 18:34:37,245:INFO:Total runtime is 0.09824811617533366 minutes
2023-02-15 18:34:37,247:INFO:SubProcess create_model() called ==================================
2023-02-15 18:34:37,247:INFO:Initializing create_model()
2023-02-15 18:34:37,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:34:37,247:INFO:Checking exceptions
2023-02-15 18:34:37,247:INFO:Importing libraries
2023-02-15 18:34:37,247:INFO:Copying training dataset
2023-02-15 18:34:37,315:INFO:Defining folds
2023-02-15 18:34:37,315:INFO:Declaring metric variables
2023-02-15 18:34:37,317:INFO:Importing untrained model
2023-02-15 18:34:37,319:INFO:Lasso Regression Imported successfully
2023-02-15 18:34:37,322:INFO:Starting cross validation
2023-02-15 18:34:37,324:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:34:41,141:INFO:Calculating mean and std
2023-02-15 18:34:41,141:INFO:Creating metrics dataframe
2023-02-15 18:34:41,143:INFO:Uploading results into container
2023-02-15 18:34:41,143:INFO:Uploading model into container now
2023-02-15 18:34:41,144:INFO:_master_model_container: 2
2023-02-15 18:34:41,144:INFO:_display_container: 2
2023-02-15 18:34:41,144:INFO:Lasso()
2023-02-15 18:34:41,144:INFO:create_model() successfully completed......................................
2023-02-15 18:34:41,277:INFO:SubProcess create_model() end ==================================
2023-02-15 18:34:41,277:INFO:Creating metrics dataframe
2023-02-15 18:34:41,283:INFO:Initializing Ridge Regression
2023-02-15 18:34:41,283:INFO:Total runtime is 0.16554920276006063 minutes
2023-02-15 18:34:41,285:INFO:SubProcess create_model() called ==================================
2023-02-15 18:34:41,285:INFO:Initializing create_model()
2023-02-15 18:34:41,285:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:34:41,285:INFO:Checking exceptions
2023-02-15 18:34:41,285:INFO:Importing libraries
2023-02-15 18:34:41,285:INFO:Copying training dataset
2023-02-15 18:34:41,354:INFO:Defining folds
2023-02-15 18:34:41,354:INFO:Declaring metric variables
2023-02-15 18:34:41,356:INFO:Importing untrained model
2023-02-15 18:34:41,358:INFO:Ridge Regression Imported successfully
2023-02-15 18:34:41,361:INFO:Starting cross validation
2023-02-15 18:34:41,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:34:45,398:INFO:Calculating mean and std
2023-02-15 18:34:45,399:INFO:Creating metrics dataframe
2023-02-15 18:34:45,401:INFO:Uploading results into container
2023-02-15 18:34:45,401:INFO:Uploading model into container now
2023-02-15 18:34:45,401:INFO:_master_model_container: 3
2023-02-15 18:34:45,401:INFO:_display_container: 2
2023-02-15 18:34:45,402:INFO:Ridge()
2023-02-15 18:34:45,402:INFO:create_model() successfully completed......................................
2023-02-15 18:34:45,535:INFO:SubProcess create_model() end ==================================
2023-02-15 18:34:45,535:INFO:Creating metrics dataframe
2023-02-15 18:34:45,541:INFO:Initializing Elastic Net
2023-02-15 18:34:45,541:INFO:Total runtime is 0.2365207632382711 minutes
2023-02-15 18:34:45,543:INFO:SubProcess create_model() called ==================================
2023-02-15 18:34:45,543:INFO:Initializing create_model()
2023-02-15 18:34:45,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:34:45,543:INFO:Checking exceptions
2023-02-15 18:34:45,543:INFO:Importing libraries
2023-02-15 18:34:45,543:INFO:Copying training dataset
2023-02-15 18:34:45,614:INFO:Defining folds
2023-02-15 18:34:45,615:INFO:Declaring metric variables
2023-02-15 18:34:45,617:INFO:Importing untrained model
2023-02-15 18:34:45,619:INFO:Elastic Net Imported successfully
2023-02-15 18:34:45,622:INFO:Starting cross validation
2023-02-15 18:34:45,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:34:49,482:INFO:Calculating mean and std
2023-02-15 18:34:49,483:INFO:Creating metrics dataframe
2023-02-15 18:34:49,485:INFO:Uploading results into container
2023-02-15 18:34:49,485:INFO:Uploading model into container now
2023-02-15 18:34:49,485:INFO:_master_model_container: 4
2023-02-15 18:34:49,485:INFO:_display_container: 2
2023-02-15 18:34:49,486:INFO:ElasticNet()
2023-02-15 18:34:49,486:INFO:create_model() successfully completed......................................
2023-02-15 18:34:49,615:INFO:SubProcess create_model() end ==================================
2023-02-15 18:34:49,615:INFO:Creating metrics dataframe
2023-02-15 18:34:49,621:INFO:Initializing Least Angle Regression
2023-02-15 18:34:49,621:INFO:Total runtime is 0.3045185844103495 minutes
2023-02-15 18:34:49,623:INFO:SubProcess create_model() called ==================================
2023-02-15 18:34:49,623:INFO:Initializing create_model()
2023-02-15 18:34:49,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:34:49,623:INFO:Checking exceptions
2023-02-15 18:34:49,623:INFO:Importing libraries
2023-02-15 18:34:49,623:INFO:Copying training dataset
2023-02-15 18:34:49,693:INFO:Defining folds
2023-02-15 18:34:49,693:INFO:Declaring metric variables
2023-02-15 18:34:49,695:INFO:Importing untrained model
2023-02-15 18:34:49,697:INFO:Least Angle Regression Imported successfully
2023-02-15 18:34:49,700:INFO:Starting cross validation
2023-02-15 18:34:49,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:34:50,841:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.277e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:34:50,842:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 18:34:50,843:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.066e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:34:50,882:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=4.772e-03, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:34:50,882:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=4.771e-03, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:34:50,984:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:34:51,086:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:34:51,249:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 18:34:52,132:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 18:34:52,132:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 18:34:52,132:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 18:34:52,899:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.570e-03, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:34:52,990:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:34:53,037:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 18:34:53,857:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.635e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:34:53,893:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.470e-03, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:34:53,897:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=2.868e-03, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:34:53,916:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=3.370e-03, with an active set of 138 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:34:54,184:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:34:54,251:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:34:54,393:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 18:34:54,896:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 18:34:54,896:INFO:Calculating mean and std
2023-02-15 18:34:54,897:INFO:Creating metrics dataframe
2023-02-15 18:34:54,899:INFO:Uploading results into container
2023-02-15 18:34:54,900:INFO:Uploading model into container now
2023-02-15 18:34:54,900:INFO:_master_model_container: 5
2023-02-15 18:34:54,900:INFO:_display_container: 2
2023-02-15 18:34:54,900:INFO:Lars(random_state=11)
2023-02-15 18:34:54,900:INFO:create_model() successfully completed......................................
2023-02-15 18:34:55,046:INFO:SubProcess create_model() end ==================================
2023-02-15 18:34:55,046:INFO:Creating metrics dataframe
2023-02-15 18:34:55,052:INFO:Initializing Lasso Least Angle Regression
2023-02-15 18:34:55,052:INFO:Total runtime is 0.3950354218482971 minutes
2023-02-15 18:34:55,054:INFO:SubProcess create_model() called ==================================
2023-02-15 18:34:55,054:INFO:Initializing create_model()
2023-02-15 18:34:55,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:34:55,054:INFO:Checking exceptions
2023-02-15 18:34:55,054:INFO:Importing libraries
2023-02-15 18:34:55,054:INFO:Copying training dataset
2023-02-15 18:34:55,123:INFO:Defining folds
2023-02-15 18:34:55,123:INFO:Declaring metric variables
2023-02-15 18:34:55,125:INFO:Importing untrained model
2023-02-15 18:34:55,127:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 18:34:55,130:INFO:Starting cross validation
2023-02-15 18:34:55,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:34:59,826:INFO:Calculating mean and std
2023-02-15 18:34:59,827:INFO:Creating metrics dataframe
2023-02-15 18:34:59,829:INFO:Uploading results into container
2023-02-15 18:34:59,830:INFO:Uploading model into container now
2023-02-15 18:34:59,830:INFO:_master_model_container: 6
2023-02-15 18:34:59,830:INFO:_display_container: 2
2023-02-15 18:34:59,830:INFO:LassoLars(random_state=11)
2023-02-15 18:34:59,831:INFO:create_model() successfully completed......................................
2023-02-15 18:34:59,983:INFO:SubProcess create_model() end ==================================
2023-02-15 18:34:59,983:INFO:Creating metrics dataframe
2023-02-15 18:34:59,990:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 18:34:59,990:INFO:Total runtime is 0.47732554276784256 minutes
2023-02-15 18:34:59,991:INFO:SubProcess create_model() called ==================================
2023-02-15 18:34:59,992:INFO:Initializing create_model()
2023-02-15 18:34:59,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:34:59,992:INFO:Checking exceptions
2023-02-15 18:34:59,992:INFO:Importing libraries
2023-02-15 18:34:59,992:INFO:Copying training dataset
2023-02-15 18:35:00,063:INFO:Defining folds
2023-02-15 18:35:00,063:INFO:Declaring metric variables
2023-02-15 18:35:00,065:INFO:Importing untrained model
2023-02-15 18:35:00,067:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 18:35:00,071:INFO:Starting cross validation
2023-02-15 18:35:00,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:35:04,823:INFO:Calculating mean and std
2023-02-15 18:35:04,823:INFO:Creating metrics dataframe
2023-02-15 18:35:04,826:INFO:Uploading results into container
2023-02-15 18:35:04,826:INFO:Uploading model into container now
2023-02-15 18:35:04,827:INFO:_master_model_container: 7
2023-02-15 18:35:04,827:INFO:_display_container: 2
2023-02-15 18:35:04,827:INFO:OrthogonalMatchingPursuit()
2023-02-15 18:35:04,827:INFO:create_model() successfully completed......................................
2023-02-15 18:35:04,978:INFO:SubProcess create_model() end ==================================
2023-02-15 18:35:04,978:INFO:Creating metrics dataframe
2023-02-15 18:35:04,984:INFO:Initializing Bayesian Ridge
2023-02-15 18:35:04,984:INFO:Total runtime is 0.5605663975079854 minutes
2023-02-15 18:35:04,986:INFO:SubProcess create_model() called ==================================
2023-02-15 18:35:04,986:INFO:Initializing create_model()
2023-02-15 18:35:04,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:35:04,986:INFO:Checking exceptions
2023-02-15 18:35:04,986:INFO:Importing libraries
2023-02-15 18:35:04,986:INFO:Copying training dataset
2023-02-15 18:35:05,058:INFO:Defining folds
2023-02-15 18:35:05,058:INFO:Declaring metric variables
2023-02-15 18:35:05,060:INFO:Importing untrained model
2023-02-15 18:35:05,062:INFO:Bayesian Ridge Imported successfully
2023-02-15 18:35:05,065:INFO:Starting cross validation
2023-02-15 18:35:05,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:35:08,946:INFO:Calculating mean and std
2023-02-15 18:35:08,947:INFO:Creating metrics dataframe
2023-02-15 18:35:08,950:INFO:Uploading results into container
2023-02-15 18:35:08,950:INFO:Uploading model into container now
2023-02-15 18:35:08,950:INFO:_master_model_container: 8
2023-02-15 18:35:08,950:INFO:_display_container: 2
2023-02-15 18:35:08,951:INFO:BayesianRidge()
2023-02-15 18:35:08,951:INFO:create_model() successfully completed......................................
2023-02-15 18:35:09,098:INFO:SubProcess create_model() end ==================================
2023-02-15 18:35:09,099:INFO:Creating metrics dataframe
2023-02-15 18:35:09,105:INFO:Initializing Passive Aggressive Regressor
2023-02-15 18:35:09,105:INFO:Total runtime is 0.6292445580164592 minutes
2023-02-15 18:35:09,106:INFO:SubProcess create_model() called ==================================
2023-02-15 18:35:09,107:INFO:Initializing create_model()
2023-02-15 18:35:09,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:35:09,107:INFO:Checking exceptions
2023-02-15 18:35:09,107:INFO:Importing libraries
2023-02-15 18:35:09,107:INFO:Copying training dataset
2023-02-15 18:35:09,176:INFO:Defining folds
2023-02-15 18:35:09,177:INFO:Declaring metric variables
2023-02-15 18:35:09,179:INFO:Importing untrained model
2023-02-15 18:35:09,180:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 18:35:09,183:INFO:Starting cross validation
2023-02-15 18:35:09,185:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:35:13,079:INFO:Calculating mean and std
2023-02-15 18:35:13,079:INFO:Creating metrics dataframe
2023-02-15 18:35:13,082:INFO:Uploading results into container
2023-02-15 18:35:13,082:INFO:Uploading model into container now
2023-02-15 18:35:13,082:INFO:_master_model_container: 9
2023-02-15 18:35:13,083:INFO:_display_container: 2
2023-02-15 18:35:13,083:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 18:35:13,083:INFO:create_model() successfully completed......................................
2023-02-15 18:35:13,235:INFO:SubProcess create_model() end ==================================
2023-02-15 18:35:13,235:INFO:Creating metrics dataframe
2023-02-15 18:35:13,245:INFO:Initializing Huber Regressor
2023-02-15 18:35:13,245:INFO:Total runtime is 0.6982542395591737 minutes
2023-02-15 18:35:13,247:INFO:SubProcess create_model() called ==================================
2023-02-15 18:35:13,247:INFO:Initializing create_model()
2023-02-15 18:35:13,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:35:13,247:INFO:Checking exceptions
2023-02-15 18:35:13,247:INFO:Importing libraries
2023-02-15 18:35:13,247:INFO:Copying training dataset
2023-02-15 18:35:13,318:INFO:Defining folds
2023-02-15 18:35:13,318:INFO:Declaring metric variables
2023-02-15 18:35:13,320:INFO:Importing untrained model
2023-02-15 18:35:13,322:INFO:Huber Regressor Imported successfully
2023-02-15 18:35:13,325:INFO:Starting cross validation
2023-02-15 18:35:13,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:35:17,192:INFO:Calculating mean and std
2023-02-15 18:35:17,193:INFO:Creating metrics dataframe
2023-02-15 18:35:17,195:INFO:Uploading results into container
2023-02-15 18:35:17,196:INFO:Uploading model into container now
2023-02-15 18:35:17,196:INFO:_master_model_container: 10
2023-02-15 18:35:17,196:INFO:_display_container: 2
2023-02-15 18:35:17,196:INFO:HuberRegressor()
2023-02-15 18:35:17,196:INFO:create_model() successfully completed......................................
2023-02-15 18:35:17,341:INFO:SubProcess create_model() end ==================================
2023-02-15 18:35:17,342:INFO:Creating metrics dataframe
2023-02-15 18:35:17,348:INFO:Initializing K Neighbors Regressor
2023-02-15 18:35:17,348:INFO:Total runtime is 0.7666338086128236 minutes
2023-02-15 18:35:17,350:INFO:SubProcess create_model() called ==================================
2023-02-15 18:35:17,350:INFO:Initializing create_model()
2023-02-15 18:35:17,350:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:35:17,350:INFO:Checking exceptions
2023-02-15 18:35:17,350:INFO:Importing libraries
2023-02-15 18:35:17,350:INFO:Copying training dataset
2023-02-15 18:35:17,419:INFO:Defining folds
2023-02-15 18:35:17,419:INFO:Declaring metric variables
2023-02-15 18:35:17,421:INFO:Importing untrained model
2023-02-15 18:35:17,423:INFO:K Neighbors Regressor Imported successfully
2023-02-15 18:35:17,426:INFO:Starting cross validation
2023-02-15 18:35:17,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:35:17,430:INFO:[I] [18:35:17.430106] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:17,723:INFO:[I] [18:35:17.723024] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:18,222:INFO:[I] [18:35:18.222184] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:18,517:INFO:[I] [18:35:18.517701] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:18,636:INFO:[I] [18:35:18.636495] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:18,931:INFO:[I] [18:35:18.931699] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:19,049:INFO:[I] [18:35:19.049917] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:19,347:INFO:[I] [18:35:19.347842] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:19,469:INFO:[I] [18:35:19.469827] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:19,764:INFO:[I] [18:35:19.764299] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:19,880:INFO:[I] [18:35:19.880621] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:20,177:INFO:[I] [18:35:20.177675] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:20,298:INFO:[I] [18:35:20.298005] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:20,598:INFO:[I] [18:35:20.598038] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:20,712:INFO:[I] [18:35:20.712793] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:21,005:INFO:[I] [18:35:21.005330] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:21,119:INFO:[I] [18:35:21.119962] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:21,413:INFO:[I] [18:35:21.413699] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:21,530:INFO:[I] [18:35:21.530247] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:21,826:INFO:[I] [18:35:21.826957] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:35:21,942:INFO:Calculating mean and std
2023-02-15 18:35:21,943:INFO:Creating metrics dataframe
2023-02-15 18:35:21,944:INFO:Uploading results into container
2023-02-15 18:35:21,945:INFO:Uploading model into container now
2023-02-15 18:35:21,945:INFO:_master_model_container: 11
2023-02-15 18:35:21,945:INFO:_display_container: 2
2023-02-15 18:35:21,945:INFO:KNeighborsRegressor()
2023-02-15 18:35:21,945:INFO:create_model() successfully completed......................................
2023-02-15 18:35:22,080:INFO:SubProcess create_model() end ==================================
2023-02-15 18:35:22,080:INFO:Creating metrics dataframe
2023-02-15 18:35:22,087:INFO:Initializing Decision Tree Regressor
2023-02-15 18:35:22,087:INFO:Total runtime is 0.8456095695495607 minutes
2023-02-15 18:35:22,088:INFO:SubProcess create_model() called ==================================
2023-02-15 18:35:22,088:INFO:Initializing create_model()
2023-02-15 18:35:22,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:35:22,089:INFO:Checking exceptions
2023-02-15 18:35:22,089:INFO:Importing libraries
2023-02-15 18:35:22,089:INFO:Copying training dataset
2023-02-15 18:35:22,158:INFO:Defining folds
2023-02-15 18:35:22,158:INFO:Declaring metric variables
2023-02-15 18:35:22,160:INFO:Importing untrained model
2023-02-15 18:35:22,162:INFO:Decision Tree Regressor Imported successfully
2023-02-15 18:35:22,165:INFO:Starting cross validation
2023-02-15 18:35:22,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:35:25,845:INFO:Calculating mean and std
2023-02-15 18:35:25,846:INFO:Creating metrics dataframe
2023-02-15 18:35:25,848:INFO:Uploading results into container
2023-02-15 18:35:25,848:INFO:Uploading model into container now
2023-02-15 18:35:25,848:INFO:_master_model_container: 12
2023-02-15 18:35:25,848:INFO:_display_container: 2
2023-02-15 18:35:25,848:INFO:DecisionTreeRegressor(random_state=11)
2023-02-15 18:35:25,848:INFO:create_model() successfully completed......................................
2023-02-15 18:35:25,978:INFO:SubProcess create_model() end ==================================
2023-02-15 18:35:25,978:INFO:Creating metrics dataframe
2023-02-15 18:35:25,985:INFO:Initializing Random Forest Regressor
2023-02-15 18:35:25,985:INFO:Total runtime is 0.9105757872263591 minutes
2023-02-15 18:35:25,986:INFO:SubProcess create_model() called ==================================
2023-02-15 18:35:25,986:INFO:Initializing create_model()
2023-02-15 18:35:25,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb7e1782a60>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb780d85970>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:35:25,987:INFO:Checking exceptions
2023-02-15 18:35:25,987:INFO:Importing libraries
2023-02-15 18:35:25,987:INFO:Copying training dataset
2023-02-15 18:35:26,055:INFO:Defining folds
2023-02-15 18:35:26,055:INFO:Declaring metric variables
2023-02-15 18:35:26,058:INFO:Importing untrained model
2023-02-15 18:35:26,058:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:35:26,060:INFO:Random Forest Regressor Imported successfully
2023-02-15 18:35:26,063:INFO:Starting cross validation
2023-02-15 18:35:26,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:35:26,066:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:35:26,361:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:35:32,142:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 297, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/nvtx/nvtx.py", line 101, in inner
    result = func(*args, **kwargs)
  File "randomforestregressor.pyx", line 588, in cuml.ensemble.randomforestregressor.RandomForestRegressor.predict
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "randomforest_common.pyx", line 353, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu
  File "randomforest_common.pyx", line 218, in cuml.ensemble.randomforest_common.BaseRandomForestModel._obtain_treelite_handle
  File "randomforest_shared.pyx", line 121, in cuml.ensemble.randomforest_shared.treelite_deserialize
  File "randomforest_shared.pyx", line 105, in cuml.ensemble.randomforest_shared.init_from_frames
  File "randomforest_shared.pyx", line 84, in cuml.ensemble.randomforest_shared._init_from_frames
RuntimeError: Cannot deserialize model from a different major Treelite version or a version before 2.4.0.
Currently running Treelite version 3.1.0
The model checkpoint was generated from Treelite version 1818850658.1936615796.1819477388

  warnings.warn(

2023-02-15 18:35:32,143:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:35:32,445:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:35:37,931:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 297, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/nvtx/nvtx.py", line 101, in inner
    result = func(*args, **kwargs)
  File "randomforestregressor.pyx", line 588, in cuml.ensemble.randomforestregressor.RandomForestRegressor.predict
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "randomforest_common.pyx", line 353, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu
  File "randomforest_common.pyx", line 218, in cuml.ensemble.randomforest_common.BaseRandomForestModel._obtain_treelite_handle
  File "randomforest_shared.pyx", line 121, in cuml.ensemble.randomforest_shared.treelite_deserialize
  File "randomforest_shared.pyx", line 105, in cuml.ensemble.randomforest_shared.init_from_frames
  File "randomforest_shared.pyx", line 84, in cuml.ensemble.randomforest_shared._init_from_frames
RuntimeError: Could not load the correct number of nodes

  warnings.warn(

2023-02-15 18:35:37,932:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:35:38,236:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:42:27,734:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:28,718:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:28,718:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:28,718:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:28,877:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 18:42:29,085:INFO:PyCaret RegressionExperiment
2023-02-15 18:42:29,085:INFO:Logging name: reg-default-name
2023-02-15 18:42:29,085:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 18:42:29,085:INFO:version 3.0.0.rc9
2023-02-15 18:42:29,085:INFO:Initializing setup()
2023-02-15 18:42:29,085:INFO:self.USI: 91ee
2023-02-15 18:42:29,085:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'memory', 'X', 'logging_param', 'html_param', 'fold_shuffle_param', '_available_plots', 'target_param', 'X_train', 'pipeline', 'n_jobs_param', 'gpu_n_jobs_param', 'y_test', 'USI', 'y', 'data', 'log_plots_param', 'idx', 'gpu_param', 'fold_groups_param', 'transform_target_param', 'seed', 'fold_generator', 'exp_id', 'X_test', 'exp_name_log'}
2023-02-15 18:42:29,085:INFO:Checking environment
2023-02-15 18:42:29,085:INFO:python_version: 3.8.16
2023-02-15 18:42:29,085:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-15 18:42:29,085:INFO:machine: x86_64
2023-02-15 18:42:29,085:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 18:42:29,085:INFO:Memory: svmem(total=134979592192, available=121037864960, percent=10.3, used=11842019328, free=42094145536, active=5246263296, inactive=83885264896, buffers=1219735552, cached=79823691776, shared=827183104, slab=3013115904)
2023-02-15 18:42:29,086:INFO:Physical Core: 16
2023-02-15 18:42:29,086:INFO:Logical Core: 32
2023-02-15 18:42:29,086:INFO:Checking libraries
2023-02-15 18:42:29,086:INFO:System:
2023-02-15 18:42:29,086:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-15 18:42:29,086:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 18:42:29,086:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 18:42:29,086:INFO:PyCaret required dependencies:
2023-02-15 18:42:29,086:INFO:                 pip: 23.0
2023-02-15 18:42:29,086:INFO:          setuptools: 60.10.0
2023-02-15 18:42:29,086:INFO:             pycaret: 3.0.0rc9
2023-02-15 18:42:29,086:INFO:             IPython: 8.10.0
2023-02-15 18:42:29,086:INFO:          ipywidgets: 7.7.3
2023-02-15 18:42:29,086:INFO:                tqdm: 4.64.1
2023-02-15 18:42:29,086:INFO:               numpy: 1.23.5
2023-02-15 18:42:29,086:INFO:              pandas: 1.5.3
2023-02-15 18:42:29,086:INFO:              jinja2: 3.1.2
2023-02-15 18:42:29,086:INFO:               scipy: 1.9.1
2023-02-15 18:42:29,086:INFO:              joblib: 1.2.0
2023-02-15 18:42:29,086:INFO:             sklearn: 1.2.1
2023-02-15 18:42:29,086:INFO:                pyod: 1.0.7
2023-02-15 18:42:29,086:INFO:            imblearn: 0.10.1
2023-02-15 18:42:29,086:INFO:   category_encoders: 2.6.0
2023-02-15 18:42:29,086:INFO:            lightgbm: 3.3.5.99
2023-02-15 18:42:29,086:INFO:               numba: 0.56.4
2023-02-15 18:42:29,086:INFO:            requests: 2.28.2
2023-02-15 18:42:29,086:INFO:          matplotlib: 3.6.3
2023-02-15 18:42:29,086:INFO:          scikitplot: 0.3.7
2023-02-15 18:42:29,086:INFO:         yellowbrick: 1.5
2023-02-15 18:42:29,086:INFO:              plotly: 5.13.0
2023-02-15 18:42:29,086:INFO:             kaleido: 0.2.1
2023-02-15 18:42:29,086:INFO:         statsmodels: 0.13.5
2023-02-15 18:42:29,086:INFO:              sktime: 0.16.1
2023-02-15 18:42:29,086:INFO:               tbats: 1.1.2
2023-02-15 18:42:29,086:INFO:            pmdarima: 2.0.2
2023-02-15 18:42:29,086:INFO:              psutil: 5.9.4
2023-02-15 18:42:29,086:INFO:PyCaret optional dependencies:
2023-02-15 18:42:29,319:INFO:                shap: 0.41.0
2023-02-15 18:42:29,319:INFO:           interpret: 0.3.0
2023-02-15 18:42:29,319:INFO:                umap: 0.5.3
2023-02-15 18:42:29,319:INFO:    pandas_profiling: 4.0.0
2023-02-15 18:42:29,319:INFO:  explainerdashboard: 0.4.2
2023-02-15 18:42:29,319:INFO:             autoviz: 0.1.58
2023-02-15 18:42:29,319:INFO:           fairlearn: 0.7.0
2023-02-15 18:42:29,319:INFO:             xgboost: 1.7.3
2023-02-15 18:42:29,319:INFO:            catboost: 1.1.1
2023-02-15 18:42:29,319:INFO:              kmodes: 0.12.2
2023-02-15 18:42:29,319:INFO:             mlxtend: 0.21.0
2023-02-15 18:42:29,319:INFO:       statsforecast: 1.4.0
2023-02-15 18:42:29,319:INFO:        tune_sklearn: 0.4.5
2023-02-15 18:42:29,319:INFO:                 ray: 2.2.0
2023-02-15 18:42:29,319:INFO:            hyperopt: 0.2.7
2023-02-15 18:42:29,319:INFO:              optuna: 3.1.0
2023-02-15 18:42:29,319:INFO:               skopt: 0.9.0
2023-02-15 18:42:29,319:INFO:              mlflow: 1.30.0
2023-02-15 18:42:29,319:INFO:              gradio: 3.18.0
2023-02-15 18:42:29,319:INFO:             fastapi: 0.92.0
2023-02-15 18:42:29,319:INFO:             uvicorn: 0.20.0
2023-02-15 18:42:29,319:INFO:              m2cgen: 0.10.0
2023-02-15 18:42:29,319:INFO:           evidently: 0.2.4
2023-02-15 18:42:29,319:INFO:               fugue: 0.8.1.dev4
2023-02-15 18:42:29,319:INFO:           streamlit: Not installed
2023-02-15 18:42:29,319:INFO:             prophet: Not installed
2023-02-15 18:42:29,319:INFO:None
2023-02-15 18:42:29,319:INFO:Set up GPU usage.
2023-02-15 18:42:29,319:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:29,319:INFO:cuml==23.2.0
2023-02-15 18:42:29,320:ERROR:Couldn't set cuML global output type
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/tabular_experiment.py", line 351, in _initialize_setup
    import cuml.common.memory_utils
ModuleNotFoundError: No module named 'cuml.common.memory_utils'
2023-02-15 18:42:29,320:INFO:Set up data.
2023-02-15 18:42:29,637:INFO:Set up train/test split.
2023-02-15 18:42:29,814:INFO:Set up index.
2023-02-15 18:42:29,862:INFO:Set up folding strategy.
2023-02-15 18:42:29,863:INFO:Assigning column types.
2023-02-15 18:42:29,968:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 18:42:29,968:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:29,968:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:29,968:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 18:42:29,968:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:29,968:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:29,971:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:42:29,971:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:29,971:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:29,973:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:42:29,974:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:29,974:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:30,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,079:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,079:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:30,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,106:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,106:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:30,107:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,107:INFO:Imported cuml.ensemble
2023-02-15 18:42:30,107:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:30,400:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:30,460:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,460:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:30,460:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,460:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,460:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:30,463:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,463:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,463:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:30,466:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,466:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,466:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:30,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,588:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,588:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:30,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,617:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,617:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:30,617:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,617:INFO:Imported cuml.ensemble
2023-02-15 18:42:30,617:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:30,696:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:30,734:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 18:42:30,735:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,735:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:30,735:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,735:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:30,737:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,737:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,737:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:30,740:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,740:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,740:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:30,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,858:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,858:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:30,886:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:42:30,886:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,886:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:30,886:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,886:INFO:Imported cuml.ensemble
2023-02-15 18:42:30,886:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:30,960:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:30,999:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,999:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:30,999:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:30,999:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:31,002:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,002:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,002:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:31,005:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,005:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,005:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:31,113:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,114:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,114:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:31,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,145:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,145:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:31,145:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,145:INFO:Imported cuml.ensemble
2023-02-15 18:42:31,145:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:31,214:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:31,250:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 18:42:31,250:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,250:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:31,250:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,250:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:31,253:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,253:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:31,256:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,256:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,256:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:31,353:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,353:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,353:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:31,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,380:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,380:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:31,380:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,380:INFO:Imported cuml.ensemble
2023-02-15 18:42:31,380:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:31,456:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:31,489:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,489:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:31,489:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,489:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:31,491:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,491:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:31,494:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,494:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,494:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:31,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,594:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,594:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:31,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,621:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,621:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:31,621:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,621:INFO:Imported cuml.ensemble
2023-02-15 18:42:31,621:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:31,696:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:31,731:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 18:42:31,731:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,731:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:31,732:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,732:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:31,734:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,734:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:31,737:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,737:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:31,840:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,840:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,840:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:31,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:42:31,867:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,867:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:31,868:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,868:INFO:Imported cuml.ensemble
2023-02-15 18:42:31,868:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:31,940:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:31,975:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,975:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:31,975:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,975:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:31,978:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,978:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:31,981:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:31,981:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:32,080:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:42:32,080:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,080:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:32,107:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 18:42:32,107:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,107:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:32,107:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,107:INFO:Imported cuml.ensemble
2023-02-15 18:42:32,107:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:32,175:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:32,211:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 18:42:32,211:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,211:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:32,212:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,212:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:32,214:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,214:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:32,217:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,217:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:32,318:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:42:32,318:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,318:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:32,346:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,346:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:32,346:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,346:INFO:Imported cuml.ensemble
2023-02-15 18:42:32,346:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:32,414:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:32,451:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,451:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:32,451:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,451:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:32,454:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,454:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:32,457:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,457:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:32,552:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 18:42:32,552:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,552:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:32,580:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,580:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:32,580:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,580:INFO:Imported cuml.ensemble
2023-02-15 18:42:32,580:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:32,653:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:32,688:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 18:42:32,689:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,689:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:32,689:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,689:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:32,691:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,692:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:32,696:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,696:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:32,802:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,802:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:32,829:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,829:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:32,829:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,829:INFO:Imported cuml.ensemble
2023-02-15 18:42:32,830:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:32,902:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:32,940:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,940:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:32,940:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,940:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:32,943:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,943:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:32,946:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:32,946:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:33,047:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:33,047:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:33,074:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:33,074:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:33,074:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:33,074:INFO:Imported cuml.ensemble
2023-02-15 18:42:33,075:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:33,149:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:33,183:INFO:Preparing preprocessing pipeline...
2023-02-15 18:42:33,198:INFO:Set up column name cleaning.
2023-02-15 18:42:33,198:INFO:Set up simple imputation.
2023-02-15 18:42:33,198:INFO:Set up feature normalization.
2023-02-15 18:42:33,560:INFO:Finished creating preprocessing pipeline.
2023-02-15 18:42:33,566:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 18:42:33,566:INFO:Creating final display dataframe.
2023-02-15 18:42:34,199:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28569, 780)
4        Transformed data shape           (28569, 775)
5   Transformed train set shape           (19998, 775)
6    Transformed test set shape            (8571, 775)
7               Ignore features                      5
8              Numeric features                    774
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   91ee
2023-02-15 18:42:34,204:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,204:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:34,204:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,204:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:34,207:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,207:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:34,210:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,210:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:34,308:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,308:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:34,335:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,335:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:34,335:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,336:INFO:Imported cuml.ensemble
2023-02-15 18:42:34,336:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:34,408:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:34,444:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,444:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 18:42:34,444:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,444:INFO:Imported cuml.linear_model.Lasso
2023-02-15 18:42:34,447:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,447:INFO:Imported cuml.linear_model.Ridge
2023-02-15 18:42:34,450:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,450:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 18:42:34,550:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,550:INFO:Imported cuml.svm.SVR
2023-02-15 18:42:34,578:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,578:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 18:42:34,578:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 18:42:34,578:INFO:Imported cuml.ensemble
2023-02-15 18:42:34,578:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 18:42:34,655:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 18:42:34,699:INFO:setup() successfully completed in 5.61s...............
2023-02-15 18:42:34,699:INFO:Initializing compare_models()
2023-02-15 18:42:34,699:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 18:42:34,699:INFO:Checking exceptions
2023-02-15 18:42:34,741:INFO:Preparing display monitor
2023-02-15 18:42:34,757:INFO:Initializing Linear Regression
2023-02-15 18:42:34,757:INFO:Total runtime is 1.5179316202799478e-06 minutes
2023-02-15 18:42:34,759:INFO:SubProcess create_model() called ==================================
2023-02-15 18:42:34,759:INFO:Initializing create_model()
2023-02-15 18:42:34,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:42:34,759:INFO:Checking exceptions
2023-02-15 18:42:34,759:INFO:Importing libraries
2023-02-15 18:42:34,759:INFO:Copying training dataset
2023-02-15 18:42:34,858:INFO:Defining folds
2023-02-15 18:42:34,858:INFO:Declaring metric variables
2023-02-15 18:42:34,861:INFO:Importing untrained model
2023-02-15 18:42:34,864:INFO:Linear Regression Imported successfully
2023-02-15 18:42:34,868:INFO:Starting cross validation
2023-02-15 18:42:34,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:42:41,515:INFO:Calculating mean and std
2023-02-15 18:42:41,516:INFO:Creating metrics dataframe
2023-02-15 18:42:41,518:INFO:Uploading results into container
2023-02-15 18:42:41,518:INFO:Uploading model into container now
2023-02-15 18:42:41,518:INFO:_master_model_container: 1
2023-02-15 18:42:41,518:INFO:_display_container: 2
2023-02-15 18:42:41,519:INFO:LinearRegression()
2023-02-15 18:42:41,519:INFO:create_model() successfully completed......................................
2023-02-15 18:42:41,706:INFO:SubProcess create_model() end ==================================
2023-02-15 18:42:41,706:INFO:Creating metrics dataframe
2023-02-15 18:42:41,712:INFO:Initializing Lasso Regression
2023-02-15 18:42:41,712:INFO:Total runtime is 0.11591983238855998 minutes
2023-02-15 18:42:41,715:INFO:SubProcess create_model() called ==================================
2023-02-15 18:42:41,715:INFO:Initializing create_model()
2023-02-15 18:42:41,715:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:42:41,715:INFO:Checking exceptions
2023-02-15 18:42:41,715:INFO:Importing libraries
2023-02-15 18:42:41,715:INFO:Copying training dataset
2023-02-15 18:42:41,825:INFO:Defining folds
2023-02-15 18:42:41,825:INFO:Declaring metric variables
2023-02-15 18:42:41,828:INFO:Importing untrained model
2023-02-15 18:42:41,830:INFO:Lasso Regression Imported successfully
2023-02-15 18:42:41,833:INFO:Starting cross validation
2023-02-15 18:42:41,836:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:42:46,519:INFO:Calculating mean and std
2023-02-15 18:42:46,520:INFO:Creating metrics dataframe
2023-02-15 18:42:46,522:INFO:Uploading results into container
2023-02-15 18:42:46,522:INFO:Uploading model into container now
2023-02-15 18:42:46,522:INFO:_master_model_container: 2
2023-02-15 18:42:46,522:INFO:_display_container: 2
2023-02-15 18:42:46,522:INFO:Lasso()
2023-02-15 18:42:46,523:INFO:create_model() successfully completed......................................
2023-02-15 18:42:46,697:INFO:SubProcess create_model() end ==================================
2023-02-15 18:42:46,697:INFO:Creating metrics dataframe
2023-02-15 18:42:46,704:INFO:Initializing Ridge Regression
2023-02-15 18:42:46,704:INFO:Total runtime is 0.19911231994628906 minutes
2023-02-15 18:42:46,706:INFO:SubProcess create_model() called ==================================
2023-02-15 18:42:46,706:INFO:Initializing create_model()
2023-02-15 18:42:46,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:42:46,706:INFO:Checking exceptions
2023-02-15 18:42:46,706:INFO:Importing libraries
2023-02-15 18:42:46,706:INFO:Copying training dataset
2023-02-15 18:42:46,805:INFO:Defining folds
2023-02-15 18:42:46,805:INFO:Declaring metric variables
2023-02-15 18:42:46,808:INFO:Importing untrained model
2023-02-15 18:42:46,810:INFO:Ridge Regression Imported successfully
2023-02-15 18:42:46,813:INFO:Starting cross validation
2023-02-15 18:42:46,816:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:42:51,754:INFO:Calculating mean and std
2023-02-15 18:42:51,755:INFO:Creating metrics dataframe
2023-02-15 18:42:51,756:INFO:Uploading results into container
2023-02-15 18:42:51,757:INFO:Uploading model into container now
2023-02-15 18:42:51,757:INFO:_master_model_container: 3
2023-02-15 18:42:51,757:INFO:_display_container: 2
2023-02-15 18:42:51,757:INFO:Ridge()
2023-02-15 18:42:51,757:INFO:create_model() successfully completed......................................
2023-02-15 18:42:51,919:INFO:SubProcess create_model() end ==================================
2023-02-15 18:42:51,919:INFO:Creating metrics dataframe
2023-02-15 18:42:51,926:INFO:Initializing Elastic Net
2023-02-15 18:42:51,926:INFO:Total runtime is 0.2861492951711019 minutes
2023-02-15 18:42:51,928:INFO:SubProcess create_model() called ==================================
2023-02-15 18:42:51,928:INFO:Initializing create_model()
2023-02-15 18:42:51,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:42:51,928:INFO:Checking exceptions
2023-02-15 18:42:51,928:INFO:Importing libraries
2023-02-15 18:42:51,928:INFO:Copying training dataset
2023-02-15 18:42:52,016:INFO:Defining folds
2023-02-15 18:42:52,016:INFO:Declaring metric variables
2023-02-15 18:42:52,019:INFO:Importing untrained model
2023-02-15 18:42:52,021:INFO:Elastic Net Imported successfully
2023-02-15 18:42:52,025:INFO:Starting cross validation
2023-02-15 18:42:52,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:42:56,809:INFO:Calculating mean and std
2023-02-15 18:42:56,809:INFO:Creating metrics dataframe
2023-02-15 18:42:56,811:INFO:Uploading results into container
2023-02-15 18:42:56,812:INFO:Uploading model into container now
2023-02-15 18:42:56,812:INFO:_master_model_container: 4
2023-02-15 18:42:56,812:INFO:_display_container: 2
2023-02-15 18:42:56,812:INFO:ElasticNet()
2023-02-15 18:42:56,812:INFO:create_model() successfully completed......................................
2023-02-15 18:42:56,970:INFO:SubProcess create_model() end ==================================
2023-02-15 18:42:56,970:INFO:Creating metrics dataframe
2023-02-15 18:42:56,976:INFO:Initializing Least Angle Regression
2023-02-15 18:42:56,976:INFO:Total runtime is 0.37031162579854326 minutes
2023-02-15 18:42:56,978:INFO:SubProcess create_model() called ==================================
2023-02-15 18:42:56,978:INFO:Initializing create_model()
2023-02-15 18:42:56,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:42:56,978:INFO:Checking exceptions
2023-02-15 18:42:56,978:INFO:Importing libraries
2023-02-15 18:42:56,978:INFO:Copying training dataset
2023-02-15 18:42:57,066:INFO:Defining folds
2023-02-15 18:42:57,067:INFO:Declaring metric variables
2023-02-15 18:42:57,069:INFO:Importing untrained model
2023-02-15 18:42:57,071:INFO:Least Angle Regression Imported successfully
2023-02-15 18:42:57,074:INFO:Starting cross validation
2023-02-15 18:42:57,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:42:58,434:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.277e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:42:58,435:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 18:42:58,437:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.066e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:42:58,502:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=4.772e-03, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:42:58,502:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=4.771e-03, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:42:58,654:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:42:58,773:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:42:58,946:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 18:42:59,979:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 18:42:59,979:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 18:42:59,979:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 18:43:00,899:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.570e-03, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:43:01,081:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:43:01,143:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 18:43:02,119:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.635e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:43:02,163:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.470e-03, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:43:02,166:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=2.868e-03, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:43:02,188:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=3.370e-03, with an active set of 138 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 18:43:02,436:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:43:02,516:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 18:43:02,673:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 18:43:03,268:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 18:43:03,268:INFO:Calculating mean and std
2023-02-15 18:43:03,269:INFO:Creating metrics dataframe
2023-02-15 18:43:03,272:INFO:Uploading results into container
2023-02-15 18:43:03,272:INFO:Uploading model into container now
2023-02-15 18:43:03,273:INFO:_master_model_container: 5
2023-02-15 18:43:03,273:INFO:_display_container: 2
2023-02-15 18:43:03,273:INFO:Lars(random_state=11)
2023-02-15 18:43:03,273:INFO:create_model() successfully completed......................................
2023-02-15 18:43:03,453:INFO:SubProcess create_model() end ==================================
2023-02-15 18:43:03,453:INFO:Creating metrics dataframe
2023-02-15 18:43:03,459:INFO:Initializing Lasso Least Angle Regression
2023-02-15 18:43:03,460:INFO:Total runtime is 0.4783761064211527 minutes
2023-02-15 18:43:03,461:INFO:SubProcess create_model() called ==================================
2023-02-15 18:43:03,462:INFO:Initializing create_model()
2023-02-15 18:43:03,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:43:03,462:INFO:Checking exceptions
2023-02-15 18:43:03,462:INFO:Importing libraries
2023-02-15 18:43:03,462:INFO:Copying training dataset
2023-02-15 18:43:03,553:INFO:Defining folds
2023-02-15 18:43:03,553:INFO:Declaring metric variables
2023-02-15 18:43:03,555:INFO:Importing untrained model
2023-02-15 18:43:03,557:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 18:43:03,560:INFO:Starting cross validation
2023-02-15 18:43:03,563:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:43:09,168:INFO:Calculating mean and std
2023-02-15 18:43:09,169:INFO:Creating metrics dataframe
2023-02-15 18:43:09,172:INFO:Uploading results into container
2023-02-15 18:43:09,172:INFO:Uploading model into container now
2023-02-15 18:43:09,173:INFO:_master_model_container: 6
2023-02-15 18:43:09,173:INFO:_display_container: 2
2023-02-15 18:43:09,173:INFO:LassoLars(random_state=11)
2023-02-15 18:43:09,173:INFO:create_model() successfully completed......................................
2023-02-15 18:43:09,344:INFO:SubProcess create_model() end ==================================
2023-02-15 18:43:09,344:INFO:Creating metrics dataframe
2023-02-15 18:43:09,351:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 18:43:09,351:INFO:Total runtime is 0.5765607357025146 minutes
2023-02-15 18:43:09,352:INFO:SubProcess create_model() called ==================================
2023-02-15 18:43:09,353:INFO:Initializing create_model()
2023-02-15 18:43:09,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:43:09,353:INFO:Checking exceptions
2023-02-15 18:43:09,353:INFO:Importing libraries
2023-02-15 18:43:09,353:INFO:Copying training dataset
2023-02-15 18:43:09,443:INFO:Defining folds
2023-02-15 18:43:09,444:INFO:Declaring metric variables
2023-02-15 18:43:09,446:INFO:Importing untrained model
2023-02-15 18:43:09,448:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 18:43:09,451:INFO:Starting cross validation
2023-02-15 18:43:09,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:43:14,984:INFO:Calculating mean and std
2023-02-15 18:43:14,985:INFO:Creating metrics dataframe
2023-02-15 18:43:14,988:INFO:Uploading results into container
2023-02-15 18:43:14,988:INFO:Uploading model into container now
2023-02-15 18:43:14,989:INFO:_master_model_container: 7
2023-02-15 18:43:14,989:INFO:_display_container: 2
2023-02-15 18:43:14,989:INFO:OrthogonalMatchingPursuit()
2023-02-15 18:43:14,989:INFO:create_model() successfully completed......................................
2023-02-15 18:43:15,154:INFO:SubProcess create_model() end ==================================
2023-02-15 18:43:15,154:INFO:Creating metrics dataframe
2023-02-15 18:43:15,161:INFO:Initializing Bayesian Ridge
2023-02-15 18:43:15,161:INFO:Total runtime is 0.6734050591786702 minutes
2023-02-15 18:43:15,163:INFO:SubProcess create_model() called ==================================
2023-02-15 18:43:15,163:INFO:Initializing create_model()
2023-02-15 18:43:15,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:43:15,163:INFO:Checking exceptions
2023-02-15 18:43:15,163:INFO:Importing libraries
2023-02-15 18:43:15,163:INFO:Copying training dataset
2023-02-15 18:43:15,252:INFO:Defining folds
2023-02-15 18:43:15,252:INFO:Declaring metric variables
2023-02-15 18:43:15,255:INFO:Importing untrained model
2023-02-15 18:43:15,257:INFO:Bayesian Ridge Imported successfully
2023-02-15 18:43:15,260:INFO:Starting cross validation
2023-02-15 18:43:15,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:43:20,155:INFO:Calculating mean and std
2023-02-15 18:43:20,155:INFO:Creating metrics dataframe
2023-02-15 18:43:20,158:INFO:Uploading results into container
2023-02-15 18:43:20,159:INFO:Uploading model into container now
2023-02-15 18:43:20,159:INFO:_master_model_container: 8
2023-02-15 18:43:20,159:INFO:_display_container: 2
2023-02-15 18:43:20,159:INFO:BayesianRidge()
2023-02-15 18:43:20,159:INFO:create_model() successfully completed......................................
2023-02-15 18:43:20,316:INFO:SubProcess create_model() end ==================================
2023-02-15 18:43:20,316:INFO:Creating metrics dataframe
2023-02-15 18:43:20,323:INFO:Initializing Passive Aggressive Regressor
2023-02-15 18:43:20,323:INFO:Total runtime is 0.7594267010688781 minutes
2023-02-15 18:43:20,324:INFO:SubProcess create_model() called ==================================
2023-02-15 18:43:20,324:INFO:Initializing create_model()
2023-02-15 18:43:20,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:43:20,325:INFO:Checking exceptions
2023-02-15 18:43:20,325:INFO:Importing libraries
2023-02-15 18:43:20,325:INFO:Copying training dataset
2023-02-15 18:43:20,404:INFO:Defining folds
2023-02-15 18:43:20,404:INFO:Declaring metric variables
2023-02-15 18:43:20,406:INFO:Importing untrained model
2023-02-15 18:43:20,408:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 18:43:20,411:INFO:Starting cross validation
2023-02-15 18:43:20,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:43:24,917:INFO:Calculating mean and std
2023-02-15 18:43:24,918:INFO:Creating metrics dataframe
2023-02-15 18:43:24,920:INFO:Uploading results into container
2023-02-15 18:43:24,926:INFO:Uploading model into container now
2023-02-15 18:43:24,926:INFO:_master_model_container: 9
2023-02-15 18:43:24,926:INFO:_display_container: 2
2023-02-15 18:43:24,926:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 18:43:24,926:INFO:create_model() successfully completed......................................
2023-02-15 18:43:25,137:INFO:SubProcess create_model() end ==================================
2023-02-15 18:43:25,137:INFO:Creating metrics dataframe
2023-02-15 18:43:25,145:INFO:Initializing Huber Regressor
2023-02-15 18:43:25,146:INFO:Total runtime is 0.8398088097572326 minutes
2023-02-15 18:43:25,148:INFO:SubProcess create_model() called ==================================
2023-02-15 18:43:25,148:INFO:Initializing create_model()
2023-02-15 18:43:25,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:43:25,148:INFO:Checking exceptions
2023-02-15 18:43:25,148:INFO:Importing libraries
2023-02-15 18:43:25,148:INFO:Copying training dataset
2023-02-15 18:43:25,240:INFO:Defining folds
2023-02-15 18:43:25,240:INFO:Declaring metric variables
2023-02-15 18:43:25,243:INFO:Importing untrained model
2023-02-15 18:43:25,245:INFO:Huber Regressor Imported successfully
2023-02-15 18:43:25,248:INFO:Starting cross validation
2023-02-15 18:43:25,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:43:29,775:INFO:Calculating mean and std
2023-02-15 18:43:29,776:INFO:Creating metrics dataframe
2023-02-15 18:43:29,782:INFO:Uploading results into container
2023-02-15 18:43:29,782:INFO:Uploading model into container now
2023-02-15 18:43:29,782:INFO:_master_model_container: 10
2023-02-15 18:43:29,782:INFO:_display_container: 2
2023-02-15 18:43:29,782:INFO:HuberRegressor()
2023-02-15 18:43:29,782:INFO:create_model() successfully completed......................................
2023-02-15 18:43:29,951:INFO:SubProcess create_model() end ==================================
2023-02-15 18:43:29,951:INFO:Creating metrics dataframe
2023-02-15 18:43:29,958:INFO:Initializing K Neighbors Regressor
2023-02-15 18:43:29,958:INFO:Total runtime is 0.920018720626831 minutes
2023-02-15 18:43:29,960:INFO:SubProcess create_model() called ==================================
2023-02-15 18:43:29,960:INFO:Initializing create_model()
2023-02-15 18:43:29,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:43:29,960:INFO:Checking exceptions
2023-02-15 18:43:29,960:INFO:Importing libraries
2023-02-15 18:43:29,960:INFO:Copying training dataset
2023-02-15 18:43:30,050:INFO:Defining folds
2023-02-15 18:43:30,050:INFO:Declaring metric variables
2023-02-15 18:43:30,052:INFO:Importing untrained model
2023-02-15 18:43:30,054:INFO:K Neighbors Regressor Imported successfully
2023-02-15 18:43:30,057:INFO:Starting cross validation
2023-02-15 18:43:30,060:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:43:30,061:INFO:[I] [18:43:30.061566] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:30,352:INFO:[I] [18:43:30.351983] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:30,518:INFO:[I] [18:43:30.518590] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:30,870:INFO:[I] [18:43:30.870171] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:30,998:INFO:[I] [18:43:30.998119] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:31,348:INFO:[I] [18:43:31.348398] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:31,474:INFO:[I] [18:43:31.474903] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:31,831:INFO:[I] [18:43:31.831007] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:31,961:INFO:[I] [18:43:31.961260] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:32,311:INFO:[I] [18:43:32.311196] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:32,440:INFO:[I] [18:43:32.440101] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:32,790:INFO:[I] [18:43:32.790466] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:32,917:INFO:[I] [18:43:32.917059] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:33,270:INFO:[I] [18:43:33.270676] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:33,398:INFO:[I] [18:43:33.398854] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:33,743:INFO:[I] [18:43:33.743563] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:33,873:INFO:[I] [18:43:33.873642] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:34,229:INFO:[I] [18:43:34.229716] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:34,361:INFO:[I] [18:43:34.361881] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:34,714:INFO:[I] [18:43:34.714111] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 18:43:34,844:INFO:Calculating mean and std
2023-02-15 18:43:34,844:INFO:Creating metrics dataframe
2023-02-15 18:43:34,846:INFO:Uploading results into container
2023-02-15 18:43:34,847:INFO:Uploading model into container now
2023-02-15 18:43:34,847:INFO:_master_model_container: 11
2023-02-15 18:43:34,847:INFO:_display_container: 2
2023-02-15 18:43:34,847:INFO:KNeighborsRegressor()
2023-02-15 18:43:34,847:INFO:create_model() successfully completed......................................
2023-02-15 18:43:35,011:INFO:SubProcess create_model() end ==================================
2023-02-15 18:43:35,011:INFO:Creating metrics dataframe
2023-02-15 18:43:35,018:INFO:Initializing Decision Tree Regressor
2023-02-15 18:43:35,018:INFO:Total runtime is 1.0043527324994403 minutes
2023-02-15 18:43:35,020:INFO:SubProcess create_model() called ==================================
2023-02-15 18:43:35,020:INFO:Initializing create_model()
2023-02-15 18:43:35,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:43:35,020:INFO:Checking exceptions
2023-02-15 18:43:35,020:INFO:Importing libraries
2023-02-15 18:43:35,020:INFO:Copying training dataset
2023-02-15 18:43:35,108:INFO:Defining folds
2023-02-15 18:43:35,108:INFO:Declaring metric variables
2023-02-15 18:43:35,110:INFO:Importing untrained model
2023-02-15 18:43:35,112:INFO:Decision Tree Regressor Imported successfully
2023-02-15 18:43:35,115:INFO:Starting cross validation
2023-02-15 18:43:35,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:43:39,372:INFO:Calculating mean and std
2023-02-15 18:43:39,373:INFO:Creating metrics dataframe
2023-02-15 18:43:39,375:INFO:Uploading results into container
2023-02-15 18:43:39,376:INFO:Uploading model into container now
2023-02-15 18:43:39,376:INFO:_master_model_container: 12
2023-02-15 18:43:39,376:INFO:_display_container: 2
2023-02-15 18:43:39,376:INFO:DecisionTreeRegressor(random_state=11)
2023-02-15 18:43:39,376:INFO:create_model() successfully completed......................................
2023-02-15 18:43:39,528:INFO:SubProcess create_model() end ==================================
2023-02-15 18:43:39,529:INFO:Creating metrics dataframe
2023-02-15 18:43:39,536:INFO:Initializing Random Forest Regressor
2023-02-15 18:43:39,536:INFO:Total runtime is 1.07964817682902 minutes
2023-02-15 18:43:39,538:INFO:SubProcess create_model() called ==================================
2023-02-15 18:43:39,538:INFO:Initializing create_model()
2023-02-15 18:43:39,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f146b68e9d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f122514d5b0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 18:43:39,538:INFO:Checking exceptions
2023-02-15 18:43:39,538:INFO:Importing libraries
2023-02-15 18:43:39,538:INFO:Copying training dataset
2023-02-15 18:43:39,623:INFO:Defining folds
2023-02-15 18:43:39,623:INFO:Declaring metric variables
2023-02-15 18:43:39,625:INFO:Importing untrained model
2023-02-15 18:43:39,626:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:43:39,628:INFO:Random Forest Regressor Imported successfully
2023-02-15 18:43:39,631:INFO:Starting cross validation
2023-02-15 18:43:39,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 18:43:39,635:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:43:39,948:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:43:40,257:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:43:40,612:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:43:40,918:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:43:41,276:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:43:41,563:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 18:43:41,917:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:00:27,292:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:28,709:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:28,710:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:28,710:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:28,949:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 19:00:29,045:INFO:PyCaret RegressionExperiment
2023-02-15 19:00:29,046:INFO:Logging name: reg-default-name
2023-02-15 19:00:29,046:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 19:00:29,046:INFO:version 3.0.0.rc9
2023-02-15 19:00:29,046:INFO:Initializing setup()
2023-02-15 19:00:29,046:INFO:self.USI: e7ee
2023-02-15 19:00:29,046:INFO:self._variable_keys: {'log_plots_param', '_available_plots', 'X', 'target_param', '_ml_usecase', 'USI', 'seed', 'X_train', 'memory', 'data', 'fold_shuffle_param', 'logging_param', 'pipeline', 'exp_id', 'idx', 'transform_target_param', 'y_train', 'gpu_n_jobs_param', 'X_test', 'y', 'y_test', 'html_param', 'fold_groups_param', 'gpu_param', 'n_jobs_param', 'exp_name_log', 'fold_generator'}
2023-02-15 19:00:29,046:INFO:Checking environment
2023-02-15 19:00:29,046:INFO:python_version: 3.8.16
2023-02-15 19:00:29,046:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-15 19:00:29,046:INFO:machine: x86_64
2023-02-15 19:00:29,059:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 19:00:29,059:INFO:Memory: svmem(total=134979592192, available=116850343936, percent=13.4, used=16096202752, free=33190887424, active=11194925056, inactive=86711603200, buffers=1227587584, cached=84464914432, shared=761036800, slab=3140079616)
2023-02-15 19:00:29,060:INFO:Physical Core: 16
2023-02-15 19:00:29,060:INFO:Logical Core: 32
2023-02-15 19:00:29,060:INFO:Checking libraries
2023-02-15 19:00:29,060:INFO:System:
2023-02-15 19:00:29,060:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-15 19:00:29,060:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 19:00:29,060:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 19:00:29,060:INFO:PyCaret required dependencies:
2023-02-15 19:00:29,060:INFO:                 pip: 23.0
2023-02-15 19:00:29,060:INFO:          setuptools: 60.10.0
2023-02-15 19:00:29,060:INFO:             pycaret: 3.0.0rc9
2023-02-15 19:00:29,061:INFO:             IPython: 8.10.0
2023-02-15 19:00:29,061:INFO:          ipywidgets: 7.7.3
2023-02-15 19:00:29,061:INFO:                tqdm: 4.64.1
2023-02-15 19:00:29,061:INFO:               numpy: 1.23.5
2023-02-15 19:00:29,061:INFO:              pandas: 1.5.3
2023-02-15 19:00:29,061:INFO:              jinja2: 3.1.2
2023-02-15 19:00:29,061:INFO:               scipy: 1.9.1
2023-02-15 19:00:29,061:INFO:              joblib: 1.2.0
2023-02-15 19:00:29,061:INFO:             sklearn: 1.2.1
2023-02-15 19:00:29,061:INFO:                pyod: 1.0.7
2023-02-15 19:00:29,061:INFO:            imblearn: 0.10.1
2023-02-15 19:00:29,061:INFO:   category_encoders: 2.6.0
2023-02-15 19:00:29,061:INFO:            lightgbm: 3.3.5.99
2023-02-15 19:00:29,061:INFO:               numba: 0.56.4
2023-02-15 19:00:29,061:INFO:            requests: 2.28.2
2023-02-15 19:00:29,061:INFO:          matplotlib: 3.6.3
2023-02-15 19:00:29,061:INFO:          scikitplot: 0.3.7
2023-02-15 19:00:29,061:INFO:         yellowbrick: 1.5
2023-02-15 19:00:29,061:INFO:              plotly: 5.13.0
2023-02-15 19:00:29,061:INFO:             kaleido: 0.2.1
2023-02-15 19:00:29,061:INFO:         statsmodels: 0.13.5
2023-02-15 19:00:29,061:INFO:              sktime: 0.16.1
2023-02-15 19:00:29,061:INFO:               tbats: 1.1.2
2023-02-15 19:00:29,061:INFO:            pmdarima: 2.0.2
2023-02-15 19:00:29,061:INFO:              psutil: 5.9.4
2023-02-15 19:00:29,061:INFO:PyCaret optional dependencies:
2023-02-15 19:00:29,700:INFO:                shap: 0.41.0
2023-02-15 19:00:29,701:INFO:           interpret: 0.3.0
2023-02-15 19:00:29,701:INFO:                umap: 0.5.3
2023-02-15 19:00:29,701:INFO:    pandas_profiling: 4.0.0
2023-02-15 19:00:29,701:INFO:  explainerdashboard: 0.4.2
2023-02-15 19:00:29,701:INFO:             autoviz: 0.1.58
2023-02-15 19:00:29,701:INFO:           fairlearn: 0.7.0
2023-02-15 19:00:29,701:INFO:             xgboost: 1.7.3
2023-02-15 19:00:29,701:INFO:            catboost: 1.1.1
2023-02-15 19:00:29,701:INFO:              kmodes: 0.12.2
2023-02-15 19:00:29,701:INFO:             mlxtend: 0.21.0
2023-02-15 19:00:29,701:INFO:       statsforecast: 1.4.0
2023-02-15 19:00:29,701:INFO:        tune_sklearn: 0.4.5
2023-02-15 19:00:29,701:INFO:                 ray: 2.2.0
2023-02-15 19:00:29,701:INFO:            hyperopt: 0.2.7
2023-02-15 19:00:29,701:INFO:              optuna: 3.1.0
2023-02-15 19:00:29,701:INFO:               skopt: 0.9.0
2023-02-15 19:00:29,701:INFO:              mlflow: 1.30.0
2023-02-15 19:00:29,701:INFO:              gradio: 3.18.0
2023-02-15 19:00:29,701:INFO:             fastapi: 0.92.0
2023-02-15 19:00:29,701:INFO:             uvicorn: 0.20.0
2023-02-15 19:00:29,701:INFO:              m2cgen: 0.10.0
2023-02-15 19:00:29,701:INFO:           evidently: 0.2.4
2023-02-15 19:00:29,701:INFO:               fugue: 0.8.1.dev4
2023-02-15 19:00:29,701:INFO:           streamlit: Not installed
2023-02-15 19:00:29,701:INFO:             prophet: Not installed
2023-02-15 19:00:29,701:INFO:None
2023-02-15 19:00:29,701:INFO:Set up GPU usage.
2023-02-15 19:00:29,701:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:29,701:INFO:cuml==23.2.0
2023-02-15 19:00:29,701:ERROR:Couldn't set cuML global output type
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/tabular_experiment.py", line 351, in _initialize_setup
    import cuml.common.memory_utils
ModuleNotFoundError: No module named 'cuml.common.memory_utils'
2023-02-15 19:00:29,701:INFO:Set up data.
2023-02-15 19:00:30,123:INFO:Set up train/test split.
2023-02-15 19:00:30,454:INFO:Set up index.
2023-02-15 19:00:30,541:INFO:Set up folding strategy.
2023-02-15 19:00:30,541:INFO:Assigning column types.
2023-02-15 19:00:30,730:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 19:00:30,730:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:30,730:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:30,730:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 19:00:30,730:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:30,730:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:30,733:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:00:30,733:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:30,733:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:30,736:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:00:30,736:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:30,736:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:30,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:00:30,921:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:30,921:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:30,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:00:30,949:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:30,949:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:30,950:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:30,950:INFO:Imported cuml.ensemble
2023-02-15 19:00:30,951:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:31,317:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:31,396:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,397:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:31,397:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 19:00:31,397:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,397:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:31,399:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:00:31,399:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,399:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:31,402:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:00:31,402:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,402:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:31,564:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:00:31,565:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,565:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:31,612:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:00:31,613:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,613:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:31,613:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,613:INFO:Imported cuml.ensemble
2023-02-15 19:00:31,614:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:31,715:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:31,809:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 19:00:31,809:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,809:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:31,809:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,809:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:31,812:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:00:31,812:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,812:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:31,815:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:00:31,815:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:31,815:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:32,002:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:00:32,002:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,002:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:32,030:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:00:32,030:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,030:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:32,030:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,030:INFO:Imported cuml.ensemble
2023-02-15 19:00:32,031:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:32,150:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:32,215:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,215:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:32,215:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,215:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:32,218:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:00:32,218:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,218:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:32,221:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:00:32,221:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,221:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:32,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:00:32,426:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,426:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:32,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:00:32,454:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,454:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:32,454:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,455:INFO:Imported cuml.ensemble
2023-02-15 19:00:32,455:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:32,559:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:32,631:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 19:00:32,631:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,631:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:32,631:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,631:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:32,634:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,634:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:32,637:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:00:32,637:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,637:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:32,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:00:32,839:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,839:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:32,870:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:00:32,870:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,870:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:32,871:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:32,871:INFO:Imported cuml.ensemble
2023-02-15 19:00:32,871:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:32,992:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:33,067:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,067:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:33,067:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,067:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:33,070:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,070:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:33,073:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:00:33,073:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,073:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:33,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:00:33,279:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,279:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:33,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:00:33,308:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,308:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:33,308:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,308:INFO:Imported cuml.ensemble
2023-02-15 19:00:33,309:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:33,422:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:33,507:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 19:00:33,507:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,507:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:33,507:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,507:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:33,510:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,510:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:33,513:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,513:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:33,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:00:33,703:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,703:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:33,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:00:33,731:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,731:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:33,731:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,731:INFO:Imported cuml.ensemble
2023-02-15 19:00:33,731:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:33,840:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:33,897:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,897:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:33,897:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,897:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:33,900:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,900:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:33,903:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:33,903:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:34,080:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:00:34,080:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,081:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:34,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:00:34,108:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,108:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:34,108:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,108:INFO:Imported cuml.ensemble
2023-02-15 19:00:34,109:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:34,207:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:34,284:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 19:00:34,285:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,285:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:34,285:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,285:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:34,288:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,288:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:34,290:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,290:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:34,470:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:00:34,470:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,470:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:34,498:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,498:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:34,498:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,499:INFO:Imported cuml.ensemble
2023-02-15 19:00:34,499:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:34,607:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:34,682:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,682:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:34,682:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,682:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:34,685:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,685:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:34,687:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,687:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:34,868:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:00:34,868:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,868:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:34,895:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,895:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:34,896:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:34,896:INFO:Imported cuml.ensemble
2023-02-15 19:00:34,896:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:35,010:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:35,096:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 19:00:35,096:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,096:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:35,096:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,096:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:35,099:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,099:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:35,102:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,102:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:35,270:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,270:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:35,297:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,297:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:35,297:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,297:INFO:Imported cuml.ensemble
2023-02-15 19:00:35,297:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:35,398:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:35,473:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,473:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:35,473:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,473:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:35,476:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,476:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:35,479:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,479:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:35,647:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,647:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:35,675:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,675:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:35,675:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:35,675:INFO:Imported cuml.ensemble
2023-02-15 19:00:35,675:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:35,800:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:35,930:INFO:Preparing preprocessing pipeline...
2023-02-15 19:00:35,967:INFO:Set up column name cleaning.
2023-02-15 19:00:35,967:INFO:Set up simple imputation.
2023-02-15 19:00:35,968:INFO:Set up feature normalization.
2023-02-15 19:00:36,928:INFO:Finished creating preprocessing pipeline.
2023-02-15 19:00:36,935:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 19:00:36,935:INFO:Creating final display dataframe.
2023-02-15 19:00:38,255:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28569, 780)
4        Transformed data shape           (28569, 775)
5   Transformed train set shape           (19998, 775)
6    Transformed test set shape            (8571, 775)
7               Ignore features                      5
8              Numeric features                    774
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   e7ee
2023-02-15 19:00:38,258:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,258:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:38,258:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,258:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:38,261:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,261:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:38,264:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,264:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:38,474:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,474:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:38,502:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,503:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:38,503:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,503:INFO:Imported cuml.ensemble
2023-02-15 19:00:38,504:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:38,614:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:38,696:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,696:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:00:38,696:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,696:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:00:38,699:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,699:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:00:38,702:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,702:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:00:38,864:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,865:INFO:Imported cuml.svm.SVR
2023-02-15 19:00:38,893:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,893:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:00:38,894:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:00:38,894:INFO:Imported cuml.ensemble
2023-02-15 19:00:38,894:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:00:39,009:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:00:39,079:INFO:setup() successfully completed in 10.03s...............
2023-02-15 19:00:39,079:INFO:Initializing compare_models()
2023-02-15 19:00:39,079:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 19:00:39,079:INFO:Checking exceptions
2023-02-15 19:00:39,164:INFO:Preparing display monitor
2023-02-15 19:00:39,168:INFO:Initializing Linear Regression
2023-02-15 19:00:39,169:INFO:Total runtime is 3.111362457275391e-06 minutes
2023-02-15 19:00:39,169:INFO:SubProcess create_model() called ==================================
2023-02-15 19:00:39,169:INFO:Initializing create_model()
2023-02-15 19:00:39,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:00:39,169:INFO:Checking exceptions
2023-02-15 19:00:39,169:INFO:Importing libraries
2023-02-15 19:00:39,169:INFO:Copying training dataset
2023-02-15 19:00:39,368:INFO:Defining folds
2023-02-15 19:00:39,368:INFO:Declaring metric variables
2023-02-15 19:00:39,368:INFO:Importing untrained model
2023-02-15 19:00:39,369:INFO:Linear Regression Imported successfully
2023-02-15 19:00:39,370:INFO:Starting cross validation
2023-02-15 19:00:39,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:00:54,178:INFO:Calculating mean and std
2023-02-15 19:00:54,179:INFO:Creating metrics dataframe
2023-02-15 19:00:54,181:INFO:Uploading results into container
2023-02-15 19:00:54,181:INFO:Uploading model into container now
2023-02-15 19:00:54,181:INFO:_master_model_container: 1
2023-02-15 19:00:54,181:INFO:_display_container: 2
2023-02-15 19:00:54,181:INFO:LinearRegression()
2023-02-15 19:00:54,181:INFO:create_model() successfully completed......................................
2023-02-15 19:00:54,541:INFO:SubProcess create_model() end ==================================
2023-02-15 19:00:54,542:INFO:Creating metrics dataframe
2023-02-15 19:00:54,545:INFO:Initializing Lasso Regression
2023-02-15 19:00:54,545:INFO:Total runtime is 0.25627437432607014 minutes
2023-02-15 19:00:54,545:INFO:SubProcess create_model() called ==================================
2023-02-15 19:00:54,545:INFO:Initializing create_model()
2023-02-15 19:00:54,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:00:54,545:INFO:Checking exceptions
2023-02-15 19:00:54,545:INFO:Importing libraries
2023-02-15 19:00:54,545:INFO:Copying training dataset
2023-02-15 19:00:54,729:INFO:Defining folds
2023-02-15 19:00:54,730:INFO:Declaring metric variables
2023-02-15 19:00:54,730:INFO:Importing untrained model
2023-02-15 19:00:54,731:INFO:Lasso Regression Imported successfully
2023-02-15 19:00:54,731:INFO:Starting cross validation
2023-02-15 19:00:54,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:00:59,883:INFO:Calculating mean and std
2023-02-15 19:00:59,884:INFO:Creating metrics dataframe
2023-02-15 19:00:59,886:INFO:Uploading results into container
2023-02-15 19:00:59,886:INFO:Uploading model into container now
2023-02-15 19:00:59,886:INFO:_master_model_container: 2
2023-02-15 19:00:59,886:INFO:_display_container: 2
2023-02-15 19:00:59,886:INFO:Lasso()
2023-02-15 19:00:59,886:INFO:create_model() successfully completed......................................
2023-02-15 19:01:00,117:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:00,117:INFO:Creating metrics dataframe
2023-02-15 19:01:00,121:INFO:Initializing Ridge Regression
2023-02-15 19:01:00,121:INFO:Total runtime is 0.3492078463236491 minutes
2023-02-15 19:01:00,121:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:00,121:INFO:Initializing create_model()
2023-02-15 19:01:00,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:00,121:INFO:Checking exceptions
2023-02-15 19:01:00,121:INFO:Importing libraries
2023-02-15 19:01:00,121:INFO:Copying training dataset
2023-02-15 19:01:00,260:INFO:Defining folds
2023-02-15 19:01:00,260:INFO:Declaring metric variables
2023-02-15 19:01:00,260:INFO:Importing untrained model
2023-02-15 19:01:00,261:INFO:Ridge Regression Imported successfully
2023-02-15 19:01:00,261:INFO:Starting cross validation
2023-02-15 19:01:00,263:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:01:00,926:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:01:02,072:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:01:02,072:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:01:02,073:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:01:02,254:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 19:01:02,563:INFO:PyCaret RegressionExperiment
2023-02-15 19:01:02,564:INFO:Logging name: reg-default-name
2023-02-15 19:01:02,564:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 19:01:02,564:INFO:version 3.0.0.rc9
2023-02-15 19:01:02,564:INFO:Initializing setup()
2023-02-15 19:01:02,564:INFO:self.USI: d747
2023-02-15 19:01:02,564:INFO:self._variable_keys: {'fold_generator', 'memory', 'seed', 'gpu_n_jobs_param', 'y_train', 'X_train', 'data', 'pipeline', 'y', 'exp_id', 'target_param', 'html_param', '_ml_usecase', 'USI', 'fold_groups_param', 'logging_param', 'n_jobs_param', 'idx', '_available_plots', 'exp_name_log', 'X_test', 'y_test', 'gpu_param', 'log_plots_param', 'X', 'transform_target_param', 'fold_shuffle_param'}
2023-02-15 19:01:02,564:INFO:Checking environment
2023-02-15 19:01:02,564:INFO:python_version: 3.8.16
2023-02-15 19:01:02,564:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-15 19:01:02,564:INFO:machine: x86_64
2023-02-15 19:01:02,564:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 19:01:02,564:INFO:Memory: svmem(total=134979592192, available=113522311168, percent=15.9, used=19062226944, free=28747276288, active=11809374208, inactive=90394628096, buffers=1228271616, cached=85941817344, shared=1123045376, slab=3180220416)
2023-02-15 19:01:02,565:INFO:Physical Core: 16
2023-02-15 19:01:02,565:INFO:Logical Core: 32
2023-02-15 19:01:02,565:INFO:Checking libraries
2023-02-15 19:01:02,565:INFO:System:
2023-02-15 19:01:02,565:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-15 19:01:02,565:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 19:01:02,565:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 19:01:02,565:INFO:PyCaret required dependencies:
2023-02-15 19:01:02,565:INFO:                 pip: 23.0
2023-02-15 19:01:02,565:INFO:          setuptools: 60.10.0
2023-02-15 19:01:02,565:INFO:             pycaret: 3.0.0rc9
2023-02-15 19:01:02,565:INFO:             IPython: 8.10.0
2023-02-15 19:01:02,565:INFO:          ipywidgets: 7.7.3
2023-02-15 19:01:02,565:INFO:                tqdm: 4.64.1
2023-02-15 19:01:02,565:INFO:               numpy: 1.23.5
2023-02-15 19:01:02,565:INFO:              pandas: 1.5.3
2023-02-15 19:01:02,565:INFO:              jinja2: 3.1.2
2023-02-15 19:01:02,565:INFO:               scipy: 1.9.1
2023-02-15 19:01:02,565:INFO:              joblib: 1.2.0
2023-02-15 19:01:02,565:INFO:             sklearn: 1.2.1
2023-02-15 19:01:02,565:INFO:                pyod: 1.0.7
2023-02-15 19:01:02,565:INFO:            imblearn: 0.10.1
2023-02-15 19:01:02,565:INFO:   category_encoders: 2.6.0
2023-02-15 19:01:02,565:INFO:            lightgbm: 3.3.5.99
2023-02-15 19:01:02,565:INFO:               numba: 0.56.4
2023-02-15 19:01:02,565:INFO:            requests: 2.28.2
2023-02-15 19:01:02,565:INFO:          matplotlib: 3.6.3
2023-02-15 19:01:02,565:INFO:          scikitplot: 0.3.7
2023-02-15 19:01:02,565:INFO:         yellowbrick: 1.5
2023-02-15 19:01:02,565:INFO:              plotly: 5.13.0
2023-02-15 19:01:02,565:INFO:             kaleido: 0.2.1
2023-02-15 19:01:02,565:INFO:         statsmodels: 0.13.5
2023-02-15 19:01:02,565:INFO:              sktime: 0.16.1
2023-02-15 19:01:02,565:INFO:               tbats: 1.1.2
2023-02-15 19:01:02,565:INFO:            pmdarima: 2.0.2
2023-02-15 19:01:02,565:INFO:              psutil: 5.9.4
2023-02-15 19:01:02,565:INFO:PyCaret optional dependencies:
2023-02-15 19:01:02,830:INFO:                shap: 0.41.0
2023-02-15 19:01:02,830:INFO:           interpret: 0.3.0
2023-02-15 19:01:02,830:INFO:                umap: 0.5.3
2023-02-15 19:01:02,830:INFO:    pandas_profiling: 4.0.0
2023-02-15 19:01:02,830:INFO:  explainerdashboard: 0.4.2
2023-02-15 19:01:02,830:INFO:             autoviz: 0.1.58
2023-02-15 19:01:02,830:INFO:           fairlearn: 0.7.0
2023-02-15 19:01:02,830:INFO:             xgboost: 1.7.3
2023-02-15 19:01:02,830:INFO:            catboost: 1.1.1
2023-02-15 19:01:02,830:INFO:              kmodes: 0.12.2
2023-02-15 19:01:02,830:INFO:             mlxtend: 0.21.0
2023-02-15 19:01:02,830:INFO:       statsforecast: 1.4.0
2023-02-15 19:01:02,830:INFO:        tune_sklearn: 0.4.5
2023-02-15 19:01:02,830:INFO:                 ray: 2.2.0
2023-02-15 19:01:02,830:INFO:            hyperopt: 0.2.7
2023-02-15 19:01:02,830:INFO:              optuna: 3.1.0
2023-02-15 19:01:02,830:INFO:               skopt: 0.9.0
2023-02-15 19:01:02,830:INFO:              mlflow: 1.30.0
2023-02-15 19:01:02,830:INFO:              gradio: 3.18.0
2023-02-15 19:01:02,830:INFO:             fastapi: 0.92.0
2023-02-15 19:01:02,830:INFO:             uvicorn: 0.20.0
2023-02-15 19:01:02,830:INFO:              m2cgen: 0.10.0
2023-02-15 19:01:02,830:INFO:           evidently: 0.2.4
2023-02-15 19:01:02,830:INFO:               fugue: 0.8.1.dev4
2023-02-15 19:01:02,830:INFO:           streamlit: Not installed
2023-02-15 19:01:02,830:INFO:             prophet: Not installed
2023-02-15 19:01:02,830:INFO:None
2023-02-15 19:01:02,830:INFO:Set up data.
2023-02-15 19:01:03,255:INFO:Set up train/test split.
2023-02-15 19:01:03,491:INFO:Set up index.
2023-02-15 19:01:03,543:INFO:Set up folding strategy.
2023-02-15 19:01:03,543:INFO:Assigning column types.
2023-02-15 19:01:03,714:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 19:01:03,715:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 19:01:03,718:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:01:03,720:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:01:03,879:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:01:03,907:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:01:03,907:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:04,016:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:04,030:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,039:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,042:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,242:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:04,244:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:04,245:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 19:01:04,248:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,250:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,453:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,454:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:04,455:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:04,459:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,610:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,634:INFO:Calculating mean and std
2023-02-15 19:01:04,634:INFO:Creating metrics dataframe
2023-02-15 19:01:04,636:INFO:Uploading results into container
2023-02-15 19:01:04,636:INFO:Uploading model into container now
2023-02-15 19:01:04,637:INFO:_master_model_container: 3
2023-02-15 19:01:04,637:INFO:_display_container: 2
2023-02-15 19:01:04,637:INFO:Ridge()
2023-02-15 19:01:04,637:INFO:create_model() successfully completed......................................
2023-02-15 19:01:04,637:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,637:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:04,639:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:04,640:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 19:01:04,645:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,818:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:04,820:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:04,826:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,928:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:04,929:INFO:Creating metrics dataframe
2023-02-15 19:01:04,933:INFO:Initializing Elastic Net
2023-02-15 19:01:04,933:INFO:Total runtime is 0.4294047673543294 minutes
2023-02-15 19:01:04,933:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:04,933:INFO:Initializing create_model()
2023-02-15 19:01:04,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:04,933:INFO:Checking exceptions
2023-02-15 19:01:04,933:INFO:Importing libraries
2023-02-15 19:01:04,933:INFO:Copying training dataset
2023-02-15 19:01:04,960:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,987:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:01:04,988:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:04,989:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:04,990:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 19:01:05,104:INFO:Defining folds
2023-02-15 19:01:05,104:INFO:Declaring metric variables
2023-02-15 19:01:05,104:INFO:Importing untrained model
2023-02-15 19:01:05,105:INFO:Elastic Net Imported successfully
2023-02-15 19:01:05,105:INFO:Starting cross validation
2023-02-15 19:01:05,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:01:05,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:01:05,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:01:05,196:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:05,198:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:05,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:01:05,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:01:05,395:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:05,397:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:05,397:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 19:01:05,532:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:01:05,560:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:05,561:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:05,723:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:01:05,751:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:05,753:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:05,754:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 19:01:05,939:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:05,942:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:06,146:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:06,148:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:06,149:INFO:Preparing preprocessing pipeline...
2023-02-15 19:01:06,171:INFO:Set up column name cleaning.
2023-02-15 19:01:06,171:INFO:Set up simple imputation.
2023-02-15 19:01:06,171:INFO:Set up feature normalization.
2023-02-15 19:01:06,527:INFO:Finished creating preprocessing pipeline.
2023-02-15 19:01:06,534:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 19:01:06,534:INFO:Creating final display dataframe.
2023-02-15 19:01:07,498:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28569, 780)
4        Transformed data shape           (28569, 775)
5   Transformed train set shape           (19998, 775)
6    Transformed test set shape            (8571, 775)
7               Ignore features                      5
8              Numeric features                    774
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   d747
2023-02-15 19:01:07,673:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:07,675:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:07,869:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:01:07,871:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:01:07,872:INFO:setup() successfully completed in 5.31s...............
2023-02-15 19:01:07,872:INFO:Initializing compare_models()
2023-02-15 19:01:07,872:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 19:01:07,872:INFO:Checking exceptions
2023-02-15 19:01:07,937:INFO:Preparing display monitor
2023-02-15 19:01:07,953:INFO:Initializing Linear Regression
2023-02-15 19:01:07,953:INFO:Total runtime is 2.07821528116862e-06 minutes
2023-02-15 19:01:07,955:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:07,955:INFO:Initializing create_model()
2023-02-15 19:01:07,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:07,955:INFO:Checking exceptions
2023-02-15 19:01:07,955:INFO:Importing libraries
2023-02-15 19:01:07,955:INFO:Copying training dataset
2023-02-15 19:01:08,104:INFO:Defining folds
2023-02-15 19:01:08,104:INFO:Declaring metric variables
2023-02-15 19:01:08,107:INFO:Importing untrained model
2023-02-15 19:01:08,109:INFO:Linear Regression Imported successfully
2023-02-15 19:01:08,112:INFO:Starting cross validation
2023-02-15 19:01:08,116:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:09,490:INFO:Calculating mean and std
2023-02-15 19:01:09,490:INFO:Creating metrics dataframe
2023-02-15 19:01:09,493:INFO:Uploading results into container
2023-02-15 19:01:09,493:INFO:Uploading model into container now
2023-02-15 19:01:09,493:INFO:_master_model_container: 4
2023-02-15 19:01:09,493:INFO:_display_container: 2
2023-02-15 19:01:09,493:INFO:ElasticNet()
2023-02-15 19:01:09,493:INFO:create_model() successfully completed......................................
2023-02-15 19:01:09,860:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:09,860:INFO:Creating metrics dataframe
2023-02-15 19:01:09,864:INFO:Initializing Least Angle Regression
2023-02-15 19:01:09,864:INFO:Total runtime is 0.5115988572438558 minutes
2023-02-15 19:01:09,864:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:09,865:INFO:Initializing create_model()
2023-02-15 19:01:09,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:09,865:INFO:Checking exceptions
2023-02-15 19:01:09,865:INFO:Importing libraries
2023-02-15 19:01:09,865:INFO:Copying training dataset
2023-02-15 19:01:10,240:INFO:Defining folds
2023-02-15 19:01:10,240:INFO:Declaring metric variables
2023-02-15 19:01:10,241:INFO:Importing untrained model
2023-02-15 19:01:10,241:INFO:Least Angle Regression Imported successfully
2023-02-15 19:01:10,241:INFO:Starting cross validation
2023-02-15 19:01:10,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:01:11,748:INFO:Calculating mean and std
2023-02-15 19:01:11,750:INFO:Creating metrics dataframe
2023-02-15 19:01:11,756:INFO:Uploading results into container
2023-02-15 19:01:11,757:INFO:Uploading model into container now
2023-02-15 19:01:11,758:INFO:_master_model_container: 1
2023-02-15 19:01:11,758:INFO:_display_container: 2
2023-02-15 19:01:11,758:INFO:LinearRegression(n_jobs=-1)
2023-02-15 19:01:11,758:INFO:create_model() successfully completed......................................
2023-02-15 19:01:12,070:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:12,070:INFO:Creating metrics dataframe
2023-02-15 19:01:12,079:INFO:Initializing Lasso Regression
2023-02-15 19:01:12,080:INFO:Total runtime is 0.06877305110295613 minutes
2023-02-15 19:01:12,083:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:12,084:INFO:Initializing create_model()
2023-02-15 19:01:12,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:12,084:INFO:Checking exceptions
2023-02-15 19:01:12,084:INFO:Importing libraries
2023-02-15 19:01:12,084:INFO:Copying training dataset
2023-02-15 19:01:12,274:INFO:Defining folds
2023-02-15 19:01:12,275:INFO:Declaring metric variables
2023-02-15 19:01:12,278:INFO:Importing untrained model
2023-02-15 19:01:12,280:INFO:Lasso Regression Imported successfully
2023-02-15 19:01:12,283:INFO:Starting cross validation
2023-02-15 19:01:12,286:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:12,555:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.277e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:12,555:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 19:01:12,588:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.066e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:13,435:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=4.772e-03, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:13,435:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=4.771e-03, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:14,817:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:01:15,045:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:01:15,394:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:01:15,891:INFO:Calculating mean and std
2023-02-15 19:01:15,892:INFO:Creating metrics dataframe
2023-02-15 19:01:15,895:INFO:Uploading results into container
2023-02-15 19:01:15,895:INFO:Uploading model into container now
2023-02-15 19:01:15,896:INFO:_master_model_container: 2
2023-02-15 19:01:15,896:INFO:_display_container: 2
2023-02-15 19:01:15,896:INFO:Lasso(random_state=11)
2023-02-15 19:01:15,896:INFO:create_model() successfully completed......................................
2023-02-15 19:01:16,202:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:16,203:INFO:Creating metrics dataframe
2023-02-15 19:01:16,210:INFO:Initializing Ridge Regression
2023-02-15 19:01:16,210:INFO:Total runtime is 0.13761534293492633 minutes
2023-02-15 19:01:16,212:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:16,212:INFO:Initializing create_model()
2023-02-15 19:01:16,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:16,212:INFO:Checking exceptions
2023-02-15 19:01:16,213:INFO:Importing libraries
2023-02-15 19:01:16,213:INFO:Copying training dataset
2023-02-15 19:01:16,303:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:01:16,303:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:01:16,303:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:01:16,376:INFO:Defining folds
2023-02-15 19:01:16,376:INFO:Declaring metric variables
2023-02-15 19:01:16,380:INFO:Importing untrained model
2023-02-15 19:01:16,383:INFO:Ridge Regression Imported successfully
2023-02-15 19:01:16,388:INFO:Starting cross validation
2023-02-15 19:01:16,393:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:17,444:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.570e-03, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:18,373:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:01:18,485:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:01:18,509:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.72048e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 19:01:18,513:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.70067e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 19:01:18,647:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.69172e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 19:01:18,909:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.67093e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 19:01:18,973:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.69889e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 19:01:19,072:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.7266e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 19:01:19,076:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.69351e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 19:01:19,173:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.64905e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 19:01:19,253:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.6808e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 19:01:19,379:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.43004e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-02-15 19:01:19,630:INFO:Calculating mean and std
2023-02-15 19:01:19,632:INFO:Creating metrics dataframe
2023-02-15 19:01:19,638:INFO:Uploading results into container
2023-02-15 19:01:19,639:INFO:Uploading model into container now
2023-02-15 19:01:19,639:INFO:_master_model_container: 3
2023-02-15 19:01:19,639:INFO:_display_container: 2
2023-02-15 19:01:19,640:INFO:Ridge(random_state=11)
2023-02-15 19:01:19,640:INFO:create_model() successfully completed......................................
2023-02-15 19:01:19,991:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:19,991:INFO:Creating metrics dataframe
2023-02-15 19:01:20,001:INFO:Initializing Elastic Net
2023-02-15 19:01:20,001:INFO:Total runtime is 0.2007990996042887 minutes
2023-02-15 19:01:20,004:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:20,004:INFO:Initializing create_model()
2023-02-15 19:01:20,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:20,004:INFO:Checking exceptions
2023-02-15 19:01:20,004:INFO:Importing libraries
2023-02-15 19:01:20,004:INFO:Copying training dataset
2023-02-15 19:01:20,024:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.635e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:20,145:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.470e-03, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:20,153:INFO:Defining folds
2023-02-15 19:01:20,153:INFO:Declaring metric variables
2023-02-15 19:01:20,156:INFO:Importing untrained model
2023-02-15 19:01:20,159:INFO:Elastic Net Imported successfully
2023-02-15 19:01:20,161:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=2.868e-03, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:20,163:INFO:Starting cross validation
2023-02-15 19:01:20,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:20,210:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=3.370e-03, with an active set of 138 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:22,136:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:01:22,234:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:01:22,414:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:01:23,026:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 19:01:23,026:INFO:Calculating mean and std
2023-02-15 19:01:23,026:INFO:Creating metrics dataframe
2023-02-15 19:01:23,029:INFO:Uploading results into container
2023-02-15 19:01:23,030:INFO:Uploading model into container now
2023-02-15 19:01:23,030:INFO:_master_model_container: 5
2023-02-15 19:01:23,030:INFO:_display_container: 2
2023-02-15 19:01:23,030:INFO:Lars(random_state=11)
2023-02-15 19:01:23,030:INFO:create_model() successfully completed......................................
2023-02-15 19:01:23,233:INFO:Calculating mean and std
2023-02-15 19:01:23,235:INFO:Creating metrics dataframe
2023-02-15 19:01:23,239:INFO:Uploading results into container
2023-02-15 19:01:23,239:INFO:Uploading model into container now
2023-02-15 19:01:23,240:INFO:_master_model_container: 4
2023-02-15 19:01:23,240:INFO:_display_container: 2
2023-02-15 19:01:23,240:INFO:ElasticNet(random_state=11)
2023-02-15 19:01:23,240:INFO:create_model() successfully completed......................................
2023-02-15 19:01:23,298:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:23,298:INFO:Creating metrics dataframe
2023-02-15 19:01:23,301:INFO:Initializing Lasso Least Angle Regression
2023-02-15 19:01:23,301:INFO:Total runtime is 0.7355513254801432 minutes
2023-02-15 19:01:23,302:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:23,302:INFO:Initializing create_model()
2023-02-15 19:01:23,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:23,302:INFO:Checking exceptions
2023-02-15 19:01:23,302:INFO:Importing libraries
2023-02-15 19:01:23,302:INFO:Copying training dataset
2023-02-15 19:01:23,438:INFO:Defining folds
2023-02-15 19:01:23,438:INFO:Declaring metric variables
2023-02-15 19:01:23,438:INFO:Importing untrained model
2023-02-15 19:01:23,438:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 19:01:23,438:INFO:Starting cross validation
2023-02-15 19:01:23,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:01:23,572:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:23,572:INFO:Creating metrics dataframe
2023-02-15 19:01:23,579:INFO:Initializing Least Angle Regression
2023-02-15 19:01:23,579:INFO:Total runtime is 0.26042501529057815 minutes
2023-02-15 19:01:23,581:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:23,581:INFO:Initializing create_model()
2023-02-15 19:01:23,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:23,581:INFO:Checking exceptions
2023-02-15 19:01:23,581:INFO:Importing libraries
2023-02-15 19:01:23,581:INFO:Copying training dataset
2023-02-15 19:01:23,757:INFO:Defining folds
2023-02-15 19:01:23,758:INFO:Declaring metric variables
2023-02-15 19:01:23,770:INFO:Importing untrained model
2023-02-15 19:01:23,773:INFO:Least Angle Regression Imported successfully
2023-02-15 19:01:23,779:INFO:Starting cross validation
2023-02-15 19:01:23,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:25,044:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.277e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:25,044:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 19:01:25,045:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.066e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:25,060:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=7.603e-03, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:25,061:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=7.396e-03, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:25,128:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:713: RuntimeWarning: overflow encountered in multiply
  least_squares *= AA

2023-02-15 19:01:25,135:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: invalid value encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-02-15 19:01:25,451:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:01:25,451:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:01:25,451:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:01:25,524:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.636e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:25,530:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:01:25,549:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=3.705e-03, with an active set of 162 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:01:25,585:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:01:25,680:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:01:25,803:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:01:26,053:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 603, in _lars_path_solver
    sign_active[n_active] = np.sign(C_)
ValueError: cannot convert float NaN to integer

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 19:01:26,054:INFO:Calculating mean and std
2023-02-15 19:01:26,055:INFO:Creating metrics dataframe
2023-02-15 19:01:26,059:INFO:Uploading results into container
2023-02-15 19:01:26,059:INFO:Uploading model into container now
2023-02-15 19:01:26,060:INFO:_master_model_container: 5
2023-02-15 19:01:26,060:INFO:_display_container: 2
2023-02-15 19:01:26,060:INFO:Lars(random_state=11)
2023-02-15 19:01:26,061:INFO:create_model() successfully completed......................................
2023-02-15 19:01:26,373:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:26,373:INFO:Creating metrics dataframe
2023-02-15 19:01:26,382:INFO:Initializing Lasso Least Angle Regression
2023-02-15 19:01:26,382:INFO:Total runtime is 0.30715430577596026 minutes
2023-02-15 19:01:26,385:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:26,385:INFO:Initializing create_model()
2023-02-15 19:01:26,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:26,386:INFO:Checking exceptions
2023-02-15 19:01:26,386:INFO:Importing libraries
2023-02-15 19:01:26,386:INFO:Copying training dataset
2023-02-15 19:01:26,540:INFO:Defining folds
2023-02-15 19:01:26,541:INFO:Declaring metric variables
2023-02-15 19:01:26,544:INFO:Importing untrained model
2023-02-15 19:01:26,546:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 19:01:26,550:INFO:Starting cross validation
2023-02-15 19:01:26,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:28,703:INFO:Calculating mean and std
2023-02-15 19:01:28,704:INFO:Creating metrics dataframe
2023-02-15 19:01:28,707:INFO:Uploading results into container
2023-02-15 19:01:28,708:INFO:Uploading model into container now
2023-02-15 19:01:28,708:INFO:_master_model_container: 6
2023-02-15 19:01:28,708:INFO:_display_container: 2
2023-02-15 19:01:28,708:INFO:LassoLars(random_state=11)
2023-02-15 19:01:28,708:INFO:create_model() successfully completed......................................
2023-02-15 19:01:29,001:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:29,001:INFO:Creating metrics dataframe
2023-02-15 19:01:29,010:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 19:01:29,010:INFO:Total runtime is 0.3509449084599813 minutes
2023-02-15 19:01:29,012:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:29,012:INFO:Initializing create_model()
2023-02-15 19:01:29,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:29,012:INFO:Checking exceptions
2023-02-15 19:01:29,012:INFO:Importing libraries
2023-02-15 19:01:29,012:INFO:Copying training dataset
2023-02-15 19:01:29,188:INFO:Defining folds
2023-02-15 19:01:29,188:INFO:Declaring metric variables
2023-02-15 19:01:29,192:INFO:Importing untrained model
2023-02-15 19:01:29,195:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 19:01:29,200:INFO:Starting cross validation
2023-02-15 19:01:29,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:31,386:INFO:Calculating mean and std
2023-02-15 19:01:31,387:INFO:Creating metrics dataframe
2023-02-15 19:01:31,390:INFO:Uploading results into container
2023-02-15 19:01:31,391:INFO:Uploading model into container now
2023-02-15 19:01:31,391:INFO:_master_model_container: 7
2023-02-15 19:01:31,391:INFO:_display_container: 2
2023-02-15 19:01:31,391:INFO:OrthogonalMatchingPursuit()
2023-02-15 19:01:31,392:INFO:create_model() successfully completed......................................
2023-02-15 19:01:31,657:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:31,657:INFO:Creating metrics dataframe
2023-02-15 19:01:31,668:INFO:Initializing Bayesian Ridge
2023-02-15 19:01:31,668:INFO:Total runtime is 0.3952446738878886 minutes
2023-02-15 19:01:31,671:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:31,671:INFO:Initializing create_model()
2023-02-15 19:01:31,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:31,671:INFO:Checking exceptions
2023-02-15 19:01:31,671:INFO:Importing libraries
2023-02-15 19:01:31,671:INFO:Copying training dataset
2023-02-15 19:01:31,795:INFO:Defining folds
2023-02-15 19:01:31,795:INFO:Declaring metric variables
2023-02-15 19:01:31,798:INFO:Importing untrained model
2023-02-15 19:01:31,800:INFO:Bayesian Ridge Imported successfully
2023-02-15 19:01:31,805:INFO:Starting cross validation
2023-02-15 19:01:31,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:33,347:INFO:Calculating mean and std
2023-02-15 19:01:33,347:INFO:Creating metrics dataframe
2023-02-15 19:01:33,350:INFO:Uploading results into container
2023-02-15 19:01:33,350:INFO:Uploading model into container now
2023-02-15 19:01:33,351:INFO:_master_model_container: 6
2023-02-15 19:01:33,351:INFO:_display_container: 2
2023-02-15 19:01:33,351:INFO:LassoLars(random_state=11)
2023-02-15 19:01:33,351:INFO:create_model() successfully completed......................................
2023-02-15 19:01:33,452:INFO:Calculating mean and std
2023-02-15 19:01:33,453:INFO:Creating metrics dataframe
2023-02-15 19:01:33,455:INFO:Uploading results into container
2023-02-15 19:01:33,456:INFO:Uploading model into container now
2023-02-15 19:01:33,456:INFO:_master_model_container: 8
2023-02-15 19:01:33,456:INFO:_display_container: 2
2023-02-15 19:01:33,456:INFO:BayesianRidge()
2023-02-15 19:01:33,456:INFO:create_model() successfully completed......................................
2023-02-15 19:01:33,590:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:33,590:INFO:Creating metrics dataframe
2023-02-15 19:01:33,593:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 19:01:33,593:INFO:Total runtime is 0.9070846954981486 minutes
2023-02-15 19:01:33,594:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:33,594:INFO:Initializing create_model()
2023-02-15 19:01:33,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:33,594:INFO:Checking exceptions
2023-02-15 19:01:33,594:INFO:Importing libraries
2023-02-15 19:01:33,594:INFO:Copying training dataset
2023-02-15 19:01:33,673:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:33,674:INFO:Creating metrics dataframe
2023-02-15 19:01:33,681:INFO:Initializing Passive Aggressive Regressor
2023-02-15 19:01:33,681:INFO:Total runtime is 0.42880372603734335 minutes
2023-02-15 19:01:33,683:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:33,684:INFO:Initializing create_model()
2023-02-15 19:01:33,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:33,684:INFO:Checking exceptions
2023-02-15 19:01:33,684:INFO:Importing libraries
2023-02-15 19:01:33,684:INFO:Copying training dataset
2023-02-15 19:01:33,753:INFO:Defining folds
2023-02-15 19:01:33,753:INFO:Declaring metric variables
2023-02-15 19:01:33,753:INFO:Importing untrained model
2023-02-15 19:01:33,754:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 19:01:33,754:INFO:Starting cross validation
2023-02-15 19:01:33,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:01:33,851:INFO:Defining folds
2023-02-15 19:01:33,852:INFO:Declaring metric variables
2023-02-15 19:01:33,855:INFO:Importing untrained model
2023-02-15 19:01:33,857:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 19:01:33,860:INFO:Starting cross validation
2023-02-15 19:01:33,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:35,545:INFO:Calculating mean and std
2023-02-15 19:01:35,546:INFO:Creating metrics dataframe
2023-02-15 19:01:35,550:INFO:Uploading results into container
2023-02-15 19:01:35,550:INFO:Uploading model into container now
2023-02-15 19:01:35,551:INFO:_master_model_container: 9
2023-02-15 19:01:35,551:INFO:_display_container: 2
2023-02-15 19:01:35,551:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 19:01:35,551:INFO:create_model() successfully completed......................................
2023-02-15 19:01:35,871:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:35,871:INFO:Creating metrics dataframe
2023-02-15 19:01:35,880:INFO:Initializing Huber Regressor
2023-02-15 19:01:35,880:INFO:Total runtime is 0.4654493570327759 minutes
2023-02-15 19:01:35,882:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:35,883:INFO:Initializing create_model()
2023-02-15 19:01:35,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:35,883:INFO:Checking exceptions
2023-02-15 19:01:35,883:INFO:Importing libraries
2023-02-15 19:01:35,883:INFO:Copying training dataset
2023-02-15 19:01:36,055:INFO:Defining folds
2023-02-15 19:01:36,055:INFO:Declaring metric variables
2023-02-15 19:01:36,058:INFO:Importing untrained model
2023-02-15 19:01:36,060:INFO:Huber Regressor Imported successfully
2023-02-15 19:01:36,063:INFO:Starting cross validation
2023-02-15 19:01:36,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:37,949:INFO:Calculating mean and std
2023-02-15 19:01:37,950:INFO:Creating metrics dataframe
2023-02-15 19:01:37,953:INFO:Uploading results into container
2023-02-15 19:01:37,953:INFO:Uploading model into container now
2023-02-15 19:01:37,954:INFO:_master_model_container: 10
2023-02-15 19:01:37,954:INFO:_display_container: 2
2023-02-15 19:01:37,954:INFO:HuberRegressor()
2023-02-15 19:01:37,954:INFO:create_model() successfully completed......................................
2023-02-15 19:01:38,224:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:38,225:INFO:Creating metrics dataframe
2023-02-15 19:01:38,234:INFO:Initializing K Neighbors Regressor
2023-02-15 19:01:38,234:INFO:Total runtime is 0.5046769857406617 minutes
2023-02-15 19:01:38,236:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:38,237:INFO:Initializing create_model()
2023-02-15 19:01:38,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:38,237:INFO:Checking exceptions
2023-02-15 19:01:38,237:INFO:Importing libraries
2023-02-15 19:01:38,237:INFO:Copying training dataset
2023-02-15 19:01:38,413:INFO:Defining folds
2023-02-15 19:01:38,413:INFO:Declaring metric variables
2023-02-15 19:01:38,416:INFO:Importing untrained model
2023-02-15 19:01:38,418:INFO:K Neighbors Regressor Imported successfully
2023-02-15 19:01:38,421:INFO:Starting cross validation
2023-02-15 19:01:38,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:42,279:INFO:Calculating mean and std
2023-02-15 19:01:42,280:INFO:Creating metrics dataframe
2023-02-15 19:01:42,282:INFO:Uploading results into container
2023-02-15 19:01:42,283:INFO:Uploading model into container now
2023-02-15 19:01:42,283:INFO:_master_model_container: 11
2023-02-15 19:01:42,283:INFO:_display_container: 2
2023-02-15 19:01:42,284:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-15 19:01:42,284:INFO:create_model() successfully completed......................................
2023-02-15 19:01:42,545:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:42,545:INFO:Creating metrics dataframe
2023-02-15 19:01:42,559:INFO:Initializing Decision Tree Regressor
2023-02-15 19:01:42,559:INFO:Total runtime is 0.5767578045527141 minutes
2023-02-15 19:01:42,561:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:42,562:INFO:Initializing create_model()
2023-02-15 19:01:42,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:42,562:INFO:Checking exceptions
2023-02-15 19:01:42,562:INFO:Importing libraries
2023-02-15 19:01:42,562:INFO:Copying training dataset
2023-02-15 19:01:42,625:INFO:Calculating mean and std
2023-02-15 19:01:42,626:INFO:Creating metrics dataframe
2023-02-15 19:01:42,629:INFO:Uploading results into container
2023-02-15 19:01:42,630:INFO:Uploading model into container now
2023-02-15 19:01:42,630:INFO:_master_model_container: 7
2023-02-15 19:01:42,630:INFO:_display_container: 2
2023-02-15 19:01:42,630:INFO:OrthogonalMatchingPursuit()
2023-02-15 19:01:42,630:INFO:create_model() successfully completed......................................
2023-02-15 19:01:42,713:INFO:Defining folds
2023-02-15 19:01:42,713:INFO:Declaring metric variables
2023-02-15 19:01:42,715:INFO:Importing untrained model
2023-02-15 19:01:42,717:INFO:Decision Tree Regressor Imported successfully
2023-02-15 19:01:42,721:INFO:Starting cross validation
2023-02-15 19:01:42,723:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:43,113:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:43,114:INFO:Creating metrics dataframe
2023-02-15 19:01:43,123:INFO:Initializing Bayesian Ridge
2023-02-15 19:01:43,123:INFO:Total runtime is 1.0659094015757242 minutes
2023-02-15 19:01:43,123:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:43,124:INFO:Initializing create_model()
2023-02-15 19:01:43,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:43,124:INFO:Checking exceptions
2023-02-15 19:01:43,124:INFO:Importing libraries
2023-02-15 19:01:43,124:INFO:Copying training dataset
2023-02-15 19:01:43,829:INFO:Defining folds
2023-02-15 19:01:43,829:INFO:Declaring metric variables
2023-02-15 19:01:43,830:INFO:Importing untrained model
2023-02-15 19:01:43,830:INFO:Bayesian Ridge Imported successfully
2023-02-15 19:01:43,830:INFO:Starting cross validation
2023-02-15 19:01:43,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:01:44,491:INFO:Calculating mean and std
2023-02-15 19:01:44,492:INFO:Creating metrics dataframe
2023-02-15 19:01:44,495:INFO:Uploading results into container
2023-02-15 19:01:44,496:INFO:Uploading model into container now
2023-02-15 19:01:44,496:INFO:_master_model_container: 12
2023-02-15 19:01:44,496:INFO:_display_container: 2
2023-02-15 19:01:44,497:INFO:DecisionTreeRegressor(random_state=11)
2023-02-15 19:01:44,497:INFO:create_model() successfully completed......................................
2023-02-15 19:01:44,770:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:44,770:INFO:Creating metrics dataframe
2023-02-15 19:01:44,778:INFO:Initializing Random Forest Regressor
2023-02-15 19:01:44,778:INFO:Total runtime is 0.6137508869171143 minutes
2023-02-15 19:01:44,780:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:44,780:INFO:Initializing create_model()
2023-02-15 19:01:44,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:44,780:INFO:Checking exceptions
2023-02-15 19:01:44,780:INFO:Importing libraries
2023-02-15 19:01:44,780:INFO:Copying training dataset
2023-02-15 19:01:44,921:INFO:Defining folds
2023-02-15 19:01:44,921:INFO:Declaring metric variables
2023-02-15 19:01:44,924:INFO:Importing untrained model
2023-02-15 19:01:44,927:INFO:Random Forest Regressor Imported successfully
2023-02-15 19:01:44,931:INFO:Starting cross validation
2023-02-15 19:01:44,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:01:49,943:INFO:Calculating mean and std
2023-02-15 19:01:49,944:INFO:Creating metrics dataframe
2023-02-15 19:01:49,947:INFO:Uploading results into container
2023-02-15 19:01:49,948:INFO:Uploading model into container now
2023-02-15 19:01:49,964:INFO:_master_model_container: 8
2023-02-15 19:01:49,964:INFO:_display_container: 2
2023-02-15 19:01:49,964:INFO:BayesianRidge()
2023-02-15 19:01:49,964:INFO:create_model() successfully completed......................................
2023-02-15 19:01:50,253:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:50,253:INFO:Creating metrics dataframe
2023-02-15 19:01:50,258:INFO:Initializing Passive Aggressive Regressor
2023-02-15 19:01:50,258:INFO:Total runtime is 1.1848241806030273 minutes
2023-02-15 19:01:50,258:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:50,258:INFO:Initializing create_model()
2023-02-15 19:01:50,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:50,258:INFO:Checking exceptions
2023-02-15 19:01:50,258:INFO:Importing libraries
2023-02-15 19:01:50,258:INFO:Copying training dataset
2023-02-15 19:01:50,417:INFO:Defining folds
2023-02-15 19:01:50,417:INFO:Declaring metric variables
2023-02-15 19:01:50,418:INFO:Importing untrained model
2023-02-15 19:01:50,418:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 19:01:50,418:INFO:Starting cross validation
2023-02-15 19:01:50,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:01:56,183:INFO:Calculating mean and std
2023-02-15 19:01:56,183:INFO:Creating metrics dataframe
2023-02-15 19:01:56,194:INFO:Uploading results into container
2023-02-15 19:01:56,195:INFO:Uploading model into container now
2023-02-15 19:01:56,195:INFO:_master_model_container: 9
2023-02-15 19:01:56,195:INFO:_display_container: 2
2023-02-15 19:01:56,195:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 19:01:56,196:INFO:create_model() successfully completed......................................
2023-02-15 19:01:56,487:INFO:SubProcess create_model() end ==================================
2023-02-15 19:01:56,488:INFO:Creating metrics dataframe
2023-02-15 19:01:56,492:INFO:Initializing Huber Regressor
2023-02-15 19:01:56,492:INFO:Total runtime is 1.2887264251708983 minutes
2023-02-15 19:01:56,492:INFO:SubProcess create_model() called ==================================
2023-02-15 19:01:56,492:INFO:Initializing create_model()
2023-02-15 19:01:56,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:01:56,492:INFO:Checking exceptions
2023-02-15 19:01:56,492:INFO:Importing libraries
2023-02-15 19:01:56,492:INFO:Copying training dataset
2023-02-15 19:01:56,662:INFO:Defining folds
2023-02-15 19:01:56,662:INFO:Declaring metric variables
2023-02-15 19:01:56,662:INFO:Importing untrained model
2023-02-15 19:01:56,663:INFO:Huber Regressor Imported successfully
2023-02-15 19:01:56,663:INFO:Starting cross validation
2023-02-15 19:01:56,667:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:02:02,327:INFO:Calculating mean and std
2023-02-15 19:02:02,333:INFO:Creating metrics dataframe
2023-02-15 19:02:02,342:INFO:Uploading results into container
2023-02-15 19:02:02,342:INFO:Uploading model into container now
2023-02-15 19:02:02,343:INFO:_master_model_container: 10
2023-02-15 19:02:02,343:INFO:_display_container: 2
2023-02-15 19:02:02,343:INFO:HuberRegressor()
2023-02-15 19:02:02,343:INFO:create_model() successfully completed......................................
2023-02-15 19:02:02,664:INFO:SubProcess create_model() end ==================================
2023-02-15 19:02:02,664:INFO:Creating metrics dataframe
2023-02-15 19:02:02,668:INFO:Initializing K Neighbors Regressor
2023-02-15 19:02:02,668:INFO:Total runtime is 1.391663360595703 minutes
2023-02-15 19:02:02,668:INFO:SubProcess create_model() called ==================================
2023-02-15 19:02:02,669:INFO:Initializing create_model()
2023-02-15 19:02:02,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:02:02,669:INFO:Checking exceptions
2023-02-15 19:02:02,669:INFO:Importing libraries
2023-02-15 19:02:02,669:INFO:Copying training dataset
2023-02-15 19:02:02,840:INFO:Defining folds
2023-02-15 19:02:02,841:INFO:Declaring metric variables
2023-02-15 19:02:02,841:INFO:Importing untrained model
2023-02-15 19:02:02,842:INFO:K Neighbors Regressor Imported successfully
2023-02-15 19:02:02,842:INFO:Starting cross validation
2023-02-15 19:02:02,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:02:02,849:INFO:[I] [19:02:02.849529] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:03,173:INFO:[I] [19:02:03.173488] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:03,887:INFO:[I] [19:02:03.887551] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:04,633:INFO:[I] [19:02:04.633027] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:04,853:INFO:[I] [19:02:04.853702] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:05,659:INFO:[I] [19:02:05.659767] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:06,279:INFO:[I] [19:02:06.279842] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:06,612:INFO:[I] [19:02:06.611968] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:06,823:INFO:[I] [19:02:06.823496] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:07,185:INFO:[I] [19:02:07.185160] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:07,904:INFO:[I] [19:02:07.904163] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:08,295:INFO:[I] [19:02:08.295484] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:08,843:INFO:[I] [19:02:08.843856] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:09,690:INFO:[I] [19:02:09.690004] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:10,325:INFO:[I] [19:02:10.325452] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:10,892:INFO:[I] [19:02:10.892259] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:11,136:INFO:[I] [19:02:11.136533] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:11,453:INFO:[I] [19:02:11.453677] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:11,673:INFO:[I] [19:02:11.673042] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:12,392:INFO:[I] [19:02:12.392446] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:02:12,595:INFO:Calculating mean and std
2023-02-15 19:02:12,595:INFO:Creating metrics dataframe
2023-02-15 19:02:12,598:INFO:Uploading results into container
2023-02-15 19:02:12,598:INFO:Uploading model into container now
2023-02-15 19:02:12,599:INFO:_master_model_container: 11
2023-02-15 19:02:12,599:INFO:_display_container: 2
2023-02-15 19:02:12,599:INFO:KNeighborsRegressor()
2023-02-15 19:02:12,599:INFO:create_model() successfully completed......................................
2023-02-15 19:02:13,013:INFO:SubProcess create_model() end ==================================
2023-02-15 19:02:13,013:INFO:Creating metrics dataframe
2023-02-15 19:02:13,029:INFO:Initializing Decision Tree Regressor
2023-02-15 19:02:13,029:INFO:Total runtime is 1.5643444816271463 minutes
2023-02-15 19:02:13,029:INFO:SubProcess create_model() called ==================================
2023-02-15 19:02:13,029:INFO:Initializing create_model()
2023-02-15 19:02:13,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:02:13,030:INFO:Checking exceptions
2023-02-15 19:02:13,030:INFO:Importing libraries
2023-02-15 19:02:13,030:INFO:Copying training dataset
2023-02-15 19:02:13,291:INFO:Defining folds
2023-02-15 19:02:13,291:INFO:Declaring metric variables
2023-02-15 19:02:13,291:INFO:Importing untrained model
2023-02-15 19:02:13,292:INFO:Decision Tree Regressor Imported successfully
2023-02-15 19:02:13,292:INFO:Starting cross validation
2023-02-15 19:02:13,296:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:02:19,269:INFO:Calculating mean and std
2023-02-15 19:02:19,270:INFO:Creating metrics dataframe
2023-02-15 19:02:19,273:INFO:Uploading results into container
2023-02-15 19:02:19,273:INFO:Uploading model into container now
2023-02-15 19:02:19,273:INFO:_master_model_container: 12
2023-02-15 19:02:19,273:INFO:_display_container: 2
2023-02-15 19:02:19,274:INFO:DecisionTreeRegressor(random_state=11)
2023-02-15 19:02:19,274:INFO:create_model() successfully completed......................................
2023-02-15 19:02:19,502:INFO:SubProcess create_model() end ==================================
2023-02-15 19:02:19,502:INFO:Creating metrics dataframe
2023-02-15 19:02:19,506:INFO:Initializing Random Forest Regressor
2023-02-15 19:02:19,506:INFO:Total runtime is 1.672294811407725 minutes
2023-02-15 19:02:19,506:INFO:SubProcess create_model() called ==================================
2023-02-15 19:02:19,506:INFO:Initializing create_model()
2023-02-15 19:02:19,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2c0b0b0850>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2be75f1eb0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:02:19,507:INFO:Checking exceptions
2023-02-15 19:02:19,507:INFO:Importing libraries
2023-02-15 19:02:19,507:INFO:Copying training dataset
2023-02-15 19:02:19,703:INFO:Defining folds
2023-02-15 19:02:19,703:INFO:Declaring metric variables
2023-02-15 19:02:19,703:INFO:Importing untrained model
2023-02-15 19:02:19,704:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:19,704:INFO:Random Forest Regressor Imported successfully
2023-02-15 19:02:19,705:INFO:Starting cross validation
2023-02-15 19:02:19,715:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:02:19,729:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:20,124:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:20,754:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:21,021:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:21,786:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:22,094:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:22,817:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:23,131:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:23,833:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:24,261:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:31,709:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 297, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/nvtx/nvtx.py", line 101, in inner
    result = func(*args, **kwargs)
  File "randomforestregressor.pyx", line 588, in cuml.ensemble.randomforestregressor.RandomForestRegressor.predict
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "randomforest_common.pyx", line 353, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu
  File "randomforest_common.pyx", line 218, in cuml.ensemble.randomforest_common.BaseRandomForestModel._obtain_treelite_handle
  File "randomforest_shared.pyx", line 121, in cuml.ensemble.randomforest_shared.treelite_deserialize
  File "randomforest_shared.pyx", line 105, in cuml.ensemble.randomforest_shared.init_from_frames
  File "randomforest_shared.pyx", line 84, in cuml.ensemble.randomforest_shared._init_from_frames
RuntimeError: Could not load the correct number of nodes

  warnings.warn(

2023-02-15 19:02:31,716:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:02:32,180:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:03:14,867:INFO:Calculating mean and std
2023-02-15 19:03:14,868:INFO:Creating metrics dataframe
2023-02-15 19:03:14,870:INFO:Uploading results into container
2023-02-15 19:03:14,871:INFO:Uploading model into container now
2023-02-15 19:03:14,871:INFO:_master_model_container: 13
2023-02-15 19:03:14,871:INFO:_display_container: 2
2023-02-15 19:03:14,871:INFO:RandomForestRegressor(n_jobs=-1, random_state=11)
2023-02-15 19:03:14,871:INFO:create_model() successfully completed......................................
2023-02-15 19:03:15,077:INFO:SubProcess create_model() end ==================================
2023-02-15 19:03:15,077:INFO:Creating metrics dataframe
2023-02-15 19:03:15,085:INFO:Initializing Extra Trees Regressor
2023-02-15 19:03:15,085:INFO:Total runtime is 2.1188671390215554 minutes
2023-02-15 19:03:15,087:INFO:SubProcess create_model() called ==================================
2023-02-15 19:03:15,087:INFO:Initializing create_model()
2023-02-15 19:03:15,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb9271ac700>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb8808df0d0>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:03:15,087:INFO:Checking exceptions
2023-02-15 19:03:15,087:INFO:Importing libraries
2023-02-15 19:03:15,087:INFO:Copying training dataset
2023-02-15 19:03:15,222:INFO:Defining folds
2023-02-15 19:03:15,222:INFO:Declaring metric variables
2023-02-15 19:03:15,225:INFO:Importing untrained model
2023-02-15 19:03:15,227:INFO:Extra Trees Regressor Imported successfully
2023-02-15 19:03:15,231:INFO:Starting cross validation
2023-02-15 19:03:15,233:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:15:09,595:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:10,743:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:10,743:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:10,743:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:10,949:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 19:15:11,034:INFO:PyCaret RegressionExperiment
2023-02-15 19:15:11,034:INFO:Logging name: reg-default-name
2023-02-15 19:15:11,034:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 19:15:11,034:INFO:version 3.0.0.rc9
2023-02-15 19:15:11,034:INFO:Initializing setup()
2023-02-15 19:15:11,034:INFO:self.USI: 4bf0
2023-02-15 19:15:11,034:INFO:self._variable_keys: {'html_param', 'gpu_param', 'X_train', '_ml_usecase', 'idx', 'exp_name_log', 'y_train', 'y_test', 'data', 'USI', '_available_plots', 'X', 'gpu_n_jobs_param', 'n_jobs_param', 'target_param', 'fold_generator', 'memory', 'logging_param', 'exp_id', 'y', 'transform_target_param', 'seed', 'X_test', 'pipeline', 'log_plots_param', 'fold_shuffle_param', 'fold_groups_param'}
2023-02-15 19:15:11,034:INFO:Checking environment
2023-02-15 19:15:11,034:INFO:python_version: 3.8.16
2023-02-15 19:15:11,034:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-15 19:15:11,034:INFO:machine: x86_64
2023-02-15 19:15:11,047:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 19:15:11,047:INFO:Memory: svmem(total=134979592192, available=115647860736, percent=14.3, used=17638825984, free=29898604544, active=13768912896, inactive=87030636544, buffers=1471246336, cached=85970915328, shared=420892672, slab=3539828736)
2023-02-15 19:15:11,048:INFO:Physical Core: 16
2023-02-15 19:15:11,048:INFO:Logical Core: 32
2023-02-15 19:15:11,048:INFO:Checking libraries
2023-02-15 19:15:11,048:INFO:System:
2023-02-15 19:15:11,048:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-15 19:15:11,048:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 19:15:11,048:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 19:15:11,048:INFO:PyCaret required dependencies:
2023-02-15 19:15:11,048:INFO:                 pip: 23.0
2023-02-15 19:15:11,048:INFO:          setuptools: 60.10.0
2023-02-15 19:15:11,048:INFO:             pycaret: 3.0.0rc9
2023-02-15 19:15:11,048:INFO:             IPython: 8.10.0
2023-02-15 19:15:11,048:INFO:          ipywidgets: 7.7.3
2023-02-15 19:15:11,048:INFO:                tqdm: 4.64.1
2023-02-15 19:15:11,048:INFO:               numpy: 1.23.5
2023-02-15 19:15:11,048:INFO:              pandas: 1.5.3
2023-02-15 19:15:11,048:INFO:              jinja2: 3.1.2
2023-02-15 19:15:11,048:INFO:               scipy: 1.9.1
2023-02-15 19:15:11,048:INFO:              joblib: 1.2.0
2023-02-15 19:15:11,048:INFO:             sklearn: 1.2.1
2023-02-15 19:15:11,048:INFO:                pyod: 1.0.7
2023-02-15 19:15:11,048:INFO:            imblearn: 0.10.1
2023-02-15 19:15:11,048:INFO:   category_encoders: 2.6.0
2023-02-15 19:15:11,048:INFO:            lightgbm: 3.3.5.99
2023-02-15 19:15:11,048:INFO:               numba: 0.56.4
2023-02-15 19:15:11,048:INFO:            requests: 2.28.2
2023-02-15 19:15:11,048:INFO:          matplotlib: 3.6.3
2023-02-15 19:15:11,049:INFO:          scikitplot: 0.3.7
2023-02-15 19:15:11,049:INFO:         yellowbrick: 1.5
2023-02-15 19:15:11,049:INFO:              plotly: 5.13.0
2023-02-15 19:15:11,049:INFO:             kaleido: 0.2.1
2023-02-15 19:15:11,049:INFO:         statsmodels: 0.13.5
2023-02-15 19:15:11,049:INFO:              sktime: 0.16.1
2023-02-15 19:15:11,049:INFO:               tbats: 1.1.2
2023-02-15 19:15:11,049:INFO:            pmdarima: 2.0.2
2023-02-15 19:15:11,049:INFO:              psutil: 5.9.4
2023-02-15 19:15:11,049:INFO:PyCaret optional dependencies:
2023-02-15 19:15:11,484:INFO:                shap: 0.41.0
2023-02-15 19:15:11,484:INFO:           interpret: 0.3.0
2023-02-15 19:15:11,484:INFO:                umap: 0.5.3
2023-02-15 19:15:11,484:INFO:    pandas_profiling: 4.0.0
2023-02-15 19:15:11,484:INFO:  explainerdashboard: 0.4.2
2023-02-15 19:15:11,484:INFO:             autoviz: 0.1.58
2023-02-15 19:15:11,484:INFO:           fairlearn: 0.7.0
2023-02-15 19:15:11,484:INFO:             xgboost: 1.7.3
2023-02-15 19:15:11,484:INFO:            catboost: 1.1.1
2023-02-15 19:15:11,484:INFO:              kmodes: 0.12.2
2023-02-15 19:15:11,484:INFO:             mlxtend: 0.21.0
2023-02-15 19:15:11,484:INFO:       statsforecast: 1.4.0
2023-02-15 19:15:11,484:INFO:        tune_sklearn: 0.4.5
2023-02-15 19:15:11,484:INFO:                 ray: 2.2.0
2023-02-15 19:15:11,484:INFO:            hyperopt: 0.2.7
2023-02-15 19:15:11,484:INFO:              optuna: 3.1.0
2023-02-15 19:15:11,484:INFO:               skopt: 0.9.0
2023-02-15 19:15:11,484:INFO:              mlflow: 1.30.0
2023-02-15 19:15:11,484:INFO:              gradio: 3.18.0
2023-02-15 19:15:11,484:INFO:             fastapi: 0.92.0
2023-02-15 19:15:11,484:INFO:             uvicorn: 0.20.0
2023-02-15 19:15:11,484:INFO:              m2cgen: 0.10.0
2023-02-15 19:15:11,484:INFO:           evidently: 0.2.4
2023-02-15 19:15:11,484:INFO:               fugue: 0.8.1.dev4
2023-02-15 19:15:11,484:INFO:           streamlit: Not installed
2023-02-15 19:15:11,484:INFO:             prophet: Not installed
2023-02-15 19:15:11,484:INFO:None
2023-02-15 19:15:11,484:INFO:Set up GPU usage.
2023-02-15 19:15:11,484:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:11,484:INFO:cuml==23.2.0
2023-02-15 19:15:11,485:ERROR:Couldn't set cuML global output type
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/tabular_experiment.py", line 351, in _initialize_setup
    import cuml.common.memory_utils
ModuleNotFoundError: No module named 'cuml.common.memory_utils'
2023-02-15 19:15:11,485:INFO:Set up data.
2023-02-15 19:15:11,834:INFO:Set up train/test split.
2023-02-15 19:15:12,058:INFO:Set up index.
2023-02-15 19:15:12,109:INFO:Set up folding strategy.
2023-02-15 19:15:12,109:INFO:Assigning column types.
2023-02-15 19:15:12,218:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 19:15:12,218:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,218:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:12,218:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,219:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,219:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:12,221:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,221:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,221:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:12,224:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,224:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,224:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:12,346:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,346:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,346:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:12,373:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,373:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,373:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:12,373:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,373:INFO:Imported cuml.ensemble
2023-02-15 19:15:12,373:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:12,649:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:12,720:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,720:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:12,720:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,720:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,720:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:12,723:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,723:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,723:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:12,725:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,725:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,725:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:12,845:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,845:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,845:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:12,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,872:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,872:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:12,872:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,872:INFO:Imported cuml.ensemble
2023-02-15 19:15:12,872:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:12,947:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:12,992:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 19:15:12,992:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,992:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:12,992:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,992:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:12,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,995:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,995:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:12,998:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:15:12,998:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:12,998:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:13,108:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,108:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,108:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:13,135:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,135:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,135:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:13,135:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,135:INFO:Imported cuml.ensemble
2023-02-15 19:15:13,136:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:13,218:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:13,266:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,266:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:13,266:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,266:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:13,270:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,270:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,270:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:13,273:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,273:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,273:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:13,403:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,403:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,403:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:13,429:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,430:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,430:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:13,430:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,430:INFO:Imported cuml.ensemble
2023-02-15 19:15:13,430:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:13,507:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:13,556:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 19:15:13,556:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,556:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:13,556:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,556:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:13,559:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,559:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:13,562:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,562:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,562:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:13,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,692:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,692:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:13,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,718:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,718:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:13,718:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,718:INFO:Imported cuml.ensemble
2023-02-15 19:15:13,719:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:13,793:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:13,843:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,844:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:13,844:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,844:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:13,847:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,848:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:13,850:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,850:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,850:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:13,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,962:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,962:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:13,989:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:15:13,989:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,989:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:13,989:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:13,989:INFO:Imported cuml.ensemble
2023-02-15 19:15:13,990:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:14,068:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:14,113:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 19:15:14,113:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,113:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:14,113:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,113:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:14,116:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,116:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:14,119:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,119:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:14,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:15:14,246:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,246:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:14,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:15:14,273:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,274:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:14,274:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,274:INFO:Imported cuml.ensemble
2023-02-15 19:15:14,274:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:14,351:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:14,399:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,399:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:14,399:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,399:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:14,402:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,402:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:14,405:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,405:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:14,550:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:15:14,550:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,550:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:14,577:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:15:14,577:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,577:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:14,577:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,577:INFO:Imported cuml.ensemble
2023-02-15 19:15:14,577:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:14,654:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:14,702:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 19:15:14,702:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,703:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:14,703:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,703:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:14,705:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,705:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:14,708:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,708:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:14,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:15:14,827:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,827:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:14,855:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,855:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:14,855:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,855:INFO:Imported cuml.ensemble
2023-02-15 19:15:14,855:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:14,933:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:14,983:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,983:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:14,983:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,983:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:14,986:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,986:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:14,989:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:14,989:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:15,115:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:15:15,115:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,115:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:15,142:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,142:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:15,142:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,142:INFO:Imported cuml.ensemble
2023-02-15 19:15:15,143:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:15,221:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:15,258:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 19:15:15,259:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,259:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:15,259:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,259:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:15,262:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,262:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:15,264:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,265:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:15,381:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,381:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:15,408:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,408:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:15,408:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,408:INFO:Imported cuml.ensemble
2023-02-15 19:15:15,409:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:15,488:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:15,536:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,536:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:15,536:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,536:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:15,539:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,539:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:15,542:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,542:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:15,669:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,669:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:15,696:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,696:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:15,696:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:15,696:INFO:Imported cuml.ensemble
2023-02-15 19:15:15,696:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:15,783:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:15,834:INFO:Preparing preprocessing pipeline...
2023-02-15 19:15:15,851:INFO:Set up column name cleaning.
2023-02-15 19:15:15,851:INFO:Set up simple imputation.
2023-02-15 19:15:15,851:INFO:Set up feature normalization.
2023-02-15 19:15:16,414:INFO:Finished creating preprocessing pipeline.
2023-02-15 19:15:16,421:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 19:15:16,421:INFO:Creating final display dataframe.
2023-02-15 19:15:17,653:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28570, 780)
4        Transformed data shape           (28570, 775)
5   Transformed train set shape           (19999, 775)
6    Transformed test set shape            (8571, 775)
7               Ignore features                      5
8              Numeric features                    774
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   4bf0
2023-02-15 19:15:17,655:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,655:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:17,655:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,656:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:17,658:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,658:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:17,661:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,661:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:17,766:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,766:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:17,794:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,794:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:17,794:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,794:INFO:Imported cuml.ensemble
2023-02-15 19:15:17,794:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:17,878:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:17,928:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,928:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:15:17,928:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,928:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:15:17,931:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,931:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:15:17,933:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:17,933:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:15:18,057:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:18,057:INFO:Imported cuml.svm.SVR
2023-02-15 19:15:18,084:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:18,084:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:15:18,085:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:15:18,085:INFO:Imported cuml.ensemble
2023-02-15 19:15:18,085:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:15:18,161:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:15:18,210:INFO:setup() successfully completed in 7.18s...............
2023-02-15 19:15:18,210:INFO:Initializing compare_models()
2023-02-15 19:15:18,210:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 19:15:18,210:INFO:Checking exceptions
2023-02-15 19:15:18,255:INFO:Preparing display monitor
2023-02-15 19:15:18,258:INFO:Initializing Linear Regression
2023-02-15 19:15:18,258:INFO:Total runtime is 8.62280527750651e-07 minutes
2023-02-15 19:15:18,258:INFO:SubProcess create_model() called ==================================
2023-02-15 19:15:18,258:INFO:Initializing create_model()
2023-02-15 19:15:18,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:15:18,258:INFO:Checking exceptions
2023-02-15 19:15:18,258:INFO:Importing libraries
2023-02-15 19:15:18,258:INFO:Copying training dataset
2023-02-15 19:15:18,380:INFO:Defining folds
2023-02-15 19:15:18,380:INFO:Declaring metric variables
2023-02-15 19:15:18,380:INFO:Importing untrained model
2023-02-15 19:15:18,381:INFO:Linear Regression Imported successfully
2023-02-15 19:15:18,382:INFO:Starting cross validation
2023-02-15 19:15:18,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:15:26,332:INFO:Calculating mean and std
2023-02-15 19:15:26,332:INFO:Creating metrics dataframe
2023-02-15 19:15:26,334:INFO:Uploading results into container
2023-02-15 19:15:26,334:INFO:Uploading model into container now
2023-02-15 19:15:26,335:INFO:_master_model_container: 1
2023-02-15 19:15:26,335:INFO:_display_container: 2
2023-02-15 19:15:26,335:INFO:LinearRegression()
2023-02-15 19:15:26,335:INFO:create_model() successfully completed......................................
2023-02-15 19:15:26,543:INFO:SubProcess create_model() end ==================================
2023-02-15 19:15:26,543:INFO:Creating metrics dataframe
2023-02-15 19:15:26,546:INFO:Initializing Lasso Regression
2023-02-15 19:15:26,546:INFO:Total runtime is 0.13813662926356 minutes
2023-02-15 19:15:26,546:INFO:SubProcess create_model() called ==================================
2023-02-15 19:15:26,547:INFO:Initializing create_model()
2023-02-15 19:15:26,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:15:26,547:INFO:Checking exceptions
2023-02-15 19:15:26,547:INFO:Importing libraries
2023-02-15 19:15:26,547:INFO:Copying training dataset
2023-02-15 19:15:26,676:INFO:Defining folds
2023-02-15 19:15:26,676:INFO:Declaring metric variables
2023-02-15 19:15:26,676:INFO:Importing untrained model
2023-02-15 19:15:26,677:INFO:Lasso Regression Imported successfully
2023-02-15 19:15:26,677:INFO:Starting cross validation
2023-02-15 19:15:26,680:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:15:32,254:INFO:Calculating mean and std
2023-02-15 19:15:32,254:INFO:Creating metrics dataframe
2023-02-15 19:15:32,256:INFO:Uploading results into container
2023-02-15 19:15:32,256:INFO:Uploading model into container now
2023-02-15 19:15:32,257:INFO:_master_model_container: 2
2023-02-15 19:15:32,257:INFO:_display_container: 2
2023-02-15 19:15:32,257:INFO:Lasso()
2023-02-15 19:15:32,257:INFO:create_model() successfully completed......................................
2023-02-15 19:15:32,456:INFO:SubProcess create_model() end ==================================
2023-02-15 19:15:32,456:INFO:Creating metrics dataframe
2023-02-15 19:15:32,459:INFO:Initializing Ridge Regression
2023-02-15 19:15:32,459:INFO:Total runtime is 0.236688498655955 minutes
2023-02-15 19:15:32,459:INFO:SubProcess create_model() called ==================================
2023-02-15 19:15:32,460:INFO:Initializing create_model()
2023-02-15 19:15:32,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:15:32,460:INFO:Checking exceptions
2023-02-15 19:15:32,460:INFO:Importing libraries
2023-02-15 19:15:32,460:INFO:Copying training dataset
2023-02-15 19:15:32,579:INFO:Defining folds
2023-02-15 19:15:32,579:INFO:Declaring metric variables
2023-02-15 19:15:32,579:INFO:Importing untrained model
2023-02-15 19:15:32,580:INFO:Ridge Regression Imported successfully
2023-02-15 19:15:32,580:INFO:Starting cross validation
2023-02-15 19:15:32,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:15:38,327:INFO:Calculating mean and std
2023-02-15 19:15:38,327:INFO:Creating metrics dataframe
2023-02-15 19:15:38,329:INFO:Uploading results into container
2023-02-15 19:15:38,330:INFO:Uploading model into container now
2023-02-15 19:15:38,330:INFO:_master_model_container: 3
2023-02-15 19:15:38,330:INFO:_display_container: 2
2023-02-15 19:15:38,330:INFO:Ridge()
2023-02-15 19:15:38,330:INFO:create_model() successfully completed......................................
2023-02-15 19:15:38,498:INFO:SubProcess create_model() end ==================================
2023-02-15 19:15:38,498:INFO:Creating metrics dataframe
2023-02-15 19:15:38,501:INFO:Initializing Elastic Net
2023-02-15 19:15:38,501:INFO:Total runtime is 0.3373846689860026 minutes
2023-02-15 19:15:38,501:INFO:SubProcess create_model() called ==================================
2023-02-15 19:15:38,501:INFO:Initializing create_model()
2023-02-15 19:15:38,501:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:15:38,501:INFO:Checking exceptions
2023-02-15 19:15:38,501:INFO:Importing libraries
2023-02-15 19:15:38,502:INFO:Copying training dataset
2023-02-15 19:15:38,628:INFO:Defining folds
2023-02-15 19:15:38,629:INFO:Declaring metric variables
2023-02-15 19:15:38,629:INFO:Importing untrained model
2023-02-15 19:15:38,629:INFO:Elastic Net Imported successfully
2023-02-15 19:15:38,630:INFO:Starting cross validation
2023-02-15 19:15:38,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:15:44,185:INFO:Calculating mean and std
2023-02-15 19:15:44,185:INFO:Creating metrics dataframe
2023-02-15 19:15:44,187:INFO:Uploading results into container
2023-02-15 19:15:44,187:INFO:Uploading model into container now
2023-02-15 19:15:44,187:INFO:_master_model_container: 4
2023-02-15 19:15:44,187:INFO:_display_container: 2
2023-02-15 19:15:44,187:INFO:ElasticNet()
2023-02-15 19:15:44,187:INFO:create_model() successfully completed......................................
2023-02-15 19:15:44,389:INFO:SubProcess create_model() end ==================================
2023-02-15 19:15:44,389:INFO:Creating metrics dataframe
2023-02-15 19:15:44,392:INFO:Initializing Least Angle Regression
2023-02-15 19:15:44,392:INFO:Total runtime is 0.43556921879450483 minutes
2023-02-15 19:15:44,392:INFO:SubProcess create_model() called ==================================
2023-02-15 19:15:44,392:INFO:Initializing create_model()
2023-02-15 19:15:44,392:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:15:44,393:INFO:Checking exceptions
2023-02-15 19:15:44,393:INFO:Importing libraries
2023-02-15 19:15:44,393:INFO:Copying training dataset
2023-02-15 19:15:44,500:INFO:Defining folds
2023-02-15 19:15:44,500:INFO:Declaring metric variables
2023-02-15 19:15:44,500:INFO:Importing untrained model
2023-02-15 19:15:44,501:INFO:Least Angle Regression Imported successfully
2023-02-15 19:15:44,501:INFO:Starting cross validation
2023-02-15 19:15:44,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:15:45,039:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.380e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:45,040:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 19:15:45,042:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.077e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:45,427:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:713: RuntimeWarning: invalid value encountered in multiply
  least_squares *= AA

2023-02-15 19:15:45,427:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:736: RuntimeWarning: divide by zero encountered in double_scalars
  gamma_ = min(g1, g2, C / AA)

2023-02-15 19:15:45,428:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-02-15 19:15:46,232:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:15:46,232:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:15:46,232:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:15:46,807:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.056e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:46,816:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.968e-04, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:46,926:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.024e-02, with an active set of 180 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:48,113:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:15:48,223:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:15:48,843:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=9.145e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:49,074:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:15:49,408:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:15:50,036:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.172e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:50,037:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 19:15:50,055:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.377e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:51,432:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:15:51,680:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:15:53,149:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.213e-03, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:54,053:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.325e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:54,106:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=4.256e-03, with an active set of 148 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:54,169:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=4.098e-03, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:55,691:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 19:15:55,691:INFO:Calculating mean and std
2023-02-15 19:15:55,692:INFO:Creating metrics dataframe
2023-02-15 19:15:55,695:INFO:Uploading results into container
2023-02-15 19:15:55,695:INFO:Uploading model into container now
2023-02-15 19:15:55,695:INFO:_master_model_container: 5
2023-02-15 19:15:55,695:INFO:_display_container: 2
2023-02-15 19:15:55,696:INFO:Lars(random_state=11)
2023-02-15 19:15:55,696:INFO:create_model() successfully completed......................................
2023-02-15 19:15:55,874:WARNING:create_model() for Lars(random_state=11) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 19:15:55,875:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2023-02-15 19:15:55,875:INFO:Initializing create_model()
2023-02-15 19:15:55,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:15:55,875:INFO:Checking exceptions
2023-02-15 19:15:55,875:INFO:Importing libraries
2023-02-15 19:15:55,875:INFO:Copying training dataset
2023-02-15 19:15:56,003:INFO:Defining folds
2023-02-15 19:15:56,003:INFO:Declaring metric variables
2023-02-15 19:15:56,003:INFO:Importing untrained model
2023-02-15 19:15:56,004:INFO:Least Angle Regression Imported successfully
2023-02-15 19:15:56,004:INFO:Starting cross validation
2023-02-15 19:15:56,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:15:56,601:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:15:56,601:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:15:56,601:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:15:58,140:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:15:58,280:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:15:58,888:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=9.145e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:15:59,034:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:15:59,333:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:16:00,882:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:16:01,132:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:16:03,358:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 19:16:03,358:INFO:Calculating mean and std
2023-02-15 19:16:03,359:INFO:Creating metrics dataframe
2023-02-15 19:16:03,361:INFO:Uploading results into container
2023-02-15 19:16:03,362:INFO:Uploading model into container now
2023-02-15 19:16:03,362:INFO:_master_model_container: 6
2023-02-15 19:16:03,362:INFO:_display_container: 2
2023-02-15 19:16:03,362:INFO:Lars(random_state=11)
2023-02-15 19:16:03,362:INFO:create_model() successfully completed......................................
2023-02-15 19:16:03,536:ERROR:create_model() for Lars(random_state=11) raised an exception or returned all 0.0:
2023-02-15 19:16:03,536:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2023-02-15 19:16:03,536:INFO:Initializing Lasso Least Angle Regression
2023-02-15 19:16:03,536:INFO:Total runtime is 0.7546332875887554 minutes
2023-02-15 19:16:03,536:INFO:SubProcess create_model() called ==================================
2023-02-15 19:16:03,536:INFO:Initializing create_model()
2023-02-15 19:16:03,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:16:03,536:INFO:Checking exceptions
2023-02-15 19:16:03,536:INFO:Importing libraries
2023-02-15 19:16:03,536:INFO:Copying training dataset
2023-02-15 19:16:03,638:INFO:Defining folds
2023-02-15 19:16:03,638:INFO:Declaring metric variables
2023-02-15 19:16:03,638:INFO:Importing untrained model
2023-02-15 19:16:03,638:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 19:16:03,639:INFO:Starting cross validation
2023-02-15 19:16:03,641:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:16:09,950:INFO:Calculating mean and std
2023-02-15 19:16:09,951:INFO:Creating metrics dataframe
2023-02-15 19:16:09,954:INFO:Uploading results into container
2023-02-15 19:16:09,954:INFO:Uploading model into container now
2023-02-15 19:16:09,954:INFO:_master_model_container: 7
2023-02-15 19:16:09,954:INFO:_display_container: 2
2023-02-15 19:16:09,955:INFO:LassoLars(random_state=11)
2023-02-15 19:16:09,955:INFO:create_model() successfully completed......................................
2023-02-15 19:16:10,167:INFO:SubProcess create_model() end ==================================
2023-02-15 19:16:10,168:INFO:Creating metrics dataframe
2023-02-15 19:16:10,171:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 19:16:10,171:INFO:Total runtime is 0.8652168313662212 minutes
2023-02-15 19:16:10,171:INFO:SubProcess create_model() called ==================================
2023-02-15 19:16:10,171:INFO:Initializing create_model()
2023-02-15 19:16:10,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:16:10,171:INFO:Checking exceptions
2023-02-15 19:16:10,171:INFO:Importing libraries
2023-02-15 19:16:10,171:INFO:Copying training dataset
2023-02-15 19:16:10,302:INFO:Defining folds
2023-02-15 19:16:10,302:INFO:Declaring metric variables
2023-02-15 19:16:10,303:INFO:Importing untrained model
2023-02-15 19:16:10,303:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 19:16:10,303:INFO:Starting cross validation
2023-02-15 19:16:10,305:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:16:16,749:INFO:Calculating mean and std
2023-02-15 19:16:16,750:INFO:Creating metrics dataframe
2023-02-15 19:16:16,752:INFO:Uploading results into container
2023-02-15 19:16:16,752:INFO:Uploading model into container now
2023-02-15 19:16:16,752:INFO:_master_model_container: 8
2023-02-15 19:16:16,752:INFO:_display_container: 2
2023-02-15 19:16:16,753:INFO:OrthogonalMatchingPursuit()
2023-02-15 19:16:16,753:INFO:create_model() successfully completed......................................
2023-02-15 19:16:16,955:INFO:SubProcess create_model() end ==================================
2023-02-15 19:16:16,955:INFO:Creating metrics dataframe
2023-02-15 19:16:16,958:INFO:Initializing Bayesian Ridge
2023-02-15 19:16:16,958:INFO:Total runtime is 0.9783345699310304 minutes
2023-02-15 19:16:16,958:INFO:SubProcess create_model() called ==================================
2023-02-15 19:16:16,958:INFO:Initializing create_model()
2023-02-15 19:16:16,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:16:16,958:INFO:Checking exceptions
2023-02-15 19:16:16,958:INFO:Importing libraries
2023-02-15 19:16:16,958:INFO:Copying training dataset
2023-02-15 19:16:17,079:INFO:Defining folds
2023-02-15 19:16:17,080:INFO:Declaring metric variables
2023-02-15 19:16:17,080:INFO:Importing untrained model
2023-02-15 19:16:17,080:INFO:Bayesian Ridge Imported successfully
2023-02-15 19:16:17,080:INFO:Starting cross validation
2023-02-15 19:16:17,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:16:36,667:INFO:Calculating mean and std
2023-02-15 19:16:36,668:INFO:Creating metrics dataframe
2023-02-15 19:16:36,670:INFO:Uploading results into container
2023-02-15 19:16:36,670:INFO:Uploading model into container now
2023-02-15 19:16:36,670:INFO:_master_model_container: 9
2023-02-15 19:16:36,670:INFO:_display_container: 2
2023-02-15 19:16:36,671:INFO:BayesianRidge()
2023-02-15 19:16:36,671:INFO:create_model() successfully completed......................................
2023-02-15 19:16:36,850:INFO:SubProcess create_model() end ==================================
2023-02-15 19:16:36,850:INFO:Creating metrics dataframe
2023-02-15 19:16:36,853:INFO:Initializing Passive Aggressive Regressor
2023-02-15 19:16:36,853:INFO:Total runtime is 1.3099218408266704 minutes
2023-02-15 19:16:36,853:INFO:SubProcess create_model() called ==================================
2023-02-15 19:16:36,854:INFO:Initializing create_model()
2023-02-15 19:16:36,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:16:36,854:INFO:Checking exceptions
2023-02-15 19:16:36,854:INFO:Importing libraries
2023-02-15 19:16:36,854:INFO:Copying training dataset
2023-02-15 19:16:36,970:INFO:Defining folds
2023-02-15 19:16:36,970:INFO:Declaring metric variables
2023-02-15 19:16:36,971:INFO:Importing untrained model
2023-02-15 19:16:36,971:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 19:16:36,971:INFO:Starting cross validation
2023-02-15 19:16:36,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:16:45,131:INFO:Calculating mean and std
2023-02-15 19:16:45,131:INFO:Creating metrics dataframe
2023-02-15 19:16:45,133:INFO:Uploading results into container
2023-02-15 19:16:45,134:INFO:Uploading model into container now
2023-02-15 19:16:45,134:INFO:_master_model_container: 10
2023-02-15 19:16:45,134:INFO:_display_container: 2
2023-02-15 19:16:45,134:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 19:16:45,134:INFO:create_model() successfully completed......................................
2023-02-15 19:16:45,340:INFO:SubProcess create_model() end ==================================
2023-02-15 19:16:45,340:INFO:Creating metrics dataframe
2023-02-15 19:16:45,343:INFO:Initializing Huber Regressor
2023-02-15 19:16:45,343:INFO:Total runtime is 1.4514160831769307 minutes
2023-02-15 19:16:45,343:INFO:SubProcess create_model() called ==================================
2023-02-15 19:16:45,343:INFO:Initializing create_model()
2023-02-15 19:16:45,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:16:45,343:INFO:Checking exceptions
2023-02-15 19:16:45,343:INFO:Importing libraries
2023-02-15 19:16:45,343:INFO:Copying training dataset
2023-02-15 19:16:45,448:INFO:Defining folds
2023-02-15 19:16:45,448:INFO:Declaring metric variables
2023-02-15 19:16:45,449:INFO:Importing untrained model
2023-02-15 19:16:45,449:INFO:Huber Regressor Imported successfully
2023-02-15 19:16:45,449:INFO:Starting cross validation
2023-02-15 19:16:45,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:17:02,751:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:17:19,999:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:17:36,261:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:17:52,437:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:18:09,033:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:18:26,145:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:18:42,345:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:18:59,118:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:19:16,150:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:19:28,641:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:19:28,884:INFO:Calculating mean and std
2023-02-15 19:19:28,884:INFO:Creating metrics dataframe
2023-02-15 19:19:28,887:INFO:Uploading results into container
2023-02-15 19:19:28,887:INFO:Uploading model into container now
2023-02-15 19:19:28,888:INFO:_master_model_container: 11
2023-02-15 19:19:28,888:INFO:_display_container: 2
2023-02-15 19:19:28,888:INFO:HuberRegressor()
2023-02-15 19:19:28,888:INFO:create_model() successfully completed......................................
2023-02-15 19:19:29,088:INFO:SubProcess create_model() end ==================================
2023-02-15 19:19:29,088:INFO:Creating metrics dataframe
2023-02-15 19:19:29,092:INFO:Initializing K Neighbors Regressor
2023-02-15 19:19:29,092:INFO:Total runtime is 4.180563155810038 minutes
2023-02-15 19:19:29,092:INFO:SubProcess create_model() called ==================================
2023-02-15 19:19:29,092:INFO:Initializing create_model()
2023-02-15 19:19:29,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:19:29,092:INFO:Checking exceptions
2023-02-15 19:19:29,092:INFO:Importing libraries
2023-02-15 19:19:29,092:INFO:Copying training dataset
2023-02-15 19:19:29,211:INFO:Defining folds
2023-02-15 19:19:29,211:INFO:Declaring metric variables
2023-02-15 19:19:29,211:INFO:Importing untrained model
2023-02-15 19:19:29,212:INFO:K Neighbors Regressor Imported successfully
2023-02-15 19:19:29,212:INFO:Starting cross validation
2023-02-15 19:19:29,214:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:19:29,216:INFO:[I] [19:19:29.216151] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:29,658:INFO:[I] [19:19:29.658727] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:29,813:INFO:[I] [19:19:29.813861] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:30,249:INFO:[I] [19:19:30.249493] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:30,390:INFO:[I] [19:19:30.390717] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:30,852:INFO:[I] [19:19:30.851982] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:30,991:INFO:[I] [19:19:30.991428] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:31,402:INFO:[I] [19:19:31.402880] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:31,544:INFO:[I] [19:19:31.544204] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:32,001:INFO:[I] [19:19:32.001847] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:32,142:INFO:[I] [19:19:32.142735] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:32,563:INFO:[I] [19:19:32.563908] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:32,704:INFO:[I] [19:19:32.704468] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:33,072:INFO:[I] [19:19:33.072672] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:33,211:INFO:[I] [19:19:33.211914] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:33,635:INFO:[I] [19:19:33.635291] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:33,768:INFO:[I] [19:19:33.768972] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:34,197:INFO:[I] [19:19:34.197723] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:34,332:INFO:[I] [19:19:34.332305] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:34,762:INFO:[I] [19:19:34.762938] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:19:34,904:INFO:Calculating mean and std
2023-02-15 19:19:34,904:INFO:Creating metrics dataframe
2023-02-15 19:19:34,906:INFO:Uploading results into container
2023-02-15 19:19:34,907:INFO:Uploading model into container now
2023-02-15 19:19:34,907:INFO:_master_model_container: 12
2023-02-15 19:19:34,907:INFO:_display_container: 2
2023-02-15 19:19:34,907:INFO:KNeighborsRegressor()
2023-02-15 19:19:34,907:INFO:create_model() successfully completed......................................
2023-02-15 19:19:35,080:INFO:SubProcess create_model() end ==================================
2023-02-15 19:19:35,080:INFO:Creating metrics dataframe
2023-02-15 19:19:35,084:INFO:Initializing Decision Tree Regressor
2023-02-15 19:19:35,084:INFO:Total runtime is 4.280426744620005 minutes
2023-02-15 19:19:35,084:INFO:SubProcess create_model() called ==================================
2023-02-15 19:19:35,084:INFO:Initializing create_model()
2023-02-15 19:19:35,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:19:35,084:INFO:Checking exceptions
2023-02-15 19:19:35,084:INFO:Importing libraries
2023-02-15 19:19:35,084:INFO:Copying training dataset
2023-02-15 19:19:35,202:INFO:Defining folds
2023-02-15 19:19:35,202:INFO:Declaring metric variables
2023-02-15 19:19:35,202:INFO:Importing untrained model
2023-02-15 19:19:35,203:INFO:Decision Tree Regressor Imported successfully
2023-02-15 19:19:35,203:INFO:Starting cross validation
2023-02-15 19:19:35,205:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:23:28,612:INFO:Calculating mean and std
2023-02-15 19:23:28,612:INFO:Creating metrics dataframe
2023-02-15 19:23:28,614:INFO:Uploading results into container
2023-02-15 19:23:28,615:INFO:Uploading model into container now
2023-02-15 19:23:28,615:INFO:_master_model_container: 13
2023-02-15 19:23:28,615:INFO:_display_container: 2
2023-02-15 19:23:28,615:INFO:DecisionTreeRegressor(random_state=11)
2023-02-15 19:23:28,615:INFO:create_model() successfully completed......................................
2023-02-15 19:23:28,811:INFO:SubProcess create_model() end ==================================
2023-02-15 19:23:28,811:INFO:Creating metrics dataframe
2023-02-15 19:23:28,815:INFO:Initializing Random Forest Regressor
2023-02-15 19:23:28,815:INFO:Total runtime is 8.175941709677378 minutes
2023-02-15 19:23:28,815:INFO:SubProcess create_model() called ==================================
2023-02-15 19:23:28,815:INFO:Initializing create_model()
2023-02-15 19:23:28,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa2d4ef3850>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa2aad0cd90>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:23:28,815:INFO:Checking exceptions
2023-02-15 19:23:28,815:INFO:Importing libraries
2023-02-15 19:23:28,815:INFO:Copying training dataset
2023-02-15 19:23:28,941:INFO:Defining folds
2023-02-15 19:23:28,941:INFO:Declaring metric variables
2023-02-15 19:23:28,941:INFO:Importing untrained model
2023-02-15 19:23:28,942:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:23:28,942:INFO:Random Forest Regressor Imported successfully
2023-02-15 19:23:28,942:INFO:Starting cross validation
2023-02-15 19:23:28,945:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:23:28,947:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:23:29,388:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:26:39,118:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:40,206:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:40,206:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:40,206:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:40,407:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 19:26:40,489:INFO:PyCaret RegressionExperiment
2023-02-15 19:26:40,489:INFO:Logging name: reg-default-name
2023-02-15 19:26:40,489:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 19:26:40,489:INFO:version 3.0.0.rc9
2023-02-15 19:26:40,489:INFO:Initializing setup()
2023-02-15 19:26:40,489:INFO:self.USI: 1ad0
2023-02-15 19:26:40,489:INFO:self._variable_keys: {'X_train', 'idx', '_available_plots', '_ml_usecase', 'html_param', 'y_test', 'exp_name_log', 'memory', 'y_train', 'log_plots_param', 'X', 'gpu_param', 'y', 'pipeline', 'target_param', 'exp_id', 'transform_target_param', 'fold_shuffle_param', 'data', 'seed', 'USI', 'logging_param', 'n_jobs_param', 'fold_generator', 'X_test', 'gpu_n_jobs_param', 'fold_groups_param'}
2023-02-15 19:26:40,489:INFO:Checking environment
2023-02-15 19:26:40,489:INFO:python_version: 3.8.16
2023-02-15 19:26:40,489:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-15 19:26:40,489:INFO:machine: x86_64
2023-02-15 19:26:40,502:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 19:26:40,502:INFO:Memory: svmem(total=134979592192, available=113408811008, percent=16.0, used=19908526080, free=31078342656, active=12505366528, inactive=87185235968, buffers=1477144576, cached=82515578880, shared=390242304, slab=3458859008)
2023-02-15 19:26:40,503:INFO:Physical Core: 16
2023-02-15 19:26:40,503:INFO:Logical Core: 32
2023-02-15 19:26:40,503:INFO:Checking libraries
2023-02-15 19:26:40,503:INFO:System:
2023-02-15 19:26:40,503:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-15 19:26:40,503:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 19:26:40,503:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 19:26:40,503:INFO:PyCaret required dependencies:
2023-02-15 19:26:40,503:INFO:                 pip: 23.0
2023-02-15 19:26:40,503:INFO:          setuptools: 60.10.0
2023-02-15 19:26:40,503:INFO:             pycaret: 3.0.0rc9
2023-02-15 19:26:40,503:INFO:             IPython: 8.10.0
2023-02-15 19:26:40,503:INFO:          ipywidgets: 7.7.3
2023-02-15 19:26:40,503:INFO:                tqdm: 4.64.1
2023-02-15 19:26:40,503:INFO:               numpy: 1.23.5
2023-02-15 19:26:40,503:INFO:              pandas: 1.5.3
2023-02-15 19:26:40,503:INFO:              jinja2: 3.1.2
2023-02-15 19:26:40,503:INFO:               scipy: 1.9.1
2023-02-15 19:26:40,503:INFO:              joblib: 1.2.0
2023-02-15 19:26:40,503:INFO:             sklearn: 1.2.1
2023-02-15 19:26:40,503:INFO:                pyod: 1.0.7
2023-02-15 19:26:40,503:INFO:            imblearn: 0.10.1
2023-02-15 19:26:40,503:INFO:   category_encoders: 2.6.0
2023-02-15 19:26:40,503:INFO:            lightgbm: 3.3.5.99
2023-02-15 19:26:40,503:INFO:               numba: 0.56.4
2023-02-15 19:26:40,503:INFO:            requests: 2.28.2
2023-02-15 19:26:40,503:INFO:          matplotlib: 3.6.3
2023-02-15 19:26:40,503:INFO:          scikitplot: 0.3.7
2023-02-15 19:26:40,503:INFO:         yellowbrick: 1.5
2023-02-15 19:26:40,503:INFO:              plotly: 5.13.0
2023-02-15 19:26:40,503:INFO:             kaleido: 0.2.1
2023-02-15 19:26:40,503:INFO:         statsmodels: 0.13.5
2023-02-15 19:26:40,503:INFO:              sktime: 0.16.1
2023-02-15 19:26:40,503:INFO:               tbats: 1.1.2
2023-02-15 19:26:40,503:INFO:            pmdarima: 2.0.2
2023-02-15 19:26:40,503:INFO:              psutil: 5.9.4
2023-02-15 19:26:40,503:INFO:PyCaret optional dependencies:
2023-02-15 19:26:40,917:INFO:                shap: 0.41.0
2023-02-15 19:26:40,917:INFO:           interpret: 0.3.0
2023-02-15 19:26:40,917:INFO:                umap: 0.5.3
2023-02-15 19:26:40,917:INFO:    pandas_profiling: 4.0.0
2023-02-15 19:26:40,917:INFO:  explainerdashboard: 0.4.2
2023-02-15 19:26:40,917:INFO:             autoviz: 0.1.58
2023-02-15 19:26:40,917:INFO:           fairlearn: 0.7.0
2023-02-15 19:26:40,917:INFO:             xgboost: 1.7.3
2023-02-15 19:26:40,917:INFO:            catboost: 1.1.1
2023-02-15 19:26:40,917:INFO:              kmodes: 0.12.2
2023-02-15 19:26:40,917:INFO:             mlxtend: 0.21.0
2023-02-15 19:26:40,917:INFO:       statsforecast: 1.4.0
2023-02-15 19:26:40,917:INFO:        tune_sklearn: 0.4.5
2023-02-15 19:26:40,917:INFO:                 ray: 2.2.0
2023-02-15 19:26:40,917:INFO:            hyperopt: 0.2.7
2023-02-15 19:26:40,917:INFO:              optuna: 3.1.0
2023-02-15 19:26:40,917:INFO:               skopt: 0.9.0
2023-02-15 19:26:40,917:INFO:              mlflow: 1.30.0
2023-02-15 19:26:40,917:INFO:              gradio: 3.18.0
2023-02-15 19:26:40,917:INFO:             fastapi: 0.92.0
2023-02-15 19:26:40,917:INFO:             uvicorn: 0.20.0
2023-02-15 19:26:40,917:INFO:              m2cgen: 0.10.0
2023-02-15 19:26:40,917:INFO:           evidently: 0.2.4
2023-02-15 19:26:40,917:INFO:               fugue: 0.8.1.dev4
2023-02-15 19:26:40,918:INFO:           streamlit: Not installed
2023-02-15 19:26:40,918:INFO:             prophet: Not installed
2023-02-15 19:26:40,918:INFO:None
2023-02-15 19:26:40,918:INFO:Set up GPU usage.
2023-02-15 19:26:40,918:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:40,918:INFO:cuml==23.2.0
2023-02-15 19:26:40,918:ERROR:Couldn't set cuML global output type
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/tabular_experiment.py", line 351, in _initialize_setup
    import cuml.common.memory_utils
ModuleNotFoundError: No module named 'cuml.common.memory_utils'
2023-02-15 19:26:40,918:INFO:Set up data.
2023-02-15 19:26:41,212:INFO:Set up train/test split.
2023-02-15 19:26:41,426:INFO:Set up index.
2023-02-15 19:26:41,483:INFO:Set up folding strategy.
2023-02-15 19:26:41,483:INFO:Assigning column types.
2023-02-15 19:26:41,611:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 19:26:41,611:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:41,611:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:41,611:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 19:26:41,611:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:41,611:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:41,614:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:26:41,614:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:41,614:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:41,617:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:26:41,617:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:41,617:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:41,750:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:26:41,751:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:41,751:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:41,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:26:41,777:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:41,777:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:41,777:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:41,777:INFO:Imported cuml.ensemble
2023-02-15 19:26:41,778:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:42,037:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:42,089:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,090:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:42,090:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,090:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,090:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:42,093:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,093:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,093:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:42,095:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,095:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,095:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:42,227:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,227:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,227:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:42,254:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,254:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,254:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:42,255:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,255:INFO:Imported cuml.ensemble
2023-02-15 19:26:42,255:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:42,334:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:42,387:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 19:26:42,387:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,387:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:42,387:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,387:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:42,390:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,390:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,390:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:42,393:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,393:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,393:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:42,522:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,522:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,522:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:42,549:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,549:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,549:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:42,549:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,549:INFO:Imported cuml.ensemble
2023-02-15 19:26:42,550:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:42,625:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:42,671:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,671:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:42,671:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,671:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:42,674:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,674:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,674:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:42,676:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,676:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,676:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:42,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,797:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,797:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:42,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,824:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,824:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:42,824:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,825:INFO:Imported cuml.ensemble
2023-02-15 19:26:42,825:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:42,900:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:42,946:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 19:26:42,946:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,946:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:42,946:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,946:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:42,949:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,949:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:42,952:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:26:42,952:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:42,952:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:43,073:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:26:43,073:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,073:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:43,100:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:26:43,100:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,100:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:43,100:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,100:INFO:Imported cuml.ensemble
2023-02-15 19:26:43,100:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:43,174:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:43,215:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,215:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:43,215:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,215:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:43,218:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,218:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:43,221:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:26:43,221:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,221:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:43,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:26:43,336:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,336:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:43,363:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:26:43,363:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,363:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:43,363:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,363:INFO:Imported cuml.ensemble
2023-02-15 19:26:43,363:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:43,439:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:43,484:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 19:26:43,484:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,484:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:43,484:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,484:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:43,487:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,487:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:43,490:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,490:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:43,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:26:43,613:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,613:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:43,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:26:43,640:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,640:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:43,641:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,641:INFO:Imported cuml.ensemble
2023-02-15 19:26:43,641:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:43,718:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:43,763:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,764:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:43,764:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,764:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:43,766:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,766:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:43,769:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,769:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:43,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:26:43,890:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,890:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:43,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:26:43,918:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,918:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:43,918:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:43,918:INFO:Imported cuml.ensemble
2023-02-15 19:26:43,918:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:43,991:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:44,038:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 19:26:44,038:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,038:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:44,038:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,038:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:44,041:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,041:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:44,044:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,044:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:44,164:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:26:44,164:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,164:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:44,191:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,191:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:44,192:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,192:INFO:Imported cuml.ensemble
2023-02-15 19:26:44,192:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:44,267:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:44,312:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,313:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:44,313:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,313:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:44,315:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,315:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:44,318:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,318:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:44,438:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:26:44,438:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,438:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:44,465:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,465:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:44,465:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,465:INFO:Imported cuml.ensemble
2023-02-15 19:26:44,465:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:44,545:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:44,592:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 19:26:44,592:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,592:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:44,592:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,592:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:44,595:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,595:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:44,597:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,597:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:44,707:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,707:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:44,734:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,734:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:44,734:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,734:INFO:Imported cuml.ensemble
2023-02-15 19:26:44,734:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:44,813:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:44,857:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,857:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:44,857:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,857:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:44,860:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,860:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:44,863:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,863:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:44,981:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:44,981:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:45,009:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:45,010:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:45,010:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:45,010:INFO:Imported cuml.ensemble
2023-02-15 19:26:45,010:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:45,088:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:45,135:INFO:Preparing preprocessing pipeline...
2023-02-15 19:26:45,150:INFO:Set up column name cleaning.
2023-02-15 19:26:45,150:INFO:Set up simple imputation.
2023-02-15 19:26:45,150:INFO:Set up feature normalization.
2023-02-15 19:26:45,564:INFO:Finished creating preprocessing pipeline.
2023-02-15 19:26:45,571:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'volumeChg24HR', 'volumeChg%24HR',
                                             'volume_$Chg24HR',
                                             'volume_$Chg%24HR', 'closeChg1HR',
                                             'closeChg%1HR', 'openChg1HR',
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-15 19:26:45,571:INFO:Creating final display dataframe.
2023-02-15 19:26:46,887:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28570, 780)
4        Transformed data shape           (28570, 775)
5   Transformed train set shape           (19999, 775)
6    Transformed test set shape            (8571, 775)
7               Ignore features                      5
8              Numeric features                    774
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15               Fold Generator                  KFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment                  False
20              Experiment Name       reg-default-name
21                          USI                   1ad0
2023-02-15 19:26:46,889:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:46,889:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:46,890:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:46,890:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:46,892:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:46,892:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:46,895:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:46,895:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:47,029:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:47,029:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:47,056:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:47,056:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:47,056:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:47,056:INFO:Imported cuml.ensemble
2023-02-15 19:26:47,056:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:47,137:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:47,189:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:47,189:INFO:Imported cuml.linear_model.LinearRegression
2023-02-15 19:26:47,189:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:47,189:INFO:Imported cuml.linear_model.Lasso
2023-02-15 19:26:47,192:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:47,192:INFO:Imported cuml.linear_model.Ridge
2023-02-15 19:26:47,195:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:47,195:INFO:Imported cuml.linear_model.ElasticNet
2023-02-15 19:26:47,342:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:47,342:INFO:Imported cuml.svm.SVR
2023-02-15 19:26:47,369:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:47,369:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-15 19:26:47,369:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:26:47,369:INFO:Imported cuml.ensemble
2023-02-15 19:26:47,370:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:26:47,444:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:26:47,486:INFO:setup() successfully completed in 7.0s...............
2023-02-15 19:26:47,486:INFO:Initializing compare_models()
2023-02-15 19:26:47,486:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 19:26:47,486:INFO:Checking exceptions
2023-02-15 19:26:47,525:INFO:Preparing display monitor
2023-02-15 19:26:47,528:INFO:Initializing Linear Regression
2023-02-15 19:26:47,528:INFO:Total runtime is 8.106231689453125e-07 minutes
2023-02-15 19:26:47,528:INFO:SubProcess create_model() called ==================================
2023-02-15 19:26:47,528:INFO:Initializing create_model()
2023-02-15 19:26:47,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:26:47,528:INFO:Checking exceptions
2023-02-15 19:26:47,528:INFO:Importing libraries
2023-02-15 19:26:47,528:INFO:Copying training dataset
2023-02-15 19:26:47,658:INFO:Defining folds
2023-02-15 19:26:47,658:INFO:Declaring metric variables
2023-02-15 19:26:47,658:INFO:Importing untrained model
2023-02-15 19:26:47,659:INFO:Linear Regression Imported successfully
2023-02-15 19:26:47,659:INFO:Starting cross validation
2023-02-15 19:26:47,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:26:55,324:INFO:Calculating mean and std
2023-02-15 19:26:55,324:INFO:Creating metrics dataframe
2023-02-15 19:26:55,326:INFO:Uploading results into container
2023-02-15 19:26:55,327:INFO:Uploading model into container now
2023-02-15 19:26:55,327:INFO:_master_model_container: 1
2023-02-15 19:26:55,327:INFO:_display_container: 2
2023-02-15 19:26:55,327:INFO:LinearRegression()
2023-02-15 19:26:55,327:INFO:create_model() successfully completed......................................
2023-02-15 19:26:55,530:INFO:SubProcess create_model() end ==================================
2023-02-15 19:26:55,531:INFO:Creating metrics dataframe
2023-02-15 19:26:55,534:INFO:Initializing Lasso Regression
2023-02-15 19:26:55,534:INFO:Total runtime is 0.13343201478322347 minutes
2023-02-15 19:26:55,534:INFO:SubProcess create_model() called ==================================
2023-02-15 19:26:55,534:INFO:Initializing create_model()
2023-02-15 19:26:55,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:26:55,534:INFO:Checking exceptions
2023-02-15 19:26:55,534:INFO:Importing libraries
2023-02-15 19:26:55,534:INFO:Copying training dataset
2023-02-15 19:26:55,671:INFO:Defining folds
2023-02-15 19:26:55,671:INFO:Declaring metric variables
2023-02-15 19:26:55,671:INFO:Importing untrained model
2023-02-15 19:26:55,672:INFO:Lasso Regression Imported successfully
2023-02-15 19:26:55,672:INFO:Starting cross validation
2023-02-15 19:26:55,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:27:01,177:INFO:Calculating mean and std
2023-02-15 19:27:01,178:INFO:Creating metrics dataframe
2023-02-15 19:27:01,179:INFO:Uploading results into container
2023-02-15 19:27:01,180:INFO:Uploading model into container now
2023-02-15 19:27:01,180:INFO:_master_model_container: 2
2023-02-15 19:27:01,180:INFO:_display_container: 2
2023-02-15 19:27:01,180:INFO:Lasso()
2023-02-15 19:27:01,180:INFO:create_model() successfully completed......................................
2023-02-15 19:27:01,381:INFO:SubProcess create_model() end ==================================
2023-02-15 19:27:01,381:INFO:Creating metrics dataframe
2023-02-15 19:27:01,385:INFO:Initializing Ridge Regression
2023-02-15 19:27:01,385:INFO:Total runtime is 0.23095073302586874 minutes
2023-02-15 19:27:01,385:INFO:SubProcess create_model() called ==================================
2023-02-15 19:27:01,385:INFO:Initializing create_model()
2023-02-15 19:27:01,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:27:01,385:INFO:Checking exceptions
2023-02-15 19:27:01,385:INFO:Importing libraries
2023-02-15 19:27:01,385:INFO:Copying training dataset
2023-02-15 19:27:01,496:INFO:Defining folds
2023-02-15 19:27:01,496:INFO:Declaring metric variables
2023-02-15 19:27:01,496:INFO:Importing untrained model
2023-02-15 19:27:01,496:INFO:Ridge Regression Imported successfully
2023-02-15 19:27:01,497:INFO:Starting cross validation
2023-02-15 19:27:01,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:27:07,157:INFO:Calculating mean and std
2023-02-15 19:27:07,158:INFO:Creating metrics dataframe
2023-02-15 19:27:07,160:INFO:Uploading results into container
2023-02-15 19:27:07,160:INFO:Uploading model into container now
2023-02-15 19:27:07,160:INFO:_master_model_container: 3
2023-02-15 19:27:07,160:INFO:_display_container: 2
2023-02-15 19:27:07,160:INFO:Ridge()
2023-02-15 19:27:07,160:INFO:create_model() successfully completed......................................
2023-02-15 19:27:07,365:INFO:SubProcess create_model() end ==================================
2023-02-15 19:27:07,366:INFO:Creating metrics dataframe
2023-02-15 19:27:07,369:INFO:Initializing Elastic Net
2023-02-15 19:27:07,369:INFO:Total runtime is 0.33068716128667197 minutes
2023-02-15 19:27:07,369:INFO:SubProcess create_model() called ==================================
2023-02-15 19:27:07,369:INFO:Initializing create_model()
2023-02-15 19:27:07,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:27:07,369:INFO:Checking exceptions
2023-02-15 19:27:07,369:INFO:Importing libraries
2023-02-15 19:27:07,369:INFO:Copying training dataset
2023-02-15 19:27:07,506:INFO:Defining folds
2023-02-15 19:27:07,506:INFO:Declaring metric variables
2023-02-15 19:27:07,506:INFO:Importing untrained model
2023-02-15 19:27:07,507:INFO:Elastic Net Imported successfully
2023-02-15 19:27:07,507:INFO:Starting cross validation
2023-02-15 19:27:07,509:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:27:12,986:INFO:Calculating mean and std
2023-02-15 19:27:12,987:INFO:Creating metrics dataframe
2023-02-15 19:27:12,989:INFO:Uploading results into container
2023-02-15 19:27:12,989:INFO:Uploading model into container now
2023-02-15 19:27:12,989:INFO:_master_model_container: 4
2023-02-15 19:27:12,989:INFO:_display_container: 2
2023-02-15 19:27:12,989:INFO:ElasticNet()
2023-02-15 19:27:12,989:INFO:create_model() successfully completed......................................
2023-02-15 19:27:13,166:INFO:SubProcess create_model() end ==================================
2023-02-15 19:27:13,166:INFO:Creating metrics dataframe
2023-02-15 19:27:13,169:INFO:Initializing Least Angle Regression
2023-02-15 19:27:13,169:INFO:Total runtime is 0.4273606061935425 minutes
2023-02-15 19:27:13,170:INFO:SubProcess create_model() called ==================================
2023-02-15 19:27:13,170:INFO:Initializing create_model()
2023-02-15 19:27:13,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:27:13,170:INFO:Checking exceptions
2023-02-15 19:27:13,170:INFO:Importing libraries
2023-02-15 19:27:13,170:INFO:Copying training dataset
2023-02-15 19:27:13,308:INFO:Defining folds
2023-02-15 19:27:13,309:INFO:Declaring metric variables
2023-02-15 19:27:13,309:INFO:Importing untrained model
2023-02-15 19:27:13,309:INFO:Least Angle Regression Imported successfully
2023-02-15 19:27:13,309:INFO:Starting cross validation
2023-02-15 19:27:13,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:27:13,838:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.380e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:13,838:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 19:27:13,846:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.077e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:14,182:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:713: RuntimeWarning: invalid value encountered in multiply
  least_squares *= AA

2023-02-15 19:27:14,187:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:736: RuntimeWarning: divide by zero encountered in double_scalars
  gamma_ = min(g1, g2, C / AA)

2023-02-15 19:27:14,188:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-02-15 19:27:14,869:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:27:14,869:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:27:14,869:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:27:15,397:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.056e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:15,411:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.968e-04, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:15,529:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.024e-02, with an active set of 180 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:16,676:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:27:16,800:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:27:17,416:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=9.145e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:17,611:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:27:17,956:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:27:18,601:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.172e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:18,604:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 19:27:18,627:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.377e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:20,344:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:27:20,604:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:27:22,161:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.213e-03, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:23,076:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.325e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:23,176:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=4.256e-03, with an active set of 148 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:23,196:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=4.098e-03, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:24,732:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 19:27:24,732:INFO:Calculating mean and std
2023-02-15 19:27:24,733:INFO:Creating metrics dataframe
2023-02-15 19:27:24,735:INFO:Uploading results into container
2023-02-15 19:27:24,735:INFO:Uploading model into container now
2023-02-15 19:27:24,736:INFO:_master_model_container: 5
2023-02-15 19:27:24,736:INFO:_display_container: 2
2023-02-15 19:27:24,736:INFO:Lars(random_state=11)
2023-02-15 19:27:24,736:INFO:create_model() successfully completed......................................
2023-02-15 19:27:24,931:WARNING:create_model() for Lars(random_state=11) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-15 19:27:24,932:WARNING:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2023-02-15 19:27:24,932:INFO:Initializing create_model()
2023-02-15 19:27:24,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:27:24,932:INFO:Checking exceptions
2023-02-15 19:27:24,932:INFO:Importing libraries
2023-02-15 19:27:24,932:INFO:Copying training dataset
2023-02-15 19:27:25,062:INFO:Defining folds
2023-02-15 19:27:25,062:INFO:Declaring metric variables
2023-02-15 19:27:25,062:INFO:Importing untrained model
2023-02-15 19:27:25,062:INFO:Least Angle Regression Imported successfully
2023-02-15 19:27:25,062:INFO:Starting cross validation
2023-02-15 19:27:25,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:27:25,604:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:27:25,604:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:27:25,604:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:27:27,031:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:27:27,156:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:27:27,775:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=9.145e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:27:28,082:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:27:28,438:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:27:29,873:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:27:30,105:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:706: RuntimeWarning: overflow encountered in add
  L_.flat[:: n_active + 1] += (2**i) * eps

2023-02-15 19:27:32,530:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/comet_ml/monkey_patching.py", line 312, in wrapper
    return_value = original(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1144, in fit
    self._fit(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 1046, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 170, in lars_path
    return _lars_path_solver(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py", line 706, in _lars_path_solver
    L_.flat[:: n_active + 1] += (2**i) * eps
OverflowError: int too large to convert to float

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 19:27:32,530:INFO:Calculating mean and std
2023-02-15 19:27:32,531:INFO:Creating metrics dataframe
2023-02-15 19:27:32,533:INFO:Uploading results into container
2023-02-15 19:27:32,534:INFO:Uploading model into container now
2023-02-15 19:27:32,534:INFO:_master_model_container: 6
2023-02-15 19:27:32,534:INFO:_display_container: 2
2023-02-15 19:27:32,534:INFO:Lars(random_state=11)
2023-02-15 19:27:32,534:INFO:create_model() successfully completed......................................
2023-02-15 19:27:32,717:ERROR:create_model() for Lars(random_state=11) raised an exception or returned all 0.0:
2023-02-15 19:27:32,717:ERROR:Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2023-02-15 19:27:32,717:INFO:Initializing Lasso Least Angle Regression
2023-02-15 19:27:32,717:INFO:Total runtime is 0.7531607389450073 minutes
2023-02-15 19:27:32,718:INFO:SubProcess create_model() called ==================================
2023-02-15 19:27:32,718:INFO:Initializing create_model()
2023-02-15 19:27:32,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:27:32,718:INFO:Checking exceptions
2023-02-15 19:27:32,718:INFO:Importing libraries
2023-02-15 19:27:32,718:INFO:Copying training dataset
2023-02-15 19:27:32,832:INFO:Defining folds
2023-02-15 19:27:32,832:INFO:Declaring metric variables
2023-02-15 19:27:32,832:INFO:Importing untrained model
2023-02-15 19:27:32,832:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 19:27:32,833:INFO:Starting cross validation
2023-02-15 19:27:32,835:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:27:38,735:INFO:Calculating mean and std
2023-02-15 19:27:38,736:INFO:Creating metrics dataframe
2023-02-15 19:27:38,738:INFO:Uploading results into container
2023-02-15 19:27:38,738:INFO:Uploading model into container now
2023-02-15 19:27:38,739:INFO:_master_model_container: 7
2023-02-15 19:27:38,739:INFO:_display_container: 2
2023-02-15 19:27:38,739:INFO:LassoLars(random_state=11)
2023-02-15 19:27:38,739:INFO:create_model() successfully completed......................................
2023-02-15 19:27:38,905:INFO:SubProcess create_model() end ==================================
2023-02-15 19:27:38,905:INFO:Creating metrics dataframe
2023-02-15 19:27:38,908:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 19:27:38,908:INFO:Total runtime is 0.8563429514567058 minutes
2023-02-15 19:27:38,908:INFO:SubProcess create_model() called ==================================
2023-02-15 19:27:38,909:INFO:Initializing create_model()
2023-02-15 19:27:38,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:27:38,909:INFO:Checking exceptions
2023-02-15 19:27:38,909:INFO:Importing libraries
2023-02-15 19:27:38,909:INFO:Copying training dataset
2023-02-15 19:27:39,027:INFO:Defining folds
2023-02-15 19:27:39,027:INFO:Declaring metric variables
2023-02-15 19:27:39,027:INFO:Importing untrained model
2023-02-15 19:27:39,028:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 19:27:39,028:INFO:Starting cross validation
2023-02-15 19:27:39,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:27:45,231:INFO:Calculating mean and std
2023-02-15 19:27:45,232:INFO:Creating metrics dataframe
2023-02-15 19:27:45,234:INFO:Uploading results into container
2023-02-15 19:27:45,235:INFO:Uploading model into container now
2023-02-15 19:27:45,235:INFO:_master_model_container: 8
2023-02-15 19:27:45,235:INFO:_display_container: 2
2023-02-15 19:27:45,235:INFO:OrthogonalMatchingPursuit()
2023-02-15 19:27:45,235:INFO:create_model() successfully completed......................................
2023-02-15 19:27:45,444:INFO:SubProcess create_model() end ==================================
2023-02-15 19:27:45,444:INFO:Creating metrics dataframe
2023-02-15 19:27:45,448:INFO:Initializing Bayesian Ridge
2023-02-15 19:27:45,448:INFO:Total runtime is 0.9653325279553732 minutes
2023-02-15 19:27:45,448:INFO:SubProcess create_model() called ==================================
2023-02-15 19:27:45,448:INFO:Initializing create_model()
2023-02-15 19:27:45,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:27:45,448:INFO:Checking exceptions
2023-02-15 19:27:45,448:INFO:Importing libraries
2023-02-15 19:27:45,448:INFO:Copying training dataset
2023-02-15 19:27:45,587:INFO:Defining folds
2023-02-15 19:27:45,587:INFO:Declaring metric variables
2023-02-15 19:27:45,587:INFO:Importing untrained model
2023-02-15 19:27:45,587:INFO:Bayesian Ridge Imported successfully
2023-02-15 19:27:45,587:INFO:Starting cross validation
2023-02-15 19:27:45,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:28:07,188:INFO:Calculating mean and std
2023-02-15 19:28:07,189:INFO:Creating metrics dataframe
2023-02-15 19:28:07,191:INFO:Uploading results into container
2023-02-15 19:28:07,191:INFO:Uploading model into container now
2023-02-15 19:28:07,192:INFO:_master_model_container: 9
2023-02-15 19:28:07,192:INFO:_display_container: 2
2023-02-15 19:28:07,192:INFO:BayesianRidge()
2023-02-15 19:28:07,192:INFO:create_model() successfully completed......................................
2023-02-15 19:28:07,404:INFO:SubProcess create_model() end ==================================
2023-02-15 19:28:07,405:INFO:Creating metrics dataframe
2023-02-15 19:28:07,408:INFO:Initializing Passive Aggressive Regressor
2023-02-15 19:28:07,408:INFO:Total runtime is 1.331335218747457 minutes
2023-02-15 19:28:07,408:INFO:SubProcess create_model() called ==================================
2023-02-15 19:28:07,408:INFO:Initializing create_model()
2023-02-15 19:28:07,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:28:07,408:INFO:Checking exceptions
2023-02-15 19:28:07,408:INFO:Importing libraries
2023-02-15 19:28:07,408:INFO:Copying training dataset
2023-02-15 19:28:07,518:INFO:Defining folds
2023-02-15 19:28:07,518:INFO:Declaring metric variables
2023-02-15 19:28:07,519:INFO:Importing untrained model
2023-02-15 19:28:07,519:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 19:28:07,519:INFO:Starting cross validation
2023-02-15 19:28:07,521:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:28:15,995:INFO:Calculating mean and std
2023-02-15 19:28:15,996:INFO:Creating metrics dataframe
2023-02-15 19:28:15,998:INFO:Uploading results into container
2023-02-15 19:28:15,998:INFO:Uploading model into container now
2023-02-15 19:28:15,999:INFO:_master_model_container: 10
2023-02-15 19:28:15,999:INFO:_display_container: 2
2023-02-15 19:28:15,999:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 19:28:15,999:INFO:create_model() successfully completed......................................
2023-02-15 19:28:16,191:INFO:SubProcess create_model() end ==================================
2023-02-15 19:28:16,191:INFO:Creating metrics dataframe
2023-02-15 19:28:16,195:INFO:Initializing Huber Regressor
2023-02-15 19:28:16,195:INFO:Total runtime is 1.4777835925420126 minutes
2023-02-15 19:28:16,195:INFO:SubProcess create_model() called ==================================
2023-02-15 19:28:16,195:INFO:Initializing create_model()
2023-02-15 19:28:16,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:28:16,195:INFO:Checking exceptions
2023-02-15 19:28:16,195:INFO:Importing libraries
2023-02-15 19:28:16,195:INFO:Copying training dataset
2023-02-15 19:28:16,334:INFO:Defining folds
2023-02-15 19:28:16,334:INFO:Declaring metric variables
2023-02-15 19:28:16,334:INFO:Importing untrained model
2023-02-15 19:28:16,334:INFO:Huber Regressor Imported successfully
2023-02-15 19:28:16,335:INFO:Starting cross validation
2023-02-15 19:28:16,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:28:32,705:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:28:49,621:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:29:05,659:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:29:22,447:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:29:38,253:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:29:54,863:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:30:10,956:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:30:27,665:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:30:44,611:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:30:56,419:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:30:56,659:INFO:Calculating mean and std
2023-02-15 19:30:56,660:INFO:Creating metrics dataframe
2023-02-15 19:30:56,662:INFO:Uploading results into container
2023-02-15 19:30:56,663:INFO:Uploading model into container now
2023-02-15 19:30:56,663:INFO:_master_model_container: 11
2023-02-15 19:30:56,663:INFO:_display_container: 2
2023-02-15 19:30:56,663:INFO:HuberRegressor()
2023-02-15 19:30:56,663:INFO:create_model() successfully completed......................................
2023-02-15 19:30:56,844:INFO:SubProcess create_model() end ==================================
2023-02-15 19:30:56,844:INFO:Creating metrics dataframe
2023-02-15 19:30:56,847:INFO:Initializing K Neighbors Regressor
2023-02-15 19:30:56,847:INFO:Total runtime is 4.155319742361705 minutes
2023-02-15 19:30:56,847:INFO:SubProcess create_model() called ==================================
2023-02-15 19:30:56,847:INFO:Initializing create_model()
2023-02-15 19:30:56,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:30:56,847:INFO:Checking exceptions
2023-02-15 19:30:56,847:INFO:Importing libraries
2023-02-15 19:30:56,847:INFO:Copying training dataset
2023-02-15 19:30:56,975:INFO:Defining folds
2023-02-15 19:30:56,975:INFO:Declaring metric variables
2023-02-15 19:30:56,975:INFO:Importing untrained model
2023-02-15 19:30:56,976:INFO:K Neighbors Regressor Imported successfully
2023-02-15 19:30:56,976:INFO:Starting cross validation
2023-02-15 19:30:56,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:30:56,979:INFO:[I] [19:30:56.979989] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:30:57,401:INFO:[I] [19:30:57.401120] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:30:57,555:INFO:[I] [19:30:57.555272] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:30:57,967:INFO:[I] [19:30:57.967265] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:30:58,106:INFO:[I] [19:30:58.106916] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:30:58,539:INFO:[I] [19:30:58.539451] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:30:58,674:INFO:[I] [19:30:58.674489] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:30:59,102:INFO:[I] [19:30:59.101992] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:30:59,235:INFO:[I] [19:30:59.235822] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:30:59,663:INFO:[I] [19:30:59.663526] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:30:59,806:INFO:[I] [19:30:59.806294] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:31:00,225:INFO:[I] [19:31:00.225235] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:31:00,370:INFO:[I] [19:31:00.370858] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:31:00,733:INFO:[I] [19:31:00.733049] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:31:00,874:INFO:[I] [19:31:00.874443] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:31:01,311:INFO:[I] [19:31:01.311659] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:31:01,450:INFO:[I] [19:31:01.450403] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:31:01,904:INFO:[I] [19:31:01.904287] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:31:02,043:INFO:[I] [19:31:02.043724] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:31:02,487:INFO:[I] [19:31:02.487234] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-15 19:31:02,620:INFO:Calculating mean and std
2023-02-15 19:31:02,621:INFO:Creating metrics dataframe
2023-02-15 19:31:02,622:INFO:Uploading results into container
2023-02-15 19:31:02,623:INFO:Uploading model into container now
2023-02-15 19:31:02,623:INFO:_master_model_container: 12
2023-02-15 19:31:02,623:INFO:_display_container: 2
2023-02-15 19:31:02,623:INFO:KNeighborsRegressor()
2023-02-15 19:31:02,623:INFO:create_model() successfully completed......................................
2023-02-15 19:31:02,828:INFO:SubProcess create_model() end ==================================
2023-02-15 19:31:02,828:INFO:Creating metrics dataframe
2023-02-15 19:31:02,832:INFO:Initializing Decision Tree Regressor
2023-02-15 19:31:02,832:INFO:Total runtime is 4.255067197481791 minutes
2023-02-15 19:31:02,832:INFO:SubProcess create_model() called ==================================
2023-02-15 19:31:02,832:INFO:Initializing create_model()
2023-02-15 19:31:02,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:31:02,832:INFO:Checking exceptions
2023-02-15 19:31:02,832:INFO:Importing libraries
2023-02-15 19:31:02,832:INFO:Copying training dataset
2023-02-15 19:31:02,971:INFO:Defining folds
2023-02-15 19:31:02,972:INFO:Declaring metric variables
2023-02-15 19:31:02,972:INFO:Importing untrained model
2023-02-15 19:31:02,972:INFO:Decision Tree Regressor Imported successfully
2023-02-15 19:31:02,972:INFO:Starting cross validation
2023-02-15 19:31:02,975:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:34:55,283:INFO:Calculating mean and std
2023-02-15 19:34:55,283:INFO:Creating metrics dataframe
2023-02-15 19:34:55,285:INFO:Uploading results into container
2023-02-15 19:34:55,286:INFO:Uploading model into container now
2023-02-15 19:34:55,286:INFO:_master_model_container: 13
2023-02-15 19:34:55,286:INFO:_display_container: 2
2023-02-15 19:34:55,286:INFO:DecisionTreeRegressor(random_state=11)
2023-02-15 19:34:55,286:INFO:create_model() successfully completed......................................
2023-02-15 19:34:55,496:INFO:SubProcess create_model() end ==================================
2023-02-15 19:34:55,496:INFO:Creating metrics dataframe
2023-02-15 19:34:55,499:INFO:Initializing Random Forest Regressor
2023-02-15 19:34:55,499:INFO:Total runtime is 8.132859508196514 minutes
2023-02-15 19:34:55,499:INFO:SubProcess create_model() called ==================================
2023-02-15 19:34:55,500:INFO:Initializing create_model()
2023-02-15 19:34:55,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f5f60709880>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5f391fc730>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:34:55,500:INFO:Checking exceptions
2023-02-15 19:34:55,500:INFO:Importing libraries
2023-02-15 19:34:55,500:INFO:Copying training dataset
2023-02-15 19:34:55,640:INFO:Defining folds
2023-02-15 19:34:55,640:INFO:Declaring metric variables
2023-02-15 19:34:55,640:INFO:Importing untrained model
2023-02-15 19:34:55,640:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:34:55,641:INFO:Random Forest Regressor Imported successfully
2023-02-15 19:34:55,641:INFO:Starting cross validation
2023-02-15 19:34:55,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-15 19:34:55,644:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:34:56,121:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:35:02,132:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 297, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/nvtx/nvtx.py", line 101, in inner
    result = func(*args, **kwargs)
  File "randomforestregressor.pyx", line 588, in cuml.ensemble.randomforestregressor.RandomForestRegressor.predict
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "randomforest_common.pyx", line 353, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu
  File "randomforest_common.pyx", line 218, in cuml.ensemble.randomforest_common.BaseRandomForestModel._obtain_treelite_handle
  File "randomforest_shared.pyx", line 121, in cuml.ensemble.randomforest_shared.treelite_deserialize
  File "randomforest_shared.pyx", line 105, in cuml.ensemble.randomforest_shared.init_from_frames
  File "randomforest_shared.pyx", line 84, in cuml.ensemble.randomforest_shared._init_from_frames
RuntimeError: Could not load the correct number of nodes

  warnings.warn(

2023-02-15 19:35:02,134:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:35:02,537:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-15 19:36:57,025:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:36:57,994:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:36:57,994:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:36:57,994:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-15 19:36:58,160:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 19:36:58,387:INFO:PyCaret RegressionExperiment
2023-02-15 19:36:58,387:INFO:Logging name: reg-default-name
2023-02-15 19:36:58,387:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-15 19:36:58,387:INFO:version 3.0.0.rc9
2023-02-15 19:36:58,387:INFO:Initializing setup()
2023-02-15 19:36:58,387:INFO:self.USI: bce3
2023-02-15 19:36:58,387:INFO:self._variable_keys: {'X_test', 'idx', '_available_plots', '_ml_usecase', 'pipeline', 'exp_id', 'log_plots_param', 'seed', 'logging_param', 'memory', 'y_train', 'y_test', 'transform_target_param', 'n_jobs_param', 'X', 'html_param', 'y', 'X_train', 'fold_generator', 'gpu_param', 'target_param', 'exp_name_log', 'data', 'fold_shuffle_param', 'fold_groups_param', 'gpu_n_jobs_param', 'USI'}
2023-02-15 19:36:58,388:INFO:Checking environment
2023-02-15 19:36:58,388:INFO:python_version: 3.8.16
2023-02-15 19:36:58,388:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-15 19:36:58,388:INFO:machine: x86_64
2023-02-15 19:36:58,388:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 19:36:58,388:INFO:Memory: svmem(total=134979592192, available=110945046528, percent=17.8, used=22371962880, free=28320256000, active=13078286336, inactive=89350131712, buffers=1480671232, cached=82806702080, shared=390574080, slab=3460403200)
2023-02-15 19:36:58,388:INFO:Physical Core: 16
2023-02-15 19:36:58,388:INFO:Logical Core: 32
2023-02-15 19:36:58,389:INFO:Checking libraries
2023-02-15 19:36:58,389:INFO:System:
2023-02-15 19:36:58,389:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-15 19:36:58,389:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-15 19:36:58,389:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-15 19:36:58,389:INFO:PyCaret required dependencies:
2023-02-15 19:36:58,389:INFO:                 pip: 23.0
2023-02-15 19:36:58,389:INFO:          setuptools: 60.10.0
2023-02-15 19:36:58,389:INFO:             pycaret: 3.0.0rc9
2023-02-15 19:36:58,389:INFO:             IPython: 8.10.0
2023-02-15 19:36:58,389:INFO:          ipywidgets: 7.7.3
2023-02-15 19:36:58,389:INFO:                tqdm: 4.64.1
2023-02-15 19:36:58,389:INFO:               numpy: 1.23.5
2023-02-15 19:36:58,389:INFO:              pandas: 1.5.3
2023-02-15 19:36:58,389:INFO:              jinja2: 3.1.2
2023-02-15 19:36:58,389:INFO:               scipy: 1.9.1
2023-02-15 19:36:58,389:INFO:              joblib: 1.2.0
2023-02-15 19:36:58,389:INFO:             sklearn: 1.2.1
2023-02-15 19:36:58,389:INFO:                pyod: 1.0.7
2023-02-15 19:36:58,389:INFO:            imblearn: 0.10.1
2023-02-15 19:36:58,389:INFO:   category_encoders: 2.6.0
2023-02-15 19:36:58,389:INFO:            lightgbm: 3.3.5.99
2023-02-15 19:36:58,389:INFO:               numba: 0.56.4
2023-02-15 19:36:58,389:INFO:            requests: 2.28.2
2023-02-15 19:36:58,389:INFO:          matplotlib: 3.6.3
2023-02-15 19:36:58,389:INFO:          scikitplot: 0.3.7
2023-02-15 19:36:58,389:INFO:         yellowbrick: 1.5
2023-02-15 19:36:58,389:INFO:              plotly: 5.13.0
2023-02-15 19:36:58,389:INFO:             kaleido: 0.2.1
2023-02-15 19:36:58,389:INFO:         statsmodels: 0.13.5
2023-02-15 19:36:58,389:INFO:              sktime: 0.16.1
2023-02-15 19:36:58,389:INFO:               tbats: 1.1.2
2023-02-15 19:36:58,389:INFO:            pmdarima: 2.0.2
2023-02-15 19:36:58,389:INFO:              psutil: 5.9.4
2023-02-15 19:36:58,389:INFO:PyCaret optional dependencies:
2023-02-15 19:36:58,627:INFO:                shap: 0.41.0
2023-02-15 19:36:58,627:INFO:           interpret: 0.3.0
2023-02-15 19:36:58,628:INFO:                umap: 0.5.3
2023-02-15 19:36:58,628:INFO:    pandas_profiling: 4.0.0
2023-02-15 19:36:58,628:INFO:  explainerdashboard: 0.4.2
2023-02-15 19:36:58,628:INFO:             autoviz: 0.1.58
2023-02-15 19:36:58,628:INFO:           fairlearn: 0.7.0
2023-02-15 19:36:58,628:INFO:             xgboost: 1.7.3
2023-02-15 19:36:58,628:INFO:            catboost: 1.1.1
2023-02-15 19:36:58,628:INFO:              kmodes: 0.12.2
2023-02-15 19:36:58,628:INFO:             mlxtend: 0.21.0
2023-02-15 19:36:58,628:INFO:       statsforecast: 1.4.0
2023-02-15 19:36:58,628:INFO:        tune_sklearn: 0.4.5
2023-02-15 19:36:58,628:INFO:                 ray: 2.2.0
2023-02-15 19:36:58,628:INFO:            hyperopt: 0.2.7
2023-02-15 19:36:58,628:INFO:              optuna: 3.1.0
2023-02-15 19:36:58,628:INFO:               skopt: 0.9.0
2023-02-15 19:36:58,628:INFO:              mlflow: 1.30.0
2023-02-15 19:36:58,628:INFO:              gradio: 3.18.0
2023-02-15 19:36:58,628:INFO:             fastapi: 0.92.0
2023-02-15 19:36:58,628:INFO:             uvicorn: 0.20.0
2023-02-15 19:36:58,628:INFO:              m2cgen: 0.10.0
2023-02-15 19:36:58,628:INFO:           evidently: 0.2.4
2023-02-15 19:36:58,628:INFO:               fugue: 0.8.1.dev4
2023-02-15 19:36:58,628:INFO:           streamlit: Not installed
2023-02-15 19:36:58,628:INFO:             prophet: Not installed
2023-02-15 19:36:58,628:INFO:None
2023-02-15 19:36:58,628:INFO:Set up data.
2023-02-15 19:36:58,943:INFO:Set up train/test split.
2023-02-15 19:36:59,132:INFO:Set up index.
2023-02-15 19:36:59,186:INFO:Set up folding strategy.
2023-02-15 19:36:59,187:INFO:Assigning column types.
2023-02-15 19:36:59,311:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 19:36:59,311:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,314:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,316:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,460:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,461:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:36:59,561:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:36:59,573:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,576:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,579:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,697:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,724:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:36:59,726:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:36:59,726:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-15 19:36:59,729:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,732:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,880:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:36:59,881:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:36:59,884:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-15 19:36:59,887:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,001:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,028:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,028:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:00,030:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:00,030:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-15 19:37:00,036:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,172:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:00,174:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:00,180:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,310:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:00,311:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:00,312:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-15 19:37:00,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,458:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:00,459:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:00,581:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,609:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,609:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:00,611:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:00,611:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 19:37:00,732:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,759:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:00,761:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:00,882:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-15 19:37:00,909:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:00,911:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:00,911:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-15 19:37:01,064:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:01,066:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:01,217:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:01,219:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:01,225:INFO:Preparing preprocessing pipeline...
2023-02-15 19:37:01,241:INFO:Set up column name cleaning.
2023-02-15 19:37:01,242:INFO:Set up simple imputation.
2023-02-15 19:37:01,242:INFO:Set up feature normalization.
2023-02-15 19:37:01,242:INFO:Set up feature selection.
2023-02-15 19:37:01,388:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:01,390:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:04,026:INFO:Finished creating preprocessing pipeline.
2023-02-15 19:37:04,036:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMRegressor(),
                                                                max_features=154,
                                                                threshold=-inf)))])
2023-02-15 19:37:04,036:INFO:Creating final display dataframe.
2023-02-15 19:37:05,333:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28570, 780)
4        Transformed data shape           (28570, 155)
5   Transformed train set shape           (19999, 155)
6    Transformed test set shape            (8571, 155)
7               Ignore features                      5
8              Numeric features                    774
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15            Feature selection                   True
16     Feature selection method                classic
17  Feature selection estimator               lightgbm
18  Number of features selected                    0.2
19               Fold Generator                  KFold
20                  Fold Number                     10
21                     CPU Jobs                     -1
22                      Use GPU                  False
23               Log Experiment                  False
24              Experiment Name       reg-default-name
25                          USI                   bce3
2023-02-15 19:37:05,484:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:05,486:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:05,634:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 19:37:05,636:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-15 19:37:05,637:INFO:setup() successfully completed in 7.25s...............
2023-02-15 19:37:05,637:INFO:Initializing compare_models()
2023-02-15 19:37:05,637:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, 'include': None, 'exclude': ['tr'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr'])
2023-02-15 19:37:05,637:INFO:Checking exceptions
2023-02-15 19:37:05,677:INFO:Preparing display monitor
2023-02-15 19:37:05,694:INFO:Initializing Linear Regression
2023-02-15 19:37:05,694:INFO:Total runtime is 2.6543935139973957e-06 minutes
2023-02-15 19:37:05,695:INFO:SubProcess create_model() called ==================================
2023-02-15 19:37:05,696:INFO:Initializing create_model()
2023-02-15 19:37:05,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:37:05,696:INFO:Checking exceptions
2023-02-15 19:37:05,696:INFO:Importing libraries
2023-02-15 19:37:05,696:INFO:Copying training dataset
2023-02-15 19:37:05,810:INFO:Defining folds
2023-02-15 19:37:05,810:INFO:Declaring metric variables
2023-02-15 19:37:05,813:INFO:Importing untrained model
2023-02-15 19:37:05,815:INFO:Linear Regression Imported successfully
2023-02-15 19:37:05,820:INFO:Starting cross validation
2023-02-15 19:37:05,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:09,785:INFO:Calculating mean and std
2023-02-15 19:48:09,787:INFO:Creating metrics dataframe
2023-02-15 19:48:09,792:INFO:Uploading results into container
2023-02-15 19:48:09,792:INFO:Uploading model into container now
2023-02-15 19:48:09,793:INFO:_master_model_container: 1
2023-02-15 19:48:09,793:INFO:_display_container: 2
2023-02-15 19:48:09,793:INFO:LinearRegression(n_jobs=-1)
2023-02-15 19:48:09,793:INFO:create_model() successfully completed......................................
2023-02-15 19:48:10,045:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:10,045:INFO:Creating metrics dataframe
2023-02-15 19:48:10,052:INFO:Initializing Lasso Regression
2023-02-15 19:48:10,052:INFO:Total runtime is 11.072638229529062 minutes
2023-02-15 19:48:10,054:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:10,054:INFO:Initializing create_model()
2023-02-15 19:48:10,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:10,054:INFO:Checking exceptions
2023-02-15 19:48:10,054:INFO:Importing libraries
2023-02-15 19:48:10,054:INFO:Copying training dataset
2023-02-15 19:48:10,163:INFO:Defining folds
2023-02-15 19:48:10,164:INFO:Declaring metric variables
2023-02-15 19:48:10,166:INFO:Importing untrained model
2023-02-15 19:48:10,168:INFO:Lasso Regression Imported successfully
2023-02-15 19:48:10,172:INFO:Starting cross validation
2023-02-15 19:48:10,178:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:12,254:INFO:Calculating mean and std
2023-02-15 19:48:12,255:INFO:Creating metrics dataframe
2023-02-15 19:48:12,259:INFO:Uploading results into container
2023-02-15 19:48:12,260:INFO:Uploading model into container now
2023-02-15 19:48:12,260:INFO:_master_model_container: 2
2023-02-15 19:48:12,260:INFO:_display_container: 2
2023-02-15 19:48:12,260:INFO:Lasso(random_state=11)
2023-02-15 19:48:12,260:INFO:create_model() successfully completed......................................
2023-02-15 19:48:12,493:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:12,493:INFO:Creating metrics dataframe
2023-02-15 19:48:12,501:INFO:Initializing Ridge Regression
2023-02-15 19:48:12,501:INFO:Total runtime is 11.11345768769582 minutes
2023-02-15 19:48:12,503:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:12,503:INFO:Initializing create_model()
2023-02-15 19:48:12,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:12,504:INFO:Checking exceptions
2023-02-15 19:48:12,504:INFO:Importing libraries
2023-02-15 19:48:12,504:INFO:Copying training dataset
2023-02-15 19:48:12,635:INFO:Defining folds
2023-02-15 19:48:12,635:INFO:Declaring metric variables
2023-02-15 19:48:12,638:INFO:Importing untrained model
2023-02-15 19:48:12,640:INFO:Ridge Regression Imported successfully
2023-02-15 19:48:12,644:INFO:Starting cross validation
2023-02-15 19:48:12,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:15,795:INFO:Calculating mean and std
2023-02-15 19:48:15,796:INFO:Creating metrics dataframe
2023-02-15 19:48:15,800:INFO:Uploading results into container
2023-02-15 19:48:15,800:INFO:Uploading model into container now
2023-02-15 19:48:15,800:INFO:_master_model_container: 3
2023-02-15 19:48:15,801:INFO:_display_container: 2
2023-02-15 19:48:15,801:INFO:Ridge(random_state=11)
2023-02-15 19:48:15,801:INFO:create_model() successfully completed......................................
2023-02-15 19:48:16,007:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:16,008:INFO:Creating metrics dataframe
2023-02-15 19:48:16,015:INFO:Initializing Elastic Net
2023-02-15 19:48:16,015:INFO:Total runtime is 11.172027798493703 minutes
2023-02-15 19:48:16,017:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:16,018:INFO:Initializing create_model()
2023-02-15 19:48:16,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:16,018:INFO:Checking exceptions
2023-02-15 19:48:16,018:INFO:Importing libraries
2023-02-15 19:48:16,018:INFO:Copying training dataset
2023-02-15 19:48:16,131:INFO:Defining folds
2023-02-15 19:48:16,132:INFO:Declaring metric variables
2023-02-15 19:48:16,134:INFO:Importing untrained model
2023-02-15 19:48:16,136:INFO:Elastic Net Imported successfully
2023-02-15 19:48:16,140:INFO:Starting cross validation
2023-02-15 19:48:16,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:19,037:INFO:Calculating mean and std
2023-02-15 19:48:19,039:INFO:Creating metrics dataframe
2023-02-15 19:48:19,043:INFO:Uploading results into container
2023-02-15 19:48:19,044:INFO:Uploading model into container now
2023-02-15 19:48:19,044:INFO:_master_model_container: 4
2023-02-15 19:48:19,045:INFO:_display_container: 2
2023-02-15 19:48:19,045:INFO:ElasticNet(random_state=11)
2023-02-15 19:48:19,045:INFO:create_model() successfully completed......................................
2023-02-15 19:48:19,250:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:19,251:INFO:Creating metrics dataframe
2023-02-15 19:48:19,258:INFO:Initializing Least Angle Regression
2023-02-15 19:48:19,258:INFO:Total runtime is 11.226081756750743 minutes
2023-02-15 19:48:19,261:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:19,261:INFO:Initializing create_model()
2023-02-15 19:48:19,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:19,261:INFO:Checking exceptions
2023-02-15 19:48:19,261:INFO:Importing libraries
2023-02-15 19:48:19,261:INFO:Copying training dataset
2023-02-15 19:48:19,380:INFO:Defining folds
2023-02-15 19:48:19,380:INFO:Declaring metric variables
2023-02-15 19:48:19,383:INFO:Importing untrained model
2023-02-15 19:48:19,385:INFO:Least Angle Regression Imported successfully
2023-02-15 19:48:19,389:INFO:Starting cross validation
2023-02-15 19:48:19,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:20,053:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.573e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-15 19:48:20,123:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-02-15 19:48:20,124:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 19:48:20,136:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in subtract
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 19:48:20,136:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in add
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-02-15 19:48:20,136:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:775: RuntimeWarning: overflow encountered in subtract
  Cov -= gamma_ * corr_eq_dir

2023-02-15 19:48:20,136:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: invalid value encountered in add
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-02-15 19:48:20,137:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: invalid value encountered in subtract
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-15 19:48:20,137:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-02-15 19:48:20,361:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 19:48:20,361:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 19:48:20,362:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 19:48:20,363:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 19:48:20,372:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: overflow encountered in matmul
  ret = a @ b

2023-02-15 19:48:20,372:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2023-02-15 19:48:20,372:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_base.py:338: RuntimeWarning: invalid value encountered in add
  return safe_sparse_dot(X, self.coef_.T, dense_output=True) + self.intercept_

2023-02-15 19:48:20,374:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:48:20,374:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:48:20,374:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-15 19:48:21,553:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-02-15 19:48:21,641:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 19:48:21,641:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 19:48:21,642:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 19:48:21,695:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 19:48:21,695:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-15 19:48:21,695:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-15 19:48:21,696:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/containers/metrics/regression.py:243: RuntimeWarning: overflow encountered in divide
  mape = np.abs(y_pred - y_true) / np.abs(y_true)

2023-02-15 19:48:21,696:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-15 19:48:21,799:INFO:Calculating mean and std
2023-02-15 19:48:21,800:INFO:Creating metrics dataframe
2023-02-15 19:48:21,804:INFO:Uploading results into container
2023-02-15 19:48:21,805:INFO:Uploading model into container now
2023-02-15 19:48:21,805:INFO:_master_model_container: 5
2023-02-15 19:48:21,805:INFO:_display_container: 2
2023-02-15 19:48:21,805:INFO:Lars(random_state=11)
2023-02-15 19:48:21,805:INFO:create_model() successfully completed......................................
2023-02-15 19:48:22,004:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:22,005:INFO:Creating metrics dataframe
2023-02-15 19:48:22,012:INFO:Initializing Lasso Least Angle Regression
2023-02-15 19:48:22,012:INFO:Total runtime is 11.271976522604625 minutes
2023-02-15 19:48:22,014:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:22,014:INFO:Initializing create_model()
2023-02-15 19:48:22,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:22,014:INFO:Checking exceptions
2023-02-15 19:48:22,014:INFO:Importing libraries
2023-02-15 19:48:22,014:INFO:Copying training dataset
2023-02-15 19:48:22,122:INFO:Defining folds
2023-02-15 19:48:22,122:INFO:Declaring metric variables
2023-02-15 19:48:22,124:INFO:Importing untrained model
2023-02-15 19:48:22,127:INFO:Lasso Least Angle Regression Imported successfully
2023-02-15 19:48:22,130:INFO:Starting cross validation
2023-02-15 19:48:22,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:23,453:INFO:Calculating mean and std
2023-02-15 19:48:23,454:INFO:Creating metrics dataframe
2023-02-15 19:48:23,457:INFO:Uploading results into container
2023-02-15 19:48:23,457:INFO:Uploading model into container now
2023-02-15 19:48:23,458:INFO:_master_model_container: 6
2023-02-15 19:48:23,458:INFO:_display_container: 2
2023-02-15 19:48:23,458:INFO:LassoLars(random_state=11)
2023-02-15 19:48:23,458:INFO:create_model() successfully completed......................................
2023-02-15 19:48:23,674:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:23,675:INFO:Creating metrics dataframe
2023-02-15 19:48:23,682:INFO:Initializing Orthogonal Matching Pursuit
2023-02-15 19:48:23,682:INFO:Total runtime is 11.299816060066224 minutes
2023-02-15 19:48:23,685:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:23,685:INFO:Initializing create_model()
2023-02-15 19:48:23,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:23,685:INFO:Checking exceptions
2023-02-15 19:48:23,685:INFO:Importing libraries
2023-02-15 19:48:23,685:INFO:Copying training dataset
2023-02-15 19:48:23,797:INFO:Defining folds
2023-02-15 19:48:23,797:INFO:Declaring metric variables
2023-02-15 19:48:23,800:INFO:Importing untrained model
2023-02-15 19:48:23,803:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-15 19:48:23,806:INFO:Starting cross validation
2023-02-15 19:48:23,812:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:25,098:INFO:Calculating mean and std
2023-02-15 19:48:25,099:INFO:Creating metrics dataframe
2023-02-15 19:48:25,103:INFO:Uploading results into container
2023-02-15 19:48:25,104:INFO:Uploading model into container now
2023-02-15 19:48:25,104:INFO:_master_model_container: 7
2023-02-15 19:48:25,104:INFO:_display_container: 2
2023-02-15 19:48:25,105:INFO:OrthogonalMatchingPursuit()
2023-02-15 19:48:25,105:INFO:create_model() successfully completed......................................
2023-02-15 19:48:25,326:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:25,326:INFO:Creating metrics dataframe
2023-02-15 19:48:25,333:INFO:Initializing Bayesian Ridge
2023-02-15 19:48:25,334:INFO:Total runtime is 11.327334308624268 minutes
2023-02-15 19:48:25,336:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:25,336:INFO:Initializing create_model()
2023-02-15 19:48:25,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:25,336:INFO:Checking exceptions
2023-02-15 19:48:25,336:INFO:Importing libraries
2023-02-15 19:48:25,336:INFO:Copying training dataset
2023-02-15 19:48:25,448:INFO:Defining folds
2023-02-15 19:48:25,449:INFO:Declaring metric variables
2023-02-15 19:48:25,451:INFO:Importing untrained model
2023-02-15 19:48:25,454:INFO:Bayesian Ridge Imported successfully
2023-02-15 19:48:25,457:INFO:Starting cross validation
2023-02-15 19:48:25,463:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:26,886:INFO:Calculating mean and std
2023-02-15 19:48:26,887:INFO:Creating metrics dataframe
2023-02-15 19:48:26,891:INFO:Uploading results into container
2023-02-15 19:48:26,891:INFO:Uploading model into container now
2023-02-15 19:48:26,892:INFO:_master_model_container: 8
2023-02-15 19:48:26,892:INFO:_display_container: 2
2023-02-15 19:48:26,892:INFO:BayesianRidge()
2023-02-15 19:48:26,892:INFO:create_model() successfully completed......................................
2023-02-15 19:48:27,119:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:27,119:INFO:Creating metrics dataframe
2023-02-15 19:48:27,131:INFO:Initializing Passive Aggressive Regressor
2023-02-15 19:48:27,131:INFO:Total runtime is 11.357291738192242 minutes
2023-02-15 19:48:27,133:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:27,133:INFO:Initializing create_model()
2023-02-15 19:48:27,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:27,133:INFO:Checking exceptions
2023-02-15 19:48:27,133:INFO:Importing libraries
2023-02-15 19:48:27,133:INFO:Copying training dataset
2023-02-15 19:48:27,249:INFO:Defining folds
2023-02-15 19:48:27,250:INFO:Declaring metric variables
2023-02-15 19:48:27,252:INFO:Importing untrained model
2023-02-15 19:48:27,255:INFO:Passive Aggressive Regressor Imported successfully
2023-02-15 19:48:27,258:INFO:Starting cross validation
2023-02-15 19:48:27,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:28,728:INFO:Calculating mean and std
2023-02-15 19:48:28,729:INFO:Creating metrics dataframe
2023-02-15 19:48:28,732:INFO:Uploading results into container
2023-02-15 19:48:28,733:INFO:Uploading model into container now
2023-02-15 19:48:28,733:INFO:_master_model_container: 9
2023-02-15 19:48:28,733:INFO:_display_container: 2
2023-02-15 19:48:28,733:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-15 19:48:28,733:INFO:create_model() successfully completed......................................
2023-02-15 19:48:28,978:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:28,978:INFO:Creating metrics dataframe
2023-02-15 19:48:28,990:INFO:Initializing Huber Regressor
2023-02-15 19:48:28,990:INFO:Total runtime is 11.388278802235922 minutes
2023-02-15 19:48:28,992:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:28,992:INFO:Initializing create_model()
2023-02-15 19:48:28,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:28,992:INFO:Checking exceptions
2023-02-15 19:48:28,992:INFO:Importing libraries
2023-02-15 19:48:28,992:INFO:Copying training dataset
2023-02-15 19:48:29,092:INFO:Defining folds
2023-02-15 19:48:29,092:INFO:Declaring metric variables
2023-02-15 19:48:29,095:INFO:Importing untrained model
2023-02-15 19:48:29,097:INFO:Huber Regressor Imported successfully
2023-02-15 19:48:29,100:INFO:Starting cross validation
2023-02-15 19:48:29,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:38,708:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:48:40,459:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:48:40,749:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:48:40,978:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:48:41,071:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:48:41,139:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:48:41,230:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:48:41,356:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:48:41,411:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:48:41,476:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-15 19:48:41,742:INFO:Calculating mean and std
2023-02-15 19:48:41,743:INFO:Creating metrics dataframe
2023-02-15 19:48:41,746:INFO:Uploading results into container
2023-02-15 19:48:41,746:INFO:Uploading model into container now
2023-02-15 19:48:41,746:INFO:_master_model_container: 10
2023-02-15 19:48:41,746:INFO:_display_container: 2
2023-02-15 19:48:41,747:INFO:HuberRegressor()
2023-02-15 19:48:41,747:INFO:create_model() successfully completed......................................
2023-02-15 19:48:41,944:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:41,944:INFO:Creating metrics dataframe
2023-02-15 19:48:41,952:INFO:Initializing K Neighbors Regressor
2023-02-15 19:48:41,952:INFO:Total runtime is 11.604307794570923 minutes
2023-02-15 19:48:41,954:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:41,954:INFO:Initializing create_model()
2023-02-15 19:48:41,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:41,954:INFO:Checking exceptions
2023-02-15 19:48:41,954:INFO:Importing libraries
2023-02-15 19:48:41,954:INFO:Copying training dataset
2023-02-15 19:48:42,061:INFO:Defining folds
2023-02-15 19:48:42,062:INFO:Declaring metric variables
2023-02-15 19:48:42,064:INFO:Importing untrained model
2023-02-15 19:48:42,066:INFO:K Neighbors Regressor Imported successfully
2023-02-15 19:48:42,070:INFO:Starting cross validation
2023-02-15 19:48:42,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:43,782:INFO:Calculating mean and std
2023-02-15 19:48:43,783:INFO:Creating metrics dataframe
2023-02-15 19:48:43,787:INFO:Uploading results into container
2023-02-15 19:48:43,787:INFO:Uploading model into container now
2023-02-15 19:48:43,787:INFO:_master_model_container: 11
2023-02-15 19:48:43,787:INFO:_display_container: 2
2023-02-15 19:48:43,788:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-15 19:48:43,788:INFO:create_model() successfully completed......................................
2023-02-15 19:48:44,007:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:44,007:INFO:Creating metrics dataframe
2023-02-15 19:48:44,016:INFO:Initializing Decision Tree Regressor
2023-02-15 19:48:44,016:INFO:Total runtime is 11.638706370194754 minutes
2023-02-15 19:48:44,018:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:44,018:INFO:Initializing create_model()
2023-02-15 19:48:44,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:44,018:INFO:Checking exceptions
2023-02-15 19:48:44,018:INFO:Importing libraries
2023-02-15 19:48:44,018:INFO:Copying training dataset
2023-02-15 19:48:44,122:INFO:Defining folds
2023-02-15 19:48:44,122:INFO:Declaring metric variables
2023-02-15 19:48:44,125:INFO:Importing untrained model
2023-02-15 19:48:44,127:INFO:Decision Tree Regressor Imported successfully
2023-02-15 19:48:44,130:INFO:Starting cross validation
2023-02-15 19:48:44,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:48:50,202:INFO:Calculating mean and std
2023-02-15 19:48:50,203:INFO:Creating metrics dataframe
2023-02-15 19:48:50,207:INFO:Uploading results into container
2023-02-15 19:48:50,207:INFO:Uploading model into container now
2023-02-15 19:48:50,208:INFO:_master_model_container: 12
2023-02-15 19:48:50,208:INFO:_display_container: 2
2023-02-15 19:48:50,208:INFO:DecisionTreeRegressor(random_state=11)
2023-02-15 19:48:50,208:INFO:create_model() successfully completed......................................
2023-02-15 19:48:50,422:INFO:SubProcess create_model() end ==================================
2023-02-15 19:48:50,422:INFO:Creating metrics dataframe
2023-02-15 19:48:50,432:INFO:Initializing Random Forest Regressor
2023-02-15 19:48:50,432:INFO:Total runtime is 11.74563564459483 minutes
2023-02-15 19:48:50,434:INFO:SubProcess create_model() called ==================================
2023-02-15 19:48:50,434:INFO:Initializing create_model()
2023-02-15 19:48:50,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:48:50,434:INFO:Checking exceptions
2023-02-15 19:48:50,434:INFO:Importing libraries
2023-02-15 19:48:50,434:INFO:Copying training dataset
2023-02-15 19:48:50,545:INFO:Defining folds
2023-02-15 19:48:50,545:INFO:Declaring metric variables
2023-02-15 19:48:50,548:INFO:Importing untrained model
2023-02-15 19:48:50,550:INFO:Random Forest Regressor Imported successfully
2023-02-15 19:48:50,553:INFO:Starting cross validation
2023-02-15 19:48:50,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:51:03,575:INFO:Calculating mean and std
2023-02-15 19:51:03,576:INFO:Creating metrics dataframe
2023-02-15 19:51:03,579:INFO:Uploading results into container
2023-02-15 19:51:03,579:INFO:Uploading model into container now
2023-02-15 19:51:03,579:INFO:_master_model_container: 13
2023-02-15 19:51:03,579:INFO:_display_container: 2
2023-02-15 19:51:03,579:INFO:RandomForestRegressor(n_jobs=-1, random_state=11)
2023-02-15 19:51:03,580:INFO:create_model() successfully completed......................................
2023-02-15 19:51:03,803:INFO:SubProcess create_model() end ==================================
2023-02-15 19:51:03,803:INFO:Creating metrics dataframe
2023-02-15 19:51:03,812:INFO:Initializing Extra Trees Regressor
2023-02-15 19:51:03,812:INFO:Total runtime is 13.968638507525128 minutes
2023-02-15 19:51:03,814:INFO:SubProcess create_model() called ==================================
2023-02-15 19:51:03,814:INFO:Initializing create_model()
2023-02-15 19:51:03,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:51:03,814:INFO:Checking exceptions
2023-02-15 19:51:03,814:INFO:Importing libraries
2023-02-15 19:51:03,814:INFO:Copying training dataset
2023-02-15 19:51:03,921:INFO:Defining folds
2023-02-15 19:51:03,921:INFO:Declaring metric variables
2023-02-15 19:51:03,924:INFO:Importing untrained model
2023-02-15 19:51:03,926:INFO:Extra Trees Regressor Imported successfully
2023-02-15 19:51:03,930:INFO:Starting cross validation
2023-02-15 19:51:03,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:51:38,055:INFO:Calculating mean and std
2023-02-15 19:51:38,056:INFO:Creating metrics dataframe
2023-02-15 19:51:38,060:INFO:Uploading results into container
2023-02-15 19:51:38,060:INFO:Uploading model into container now
2023-02-15 19:51:38,060:INFO:_master_model_container: 14
2023-02-15 19:51:38,060:INFO:_display_container: 2
2023-02-15 19:51:38,061:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=11)
2023-02-15 19:51:38,061:INFO:create_model() successfully completed......................................
2023-02-15 19:51:38,308:INFO:SubProcess create_model() end ==================================
2023-02-15 19:51:38,308:INFO:Creating metrics dataframe
2023-02-15 19:51:38,318:INFO:Initializing AdaBoost Regressor
2023-02-15 19:51:38,318:INFO:Total runtime is 14.543739406267804 minutes
2023-02-15 19:51:38,320:INFO:SubProcess create_model() called ==================================
2023-02-15 19:51:38,320:INFO:Initializing create_model()
2023-02-15 19:51:38,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:51:38,320:INFO:Checking exceptions
2023-02-15 19:51:38,321:INFO:Importing libraries
2023-02-15 19:51:38,321:INFO:Copying training dataset
2023-02-15 19:51:38,430:INFO:Defining folds
2023-02-15 19:51:38,431:INFO:Declaring metric variables
2023-02-15 19:51:38,433:INFO:Importing untrained model
2023-02-15 19:51:38,436:INFO:AdaBoost Regressor Imported successfully
2023-02-15 19:51:38,439:INFO:Starting cross validation
2023-02-15 19:51:38,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:51:57,088:INFO:Calculating mean and std
2023-02-15 19:51:57,089:INFO:Creating metrics dataframe
2023-02-15 19:51:57,094:INFO:Uploading results into container
2023-02-15 19:51:57,094:INFO:Uploading model into container now
2023-02-15 19:51:57,095:INFO:_master_model_container: 15
2023-02-15 19:51:57,095:INFO:_display_container: 2
2023-02-15 19:51:57,095:INFO:AdaBoostRegressor(random_state=11)
2023-02-15 19:51:57,095:INFO:create_model() successfully completed......................................
2023-02-15 19:51:57,326:INFO:SubProcess create_model() end ==================================
2023-02-15 19:51:57,327:INFO:Creating metrics dataframe
2023-02-15 19:51:57,336:INFO:Initializing Gradient Boosting Regressor
2023-02-15 19:51:57,336:INFO:Total runtime is 14.860711658000948 minutes
2023-02-15 19:51:57,338:INFO:SubProcess create_model() called ==================================
2023-02-15 19:51:57,339:INFO:Initializing create_model()
2023-02-15 19:51:57,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:51:57,339:INFO:Checking exceptions
2023-02-15 19:51:57,339:INFO:Importing libraries
2023-02-15 19:51:57,339:INFO:Copying training dataset
2023-02-15 19:51:57,443:INFO:Defining folds
2023-02-15 19:51:57,443:INFO:Declaring metric variables
2023-02-15 19:51:57,446:INFO:Importing untrained model
2023-02-15 19:51:57,448:INFO:Gradient Boosting Regressor Imported successfully
2023-02-15 19:51:57,451:INFO:Starting cross validation
2023-02-15 19:51:57,456:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:53:10,176:INFO:Calculating mean and std
2023-02-15 19:53:10,177:INFO:Creating metrics dataframe
2023-02-15 19:53:10,181:INFO:Uploading results into container
2023-02-15 19:53:10,181:INFO:Uploading model into container now
2023-02-15 19:53:10,181:INFO:_master_model_container: 16
2023-02-15 19:53:10,181:INFO:_display_container: 2
2023-02-15 19:53:10,181:INFO:GradientBoostingRegressor(random_state=11)
2023-02-15 19:53:10,181:INFO:create_model() successfully completed......................................
2023-02-15 19:53:10,401:INFO:SubProcess create_model() end ==================================
2023-02-15 19:53:10,401:INFO:Creating metrics dataframe
2023-02-15 19:53:10,411:INFO:Initializing Extreme Gradient Boosting
2023-02-15 19:53:10,411:INFO:Total runtime is 16.078618832429253 minutes
2023-02-15 19:53:10,413:INFO:SubProcess create_model() called ==================================
2023-02-15 19:53:10,413:INFO:Initializing create_model()
2023-02-15 19:53:10,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:53:10,413:INFO:Checking exceptions
2023-02-15 19:53:10,413:INFO:Importing libraries
2023-02-15 19:53:10,413:INFO:Copying training dataset
2023-02-15 19:53:10,517:INFO:Defining folds
2023-02-15 19:53:10,517:INFO:Declaring metric variables
2023-02-15 19:53:10,520:INFO:Importing untrained model
2023-02-15 19:53:10,523:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 19:53:10,526:INFO:Starting cross validation
2023-02-15 19:53:10,532:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 19:53:44,438:INFO:Calculating mean and std
2023-02-15 19:53:44,439:INFO:Creating metrics dataframe
2023-02-15 19:53:44,442:INFO:Uploading results into container
2023-02-15 19:53:44,443:INFO:Uploading model into container now
2023-02-15 19:53:44,443:INFO:_master_model_container: 17
2023-02-15 19:53:44,443:INFO:_display_container: 2
2023-02-15 19:53:44,443:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=11, ...)
2023-02-15 19:53:44,443:INFO:create_model() successfully completed......................................
2023-02-15 19:53:44,632:INFO:SubProcess create_model() end ==================================
2023-02-15 19:53:44,632:INFO:Creating metrics dataframe
2023-02-15 19:53:44,640:INFO:Initializing Light Gradient Boosting Machine
2023-02-15 19:53:44,640:INFO:Total runtime is 16.64910751183828 minutes
2023-02-15 19:53:44,642:INFO:SubProcess create_model() called ==================================
2023-02-15 19:53:44,642:INFO:Initializing create_model()
2023-02-15 19:53:44,642:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 19:53:44,642:INFO:Checking exceptions
2023-02-15 19:53:44,642:INFO:Importing libraries
2023-02-15 19:53:44,642:INFO:Copying training dataset
2023-02-15 19:53:44,740:INFO:Defining folds
2023-02-15 19:53:44,740:INFO:Declaring metric variables
2023-02-15 19:53:44,743:INFO:Importing untrained model
2023-02-15 19:53:44,745:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 19:53:44,748:INFO:Starting cross validation
2023-02-15 19:53:44,755:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 20:12:21,555:INFO:Calculating mean and std
2023-02-15 20:12:21,557:INFO:Creating metrics dataframe
2023-02-15 20:12:21,560:INFO:Uploading results into container
2023-02-15 20:12:21,561:INFO:Uploading model into container now
2023-02-15 20:12:21,561:INFO:_master_model_container: 18
2023-02-15 20:12:21,561:INFO:_display_container: 2
2023-02-15 20:12:21,562:INFO:LGBMRegressor(n_jobs=-1, random_state=11)
2023-02-15 20:12:21,562:INFO:create_model() successfully completed......................................
2023-02-15 20:12:21,724:INFO:SubProcess create_model() end ==================================
2023-02-15 20:12:21,724:INFO:Creating metrics dataframe
2023-02-15 20:12:21,732:INFO:Initializing CatBoost Regressor
2023-02-15 20:12:21,732:INFO:Total runtime is 35.26731301148733 minutes
2023-02-15 20:12:21,734:INFO:SubProcess create_model() called ==================================
2023-02-15 20:12:21,735:INFO:Initializing create_model()
2023-02-15 20:12:21,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 20:12:21,735:INFO:Checking exceptions
2023-02-15 20:12:21,735:INFO:Importing libraries
2023-02-15 20:12:21,735:INFO:Copying training dataset
2023-02-15 20:12:21,828:INFO:Defining folds
2023-02-15 20:12:21,828:INFO:Declaring metric variables
2023-02-15 20:12:21,830:INFO:Importing untrained model
2023-02-15 20:12:21,832:INFO:CatBoost Regressor Imported successfully
2023-02-15 20:12:21,835:INFO:Starting cross validation
2023-02-15 20:12:21,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 20:14:04,855:INFO:Calculating mean and std
2023-02-15 20:14:04,856:INFO:Creating metrics dataframe
2023-02-15 20:14:04,860:INFO:Uploading results into container
2023-02-15 20:14:04,860:INFO:Uploading model into container now
2023-02-15 20:14:04,861:INFO:_master_model_container: 19
2023-02-15 20:14:04,861:INFO:_display_container: 2
2023-02-15 20:14:04,861:INFO:<catboost.core.CatBoostRegressor object at 0x7fe6be7081f0>
2023-02-15 20:14:04,861:INFO:create_model() successfully completed......................................
2023-02-15 20:14:05,029:INFO:SubProcess create_model() end ==================================
2023-02-15 20:14:05,029:INFO:Creating metrics dataframe
2023-02-15 20:14:05,037:INFO:Initializing Dummy Regressor
2023-02-15 20:14:05,037:INFO:Total runtime is 36.98906588951747 minutes
2023-02-15 20:14:05,039:INFO:SubProcess create_model() called ==================================
2023-02-15 20:14:05,039:INFO:Initializing create_model()
2023-02-15 20:14:05,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe6b7538250>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 20:14:05,039:INFO:Checking exceptions
2023-02-15 20:14:05,040:INFO:Importing libraries
2023-02-15 20:14:05,040:INFO:Copying training dataset
2023-02-15 20:14:05,132:INFO:Defining folds
2023-02-15 20:14:05,132:INFO:Declaring metric variables
2023-02-15 20:14:05,135:INFO:Importing untrained model
2023-02-15 20:14:05,137:INFO:Dummy Regressor Imported successfully
2023-02-15 20:14:05,140:INFO:Starting cross validation
2023-02-15 20:14:05,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 20:14:07,588:INFO:Calculating mean and std
2023-02-15 20:14:07,592:INFO:Creating metrics dataframe
2023-02-15 20:14:07,596:INFO:Uploading results into container
2023-02-15 20:14:07,596:INFO:Uploading model into container now
2023-02-15 20:14:07,596:INFO:_master_model_container: 20
2023-02-15 20:14:07,597:INFO:_display_container: 2
2023-02-15 20:14:07,597:INFO:DummyRegressor()
2023-02-15 20:14:07,597:INFO:create_model() successfully completed......................................
2023-02-15 20:14:07,743:INFO:SubProcess create_model() end ==================================
2023-02-15 20:14:07,743:INFO:Creating metrics dataframe
2023-02-15 20:14:07,756:INFO:Initializing create_model()
2023-02-15 20:14:07,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe6fdb84e50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=11), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 20:14:07,757:INFO:Checking exceptions
2023-02-15 20:14:07,758:INFO:Importing libraries
2023-02-15 20:14:07,758:INFO:Copying training dataset
2023-02-15 20:14:07,833:INFO:Defining folds
2023-02-15 20:14:07,833:INFO:Declaring metric variables
2023-02-15 20:14:07,834:INFO:Importing untrained model
2023-02-15 20:14:07,834:INFO:Declaring custom model
2023-02-15 20:14:07,834:INFO:Extra Trees Regressor Imported successfully
2023-02-15 20:14:07,839:INFO:Cross validation set to False
2023-02-15 20:14:07,839:INFO:Fitting Model
2023-02-15 20:14:11,046:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=11)
2023-02-15 20:14:11,046:INFO:create_model() successfully completed......................................
2023-02-15 20:14:11,206:INFO:_master_model_container: 20
2023-02-15 20:14:11,206:INFO:_display_container: 2
2023-02-15 20:14:11,206:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=11)
2023-02-15 20:14:11,206:INFO:compare_models() successfully completed......................................
2023-02-16 08:25:08,661:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:09,495:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:09,496:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:09,496:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:09,654:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-16 08:25:09,833:INFO:PyCaret RegressionExperiment
2023-02-16 08:25:09,833:INFO:Logging name: reg-default-name
2023-02-16 08:25:09,833:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-16 08:25:09,834:INFO:version 3.0.0.rc9
2023-02-16 08:25:09,834:INFO:Initializing setup()
2023-02-16 08:25:09,834:INFO:self.USI: a325
2023-02-16 08:25:09,834:INFO:self._variable_keys: {'pipeline', 'html_param', 'idx', 'fold_generator', 'X_test', 'y', 'y_train', 'fold_groups_param', 'log_plots_param', 'USI', 'exp_name_log', 'gpu_n_jobs_param', 'transform_target_param', '_available_plots', 'n_jobs_param', 'fold_shuffle_param', 'target_param', 'X', 'gpu_param', 'y_test', 'exp_id', 'logging_param', 'seed', 'data', 'X_train', '_ml_usecase', 'memory'}
2023-02-16 08:25:09,834:INFO:Checking environment
2023-02-16 08:25:09,834:INFO:python_version: 3.8.16
2023-02-16 08:25:09,834:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-16 08:25:09,834:INFO:machine: x86_64
2023-02-16 08:25:09,834:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-16 08:25:09,834:INFO:Memory: svmem(total=134979592192, available=117437403136, percent=13.0, used=15788589056, free=26077519872, active=12602707968, inactive=91602407424, buffers=1676750848, cached=91436732416, shared=489238528, slab=3748278272)
2023-02-16 08:25:09,834:INFO:Physical Core: 16
2023-02-16 08:25:09,834:INFO:Logical Core: 32
2023-02-16 08:25:09,835:INFO:Checking libraries
2023-02-16 08:25:09,835:INFO:System:
2023-02-16 08:25:09,835:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-16 08:25:09,835:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-16 08:25:09,835:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-16 08:25:09,835:INFO:PyCaret required dependencies:
2023-02-16 08:25:09,835:INFO:                 pip: 23.0
2023-02-16 08:25:09,835:INFO:          setuptools: 60.10.0
2023-02-16 08:25:09,835:INFO:             pycaret: 3.0.0rc9
2023-02-16 08:25:09,835:INFO:             IPython: 8.10.0
2023-02-16 08:25:09,835:INFO:          ipywidgets: 7.7.3
2023-02-16 08:25:09,835:INFO:                tqdm: 4.64.1
2023-02-16 08:25:09,835:INFO:               numpy: 1.23.5
2023-02-16 08:25:09,835:INFO:              pandas: 1.5.3
2023-02-16 08:25:09,835:INFO:              jinja2: 3.1.2
2023-02-16 08:25:09,835:INFO:               scipy: 1.9.1
2023-02-16 08:25:09,835:INFO:              joblib: 1.2.0
2023-02-16 08:25:09,835:INFO:             sklearn: 1.2.1
2023-02-16 08:25:09,835:INFO:                pyod: 1.0.7
2023-02-16 08:25:09,835:INFO:            imblearn: 0.10.1
2023-02-16 08:25:09,835:INFO:   category_encoders: 2.6.0
2023-02-16 08:25:09,835:INFO:            lightgbm: 3.3.5.99
2023-02-16 08:25:09,835:INFO:               numba: 0.56.4
2023-02-16 08:25:09,835:INFO:            requests: 2.28.2
2023-02-16 08:25:09,835:INFO:          matplotlib: 3.6.3
2023-02-16 08:25:09,835:INFO:          scikitplot: 0.3.7
2023-02-16 08:25:09,835:INFO:         yellowbrick: 1.5
2023-02-16 08:25:09,835:INFO:              plotly: 5.13.0
2023-02-16 08:25:09,835:INFO:             kaleido: 0.2.1
2023-02-16 08:25:09,835:INFO:         statsmodels: 0.13.5
2023-02-16 08:25:09,835:INFO:              sktime: 0.16.1
2023-02-16 08:25:09,835:INFO:               tbats: 1.1.2
2023-02-16 08:25:09,835:INFO:            pmdarima: 2.0.2
2023-02-16 08:25:09,835:INFO:              psutil: 5.9.4
2023-02-16 08:25:09,835:INFO:PyCaret optional dependencies:
2023-02-16 08:25:10,055:INFO:                shap: 0.41.0
2023-02-16 08:25:10,055:INFO:           interpret: 0.3.0
2023-02-16 08:25:10,055:INFO:                umap: 0.5.3
2023-02-16 08:25:10,055:INFO:    pandas_profiling: 4.0.0
2023-02-16 08:25:10,055:INFO:  explainerdashboard: 0.4.2
2023-02-16 08:25:10,055:INFO:             autoviz: 0.1.58
2023-02-16 08:25:10,055:INFO:           fairlearn: 0.7.0
2023-02-16 08:25:10,055:INFO:             xgboost: 1.7.3
2023-02-16 08:25:10,055:INFO:            catboost: 1.1.1
2023-02-16 08:25:10,055:INFO:              kmodes: 0.12.2
2023-02-16 08:25:10,055:INFO:             mlxtend: 0.21.0
2023-02-16 08:25:10,055:INFO:       statsforecast: 1.4.0
2023-02-16 08:25:10,055:INFO:        tune_sklearn: 0.4.5
2023-02-16 08:25:10,055:INFO:                 ray: 2.2.0
2023-02-16 08:25:10,055:INFO:            hyperopt: 0.2.7
2023-02-16 08:25:10,055:INFO:              optuna: 3.1.0
2023-02-16 08:25:10,055:INFO:               skopt: 0.9.0
2023-02-16 08:25:10,055:INFO:              mlflow: 1.30.0
2023-02-16 08:25:10,055:INFO:              gradio: 3.18.0
2023-02-16 08:25:10,055:INFO:             fastapi: 0.92.0
2023-02-16 08:25:10,056:INFO:             uvicorn: 0.20.0
2023-02-16 08:25:10,056:INFO:              m2cgen: 0.10.0
2023-02-16 08:25:10,056:INFO:           evidently: 0.2.4
2023-02-16 08:25:10,056:INFO:               fugue: 0.8.1.dev4
2023-02-16 08:25:10,056:INFO:           streamlit: Not installed
2023-02-16 08:25:10,056:INFO:             prophet: Not installed
2023-02-16 08:25:10,056:INFO:None
2023-02-16 08:25:10,056:INFO:Set up GPU usage.
2023-02-16 08:25:10,056:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,056:INFO:cuml==23.2.0
2023-02-16 08:25:10,056:ERROR:Couldn't set cuML global output type
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/tabular_experiment.py", line 351, in _initialize_setup
    import cuml.common.memory_utils
ModuleNotFoundError: No module named 'cuml.common.memory_utils'
2023-02-16 08:25:10,056:INFO:Set up data.
2023-02-16 08:25:10,298:INFO:Set up train/test split.
2023-02-16 08:25:10,424:INFO:Set up index.
2023-02-16 08:25:10,456:INFO:Set up folding strategy.
2023-02-16 08:25:10,457:INFO:Assigning column types.
2023-02-16 08:25:10,531:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-16 08:25:10,532:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,532:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:10,532:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-16 08:25:10,532:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,532:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:10,534:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 08:25:10,534:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,534:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:10,537:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 08:25:10,537:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,537:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:10,623:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 08:25:10,623:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,623:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:10,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 08:25:10,649:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,649:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:10,649:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,649:INFO:Imported cuml.ensemble
2023-02-16 08:25:10,650:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:10,941:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:10,985:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,985:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:10,985:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-16 08:25:10,985:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,985:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:10,988:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 08:25:10,988:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,988:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:10,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 08:25:10,990:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:10,990:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:11,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,085:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,085:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:11,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,111:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,111:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:11,111:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,111:INFO:Imported cuml.ensemble
2023-02-16 08:25:11,111:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:11,177:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:11,209:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-16 08:25:11,209:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,209:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:11,209:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,209:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:11,212:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,212:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,212:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:11,215:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,215:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,215:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:11,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,310:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,310:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:11,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,336:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,336:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:11,336:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,336:INFO:Imported cuml.ensemble
2023-02-16 08:25:11,336:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:11,408:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:11,441:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,441:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:11,441:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,441:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:11,443:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,443:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,444:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:11,446:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,446:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,446:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:11,541:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,541:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,541:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:11,568:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,568:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,568:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:11,568:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,568:INFO:Imported cuml.ensemble
2023-02-16 08:25:11,568:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:11,638:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:11,670:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-16 08:25:11,671:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,671:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:11,671:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,671:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:11,675:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,675:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:11,678:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,678:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,678:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:11,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,772:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,772:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:11,798:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,799:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,799:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:11,799:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,799:INFO:Imported cuml.ensemble
2023-02-16 08:25:11,799:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:11,872:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:11,904:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,904:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:11,904:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,904:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:11,907:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,907:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:11,910:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 08:25:11,910:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:11,910:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:12,004:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 08:25:12,004:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,004:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:12,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 08:25:12,031:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,031:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:12,031:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,031:INFO:Imported cuml.ensemble
2023-02-16 08:25:12,031:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:12,097:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:12,129:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-16 08:25:12,129:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,129:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:12,129:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,129:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:12,132:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,132:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:12,135:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,135:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:12,228:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 08:25:12,228:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,228:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:12,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 08:25:12,255:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,255:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:12,255:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,255:INFO:Imported cuml.ensemble
2023-02-16 08:25:12,255:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:12,324:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:12,356:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,356:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:12,356:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,356:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:12,359:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,359:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:12,362:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,362:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:12,458:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 08:25:12,458:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,458:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:12,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 08:25:12,485:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,485:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:12,485:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,485:INFO:Imported cuml.ensemble
2023-02-16 08:25:12,485:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:12,549:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:12,581:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-16 08:25:12,581:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,581:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:12,582:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,582:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:12,584:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,584:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:12,587:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,587:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:12,681:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 08:25:12,681:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,681:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:12,708:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,708:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:12,708:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,708:INFO:Imported cuml.ensemble
2023-02-16 08:25:12,708:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:12,775:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:12,807:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,807:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:12,807:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,807:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:12,810:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,810:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:12,813:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,813:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:12,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 08:25:12,907:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,907:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:12,934:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,934:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:12,934:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:12,934:INFO:Imported cuml.ensemble
2023-02-16 08:25:12,934:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:13,002:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:13,034:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-16 08:25:13,034:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,034:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:13,034:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,034:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:13,037:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,037:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:13,040:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,040:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:13,134:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,134:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:13,161:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,161:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:13,161:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,161:INFO:Imported cuml.ensemble
2023-02-16 08:25:13,161:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:13,225:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:13,257:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,257:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:13,257:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,257:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:13,260:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,260:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:13,263:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,263:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:13,358:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,358:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:13,385:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,385:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:13,385:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,385:INFO:Imported cuml.ensemble
2023-02-16 08:25:13,385:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:13,459:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:13,492:INFO:Preparing preprocessing pipeline...
2023-02-16 08:25:13,502:INFO:Set up column name cleaning.
2023-02-16 08:25:13,502:INFO:Set up simple imputation.
2023-02-16 08:25:13,502:INFO:Set up feature normalization.
2023-02-16 08:25:13,502:INFO:Set up feature selection.
2023-02-16 08:25:13,502:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,502:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:13,503:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,503:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:13,505:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,505:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:13,508:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,508:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:13,601:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,601:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:13,628:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,628:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:13,628:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:13,628:INFO:Imported cuml.ensemble
2023-02-16 08:25:13,628:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:13,700:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:15,889:INFO:Finished creating preprocessing pipeline.
2023-02-16 08:25:15,898:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMRegressor(),
                                                                max_features=154,
                                                                threshold=-inf)))])
2023-02-16 08:25:15,898:INFO:Creating final display dataframe.
2023-02-16 08:25:16,976:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28583, 780)
4        Transformed data shape           (28583, 155)
5   Transformed train set shape           (20008, 155)
6    Transformed test set shape            (8575, 155)
7               Ignore features                      5
8              Numeric features                    774
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13                    Normalize                   True
14             Normalize method                 zscore
15            Feature selection                   True
16     Feature selection method                classic
17  Feature selection estimator               lightgbm
18  Number of features selected                    0.2
19               Fold Generator                  KFold
20                  Fold Number                     10
21                     CPU Jobs                     -1
22                      Use GPU                   True
23               Log Experiment                  False
24              Experiment Name       reg-default-name
25                          USI                   a325
2023-02-16 08:25:16,981:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:16,981:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:16,981:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:16,981:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:16,985:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:16,985:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:16,989:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:16,989:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:17,085:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:17,085:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:17,112:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:17,112:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:17,112:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:17,112:INFO:Imported cuml.ensemble
2023-02-16 08:25:17,112:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:17,179:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:17,212:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:17,212:INFO:Imported cuml.linear_model.LinearRegression
2023-02-16 08:25:17,212:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:17,212:INFO:Imported cuml.linear_model.Lasso
2023-02-16 08:25:17,215:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:17,215:INFO:Imported cuml.linear_model.Ridge
2023-02-16 08:25:17,218:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:17,218:INFO:Imported cuml.linear_model.ElasticNet
2023-02-16 08:25:17,312:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:17,312:INFO:Imported cuml.svm.SVR
2023-02-16 08:25:17,340:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:17,340:INFO:Imported cuml.neighbors.KNeighborsRegressor
2023-02-16 08:25:17,340:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 08:25:17,340:INFO:Imported cuml.ensemble
2023-02-16 08:25:17,340:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 08:25:17,414:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 08:25:17,446:INFO:setup() successfully completed in 7.61s...............
2023-02-16 08:25:17,446:INFO:Initializing compare_models()
2023-02-16 08:25:17,446:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, 'include': None, 'exclude': ['tr', 'lightgbm'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr', 'lightgbm'])
2023-02-16 08:25:17,446:INFO:Checking exceptions
2023-02-16 08:25:17,476:INFO:Preparing display monitor
2023-02-16 08:25:17,491:INFO:Initializing Linear Regression
2023-02-16 08:25:17,491:INFO:Total runtime is 8.463859558105468e-07 minutes
2023-02-16 08:25:17,493:INFO:SubProcess create_model() called ==================================
2023-02-16 08:25:17,493:INFO:Initializing create_model()
2023-02-16 08:25:17,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:25:17,493:INFO:Checking exceptions
2023-02-16 08:25:17,493:INFO:Importing libraries
2023-02-16 08:25:17,493:INFO:Copying training dataset
2023-02-16 08:25:17,579:INFO:Defining folds
2023-02-16 08:25:17,579:INFO:Declaring metric variables
2023-02-16 08:25:17,582:INFO:Importing untrained model
2023-02-16 08:25:17,584:INFO:Linear Regression Imported successfully
2023-02-16 08:25:17,587:INFO:Starting cross validation
2023-02-16 08:25:17,594:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:25:18,326:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029500 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-16 08:25:18,328:INFO:[LightGBM] [Info] Total Bins 197370
2023-02-16 08:25:18,333:INFO:[LightGBM] [Info] Number of data points in the train set: 18007, number of used features: 774
2023-02-16 08:25:18,334:INFO:[LightGBM] [Info] Start training from score 0.001495
2023-02-16 08:25:22,134:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026461 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-16 08:25:22,136:INFO:[LightGBM] [Info] Total Bins 197370
2023-02-16 08:25:22,141:INFO:[LightGBM] [Info] Number of data points in the train set: 18007, number of used features: 774
2023-02-16 08:25:22,142:INFO:[LightGBM] [Info] Start training from score 0.001626
2023-02-16 08:25:24,225:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026894 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-16 08:25:24,228:INFO:[LightGBM] [Info] Total Bins 197370
2023-02-16 08:25:24,231:INFO:[LightGBM] [Info] Number of data points in the train set: 18007, number of used features: 774
2023-02-16 08:25:24,233:INFO:[LightGBM] [Info] Start training from score 0.001565
2023-02-16 08:25:26,281:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028740 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-16 08:25:26,284:INFO:[LightGBM] [Info] Total Bins 197370
2023-02-16 08:25:26,287:INFO:[LightGBM] [Info] Number of data points in the train set: 18007, number of used features: 774
2023-02-16 08:25:26,288:INFO:[LightGBM] [Info] Start training from score 0.001508
2023-02-16 08:25:28,280:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021883 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-16 08:25:28,283:INFO:[LightGBM] [Info] Total Bins 197370
2023-02-16 08:25:28,286:INFO:[LightGBM] [Info] Number of data points in the train set: 18007, number of used features: 774
2023-02-16 08:25:28,287:INFO:[LightGBM] [Info] Start training from score 0.001907
2023-02-16 08:25:30,255:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020311 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-16 08:25:30,257:INFO:[LightGBM] [Info] Total Bins 197370
2023-02-16 08:25:30,260:INFO:[LightGBM] [Info] Number of data points in the train set: 18007, number of used features: 774
2023-02-16 08:25:30,262:INFO:[LightGBM] [Info] Start training from score 0.001709
2023-02-16 08:25:32,212:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021993 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-16 08:25:32,214:INFO:[LightGBM] [Info] Total Bins 197370
2023-02-16 08:25:32,218:INFO:[LightGBM] [Info] Number of data points in the train set: 18007, number of used features: 774
2023-02-16 08:25:32,219:INFO:[LightGBM] [Info] Start training from score 0.001597
2023-02-16 08:25:34,238:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029806 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-16 08:25:34,241:INFO:[LightGBM] [Info] Total Bins 197370
2023-02-16 08:25:34,244:INFO:[LightGBM] [Info] Number of data points in the train set: 18007, number of used features: 774
2023-02-16 08:25:34,245:INFO:[LightGBM] [Info] Start training from score 0.001341
2023-02-16 08:25:36,289:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028612 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-16 08:25:36,292:INFO:[LightGBM] [Info] Total Bins 197370
2023-02-16 08:25:36,295:INFO:[LightGBM] [Info] Number of data points in the train set: 18008, number of used features: 774
2023-02-16 08:25:36,297:INFO:[LightGBM] [Info] Start training from score 0.001792
2023-02-16 08:25:38,358:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030427 seconds.
You can set `force_col_wise=true` to remove the overhead.
2023-02-16 08:25:38,361:INFO:[LightGBM] [Info] Total Bins 197370
2023-02-16 08:25:38,364:INFO:[LightGBM] [Info] Number of data points in the train set: 18008, number of used features: 774
2023-02-16 08:25:38,365:INFO:[LightGBM] [Info] Start training from score 0.001483
2023-02-16 08:25:39,818:INFO:Calculating mean and std
2023-02-16 08:25:39,819:INFO:Creating metrics dataframe
2023-02-16 08:25:39,821:INFO:Uploading results into container
2023-02-16 08:25:39,821:INFO:Uploading model into container now
2023-02-16 08:25:39,822:INFO:_master_model_container: 1
2023-02-16 08:25:39,822:INFO:_display_container: 2
2023-02-16 08:25:39,822:INFO:LinearRegression()
2023-02-16 08:25:39,822:INFO:create_model() successfully completed......................................
2023-02-16 08:25:40,024:INFO:SubProcess create_model() end ==================================
2023-02-16 08:25:40,024:INFO:Creating metrics dataframe
2023-02-16 08:25:40,030:INFO:Initializing Lasso Regression
2023-02-16 08:25:40,030:INFO:Total runtime is 0.3756618142127991 minutes
2023-02-16 08:25:40,032:INFO:SubProcess create_model() called ==================================
2023-02-16 08:25:40,032:INFO:Initializing create_model()
2023-02-16 08:25:40,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:25:40,032:INFO:Checking exceptions
2023-02-16 08:25:40,032:INFO:Importing libraries
2023-02-16 08:25:40,033:INFO:Copying training dataset
2023-02-16 08:25:40,099:INFO:Defining folds
2023-02-16 08:25:40,099:INFO:Declaring metric variables
2023-02-16 08:25:40,101:INFO:Importing untrained model
2023-02-16 08:25:40,103:INFO:Lasso Regression Imported successfully
2023-02-16 08:25:40,107:INFO:Starting cross validation
2023-02-16 08:25:40,112:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:25:44,064:INFO:Calculating mean and std
2023-02-16 08:25:44,064:INFO:Creating metrics dataframe
2023-02-16 08:25:44,066:INFO:Uploading results into container
2023-02-16 08:25:44,067:INFO:Uploading model into container now
2023-02-16 08:25:44,067:INFO:_master_model_container: 2
2023-02-16 08:25:44,067:INFO:_display_container: 2
2023-02-16 08:25:44,067:INFO:Lasso()
2023-02-16 08:25:44,067:INFO:create_model() successfully completed......................................
2023-02-16 08:25:44,215:INFO:SubProcess create_model() end ==================================
2023-02-16 08:25:44,215:INFO:Creating metrics dataframe
2023-02-16 08:25:44,221:INFO:Initializing Ridge Regression
2023-02-16 08:25:44,221:INFO:Total runtime is 0.445505424340566 minutes
2023-02-16 08:25:44,223:INFO:SubProcess create_model() called ==================================
2023-02-16 08:25:44,223:INFO:Initializing create_model()
2023-02-16 08:25:44,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:25:44,223:INFO:Checking exceptions
2023-02-16 08:25:44,223:INFO:Importing libraries
2023-02-16 08:25:44,223:INFO:Copying training dataset
2023-02-16 08:25:44,292:INFO:Defining folds
2023-02-16 08:25:44,292:INFO:Declaring metric variables
2023-02-16 08:25:44,294:INFO:Importing untrained model
2023-02-16 08:25:44,296:INFO:Ridge Regression Imported successfully
2023-02-16 08:25:44,299:INFO:Starting cross validation
2023-02-16 08:25:44,304:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:25:48,279:INFO:Calculating mean and std
2023-02-16 08:25:48,280:INFO:Creating metrics dataframe
2023-02-16 08:25:48,282:INFO:Uploading results into container
2023-02-16 08:25:48,282:INFO:Uploading model into container now
2023-02-16 08:25:48,283:INFO:_master_model_container: 3
2023-02-16 08:25:48,283:INFO:_display_container: 2
2023-02-16 08:25:48,283:INFO:Ridge()
2023-02-16 08:25:48,283:INFO:create_model() successfully completed......................................
2023-02-16 08:25:48,431:INFO:SubProcess create_model() end ==================================
2023-02-16 08:25:48,431:INFO:Creating metrics dataframe
2023-02-16 08:25:48,438:INFO:Initializing Elastic Net
2023-02-16 08:25:48,438:INFO:Total runtime is 0.5157823324203491 minutes
2023-02-16 08:25:48,440:INFO:SubProcess create_model() called ==================================
2023-02-16 08:25:48,440:INFO:Initializing create_model()
2023-02-16 08:25:48,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:25:48,440:INFO:Checking exceptions
2023-02-16 08:25:48,440:INFO:Importing libraries
2023-02-16 08:25:48,440:INFO:Copying training dataset
2023-02-16 08:25:48,509:INFO:Defining folds
2023-02-16 08:25:48,510:INFO:Declaring metric variables
2023-02-16 08:25:48,512:INFO:Importing untrained model
2023-02-16 08:25:48,514:INFO:Elastic Net Imported successfully
2023-02-16 08:25:48,517:INFO:Starting cross validation
2023-02-16 08:25:48,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:25:52,421:INFO:Calculating mean and std
2023-02-16 08:25:52,422:INFO:Creating metrics dataframe
2023-02-16 08:25:52,424:INFO:Uploading results into container
2023-02-16 08:25:52,424:INFO:Uploading model into container now
2023-02-16 08:25:52,424:INFO:_master_model_container: 4
2023-02-16 08:25:52,424:INFO:_display_container: 2
2023-02-16 08:25:52,424:INFO:ElasticNet()
2023-02-16 08:25:52,424:INFO:create_model() successfully completed......................................
2023-02-16 08:25:52,562:INFO:SubProcess create_model() end ==================================
2023-02-16 08:25:52,562:INFO:Creating metrics dataframe
2023-02-16 08:25:52,568:INFO:Initializing Least Angle Regression
2023-02-16 08:25:52,568:INFO:Total runtime is 0.584624421596527 minutes
2023-02-16 08:25:52,570:INFO:SubProcess create_model() called ==================================
2023-02-16 08:25:52,570:INFO:Initializing create_model()
2023-02-16 08:25:52,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:25:52,570:INFO:Checking exceptions
2023-02-16 08:25:52,570:INFO:Importing libraries
2023-02-16 08:25:52,570:INFO:Copying training dataset
2023-02-16 08:25:52,633:INFO:Defining folds
2023-02-16 08:25:52,634:INFO:Declaring metric variables
2023-02-16 08:25:52,636:INFO:Importing untrained model
2023-02-16 08:25:52,638:INFO:Least Angle Regression Imported successfully
2023-02-16 08:25:52,641:INFO:Starting cross validation
2023-02-16 08:25:52,646:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:25:53,452:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=2.463e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-16 08:25:54,533:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-16 08:25:54,533:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-02-16 08:25:54,534:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-02-16 08:25:54,535:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2023-02-16 08:25:55,384:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=3.468e+00, with an active set of 145 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-16 08:25:56,318:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=2.143e-03, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-02-16 08:25:57,373:INFO:Calculating mean and std
2023-02-16 08:25:57,374:INFO:Creating metrics dataframe
2023-02-16 08:25:57,377:INFO:Uploading results into container
2023-02-16 08:25:57,377:INFO:Uploading model into container now
2023-02-16 08:25:57,377:INFO:_master_model_container: 5
2023-02-16 08:25:57,377:INFO:_display_container: 2
2023-02-16 08:25:57,378:INFO:Lars(random_state=11)
2023-02-16 08:25:57,378:INFO:create_model() successfully completed......................................
2023-02-16 08:25:57,528:INFO:SubProcess create_model() end ==================================
2023-02-16 08:25:57,528:INFO:Creating metrics dataframe
2023-02-16 08:25:57,535:INFO:Initializing Lasso Least Angle Regression
2023-02-16 08:25:57,535:INFO:Total runtime is 0.66740296681722 minutes
2023-02-16 08:25:57,537:INFO:SubProcess create_model() called ==================================
2023-02-16 08:25:57,537:INFO:Initializing create_model()
2023-02-16 08:25:57,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:25:57,537:INFO:Checking exceptions
2023-02-16 08:25:57,537:INFO:Importing libraries
2023-02-16 08:25:57,537:INFO:Copying training dataset
2023-02-16 08:25:57,600:INFO:Defining folds
2023-02-16 08:25:57,600:INFO:Declaring metric variables
2023-02-16 08:25:57,602:INFO:Importing untrained model
2023-02-16 08:25:57,604:INFO:Lasso Least Angle Regression Imported successfully
2023-02-16 08:25:57,607:INFO:Starting cross validation
2023-02-16 08:25:57,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:26:02,042:INFO:Calculating mean and std
2023-02-16 08:26:02,042:INFO:Creating metrics dataframe
2023-02-16 08:26:02,045:INFO:Uploading results into container
2023-02-16 08:26:02,046:INFO:Uploading model into container now
2023-02-16 08:26:02,046:INFO:_master_model_container: 6
2023-02-16 08:26:02,046:INFO:_display_container: 2
2023-02-16 08:26:02,046:INFO:LassoLars(random_state=11)
2023-02-16 08:26:02,046:INFO:create_model() successfully completed......................................
2023-02-16 08:26:02,195:INFO:SubProcess create_model() end ==================================
2023-02-16 08:26:02,195:INFO:Creating metrics dataframe
2023-02-16 08:26:02,201:INFO:Initializing Orthogonal Matching Pursuit
2023-02-16 08:26:02,201:INFO:Total runtime is 0.7451749602953592 minutes
2023-02-16 08:26:02,203:INFO:SubProcess create_model() called ==================================
2023-02-16 08:26:02,203:INFO:Initializing create_model()
2023-02-16 08:26:02,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:26:02,203:INFO:Checking exceptions
2023-02-16 08:26:02,203:INFO:Importing libraries
2023-02-16 08:26:02,203:INFO:Copying training dataset
2023-02-16 08:26:02,267:INFO:Defining folds
2023-02-16 08:26:02,267:INFO:Declaring metric variables
2023-02-16 08:26:02,270:INFO:Importing untrained model
2023-02-16 08:26:02,271:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-16 08:26:02,274:INFO:Starting cross validation
2023-02-16 08:26:02,280:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:26:06,758:INFO:Calculating mean and std
2023-02-16 08:26:06,758:INFO:Creating metrics dataframe
2023-02-16 08:26:06,761:INFO:Uploading results into container
2023-02-16 08:26:06,762:INFO:Uploading model into container now
2023-02-16 08:26:06,762:INFO:_master_model_container: 7
2023-02-16 08:26:06,762:INFO:_display_container: 2
2023-02-16 08:26:06,762:INFO:OrthogonalMatchingPursuit()
2023-02-16 08:26:06,762:INFO:create_model() successfully completed......................................
2023-02-16 08:26:06,910:INFO:SubProcess create_model() end ==================================
2023-02-16 08:26:06,910:INFO:Creating metrics dataframe
2023-02-16 08:26:06,916:INFO:Initializing Bayesian Ridge
2023-02-16 08:26:06,916:INFO:Total runtime is 0.8237560709317524 minutes
2023-02-16 08:26:06,918:INFO:SubProcess create_model() called ==================================
2023-02-16 08:26:06,918:INFO:Initializing create_model()
2023-02-16 08:26:06,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:26:06,918:INFO:Checking exceptions
2023-02-16 08:26:06,918:INFO:Importing libraries
2023-02-16 08:26:06,918:INFO:Copying training dataset
2023-02-16 08:26:06,980:INFO:Defining folds
2023-02-16 08:26:06,981:INFO:Declaring metric variables
2023-02-16 08:26:06,983:INFO:Importing untrained model
2023-02-16 08:26:06,984:INFO:Bayesian Ridge Imported successfully
2023-02-16 08:26:06,987:INFO:Starting cross validation
2023-02-16 08:26:06,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:26:12,826:INFO:Calculating mean and std
2023-02-16 08:26:12,827:INFO:Creating metrics dataframe
2023-02-16 08:26:12,830:INFO:Uploading results into container
2023-02-16 08:26:12,830:INFO:Uploading model into container now
2023-02-16 08:26:12,830:INFO:_master_model_container: 8
2023-02-16 08:26:12,830:INFO:_display_container: 2
2023-02-16 08:26:12,830:INFO:BayesianRidge()
2023-02-16 08:26:12,830:INFO:create_model() successfully completed......................................
2023-02-16 08:26:12,976:INFO:SubProcess create_model() end ==================================
2023-02-16 08:26:12,977:INFO:Creating metrics dataframe
2023-02-16 08:26:12,983:INFO:Initializing Passive Aggressive Regressor
2023-02-16 08:26:12,983:INFO:Total runtime is 0.9248699863751728 minutes
2023-02-16 08:26:12,985:INFO:SubProcess create_model() called ==================================
2023-02-16 08:26:12,985:INFO:Initializing create_model()
2023-02-16 08:26:12,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:26:12,985:INFO:Checking exceptions
2023-02-16 08:26:12,985:INFO:Importing libraries
2023-02-16 08:26:12,985:INFO:Copying training dataset
2023-02-16 08:26:13,047:INFO:Defining folds
2023-02-16 08:26:13,047:INFO:Declaring metric variables
2023-02-16 08:26:13,049:INFO:Importing untrained model
2023-02-16 08:26:13,051:INFO:Passive Aggressive Regressor Imported successfully
2023-02-16 08:26:13,053:INFO:Starting cross validation
2023-02-16 08:26:13,059:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:26:17,326:INFO:Calculating mean and std
2023-02-16 08:26:17,326:INFO:Creating metrics dataframe
2023-02-16 08:26:17,329:INFO:Uploading results into container
2023-02-16 08:26:17,330:INFO:Uploading model into container now
2023-02-16 08:26:17,330:INFO:_master_model_container: 9
2023-02-16 08:26:17,330:INFO:_display_container: 2
2023-02-16 08:26:17,330:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-16 08:26:17,330:INFO:create_model() successfully completed......................................
2023-02-16 08:26:17,475:INFO:SubProcess create_model() end ==================================
2023-02-16 08:26:17,475:INFO:Creating metrics dataframe
2023-02-16 08:26:17,482:INFO:Initializing Huber Regressor
2023-02-16 08:26:17,482:INFO:Total runtime is 0.999848977724711 minutes
2023-02-16 08:26:17,483:INFO:SubProcess create_model() called ==================================
2023-02-16 08:26:17,484:INFO:Initializing create_model()
2023-02-16 08:26:17,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:26:17,484:INFO:Checking exceptions
2023-02-16 08:26:17,484:INFO:Importing libraries
2023-02-16 08:26:17,484:INFO:Copying training dataset
2023-02-16 08:26:17,551:INFO:Defining folds
2023-02-16 08:26:17,551:INFO:Declaring metric variables
2023-02-16 08:26:17,553:INFO:Importing untrained model
2023-02-16 08:26:17,555:INFO:Huber Regressor Imported successfully
2023-02-16 08:26:17,558:INFO:Starting cross validation
2023-02-16 08:26:17,563:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:26:20,120:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 08:26:22,743:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 08:26:25,697:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 08:26:28,162:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 08:26:30,695:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 08:26:33,313:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 08:26:35,985:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 08:26:38,623:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 08:26:41,390:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 08:26:44,362:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 08:26:44,515:INFO:Calculating mean and std
2023-02-16 08:26:44,516:INFO:Creating metrics dataframe
2023-02-16 08:26:44,518:INFO:Uploading results into container
2023-02-16 08:26:44,519:INFO:Uploading model into container now
2023-02-16 08:26:44,519:INFO:_master_model_container: 10
2023-02-16 08:26:44,519:INFO:_display_container: 2
2023-02-16 08:26:44,519:INFO:HuberRegressor()
2023-02-16 08:26:44,519:INFO:create_model() successfully completed......................................
2023-02-16 08:26:44,670:INFO:SubProcess create_model() end ==================================
2023-02-16 08:26:44,670:INFO:Creating metrics dataframe
2023-02-16 08:26:44,677:INFO:Initializing K Neighbors Regressor
2023-02-16 08:26:44,677:INFO:Total runtime is 1.4531099836031596 minutes
2023-02-16 08:26:44,679:INFO:SubProcess create_model() called ==================================
2023-02-16 08:26:44,679:INFO:Initializing create_model()
2023-02-16 08:26:44,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:26:44,679:INFO:Checking exceptions
2023-02-16 08:26:44,679:INFO:Importing libraries
2023-02-16 08:26:44,679:INFO:Copying training dataset
2023-02-16 08:26:44,743:INFO:Defining folds
2023-02-16 08:26:44,743:INFO:Declaring metric variables
2023-02-16 08:26:44,745:INFO:Importing untrained model
2023-02-16 08:26:44,747:INFO:K Neighbors Regressor Imported successfully
2023-02-16 08:26:44,751:INFO:Starting cross validation
2023-02-16 08:26:44,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:26:44,758:INFO:[I] [08:26:44.758137] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:45,053:INFO:[I] [08:26:45.053282] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:45,179:INFO:[I] [08:26:45.179062] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:45,477:INFO:[I] [08:26:45.477193] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:45,577:INFO:[I] [08:26:45.577906] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:45,878:INFO:[I] [08:26:45.878174] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:45,978:INFO:[I] [08:26:45.978697] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:46,281:INFO:[I] [08:26:46.281344] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:46,381:INFO:[I] [08:26:46.381435] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:46,679:INFO:[I] [08:26:46.679652] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:46,779:INFO:[I] [08:26:46.779534] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:47,081:INFO:[I] [08:26:47.081283] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:47,181:INFO:[I] [08:26:47.181513] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:47,476:INFO:[I] [08:26:47.476782] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:47,577:INFO:[I] [08:26:47.577664] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:47,879:INFO:[I] [08:26:47.879347] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:47,979:INFO:[I] [08:26:47.979404] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:48,296:INFO:[I] [08:26:48.296843] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:48,395:INFO:[I] [08:26:48.395195] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:48,685:INFO:[I] [08:26:48.685961] Unused keyword parameter: n_jobs during cuML estimator initialization
2023-02-16 08:26:48,783:INFO:Calculating mean and std
2023-02-16 08:26:48,784:INFO:Creating metrics dataframe
2023-02-16 08:26:48,786:INFO:Uploading results into container
2023-02-16 08:26:48,786:INFO:Uploading model into container now
2023-02-16 08:26:48,786:INFO:_master_model_container: 11
2023-02-16 08:26:48,786:INFO:_display_container: 2
2023-02-16 08:26:48,787:INFO:KNeighborsRegressor()
2023-02-16 08:26:48,787:INFO:create_model() successfully completed......................................
2023-02-16 08:26:48,924:INFO:SubProcess create_model() end ==================================
2023-02-16 08:26:48,924:INFO:Creating metrics dataframe
2023-02-16 08:26:48,931:INFO:Initializing Decision Tree Regressor
2023-02-16 08:26:48,931:INFO:Total runtime is 1.5239967942237853 minutes
2023-02-16 08:26:48,932:INFO:SubProcess create_model() called ==================================
2023-02-16 08:26:48,932:INFO:Initializing create_model()
2023-02-16 08:26:48,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:26:48,932:INFO:Checking exceptions
2023-02-16 08:26:48,933:INFO:Importing libraries
2023-02-16 08:26:48,933:INFO:Copying training dataset
2023-02-16 08:26:48,995:INFO:Defining folds
2023-02-16 08:26:48,995:INFO:Declaring metric variables
2023-02-16 08:26:48,997:INFO:Importing untrained model
2023-02-16 08:26:48,999:INFO:Decision Tree Regressor Imported successfully
2023-02-16 08:26:49,002:INFO:Starting cross validation
2023-02-16 08:26:49,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:27:34,741:INFO:Calculating mean and std
2023-02-16 08:27:34,742:INFO:Creating metrics dataframe
2023-02-16 08:27:34,744:INFO:Uploading results into container
2023-02-16 08:27:34,744:INFO:Uploading model into container now
2023-02-16 08:27:34,744:INFO:_master_model_container: 12
2023-02-16 08:27:34,744:INFO:_display_container: 2
2023-02-16 08:27:34,744:INFO:DecisionTreeRegressor(random_state=11)
2023-02-16 08:27:34,744:INFO:create_model() successfully completed......................................
2023-02-16 08:27:34,877:INFO:SubProcess create_model() end ==================================
2023-02-16 08:27:34,877:INFO:Creating metrics dataframe
2023-02-16 08:27:34,885:INFO:Initializing Random Forest Regressor
2023-02-16 08:27:34,885:INFO:Total runtime is 2.28989839553833 minutes
2023-02-16 08:27:34,886:INFO:SubProcess create_model() called ==================================
2023-02-16 08:27:34,887:INFO:Initializing create_model()
2023-02-16 08:27:34,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f59d22d8790>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f59f80d4a60>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 08:27:34,887:INFO:Checking exceptions
2023-02-16 08:27:34,887:INFO:Importing libraries
2023-02-16 08:27:34,887:INFO:Copying training dataset
2023-02-16 08:27:34,949:INFO:Defining folds
2023-02-16 08:27:34,950:INFO:Declaring metric variables
2023-02-16 08:27:34,952:INFO:Importing untrained model
2023-02-16 08:27:34,952:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-16 08:27:34,954:INFO:Random Forest Regressor Imported successfully
2023-02-16 08:27:34,957:INFO:Starting cross validation
2023-02-16 08:27:34,963:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-16 08:27:34,964:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-16 08:27:35,262:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-16 08:27:37,195:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 297, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/nvtx/nvtx.py", line 101, in inner
    result = func(*args, **kwargs)
  File "randomforestregressor.pyx", line 588, in cuml.ensemble.randomforestregressor.RandomForestRegressor.predict
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "randomforest_common.pyx", line 353, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu
  File "randomforest_common.pyx", line 218, in cuml.ensemble.randomforest_common.BaseRandomForestModel._obtain_treelite_handle
  File "randomforest_shared.pyx", line 121, in cuml.ensemble.randomforest_shared.treelite_deserialize
  File "randomforest_shared.pyx", line 105, in cuml.ensemble.randomforest_shared.init_from_frames
  File "randomforest_shared.pyx", line 84, in cuml.ensemble.randomforest_shared._init_from_frames
RuntimeError: Cannot deserialize model from a different major Treelite version or a version before 2.4.0.
Currently running Treelite version 3.1.0
The model checkpoint was generated from Treelite version 21861.1.0

  warnings.warn(

2023-02-16 08:27:37,195:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 297, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/nvtx/nvtx.py", line 101, in inner
    result = func(*args, **kwargs)
  File "randomforestregressor.pyx", line 588, in cuml.ensemble.randomforestregressor.RandomForestRegressor.predict
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "randomforest_common.pyx", line 353, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu
  File "randomforest_common.pyx", line 218, in cuml.ensemble.randomforest_common.BaseRandomForestModel._obtain_treelite_handle
  File "randomforest_shared.pyx", line 121, in cuml.ensemble.randomforest_shared.treelite_deserialize
  File "randomforest_shared.pyx", line 105, in cuml.ensemble.randomforest_shared.init_from_frames
  File "randomforest_shared.pyx", line 84, in cuml.ensemble.randomforest_shared._init_from_frames
RuntimeError: Cannot deserialize model from a different major Treelite version or a version before 2.4.0.
Currently running Treelite version 3.1.0
The model checkpoint was generated from Treelite version 627533891.1380463666.0

  warnings.warn(

2023-02-16 08:27:37,195:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 297, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/nvtx/nvtx.py", line 101, in inner
    result = func(*args, **kwargs)
  File "randomforestregressor.pyx", line 588, in cuml.ensemble.randomforestregressor.RandomForestRegressor.predict
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "randomforest_common.pyx", line 353, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu
  File "randomforest_common.pyx", line 218, in cuml.ensemble.randomforest_common.BaseRandomForestModel._obtain_treelite_handle
  File "randomforest_shared.pyx", line 121, in cuml.ensemble.randomforest_shared.treelite_deserialize
  File "randomforest_shared.pyx", line 105, in cuml.ensemble.randomforest_shared.init_from_frames
  File "randomforest_shared.pyx", line 84, in cuml.ensemble.randomforest_shared._init_from_frames
RuntimeError: Cannot deserialize model from a different major Treelite version or a version before 2.4.0.
Currently running Treelite version 3.1.0
The model checkpoint was generated from Treelite version 841312104.5392436.0

  warnings.warn(

2023-02-16 08:27:37,197:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-16 08:27:37,485:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-16 08:27:39,365:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 297, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/nvtx/nvtx.py", line 101, in inner
    result = func(*args, **kwargs)
  File "randomforestregressor.pyx", line 588, in cuml.ensemble.randomforestregressor.RandomForestRegressor.predict
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "randomforest_common.pyx", line 353, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu
  File "randomforest_common.pyx", line 218, in cuml.ensemble.randomforest_common.BaseRandomForestModel._obtain_treelite_handle
  File "randomforest_shared.pyx", line 121, in cuml.ensemble.randomforest_shared.treelite_deserialize
  File "randomforest_shared.pyx", line 105, in cuml.ensemble.randomforest_shared.init_from_frames
  File "randomforest_shared.pyx", line 84, in cuml.ensemble.randomforest_shared._init_from_frames
RuntimeError: Cannot deserialize model from a different major Treelite version or a version before 2.4.0.
Currently running Treelite version 3.1.0
The model checkpoint was generated from Treelite version 21861.808334687.2003132228

  warnings.warn(

2023-02-16 08:27:39,365:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 297, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/nvtx/nvtx.py", line 101, in inner
    result = func(*args, **kwargs)
  File "randomforestregressor.pyx", line 588, in cuml.ensemble.randomforestregressor.RandomForestRegressor.predict
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "randomforest_common.pyx", line 353, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu
  File "randomforest_common.pyx", line 218, in cuml.ensemble.randomforest_common.BaseRandomForestModel._obtain_treelite_handle
  File "randomforest_shared.pyx", line 121, in cuml.ensemble.randomforest_shared.treelite_deserialize
  File "randomforest_shared.pyx", line 105, in cuml.ensemble.randomforest_shared.init_from_frames
  File "randomforest_shared.pyx", line 84, in cuml.ensemble.randomforest_shared._init_from_frames
RuntimeError: Cannot deserialize model from a different major Treelite version or a version before 2.4.0.
Currently running Treelite version 3.1.0
The model checkpoint was generated from Treelite version 0.48.0

  warnings.warn(

2023-02-16 08:27:39,366:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-16 08:27:39,657:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-16 08:27:41,528:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 297, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/nvtx/nvtx.py", line 101, in inner
    result = func(*args, **kwargs)
  File "randomforestregressor.pyx", line 588, in cuml.ensemble.randomforestregressor.RandomForestRegressor.predict
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 190, in wrapper
    ret = func(*args, **kwargs)
  File "randomforest_common.pyx", line 353, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu
  File "randomforest_common.pyx", line 218, in cuml.ensemble.randomforest_common.BaseRandomForestModel._obtain_treelite_handle
  File "randomforest_shared.pyx", line 121, in cuml.ensemble.randomforest_shared.treelite_deserialize
  File "randomforest_shared.pyx", line 105, in cuml.ensemble.randomforest_shared.init_from_frames
  File "randomforest_shared.pyx", line 84, in cuml.ensemble.randomforest_shared._init_from_frames
RuntimeError: Cannot deserialize model from a different major Treelite version or a version before 2.4.0.
Currently running Treelite version 3.1.0
The model checkpoint was generated from Treelite version 875903284.892349797.808333344

  warnings.warn(

2023-02-16 08:27:41,529:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-16 08:27:41,819:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/cuml/internals/api_decorators.py:342: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set
  return func(**kwargs)

2023-02-16 09:49:24,357:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 09:49:27,015:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 09:49:27,015:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 09:49:27,015:INFO:Soft dependency imported: cuml: 23.2.0
2023-02-16 09:49:27,704:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-16 09:57:33,293:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/spyder/plugins/variableexplorer/widgets/dataframeeditor.py:244: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  for __, col in self.df.iteritems():

2023-02-16 09:57:44,712:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute `base_estimator_` was deprecated in version 1.2 and will be removed in 1.4. Use `estimator_` instead.
  warnings.warn(msg, category=FutureWarning)

2023-02-16 10:02:31,969:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/spyder/plugins/variableexplorer/widgets/dataframeeditor.py:244: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  for __, col in self.df.iteritems():

2023-02-16 10:07:41,145:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/spyder/plugins/variableexplorer/widgets/dataframeeditor.py:244: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  for __, col in self.df.iteritems():

2023-02-16 10:10:50,011:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,020:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,020:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,029:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,029:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,039:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,039:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,048:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,049:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,059:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,059:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,070:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,071:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,081:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,081:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,093:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,093:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,105:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,105:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,117:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,118:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,131:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,132:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,144:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,144:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,157:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,157:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,170:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,170:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,184:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,184:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,197:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,197:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,211:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,211:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,224:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,224:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,238:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,238:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,251:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,252:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,264:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,265:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,279:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,279:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,292:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,292:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,306:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,307:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,320:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,321:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,335:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,335:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,350:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,350:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,365:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,366:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,381:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,381:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,398:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,399:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,413:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,414:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,429:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,429:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,445:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,445:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,462:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,462:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,478:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,478:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,495:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,495:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,511:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,512:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,528:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,528:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,545:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,546:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,563:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,564:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,580:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,581:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,598:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,598:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,616:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,616:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,633:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,633:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,650:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,651:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,668:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,668:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,686:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,687:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,707:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,707:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,726:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,726:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,744:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,745:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,763:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,763:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,782:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,782:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,800:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,800:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,819:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,819:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,839:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,839:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,858:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,858:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,881:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,882:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,902:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,902:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,923:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,923:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,943:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,943:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,964:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,965:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:50,986:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:50,986:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,007:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,007:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,028:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,028:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,048:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,049:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,071:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,072:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,093:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,093:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,114:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,115:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,137:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,137:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,160:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,160:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,183:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,183:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,206:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,207:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,231:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,231:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,257:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,258:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,282:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,283:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,311:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,311:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,339:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,339:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,373:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,373:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,400:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,401:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,428:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,428:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,455:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,455:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,483:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,483:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,511:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,511:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,537:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,537:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,564:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,565:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,593:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,593:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,619:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,619:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,647:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,648:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,677:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,678:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,705:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,706:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,734:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,734:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,764:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,764:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,793:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,794:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,822:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,822:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,852:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,853:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,881:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,882:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,917:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,918:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,948:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,948:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:51,978:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:51,979:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,014:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,015:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,043:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,044:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,076:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,077:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,128:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,128:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,160:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,160:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,193:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,193:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,230:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,230:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,262:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,262:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,294:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,295:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,354:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,354:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,386:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,386:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,418:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,419:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,457:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,457:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,487:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,488:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,522:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,522:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,563:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,564:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,597:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,597:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,634:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,634:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,690:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,690:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,726:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,726:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,761:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,762:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,802:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,802:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,838:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,838:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,875:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,876:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,933:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,933:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:52,968:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:52,969:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,006:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,007:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,048:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,048:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,461:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,462:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,510:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,510:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,553:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,553:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,600:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,600:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,642:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,642:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,692:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,693:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,738:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,738:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,790:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,791:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,839:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,840:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,895:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,895:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,943:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,944:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:53,999:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:53,999:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,048:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,049:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,111:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,111:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,162:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,162:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,221:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,222:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,272:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,273:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,330:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,330:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,385:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,386:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,446:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,446:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,499:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,499:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,561:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,561:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,615:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,615:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,674:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,675:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,728:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,729:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,789:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,789:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,844:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,845:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,906:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,907:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:54,967:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:54,968:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,045:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,045:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,103:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,104:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,169:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,169:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,226:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,226:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,287:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,287:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,342:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,342:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,403:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,404:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,458:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,458:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,521:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,521:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,577:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,578:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,642:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,643:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,702:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,703:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,768:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,769:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,829:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,830:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,893:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,893:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:55,953:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:55,953:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,019:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,019:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,076:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,077:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,142:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,142:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,199:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,200:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,267:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,267:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,326:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,327:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,395:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,395:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,452:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,453:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,517:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,517:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,576:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,576:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,641:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,642:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,699:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,699:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,765:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,765:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,822:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,822:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,887:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,887:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:56,945:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:56,946:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,011:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,012:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,070:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,070:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,138:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,138:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,198:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,198:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,264:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,265:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,324:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,325:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,390:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,391:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,450:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,450:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,521:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,521:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,589:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,589:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,664:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,665:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,730:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,731:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,801:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,802:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,864:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,864:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,935:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,936:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:57,997:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:57,998:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,066:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,067:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,128:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,129:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,199:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,199:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,260:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,260:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,330:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,330:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,393:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,394:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,464:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,464:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,527:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,528:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,599:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,600:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,664:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,664:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,736:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,736:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,800:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,801:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,873:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,873:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:58,937:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:58,937:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,012:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,012:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,077:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,077:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,150:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,151:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,215:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,215:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,288:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,288:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,352:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,353:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,428:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,428:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,493:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,494:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,569:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,569:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,635:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,635:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,711:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,711:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,780:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,780:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,860:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,861:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:10:59,929:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:10:59,929:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,008:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,008:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,076:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,076:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,154:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,155:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,224:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,224:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,303:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,304:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,374:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,375:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,455:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,456:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,528:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,528:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,611:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,611:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,683:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,683:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,764:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,764:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,876:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,876:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:00,949:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:00,949:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,055:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,055:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,130:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,131:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,203:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,204:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,286:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,287:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,404:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,404:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,479:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,480:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,588:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,589:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,663:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,664:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,771:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,771:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,855:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,855:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:01,974:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:01,974:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,050:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,050:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,159:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,159:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,236:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,237:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,346:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,347:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,425:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,425:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,537:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,537:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,615:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,615:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,726:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,727:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,804:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,805:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,916:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,916:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:02,995:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:02,995:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:03,108:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:03,109:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:03,187:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:03,187:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:03,299:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:03,299:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:03,379:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:03,379:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:03,493:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:03,494:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:03,574:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:03,574:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:03,692:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:03,693:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:03,773:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:03,773:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:03,887:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:03,888:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:03,968:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:03,969:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:04,084:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:04,085:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:04,165:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:04,166:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:04,283:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:04,283:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:04,366:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:04,366:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:04,483:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:04,483:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:04,564:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:04,564:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:04,681:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:04,681:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:04,772:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:04,773:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:04,891:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:04,891:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:04,974:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:04,974:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:05,092:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:05,093:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:05,176:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:05,176:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:05,273:INFO:PyCaret RegressionExperiment
2023-02-16 10:11:05,273:INFO:Logging name: reg-default-name
2023-02-16 10:11:05,273:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-16 10:11:05,273:INFO:version 3.0.0.rc9
2023-02-16 10:11:05,273:INFO:Initializing setup()
2023-02-16 10:11:05,273:INFO:self.USI: f053
2023-02-16 10:11:05,273:INFO:self._variable_keys: {'X_test', 'idx', '_available_plots', '_ml_usecase', 'pipeline', 'exp_id', 'log_plots_param', 'seed', 'logging_param', 'memory', 'y_train', 'y_test', 'transform_target_param', 'n_jobs_param', 'X', 'html_param', 'y', 'X_train', 'fold_generator', 'gpu_param', 'target_param', 'exp_name_log', 'data', 'fold_shuffle_param', 'fold_groups_param', 'gpu_n_jobs_param', 'USI'}
2023-02-16 10:11:05,273:INFO:Checking environment
2023-02-16 10:11:05,273:INFO:python_version: 3.8.16
2023-02-16 10:11:05,273:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-16 10:11:05,273:INFO:machine: x86_64
2023-02-16 10:11:05,273:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-16 10:11:05,273:INFO:Memory: svmem(total=134979592192, available=115611201536, percent=14.3, used=17484288000, free=44185427968, active=13567819776, inactive=72464281600, buffers=1716330496, cached=71593545728, shared=616984576, slab=3854417920)
2023-02-16 10:11:05,274:INFO:Physical Core: 16
2023-02-16 10:11:05,274:INFO:Logical Core: 32
2023-02-16 10:11:05,274:INFO:Checking libraries
2023-02-16 10:11:05,274:INFO:System:
2023-02-16 10:11:05,274:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-16 10:11:05,274:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-16 10:11:05,274:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-16 10:11:05,274:INFO:PyCaret required dependencies:
2023-02-16 10:11:05,274:INFO:                 pip: 23.0
2023-02-16 10:11:05,274:INFO:          setuptools: 60.10.0
2023-02-16 10:11:05,274:INFO:             pycaret: 3.0.0rc9
2023-02-16 10:11:05,274:INFO:             IPython: 8.10.0
2023-02-16 10:11:05,274:INFO:          ipywidgets: 7.7.3
2023-02-16 10:11:05,274:INFO:                tqdm: 4.64.1
2023-02-16 10:11:05,274:INFO:               numpy: 1.23.5
2023-02-16 10:11:05,274:INFO:              pandas: 1.5.3
2023-02-16 10:11:05,274:INFO:              jinja2: 3.1.2
2023-02-16 10:11:05,274:INFO:               scipy: 1.9.1
2023-02-16 10:11:05,274:INFO:              joblib: 1.2.0
2023-02-16 10:11:05,274:INFO:             sklearn: 1.2.1
2023-02-16 10:11:05,274:INFO:                pyod: 1.0.7
2023-02-16 10:11:05,274:INFO:            imblearn: 0.10.1
2023-02-16 10:11:05,274:INFO:   category_encoders: 2.6.0
2023-02-16 10:11:05,274:INFO:            lightgbm: 3.3.5.99
2023-02-16 10:11:05,274:INFO:               numba: 0.56.4
2023-02-16 10:11:05,274:INFO:            requests: 2.28.2
2023-02-16 10:11:05,274:INFO:          matplotlib: 3.6.3
2023-02-16 10:11:05,274:INFO:          scikitplot: 0.3.7
2023-02-16 10:11:05,274:INFO:         yellowbrick: 1.5
2023-02-16 10:11:05,274:INFO:              plotly: 5.13.0
2023-02-16 10:11:05,274:INFO:             kaleido: 0.2.1
2023-02-16 10:11:05,274:INFO:         statsmodels: 0.13.5
2023-02-16 10:11:05,274:INFO:              sktime: 0.16.1
2023-02-16 10:11:05,274:INFO:               tbats: 1.1.2
2023-02-16 10:11:05,274:INFO:            pmdarima: 2.0.2
2023-02-16 10:11:05,274:INFO:              psutil: 5.9.4
2023-02-16 10:11:05,274:INFO:PyCaret optional dependencies:
2023-02-16 10:11:05,275:INFO:                shap: 0.41.0
2023-02-16 10:11:05,275:INFO:           interpret: 0.3.0
2023-02-16 10:11:05,275:INFO:                umap: 0.5.3
2023-02-16 10:11:05,275:INFO:    pandas_profiling: 4.0.0
2023-02-16 10:11:05,275:INFO:  explainerdashboard: 0.4.2
2023-02-16 10:11:05,275:INFO:             autoviz: 0.1.58
2023-02-16 10:11:05,275:INFO:           fairlearn: 0.7.0
2023-02-16 10:11:05,275:INFO:             xgboost: 1.7.3
2023-02-16 10:11:05,275:INFO:            catboost: 1.1.1
2023-02-16 10:11:05,275:INFO:              kmodes: 0.12.2
2023-02-16 10:11:05,275:INFO:             mlxtend: 0.21.0
2023-02-16 10:11:05,275:INFO:       statsforecast: 1.4.0
2023-02-16 10:11:05,275:INFO:        tune_sklearn: 0.4.5
2023-02-16 10:11:05,275:INFO:                 ray: 2.2.0
2023-02-16 10:11:05,275:INFO:            hyperopt: 0.2.7
2023-02-16 10:11:05,275:INFO:              optuna: 3.1.0
2023-02-16 10:11:05,275:INFO:               skopt: 0.9.0
2023-02-16 10:11:05,275:INFO:              mlflow: 1.30.0
2023-02-16 10:11:05,275:INFO:              gradio: 3.18.0
2023-02-16 10:11:05,275:INFO:             fastapi: 0.92.0
2023-02-16 10:11:05,275:INFO:             uvicorn: 0.20.0
2023-02-16 10:11:05,275:INFO:              m2cgen: 0.10.0
2023-02-16 10:11:05,275:INFO:           evidently: 0.2.4
2023-02-16 10:11:05,275:INFO:               fugue: 0.8.1.dev4
2023-02-16 10:11:05,275:INFO:           streamlit: Not installed
2023-02-16 10:11:05,275:INFO:             prophet: Not installed
2023-02-16 10:11:05,275:INFO:None
2023-02-16 10:11:05,275:INFO:Set up data.
2023-02-16 10:11:05,501:INFO:Set up train/test split.
2023-02-16 10:11:05,613:INFO:Set up index.
2023-02-16 10:11:05,646:INFO:Set up folding strategy.
2023-02-16 10:11:05,646:INFO:Assigning column types.
2023-02-16 10:11:05,708:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-16 10:11:05,708:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,711:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,713:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,818:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:05,819:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:05,820:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,822:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,825:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,928:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:05,930:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:05,930:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-16 10:11:05,933:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 10:11:05,936:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,011:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,041:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:06,042:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:06,045:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,125:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,152:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:06,153:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:06,154:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-16 10:11:06,159:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,234:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,261:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,261:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:06,263:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:06,268:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,341:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,368:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,369:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:06,370:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:06,371:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-16 10:11:06,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,477:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,477:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:06,479:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:06,558:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,586:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:06,587:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:06,588:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-16 10:11:06,678:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,705:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:06,706:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:06,788:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:11:06,815:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:06,817:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:06,817:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-16 10:11:06,923:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:06,925:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:07,032:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:07,033:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:07,034:INFO:Preparing preprocessing pipeline...
2023-02-16 10:11:07,042:INFO:Set up column name cleaning.
2023-02-16 10:11:07,042:INFO:Set up simple imputation.
2023-02-16 10:11:07,042:INFO:Set up removing multicollinearity.
2023-02-16 10:11:07,042:INFO:Set up feature normalization.
2023-02-16 10:11:07,042:INFO:Set up feature selection.
2023-02-16 10:11:07,148:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:11:07,149:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:11:44,678:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,689:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,689:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,698:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,699:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,709:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,709:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,720:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,720:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,731:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,731:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,743:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,743:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,757:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,758:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,770:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,770:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,783:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,783:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,795:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,796:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,808:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,808:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,821:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,821:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,835:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,835:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,849:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,849:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,862:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,863:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,876:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,876:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,891:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,891:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,905:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,905:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,919:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,920:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,934:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,934:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,948:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,949:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,964:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,965:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,979:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,979:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:44,994:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:44,995:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,013:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,013:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,029:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,030:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,045:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,045:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,061:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,062:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,080:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,081:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,098:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,098:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,117:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,118:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,136:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,136:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,156:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,156:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,176:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,177:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,198:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,198:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,217:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,218:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,238:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,238:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,257:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,258:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,302:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,302:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,322:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,323:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,351:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,351:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,374:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,375:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,406:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,407:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,439:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,439:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,463:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,464:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,487:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,487:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,511:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,511:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,544:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,545:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,579:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,579:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,603:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,604:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,628:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,629:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,655:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,655:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,690:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,691:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,727:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,727:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,753:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,753:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,781:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,781:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,808:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,808:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,847:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,847:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,888:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,888:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,917:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,917:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,944:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,944:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:45,972:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:45,972:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,009:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,009:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,048:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,048:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,076:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,076:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,104:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,104:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,135:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,135:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,173:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,174:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,214:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,214:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,243:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,243:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,272:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,273:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,301:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,302:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,342:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,342:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,384:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,384:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,414:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,414:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,445:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,445:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,475:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,475:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,518:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,518:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,561:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,561:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,593:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,593:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,623:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,623:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,655:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,655:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,699:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,700:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,745:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,745:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,778:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,778:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,810:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,811:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,843:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,844:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,889:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,889:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,935:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,936:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:46,968:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:46,969:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,003:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,004:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,037:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,038:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,084:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,084:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,132:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,133:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,167:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,168:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,202:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,202:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,237:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,237:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,288:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,288:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,338:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,338:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,375:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,376:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,412:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,412:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,448:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,449:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,497:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,498:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,548:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,549:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,586:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,586:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,623:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,623:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,660:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,660:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,712:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,712:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,766:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,766:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,805:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,805:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,842:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,843:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,881:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,882:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,936:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,936:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:47,989:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:47,990:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,028:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,028:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,067:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,067:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,107:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,108:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,162:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,163:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,218:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,219:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,258:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,259:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,300:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,300:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,340:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,341:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,398:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,398:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,455:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,456:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,497:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,498:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,538:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,539:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:48,580:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:48,580:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,146:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,146:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,201:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,201:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,279:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,279:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,333:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,333:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,407:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,407:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,461:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,461:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,538:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,538:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,593:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,594:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,671:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,671:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,728:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,729:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,807:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,807:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,862:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,862:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:49,944:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:49,944:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,000:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,000:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,077:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,077:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,134:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,135:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,215:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,215:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,271:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,271:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,350:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,350:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,408:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,409:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,490:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,490:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,548:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,548:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,630:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,630:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,690:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,691:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,771:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,771:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,833:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,834:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,923:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,924:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:50,983:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:50,983:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,065:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,065:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,123:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,123:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,206:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,206:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,265:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,265:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,348:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,348:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,408:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,408:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,497:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,497:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,558:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,558:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,643:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,643:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,705:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,706:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,792:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,792:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,854:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,855:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:51,944:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:51,945:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,006:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,007:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,093:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,093:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,154:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,155:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,244:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,244:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,306:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,306:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,395:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,395:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,459:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,459:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,547:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,547:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,611:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,611:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,702:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,702:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,766:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,766:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,854:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,855:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:52,919:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:52,920:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,010:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,010:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,075:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,076:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,166:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,167:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,232:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,232:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,323:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,323:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,390:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,391:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,482:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,483:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,551:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,551:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,645:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,645:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,715:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,715:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,812:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,812:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,880:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,880:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:53,977:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:53,977:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,048:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,048:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,145:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,146:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,217:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,218:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,318:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,318:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,390:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,390:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,491:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,491:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,565:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,565:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,670:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,670:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,745:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,745:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,849:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,849:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:54,926:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:54,926:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,028:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,028:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,099:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,099:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,198:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,199:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,270:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,270:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,369:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,369:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,440:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,440:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,540:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,541:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,613:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,614:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,715:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,715:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,787:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,787:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,890:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,890:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:55,962:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:55,963:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:56,064:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:56,064:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:56,138:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:56,139:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:56,242:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:56,243:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:56,316:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:56,316:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:56,420:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:56,421:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:56,494:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:56,495:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:56,601:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:56,601:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:56,692:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:56,693:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:56,819:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:56,820:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:56,910:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:56,911:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:57,037:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:57,037:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:57,128:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:57,128:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:57,251:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:57,251:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:57,344:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:57,345:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:57,468:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:57,468:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:57,559:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:57,560:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:57,683:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:57,683:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:57,783:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:57,783:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:57,915:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:57,915:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:58,013:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:58,014:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:58,136:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:58,137:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:58,230:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:58,230:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:58,357:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:58,357:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:58,455:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:58,456:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:58,581:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:58,582:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:58,679:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:58,679:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:58,810:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:58,811:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:58,908:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:58,908:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:59,036:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:59,036:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:59,132:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:59,132:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:59,260:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:59,261:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:59,359:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:59,359:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:59,487:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:59,487:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:59,584:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:59,584:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:59,714:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:59,714:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:59,811:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:59,811:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:11:59,941:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:11:59,941:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:00,039:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:00,040:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:00,170:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:00,171:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:00,271:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:00,271:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:00,402:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:00,402:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:00,500:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:00,501:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:00,632:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:00,632:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:00,731:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:00,732:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:00,863:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:00,864:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:00,964:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:00,964:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:01,096:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:01,096:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:01,200:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:01,200:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:01,333:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:01,333:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:01,434:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:01,434:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:01,566:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:01,567:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:01,668:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:01,669:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:01,802:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:01,803:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:01,905:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:01,905:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:02,041:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:02,041:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:02,142:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:02,142:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:02,284:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:02,284:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:02,387:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:02,387:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:02,524:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:02,524:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:02,626:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:02,627:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:02,765:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:02,765:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:02,870:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:02,871:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:03,010:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:03,011:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:03,115:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:03,115:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:03,262:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:03,263:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:03,367:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:03,368:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:03,507:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:03,507:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:03,614:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:03,614:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:03,753:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:03,753:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:03,859:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:03,859:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:04,001:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:04,001:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:04,103:WARNING:/home/moussa/github/RND/rv_data.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg"+time] = (futures_candle_df[column]-shift[column])

2023-02-16 10:12:04,104:WARNING:/home/moussa/github/RND/rv_data.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[column+"Chg%"+time] = df[column+"Chg"+time]/shift[column]

2023-02-16 10:12:04,213:INFO:PyCaret RegressionExperiment
2023-02-16 10:12:04,213:INFO:Logging name: reg-default-name
2023-02-16 10:12:04,213:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-16 10:12:04,213:INFO:version 3.0.0.rc9
2023-02-16 10:12:04,213:INFO:Initializing setup()
2023-02-16 10:12:04,213:INFO:self.USI: c16f
2023-02-16 10:12:04,213:INFO:self._variable_keys: {'X_test', 'idx', '_available_plots', '_ml_usecase', 'pipeline', 'exp_id', 'log_plots_param', 'seed', 'logging_param', 'memory', 'y_train', 'y_test', 'transform_target_param', 'n_jobs_param', 'X', 'html_param', 'y', 'X_train', 'fold_generator', 'gpu_param', 'target_param', 'exp_name_log', 'data', 'fold_shuffle_param', 'fold_groups_param', 'gpu_n_jobs_param', 'USI'}
2023-02-16 10:12:04,213:INFO:Checking environment
2023-02-16 10:12:04,213:INFO:python_version: 3.8.16
2023-02-16 10:12:04,213:INFO:python_build: ('default', 'Feb  1 2023 16:01:55')
2023-02-16 10:12:04,213:INFO:machine: x86_64
2023-02-16 10:12:04,213:INFO:platform: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-16 10:12:04,213:INFO:Memory: svmem(total=134979592192, available=115123216384, percent=14.7, used=17978966016, free=43695677440, active=13568204800, inactive=72951463936, buffers=1716633600, cached=71588315136, shared=610299904, slab=3854577664)
2023-02-16 10:12:04,213:INFO:Physical Core: 16
2023-02-16 10:12:04,213:INFO:Logical Core: 32
2023-02-16 10:12:04,213:INFO:Checking libraries
2023-02-16 10:12:04,214:INFO:System:
2023-02-16 10:12:04,214:INFO:    python: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0]
2023-02-16 10:12:04,214:INFO:executable: /home/moussa/anaconda3/envs/research/bin/python
2023-02-16 10:12:04,214:INFO:   machine: Linux-5.13.0-39-generic-x86_64-with-glibc2.10
2023-02-16 10:12:04,214:INFO:PyCaret required dependencies:
2023-02-16 10:12:04,214:INFO:                 pip: 23.0
2023-02-16 10:12:04,214:INFO:          setuptools: 60.10.0
2023-02-16 10:12:04,214:INFO:             pycaret: 3.0.0rc9
2023-02-16 10:12:04,214:INFO:             IPython: 8.10.0
2023-02-16 10:12:04,214:INFO:          ipywidgets: 7.7.3
2023-02-16 10:12:04,214:INFO:                tqdm: 4.64.1
2023-02-16 10:12:04,214:INFO:               numpy: 1.23.5
2023-02-16 10:12:04,214:INFO:              pandas: 1.5.3
2023-02-16 10:12:04,214:INFO:              jinja2: 3.1.2
2023-02-16 10:12:04,214:INFO:               scipy: 1.9.1
2023-02-16 10:12:04,214:INFO:              joblib: 1.2.0
2023-02-16 10:12:04,214:INFO:             sklearn: 1.2.1
2023-02-16 10:12:04,214:INFO:                pyod: 1.0.7
2023-02-16 10:12:04,214:INFO:            imblearn: 0.10.1
2023-02-16 10:12:04,214:INFO:   category_encoders: 2.6.0
2023-02-16 10:12:04,214:INFO:            lightgbm: 3.3.5.99
2023-02-16 10:12:04,214:INFO:               numba: 0.56.4
2023-02-16 10:12:04,214:INFO:            requests: 2.28.2
2023-02-16 10:12:04,214:INFO:          matplotlib: 3.6.3
2023-02-16 10:12:04,214:INFO:          scikitplot: 0.3.7
2023-02-16 10:12:04,214:INFO:         yellowbrick: 1.5
2023-02-16 10:12:04,214:INFO:              plotly: 5.13.0
2023-02-16 10:12:04,214:INFO:             kaleido: 0.2.1
2023-02-16 10:12:04,214:INFO:         statsmodels: 0.13.5
2023-02-16 10:12:04,214:INFO:              sktime: 0.16.1
2023-02-16 10:12:04,214:INFO:               tbats: 1.1.2
2023-02-16 10:12:04,214:INFO:            pmdarima: 2.0.2
2023-02-16 10:12:04,214:INFO:              psutil: 5.9.4
2023-02-16 10:12:04,214:INFO:PyCaret optional dependencies:
2023-02-16 10:12:04,214:INFO:                shap: 0.41.0
2023-02-16 10:12:04,214:INFO:           interpret: 0.3.0
2023-02-16 10:12:04,214:INFO:                umap: 0.5.3
2023-02-16 10:12:04,214:INFO:    pandas_profiling: 4.0.0
2023-02-16 10:12:04,214:INFO:  explainerdashboard: 0.4.2
2023-02-16 10:12:04,214:INFO:             autoviz: 0.1.58
2023-02-16 10:12:04,214:INFO:           fairlearn: 0.7.0
2023-02-16 10:12:04,214:INFO:             xgboost: 1.7.3
2023-02-16 10:12:04,214:INFO:            catboost: 1.1.1
2023-02-16 10:12:04,214:INFO:              kmodes: 0.12.2
2023-02-16 10:12:04,214:INFO:             mlxtend: 0.21.0
2023-02-16 10:12:04,214:INFO:       statsforecast: 1.4.0
2023-02-16 10:12:04,214:INFO:        tune_sklearn: 0.4.5
2023-02-16 10:12:04,214:INFO:                 ray: 2.2.0
2023-02-16 10:12:04,214:INFO:            hyperopt: 0.2.7
2023-02-16 10:12:04,214:INFO:              optuna: 3.1.0
2023-02-16 10:12:04,214:INFO:               skopt: 0.9.0
2023-02-16 10:12:04,214:INFO:              mlflow: 1.30.0
2023-02-16 10:12:04,214:INFO:              gradio: 3.18.0
2023-02-16 10:12:04,214:INFO:             fastapi: 0.92.0
2023-02-16 10:12:04,214:INFO:             uvicorn: 0.20.0
2023-02-16 10:12:04,214:INFO:              m2cgen: 0.10.0
2023-02-16 10:12:04,214:INFO:           evidently: 0.2.4
2023-02-16 10:12:04,214:INFO:               fugue: 0.8.1.dev4
2023-02-16 10:12:04,214:INFO:           streamlit: Not installed
2023-02-16 10:12:04,214:INFO:             prophet: Not installed
2023-02-16 10:12:04,214:INFO:None
2023-02-16 10:12:04,214:INFO:Set up data.
2023-02-16 10:12:04,438:INFO:Set up train/test split.
2023-02-16 10:12:04,549:INFO:Set up index.
2023-02-16 10:12:04,581:INFO:Set up folding strategy.
2023-02-16 10:12:04,581:INFO:Assigning column types.
2023-02-16 10:12:04,645:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-16 10:12:04,646:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,648:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,651:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,763:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:04,764:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:04,765:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,767:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,770:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,854:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,881:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,881:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:04,882:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:04,883:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-16 10:12:04,885:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,888:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,972:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:12:04,998:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:05,000:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:05,003:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,005:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,116:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:05,117:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:05,117:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-16 10:12:05,123:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,232:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:05,234:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:05,240:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,321:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,347:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:05,348:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:05,349:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-16 10:12:05,437:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,463:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,464:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:05,466:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:05,559:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,586:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:05,588:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:05,588:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-16 10:12:05,678:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,705:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:05,706:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:05,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-16 10:12:05,824:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:05,825:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:05,826:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-16 10:12:05,942:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:05,944:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:06,062:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:06,064:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:06,065:INFO:Preparing preprocessing pipeline...
2023-02-16 10:12:06,073:INFO:Set up column name cleaning.
2023-02-16 10:12:06,074:INFO:Set up simple imputation.
2023-02-16 10:12:06,074:INFO:Set up removing multicollinearity.
2023-02-16 10:12:06,074:INFO:Set up feature normalization.
2023-02-16 10:12:20,973:INFO:Finished creating preprocessing pipeline.
2023-02-16 10:12:20,979:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['open', 'high', 'low', 'close',
                                             'volume', 'volume_24HR',
                                             'volume_24HR$', 'volume_$',
                                             'closeChg24HR', 'closeChg%24HR',
                                             'openChg24HR', 'openChg%24HR',
                                             'highChg24HR', 'highChg%24HR',
                                             'lowC...
                                             'openChg%1HR', 'highChg1HR',
                                             'highChg%1HR', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-02-16 10:12:20,980:INFO:Creating final display dataframe.
2023-02-16 10:12:22,869:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     11
1                        Target  closeChg%_forward24HR
2                   Target type             Regression
3           Original data shape           (28585, 780)
4        Transformed data shape           (28585, 133)
5   Transformed train set shape           (20009, 133)
6    Transformed test set shape            (8576, 133)
7               Ignore features                      5
8              Numeric features                    774
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Remove multicollinearity                   True
14  Multicollinearity threshold                    0.9
15                    Normalize                   True
16             Normalize method                 zscore
17               Fold Generator                  KFold
18                  Fold Number                     10
19                     CPU Jobs                     -1
20                      Use GPU                  False
21               Log Experiment                  False
22              Experiment Name       reg-default-name
23                          USI                   c16f
2023-02-16 10:12:22,999:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:23,000:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:23,118:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 10:12:23,119:INFO:Soft dependency imported: catboost: 1.1.1
2023-02-16 10:12:23,120:INFO:setup() successfully completed in 18.91s...............
2023-02-16 10:12:23,120:INFO:Initializing compare_models()
2023-02-16 10:12:23,120:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, 'include': None, 'exclude': ['tr', 'lightgbm'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['tr', 'lightgbm'])
2023-02-16 10:12:23,120:INFO:Checking exceptions
2023-02-16 10:12:23,146:INFO:Preparing display monitor
2023-02-16 10:12:23,160:INFO:Initializing Linear Regression
2023-02-16 10:12:23,160:INFO:Total runtime is 1.3430913289388022e-06 minutes
2023-02-16 10:12:23,161:INFO:SubProcess create_model() called ==================================
2023-02-16 10:12:23,161:INFO:Initializing create_model()
2023-02-16 10:12:23,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:12:23,161:INFO:Checking exceptions
2023-02-16 10:12:23,162:INFO:Importing libraries
2023-02-16 10:12:23,162:INFO:Copying training dataset
2023-02-16 10:12:23,239:INFO:Defining folds
2023-02-16 10:12:23,240:INFO:Declaring metric variables
2023-02-16 10:12:23,242:INFO:Importing untrained model
2023-02-16 10:12:23,243:INFO:Linear Regression Imported successfully
2023-02-16 10:12:23,246:INFO:Starting cross validation
2023-02-16 10:12:23,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:12:41,771:INFO:Calculating mean and std
2023-02-16 10:12:41,772:INFO:Creating metrics dataframe
2023-02-16 10:12:41,777:INFO:Uploading results into container
2023-02-16 10:12:41,778:INFO:Uploading model into container now
2023-02-16 10:12:41,778:INFO:_master_model_container: 1
2023-02-16 10:12:41,778:INFO:_display_container: 2
2023-02-16 10:12:41,778:INFO:LinearRegression(n_jobs=-1)
2023-02-16 10:12:41,778:INFO:create_model() successfully completed......................................
2023-02-16 10:12:41,945:INFO:SubProcess create_model() end ==================================
2023-02-16 10:12:41,946:INFO:Creating metrics dataframe
2023-02-16 10:12:41,951:INFO:Initializing Lasso Regression
2023-02-16 10:12:41,951:INFO:Total runtime is 0.31319461663564047 minutes
2023-02-16 10:12:41,953:INFO:SubProcess create_model() called ==================================
2023-02-16 10:12:41,953:INFO:Initializing create_model()
2023-02-16 10:12:41,953:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:12:41,953:INFO:Checking exceptions
2023-02-16 10:12:41,953:INFO:Importing libraries
2023-02-16 10:12:41,953:INFO:Copying training dataset
2023-02-16 10:12:42,033:INFO:Defining folds
2023-02-16 10:12:42,034:INFO:Declaring metric variables
2023-02-16 10:12:42,036:INFO:Importing untrained model
2023-02-16 10:12:42,037:INFO:Lasso Regression Imported successfully
2023-02-16 10:12:42,040:INFO:Starting cross validation
2023-02-16 10:12:42,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:13:00,023:INFO:Calculating mean and std
2023-02-16 10:13:00,024:INFO:Creating metrics dataframe
2023-02-16 10:13:00,028:INFO:Uploading results into container
2023-02-16 10:13:00,029:INFO:Uploading model into container now
2023-02-16 10:13:00,029:INFO:_master_model_container: 2
2023-02-16 10:13:00,029:INFO:_display_container: 2
2023-02-16 10:13:00,030:INFO:Lasso(random_state=11)
2023-02-16 10:13:00,030:INFO:create_model() successfully completed......................................
2023-02-16 10:13:00,190:INFO:SubProcess create_model() end ==================================
2023-02-16 10:13:00,190:INFO:Creating metrics dataframe
2023-02-16 10:13:00,196:INFO:Initializing Ridge Regression
2023-02-16 10:13:00,196:INFO:Total runtime is 0.6172722697257995 minutes
2023-02-16 10:13:00,198:INFO:SubProcess create_model() called ==================================
2023-02-16 10:13:00,198:INFO:Initializing create_model()
2023-02-16 10:13:00,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:13:00,198:INFO:Checking exceptions
2023-02-16 10:13:00,198:INFO:Importing libraries
2023-02-16 10:13:00,198:INFO:Copying training dataset
2023-02-16 10:13:00,278:INFO:Defining folds
2023-02-16 10:13:00,278:INFO:Declaring metric variables
2023-02-16 10:13:00,280:INFO:Importing untrained model
2023-02-16 10:13:00,282:INFO:Ridge Regression Imported successfully
2023-02-16 10:13:00,285:INFO:Starting cross validation
2023-02-16 10:13:00,289:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:13:18,129:INFO:Calculating mean and std
2023-02-16 10:13:18,130:INFO:Creating metrics dataframe
2023-02-16 10:13:18,133:INFO:Uploading results into container
2023-02-16 10:13:18,133:INFO:Uploading model into container now
2023-02-16 10:13:18,134:INFO:_master_model_container: 3
2023-02-16 10:13:18,134:INFO:_display_container: 2
2023-02-16 10:13:18,134:INFO:Ridge(random_state=11)
2023-02-16 10:13:18,134:INFO:create_model() successfully completed......................................
2023-02-16 10:13:18,280:INFO:SubProcess create_model() end ==================================
2023-02-16 10:13:18,281:INFO:Creating metrics dataframe
2023-02-16 10:13:18,287:INFO:Initializing Elastic Net
2023-02-16 10:13:18,287:INFO:Total runtime is 0.9187860290209452 minutes
2023-02-16 10:13:18,289:INFO:SubProcess create_model() called ==================================
2023-02-16 10:13:18,289:INFO:Initializing create_model()
2023-02-16 10:13:18,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:13:18,289:INFO:Checking exceptions
2023-02-16 10:13:18,289:INFO:Importing libraries
2023-02-16 10:13:18,289:INFO:Copying training dataset
2023-02-16 10:13:18,366:INFO:Defining folds
2023-02-16 10:13:18,367:INFO:Declaring metric variables
2023-02-16 10:13:18,369:INFO:Importing untrained model
2023-02-16 10:13:18,370:INFO:Elastic Net Imported successfully
2023-02-16 10:13:18,373:INFO:Starting cross validation
2023-02-16 10:13:18,378:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:13:35,632:INFO:Calculating mean and std
2023-02-16 10:13:35,633:INFO:Creating metrics dataframe
2023-02-16 10:13:35,636:INFO:Uploading results into container
2023-02-16 10:13:35,636:INFO:Uploading model into container now
2023-02-16 10:13:35,636:INFO:_master_model_container: 4
2023-02-16 10:13:35,636:INFO:_display_container: 2
2023-02-16 10:13:35,636:INFO:ElasticNet(random_state=11)
2023-02-16 10:13:35,636:INFO:create_model() successfully completed......................................
2023-02-16 10:13:35,796:INFO:SubProcess create_model() end ==================================
2023-02-16 10:13:35,796:INFO:Creating metrics dataframe
2023-02-16 10:13:35,802:INFO:Initializing Least Angle Regression
2023-02-16 10:13:35,802:INFO:Total runtime is 1.2107102076212564 minutes
2023-02-16 10:13:35,804:INFO:SubProcess create_model() called ==================================
2023-02-16 10:13:35,804:INFO:Initializing create_model()
2023-02-16 10:13:35,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:13:35,804:INFO:Checking exceptions
2023-02-16 10:13:35,804:INFO:Importing libraries
2023-02-16 10:13:35,804:INFO:Copying training dataset
2023-02-16 10:13:35,886:INFO:Defining folds
2023-02-16 10:13:35,886:INFO:Declaring metric variables
2023-02-16 10:13:35,888:INFO:Importing untrained model
2023-02-16 10:13:35,890:INFO:Least Angle Regression Imported successfully
2023-02-16 10:13:35,893:INFO:Starting cross validation
2023-02-16 10:13:35,897:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:13:52,730:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-16 10:13:52,730:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-02-16 10:13:52,730:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:772: RuntimeWarning: overflow encountered in add
  coef[active] = prev_coef[active] + gamma_ * least_squares

2023-02-16 10:13:52,730:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: overflow encountered in subtract
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-16 10:13:52,730:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in add
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-02-16 10:13:52,730:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-02-16 10:13:52,730:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:772: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2023-02-16 10:13:52,730:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:775: RuntimeWarning: overflow encountered in subtract
  Cov -= gamma_ * corr_eq_dir

2023-02-16 10:13:52,730:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:731: RuntimeWarning: invalid value encountered in subtract
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-02-16 10:13:52,731:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: invalid value encountered in add
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-02-16 10:13:52,833:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: overflow encountered in matmul
  ret = a @ b

2023-02-16 10:13:52,833:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2023-02-16 10:13:52,835:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-16 10:13:52,835:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-16 10:13:52,835:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-02-16 10:13:53,271:INFO:Calculating mean and std
2023-02-16 10:13:53,272:INFO:Creating metrics dataframe
2023-02-16 10:13:53,276:INFO:Uploading results into container
2023-02-16 10:13:53,277:INFO:Uploading model into container now
2023-02-16 10:13:53,277:INFO:_master_model_container: 5
2023-02-16 10:13:53,277:INFO:_display_container: 2
2023-02-16 10:13:53,277:INFO:Lars(random_state=11)
2023-02-16 10:13:53,277:INFO:create_model() successfully completed......................................
2023-02-16 10:13:53,426:INFO:SubProcess create_model() end ==================================
2023-02-16 10:13:53,426:INFO:Creating metrics dataframe
2023-02-16 10:13:53,433:INFO:Initializing Lasso Least Angle Regression
2023-02-16 10:13:53,433:INFO:Total runtime is 1.5045517524083454 minutes
2023-02-16 10:13:53,435:INFO:SubProcess create_model() called ==================================
2023-02-16 10:13:53,435:INFO:Initializing create_model()
2023-02-16 10:13:53,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:13:53,435:INFO:Checking exceptions
2023-02-16 10:13:53,435:INFO:Importing libraries
2023-02-16 10:13:53,435:INFO:Copying training dataset
2023-02-16 10:13:53,514:INFO:Defining folds
2023-02-16 10:13:53,514:INFO:Declaring metric variables
2023-02-16 10:13:53,517:INFO:Importing untrained model
2023-02-16 10:13:53,518:INFO:Lasso Least Angle Regression Imported successfully
2023-02-16 10:13:53,521:INFO:Starting cross validation
2023-02-16 10:13:53,525:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:14:10,734:INFO:Calculating mean and std
2023-02-16 10:14:10,735:INFO:Creating metrics dataframe
2023-02-16 10:14:10,738:INFO:Uploading results into container
2023-02-16 10:14:10,738:INFO:Uploading model into container now
2023-02-16 10:14:10,738:INFO:_master_model_container: 6
2023-02-16 10:14:10,738:INFO:_display_container: 2
2023-02-16 10:14:10,739:INFO:LassoLars(random_state=11)
2023-02-16 10:14:10,739:INFO:create_model() successfully completed......................................
2023-02-16 10:14:10,892:INFO:SubProcess create_model() end ==================================
2023-02-16 10:14:10,892:INFO:Creating metrics dataframe
2023-02-16 10:14:10,899:INFO:Initializing Orthogonal Matching Pursuit
2023-02-16 10:14:10,899:INFO:Total runtime is 1.7956501563390095 minutes
2023-02-16 10:14:10,900:INFO:SubProcess create_model() called ==================================
2023-02-16 10:14:10,901:INFO:Initializing create_model()
2023-02-16 10:14:10,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:14:10,901:INFO:Checking exceptions
2023-02-16 10:14:10,901:INFO:Importing libraries
2023-02-16 10:14:10,901:INFO:Copying training dataset
2023-02-16 10:14:10,981:INFO:Defining folds
2023-02-16 10:14:10,981:INFO:Declaring metric variables
2023-02-16 10:14:10,983:INFO:Importing untrained model
2023-02-16 10:14:10,985:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-16 10:14:10,988:INFO:Starting cross validation
2023-02-16 10:14:10,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:14:27,771:INFO:Calculating mean and std
2023-02-16 10:14:27,772:INFO:Creating metrics dataframe
2023-02-16 10:14:27,774:INFO:Uploading results into container
2023-02-16 10:14:27,775:INFO:Uploading model into container now
2023-02-16 10:14:27,775:INFO:_master_model_container: 7
2023-02-16 10:14:27,775:INFO:_display_container: 2
2023-02-16 10:14:27,775:INFO:OrthogonalMatchingPursuit()
2023-02-16 10:14:27,775:INFO:create_model() successfully completed......................................
2023-02-16 10:14:27,934:INFO:SubProcess create_model() end ==================================
2023-02-16 10:14:27,934:INFO:Creating metrics dataframe
2023-02-16 10:14:27,941:INFO:Initializing Bayesian Ridge
2023-02-16 10:14:27,941:INFO:Total runtime is 2.0796901981035867 minutes
2023-02-16 10:14:27,943:INFO:SubProcess create_model() called ==================================
2023-02-16 10:14:27,943:INFO:Initializing create_model()
2023-02-16 10:14:27,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:14:27,943:INFO:Checking exceptions
2023-02-16 10:14:27,943:INFO:Importing libraries
2023-02-16 10:14:27,943:INFO:Copying training dataset
2023-02-16 10:14:28,024:INFO:Defining folds
2023-02-16 10:14:28,024:INFO:Declaring metric variables
2023-02-16 10:14:28,026:INFO:Importing untrained model
2023-02-16 10:14:28,028:INFO:Bayesian Ridge Imported successfully
2023-02-16 10:14:28,031:INFO:Starting cross validation
2023-02-16 10:14:28,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:14:45,296:INFO:Calculating mean and std
2023-02-16 10:14:45,297:INFO:Creating metrics dataframe
2023-02-16 10:14:45,299:INFO:Uploading results into container
2023-02-16 10:14:45,300:INFO:Uploading model into container now
2023-02-16 10:14:45,300:INFO:_master_model_container: 8
2023-02-16 10:14:45,300:INFO:_display_container: 2
2023-02-16 10:14:45,300:INFO:BayesianRidge()
2023-02-16 10:14:45,300:INFO:create_model() successfully completed......................................
2023-02-16 10:14:45,490:INFO:SubProcess create_model() end ==================================
2023-02-16 10:14:45,490:INFO:Creating metrics dataframe
2023-02-16 10:14:45,497:INFO:Initializing Passive Aggressive Regressor
2023-02-16 10:14:45,497:INFO:Total runtime is 2.372293392817179 minutes
2023-02-16 10:14:45,499:INFO:SubProcess create_model() called ==================================
2023-02-16 10:14:45,499:INFO:Initializing create_model()
2023-02-16 10:14:45,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:14:45,499:INFO:Checking exceptions
2023-02-16 10:14:45,499:INFO:Importing libraries
2023-02-16 10:14:45,499:INFO:Copying training dataset
2023-02-16 10:14:45,586:INFO:Defining folds
2023-02-16 10:14:45,586:INFO:Declaring metric variables
2023-02-16 10:14:45,588:INFO:Importing untrained model
2023-02-16 10:14:45,590:INFO:Passive Aggressive Regressor Imported successfully
2023-02-16 10:14:45,593:INFO:Starting cross validation
2023-02-16 10:14:45,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:15:03,338:INFO:Calculating mean and std
2023-02-16 10:15:03,339:INFO:Creating metrics dataframe
2023-02-16 10:15:03,342:INFO:Uploading results into container
2023-02-16 10:15:03,342:INFO:Uploading model into container now
2023-02-16 10:15:03,343:INFO:_master_model_container: 9
2023-02-16 10:15:03,343:INFO:_display_container: 2
2023-02-16 10:15:03,343:INFO:PassiveAggressiveRegressor(random_state=11)
2023-02-16 10:15:03,343:INFO:create_model() successfully completed......................................
2023-02-16 10:15:03,513:INFO:SubProcess create_model() end ==================================
2023-02-16 10:15:03,513:INFO:Creating metrics dataframe
2023-02-16 10:15:03,520:INFO:Initializing Huber Regressor
2023-02-16 10:15:03,520:INFO:Total runtime is 2.6726761937141417 minutes
2023-02-16 10:15:03,522:INFO:SubProcess create_model() called ==================================
2023-02-16 10:15:03,522:INFO:Initializing create_model()
2023-02-16 10:15:03,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:15:03,522:INFO:Checking exceptions
2023-02-16 10:15:03,522:INFO:Importing libraries
2023-02-16 10:15:03,522:INFO:Copying training dataset
2023-02-16 10:15:03,603:INFO:Defining folds
2023-02-16 10:15:03,603:INFO:Declaring metric variables
2023-02-16 10:15:03,605:INFO:Importing untrained model
2023-02-16 10:15:03,607:INFO:Huber Regressor Imported successfully
2023-02-16 10:15:03,610:INFO:Starting cross validation
2023-02-16 10:15:03,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:15:24,751:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 10:15:25,012:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 10:15:25,124:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 10:15:25,830:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 10:15:26,051:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 10:15:26,158:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 10:15:26,274:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 10:15:26,293:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 10:15:26,320:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 10:15:26,594:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-16 10:15:26,822:INFO:Calculating mean and std
2023-02-16 10:15:26,823:INFO:Creating metrics dataframe
2023-02-16 10:15:26,826:INFO:Uploading results into container
2023-02-16 10:15:26,826:INFO:Uploading model into container now
2023-02-16 10:15:26,827:INFO:_master_model_container: 10
2023-02-16 10:15:26,827:INFO:_display_container: 2
2023-02-16 10:15:26,827:INFO:HuberRegressor()
2023-02-16 10:15:26,827:INFO:create_model() successfully completed......................................
2023-02-16 10:15:26,990:INFO:SubProcess create_model() end ==================================
2023-02-16 10:15:26,990:INFO:Creating metrics dataframe
2023-02-16 10:15:26,997:INFO:Initializing K Neighbors Regressor
2023-02-16 10:15:26,998:INFO:Total runtime is 3.0639641324679054 minutes
2023-02-16 10:15:26,999:INFO:SubProcess create_model() called ==================================
2023-02-16 10:15:26,999:INFO:Initializing create_model()
2023-02-16 10:15:26,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:15:26,999:INFO:Checking exceptions
2023-02-16 10:15:26,999:INFO:Importing libraries
2023-02-16 10:15:27,000:INFO:Copying training dataset
2023-02-16 10:15:27,080:INFO:Defining folds
2023-02-16 10:15:27,081:INFO:Declaring metric variables
2023-02-16 10:15:27,083:INFO:Importing untrained model
2023-02-16 10:15:27,084:INFO:K Neighbors Regressor Imported successfully
2023-02-16 10:15:27,087:INFO:Starting cross validation
2023-02-16 10:15:27,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:15:44,492:INFO:Calculating mean and std
2023-02-16 10:15:44,493:INFO:Creating metrics dataframe
2023-02-16 10:15:44,495:INFO:Uploading results into container
2023-02-16 10:15:44,496:INFO:Uploading model into container now
2023-02-16 10:15:44,496:INFO:_master_model_container: 11
2023-02-16 10:15:44,496:INFO:_display_container: 2
2023-02-16 10:15:44,496:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-16 10:15:44,496:INFO:create_model() successfully completed......................................
2023-02-16 10:15:44,664:INFO:SubProcess create_model() end ==================================
2023-02-16 10:15:44,665:INFO:Creating metrics dataframe
2023-02-16 10:15:44,672:INFO:Initializing Decision Tree Regressor
2023-02-16 10:15:44,672:INFO:Total runtime is 3.3585369785626726 minutes
2023-02-16 10:15:44,674:INFO:SubProcess create_model() called ==================================
2023-02-16 10:15:44,674:INFO:Initializing create_model()
2023-02-16 10:15:44,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:15:44,674:INFO:Checking exceptions
2023-02-16 10:15:44,674:INFO:Importing libraries
2023-02-16 10:15:44,674:INFO:Copying training dataset
2023-02-16 10:15:44,753:INFO:Defining folds
2023-02-16 10:15:44,753:INFO:Declaring metric variables
2023-02-16 10:15:44,756:INFO:Importing untrained model
2023-02-16 10:15:44,757:INFO:Decision Tree Regressor Imported successfully
2023-02-16 10:15:44,760:INFO:Starting cross validation
2023-02-16 10:15:44,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:16:05,786:INFO:Calculating mean and std
2023-02-16 10:16:05,787:INFO:Creating metrics dataframe
2023-02-16 10:16:05,789:INFO:Uploading results into container
2023-02-16 10:16:05,790:INFO:Uploading model into container now
2023-02-16 10:16:05,790:INFO:_master_model_container: 12
2023-02-16 10:16:05,790:INFO:_display_container: 2
2023-02-16 10:16:05,791:INFO:DecisionTreeRegressor(random_state=11)
2023-02-16 10:16:05,791:INFO:create_model() successfully completed......................................
2023-02-16 10:16:05,934:INFO:SubProcess create_model() end ==================================
2023-02-16 10:16:05,934:INFO:Creating metrics dataframe
2023-02-16 10:16:05,941:INFO:Initializing Random Forest Regressor
2023-02-16 10:16:05,941:INFO:Total runtime is 3.7130224982897437 minutes
2023-02-16 10:16:05,943:INFO:SubProcess create_model() called ==================================
2023-02-16 10:16:05,943:INFO:Initializing create_model()
2023-02-16 10:16:05,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:16:05,943:INFO:Checking exceptions
2023-02-16 10:16:05,943:INFO:Importing libraries
2023-02-16 10:16:05,943:INFO:Copying training dataset
2023-02-16 10:16:06,021:INFO:Defining folds
2023-02-16 10:16:06,021:INFO:Declaring metric variables
2023-02-16 10:16:06,023:INFO:Importing untrained model
2023-02-16 10:16:06,025:INFO:Random Forest Regressor Imported successfully
2023-02-16 10:16:06,028:INFO:Starting cross validation
2023-02-16 10:16:06,032:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:16:26,304:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:223: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-02-16 10:16:26,528:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:223: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-02-16 10:16:27,066:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:223: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-02-16 10:16:27,076:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:223: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-02-16 10:16:27,263:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:230: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-02-16 10:16:27,431:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:223: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-02-16 10:16:27,459:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:230: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-02-16 10:16:28,017:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:230: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-02-16 10:16:28,019:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:230: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-02-16 10:16:28,422:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:230: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-02-16 10:18:10,670:INFO:Calculating mean and std
2023-02-16 10:18:10,671:INFO:Creating metrics dataframe
2023-02-16 10:18:10,675:INFO:Uploading results into container
2023-02-16 10:18:10,676:INFO:Uploading model into container now
2023-02-16 10:18:10,676:INFO:_master_model_container: 13
2023-02-16 10:18:10,676:INFO:_display_container: 2
2023-02-16 10:18:10,676:INFO:RandomForestRegressor(n_jobs=-1, random_state=11)
2023-02-16 10:18:10,676:INFO:create_model() successfully completed......................................
2023-02-16 10:18:10,816:INFO:SubProcess create_model() end ==================================
2023-02-16 10:18:10,816:INFO:Creating metrics dataframe
2023-02-16 10:18:10,824:INFO:Initializing Extra Trees Regressor
2023-02-16 10:18:10,824:INFO:Total runtime is 5.794409004847209 minutes
2023-02-16 10:18:10,826:INFO:SubProcess create_model() called ==================================
2023-02-16 10:18:10,826:INFO:Initializing create_model()
2023-02-16 10:18:10,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:18:10,826:INFO:Checking exceptions
2023-02-16 10:18:10,826:INFO:Importing libraries
2023-02-16 10:18:10,826:INFO:Copying training dataset
2023-02-16 10:18:10,905:INFO:Defining folds
2023-02-16 10:18:10,906:INFO:Declaring metric variables
2023-02-16 10:18:10,908:INFO:Importing untrained model
2023-02-16 10:18:10,910:INFO:Extra Trees Regressor Imported successfully
2023-02-16 10:18:10,913:INFO:Starting cross validation
2023-02-16 10:18:10,917:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 10:18:30,798:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:230: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-02-16 10:18:31,185:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:230: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-02-16 10:18:31,588:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:230: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-02-16 10:18:38,774:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:252: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 10:18:39,799:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:252: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 10:18:40,997:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-02-16 10:18:42,354:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-02-16 10:18:43,233:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:295: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-16 10:18:44,324:WARNING:/home/moussa/anaconda3/envs/research/lib/python3.8/site-packages/pycaret/internal/pipeline.py:295: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-16 10:18:47,049:INFO:Calculating mean and std
2023-02-16 10:18:47,050:INFO:Creating metrics dataframe
2023-02-16 10:18:47,053:INFO:Uploading results into container
2023-02-16 10:18:47,054:INFO:Uploading model into container now
2023-02-16 10:18:47,054:INFO:_master_model_container: 14
2023-02-16 10:18:47,054:INFO:_display_container: 2
2023-02-16 10:18:47,054:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=11)
2023-02-16 10:18:47,054:INFO:create_model() successfully completed......................................
2023-02-16 10:18:47,208:INFO:SubProcess create_model() end ==================================
2023-02-16 10:18:47,208:INFO:Creating metrics dataframe
2023-02-16 10:18:47,216:INFO:Initializing AdaBoost Regressor
2023-02-16 10:18:47,216:INFO:Total runtime is 6.40093960762024 minutes
2023-02-16 10:18:47,218:INFO:SubProcess create_model() called ==================================
2023-02-16 10:18:47,218:INFO:Initializing create_model()
2023-02-16 10:18:47,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fe4cde66d30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fe4cdab80a0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 10:18:47,218:INFO:Checking exceptions
2023-02-16 10:18:47,218:INFO:Importing libraries
2023-02-16 10:18:47,218:INFO:Copying training dataset
2023-02-16 10:18:47,298:INFO:Defining folds
2023-02-16 10:18:47,298:INFO:Declaring metric variables
2023-02-16 10:18:47,300:INFO:Importing untrained model
2023-02-16 10:18:47,302:INFO:AdaBoost Regressor Imported successfully
2023-02-16 10:18:47,305:INFO:Starting cross validation
2023-02-16 10:18:47,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f07499-e9d6-4af3-aac4-fcd816d15d89",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4016010177.py, line 113)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_160085/4016010177.py\"\u001b[0;36m, line \u001b[0;32m113\u001b[0m\n\u001b[0;31m    params = {import ohlc\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import logging\n",
    "import json\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# see documentation: https://docs.amberdata.io/reference/reference-getting-started\n",
    "class AmberData:\n",
    "    URL = 'https://web3api.io/api'\n",
    "    WSS = 'wss://ws.web3api.io'\n",
    "    QUOTES = ['USD', 'USDC', 'USDT']\n",
    "    INTERVALS = {\n",
    "        'minutes': dt.timedelta(days=1),\n",
    "        'hours': dt.timedelta(days=30),\n",
    "        'days': dt.timedelta(days=365),\n",
    "        'weeks': dt.timedelta(days=(365 * 10))\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.key = 'UAKeb75c7488ce4acf005daec2655ab6ebb'\n",
    "\n",
    "    def header(self):\n",
    "        headers = {\n",
    "            'x-api-key': self.key\n",
    "        }\n",
    "        return headers\n",
    "\n",
    "    def _request(self, method, path, params=None):\n",
    "        if params is None:\n",
    "            params = {}\n",
    "        try:\n",
    "            req = requests.request(method=method, url=self.URL + path, params=params, headers=self.header())\n",
    "            response = req.json()\n",
    "            return response.get('payload', dict())\n",
    "        except Exception as e:\n",
    "            logging.warning('amberdata exception %s %s', e, req)\n",
    "            print(path, params, 'exception', e, 'waiting 30 seconds...')\n",
    "            time.sleep(10)\n",
    "            return self._request(method, path, params)\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_markets(pair_dict):\n",
    "        flattened = list()\n",
    "        for pair, pair_data in pair_dict.items():\n",
    "            for exchange, exchange_data in pair_data.items():\n",
    "                flattened_data = dict()\n",
    "                flattened_data['pair'] = pair\n",
    "                flattened_data['exchange'] = exchange\n",
    "                for metric, metric_dates in exchange_data.items():\n",
    "                    for date in metric_dates:\n",
    "                        if not metric_dates[date]: continue\n",
    "                        metric_dates[date] = dt.datetime.fromtimestamp(metric_dates[date] / 1e3)\n",
    "                    flattened_data[metric] = metric_dates\n",
    "                flattened.append(flattened_data)\n",
    "        return flattened\n",
    "\n",
    "    def get_spot_markets(self, pair=None, exchange=None, time_format='ms', include_dates=True):\n",
    "        params = {\n",
    "            'includeDates': str(include_dates).lower(),\n",
    "            'timeFormat': time_format\n",
    "        }\n",
    "        if pair:\n",
    "            params['pair'] = pair.lower()\n",
    "        if exchange:\n",
    "            params['exchange'] = exchange.lower()\n",
    "        data = self._request('GET', '/v2/market/pairs', params=params)\n",
    "        return self.flatten_markets(data)\n",
    "\n",
    "    def get_base_spot_markets(self, base=None, exchange=None, time_format='ms'):\n",
    "        markets = []\n",
    "        for quote in self.QUOTES:\n",
    "            quote_markets = self.get_spot_markets(pair=f\"{base}_{quote}\", exchange=exchange, time_format=time_format)\n",
    "            markets += quote_markets\n",
    "        return markets\n",
    "\n",
    "    def get_oldest_spot_market(self, base, exchange=None):\n",
    "        markets = self.get_base_spot_markets(base=base, exchange=exchange)\n",
    "        if not markets:\n",
    "            markets = self.get_base_spot_markets(base=base, exchange=None)\n",
    "        if not markets:\n",
    "            return dict()\n",
    "        now = dt.datetime.utcnow()\n",
    "        oldest = None\n",
    "        for market in markets:\n",
    "            if 'ohlc' not in market: continue\n",
    "            if market['ohlc'].get('startDate') is None or market['ohlc']['endDate'] is None: continue\n",
    "            if now - market['ohlc']['endDate'] > dt.timedelta(hours=1): continue\n",
    "            if oldest is None or market['ohlc']['startDate'] < oldest['ohlc']['startDate']: oldest = market\n",
    "        return oldest\n",
    "\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_spot_candles(pair, candles):\n",
    "        if not candles.get('data'): return dict()\n",
    "        candle_list = list()\n",
    "        columns = candles['metadata']['columns']\n",
    "        for exchange, exchange_candles in candles['data'].items():\n",
    "            for exchange_candle in exchange_candles:\n",
    "                candle_data = dict(zip(columns, exchange_candle))\n",
    "                candle_data['pair'] = pair\n",
    "                candle_data['exchange'] = exchange\n",
    "                candle_data['dt'] = dt.datetime.fromtimestamp(candle_data['timestamp'] / 1e3)\n",
    "                candle_list.append(candle_data)\n",
    "        return candle_list\n",
    "\n",
    "    def get_interval_spot_candles(self, pair, exchange, interval, start, end=None, time_format='ms'):\n",
    "        if end is None:\n",
    "            end = start + self.INTERVALS[interval]\n",
    "        params = {import ohlc\n",
    "            'exchange': exchange,\n",
    "            'timeFormat': time_format,\n",
    "            'startDate': start.isoformat(),\n",
    "            'endDate': min(start + self.INTERVALS[interval], end).isoformat(),\n",
    "            'timeInterval': interval\n",
    "        }\n",
    "        candles = self._request('GET', f'/v2/market/spot/ohlcv/{pair}/historical', params=params)\n",
    "        return self.flatten_spot_candles(pair, candles)\n",
    "\n",
    "    def get_spot_candles(self, pair, exchange, interval, start=None, end=None, time_format='ms'):\n",
    "        end_time = dt.datetime.utcnow() if end is None else end\n",
    "        start_time = end_time - self.INTERVALS[interval] if start is None else start\n",
    "        # print(start_time, end_time)\n",
    "        candles = []\n",
    "        while start_time <= end_time:\n",
    "            interval_candles = self.get_interval_spot_candles(pair, exchange, interval, start_time, end_time, time_format)\n",
    "            candles += interval_candles\n",
    "            start_time += self.INTERVALS[interval]\n",
    "        return candles\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_futures_candles(instrument, candles):\n",
    "        if not candles.get('data'): return dict()\n",
    "        candle_list = list()\n",
    "        # print(candles)\n",
    "        # columns = candles['metadata']['columns']\n",
    "        for candle_data in candles['data']:\n",
    "            # for exchange_candle in exchange_candles:\n",
    "            # candle_data = dict(zip(columns, exchange_candle))\n",
    "            candle_data['instrument'] = instrument\n",
    "            # candle_data['exchange'] = exchange\n",
    "            candle_data['dt'] = dt.datetime.fromtimestamp(candle_data['timestamp'] / 1e3)\n",
    "            candle_list.append(candle_data)\n",
    "        return candle_list\n",
    "\n",
    "    def get_interval_futures_candles(self, instrument, exchange, interval, start, time_format='ms'):\n",
    "        params = {\n",
    "            'exchange': exchange,\n",
    "            'timeFormat': time_format,\n",
    "            'startDate': start.isoformat(),\n",
    "            'endDate': (start + self.INTERVALS[interval]).isoformat(),\n",
    "            'timeInterval': interval\n",
    "        }\n",
    "        candles = self._request('GET', f'/v2/market/futures/ohlcv/{instrument}/historical', params=params)\n",
    "        return self.flatten_futures_candles(instrument, candles)\n",
    "\n",
    "    def get_futures_candles(self, instrument, exchange, interval, start=None, end=None, time_format='ms'):\n",
    "        end_time = dt.datetime.utcnow() if end is None else end\n",
    "        start_time = end_time - self.INTERVALS[interval] if start is None else start\n",
    "\n",
    "        candles = []\n",
    "        while start_time <= end_time:\n",
    "            interval_candles = self.get_interval_futures_candles(instrument, exchange, interval, start_time, time_format)\n",
    "            candles += interval_candles\n",
    "            start_time += self.INTERVALS[interval]\n",
    "        return candles\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_spot_trades(pair, trades):\n",
    "        if not trades.get('data'): return dict()\n",
    "        trade_list = list()\n",
    "        columns = trades['metadata']['columns']\n",
    "        for trade in trades['data']:\n",
    "            trade_data = dict(zip(columns, trade))\n",
    "            trade_data['pair'] = pair\n",
    "            trade_data['dt'] = dt.datetime.fromtimestamp(trade_data['timestamp'] / 1e3)\n",
    "            trade_list.append(trade_data)\n",
    "        return trade_list\n",
    "\n",
    "    def get_interval_spot_trades(self, pair, exchange, interval, start, time_format='ms', flatten=True):\n",
    "        if isinstance(interval, str):\n",
    "            interval_delta = self.INTERVALS[interval]\n",
    "        else:\n",
    "            interval_delta = dt.timedelta(minutes=interval)\n",
    "\n",
    "    def get_spot_price(self, pair, exchange=None):\n",
    "        params = {}\n",
    "        if exchange is not None:\n",
    "            params['exchange'] = exchange\n",
    "        spot = self._request('GET', f'/v2/market/spot/prices/pairs/{pair}/latest/', params=params)\n",
    "        spot['dt'] = dt.datetime.fromtimestamp(spot['timestamp'] / 1e3)\n",
    "        for field in ['price', 'volume']:\n",
    "            try:\n",
    "                spot[field] = float(spot[field])\n",
    "            except Exception as e:\n",
    "                print(e, type(e), spot)\n",
    "        return spot\n",
    "\n",
    "    def get_interval_funding_rates(self, instrument, exchange, interval, start, time_format='ms'):\n",
    "        params = {\n",
    "            'exchange': exchange,\n",
    "            'timeFormat': time_format,\n",
    "            'startDate': start.isoformat(),\n",
    "            'endDate': (start + self.INTERVALS[interval]).isoformat(),\n",
    "            'timeInterval': interval\n",
    "        }\n",
    "        data = self._request('GET', f'/v2/market/futures/funding-rates/{instrument}/historical', params=params)\n",
    "        funding_rates = data['data']\n",
    "        for rate in funding_rates:\n",
    "            rate['dt'] = dt.datetime.fromtimestamp(rate['timestamp'] / 1e3)\n",
    "            rate['instrument'] = instrument\n",
    "        return funding_rates\n",
    "\n",
    "    def get_spot_trades(self, pair, exchange, interval, start=None, end=None, time_format='ms'):\n",
    "        end_time = dt.datetime.utcnow() if end is None else end\n",
    "        start_time = end_time - self.INTERVALS[interval] if start is None else start\n",
    "\n",
    "        trades = []\n",
    "        while start_time <= end_time:\n",
    "            interval_trades = self.get_interval_spot_trades(pair, exchange, interval, start_time, time_format)\n",
    "            trades += interval_trades\n",
    "            start_time += self.INTERVALS[interval]\n",
    "        return trades\n",
    "\n",
    "    def get_funding_rates(self, instrument, exchange, interval='hours', start=None, end=None, time_format='ms'):\n",
    "        end_time = dt.datetime.utcnow() if end is None else end\n",
    "        start_time = end_time - self.INTERVALS[interval] if start is None else start\n",
    "\n",
    "        funding_rates = []\n",
    "        while start_time <= end_time:\n",
    "            interval_funding_rates = self.get_interval_funding_rates(instrument, exchange, interval, start_time, time_format)\n",
    "            funding_rates += interval_funding_rates\n",
    "            start_time += self.INTERVALS[interval]\n",
    "        return funding_rates\n",
    "\n",
    "    def get_latest_funding_rates(self, exchange, instrument=None, time_format='ms'):\n",
    "        params = {\n",
    "            'timeFormat': time_format\n",
    "        }\n",
    "        if instrument is not None:\n",
    "            params['instrument'] = instrument\n",
    "        funding_rates = self._request('GET', f'/v2/market/futures/funding-rates/exchange/{exchange}/latest', params=params)\n",
    "        for rate in funding_rates:\n",
    "            rate['dt'] = dt.datetime.fromtimestamp(rate['timestamp'] / 1e3)\n",
    "            rate['exchange'] = exchange\n",
    "        return funding_rates\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fd6a7c3-7ac7-46d2-b067-f90e47d3e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import logging\n",
    "import json\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "def create_changePCT(df, shift, column, time):\n",
    "    df[column+\"Chg\"+time] = (futures_candle_df[column]-shift[column])\n",
    "    df[column+\"Chg%\"+time] = df[column+\"Chg\"+time]/shift[column]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ed3f6-1ecc-4245-810e-a0b7e15fd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = datetime.now()\n",
    "amberdata = AmberData()\n",
    "now = datetime.now()\n",
    "start = dt.datetime(2018, 1, 1)\n",
    "end = dt.datetime.combine(dt.date.today(), dt.time.min)\n",
    "\n",
    "# spot_candles = amberdata.get_spot_candles(pair='btc_usdt', exchange='binance', interval='hours', start=start, end=end)\n",
    "# spot_candle_df = pd.DataFrame(spot_candles)\n",
    "# print(spot_candle_df)\n",
    "ticker = \"BTCUSDT\"\n",
    "exchange_in = 'binance'\n",
    "interval_in = 'hours'\n",
    "shift_val = 24\n",
    "futures_candles = amberdata.get_futures_candles(instrument=ticker, exchange=exchange_in, interval=interval_in, start=start, end=end)\n",
    "futures_candle_df = pd.DataFrame(futures_candles)\n",
    "print(futures_candle_df)\n",
    "end = datetime.now()\n",
    "print('raw data', end-now)\n",
    "#futures_candle_df['close_forward24'] = futures_candle_df['close'].shift(-1)\n",
    "futures_candle_df['volume_24HR'] = futures_candle_df['volume'].rolling(24).sum()\n",
    "# futures_candle_df['volume_24HR$'] = futures_candle_df['volume_24HR'].rolling(24).sum()*futures_candle_df['close']\n",
    "# futures_candle_df['volume_$'] = futures_candle_df['volume'].rolling(24).sum()*futures_candle_df['close']\n",
    "\n",
    "\n",
    "\n",
    "futures_candle_df['volume_$'] = futures_candle_df['volume']*futures_candle_df['close']\n",
    "futures_candle_df['volume_24HR$'] = futures_candle_df['volume_$'].rolling(24).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fde04f-25e1-445c-81f0-881f3e214474",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_df = futures_candle_df.copy(deep=True).shift(shift_val)\n",
    "#24hr raw feature changes\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df, \"close\", \"24HR\")\n",
    "futures_candle_df= create_changePCT(futures_candle_df, shift_df, \"open\", \"24HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df, \"high\", \"24HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df, \"low\", \"24HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df, 'volume_24HR', \"24HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df, 'volume_24HR$', \"24HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df, 'volume', \"24HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df, 'volume_$', \"24HR\")\n",
    "#1hr raw feature changes\n",
    "\n",
    "shift_df1hr = futures_candle_df.copy(deep=True).shift(1)\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df1hr, \"close\", \"1HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df1hr, \"open\", \"1HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df1hr, \"high\", \"1HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df1hr, \"low\", \"1HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df1hr, 'volume_24HR', \"1HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df1hr, 'volume_24HR$', \"1HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df, 'volume', \"1HR\")\n",
    "futures_candle_df = create_changePCT(futures_candle_df, shift_df, 'volume_$', \"1HR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f7016-deba-4f79-836f-e9c9d750ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for prediction 24hr ahead\n",
    "futures_candle_df['closeChg%_forward24HR'] = futures_candle_df['closeChg%24HR'].shift(-24)\n",
    "futures_candle_df['closeChg%_forward1HR'] = futures_candle_df['closeChg%1HR'].shift(-1)\n",
    "#used parkinson and garman-klass\n",
    "futures_candle_df['hl_log_sqr'] = np.log(futures_candle_df[\"high\"]/futures_candle_df[\"low\"])**2\n",
    "#used in garman-klass\n",
    "futures_candle_df['co_log_sqr'] = np.log(futures_candle_df[\"close\"]/futures_candle_df[\"open\"])**2\n",
    "#used in rogers-satchell\n",
    "futures_candle_df['hc_log'] = np.log(futures_candle_df[\"high\"]/futures_candle_df[\"close\"])\n",
    "futures_candle_df['ho_log'] = np.log(futures_candle_df[\"high\"]/futures_candle_df[\"open\"])\n",
    "futures_candle_df['lc_log'] = np.log(futures_candle_df[\"low\"]/futures_candle_df[\"close\"])\n",
    "futures_candle_df['lo_log'] = np.log(futures_candle_df[\"low\"]/futures_candle_df[\"open\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb27b3e4-08d2-4b9b-82e3-16ab01bba304",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '3D'\n",
    "futures_candle_df['close_ewm'+day] = futures_candle_df['close'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['open_ewm'+day] = futures_candle_df['open'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['high_ewm'+day] = futures_candle_df['high'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['low_ewm'+day] = futures_candle_df['low'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['hl_log_sqr_ewm'+day] = futures_candle_df['hl_log_sqr'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['co_log_sqr_ewm'+day] = futures_candle_df['co_log_sqr'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['hc_log_ewm'+day] = futures_candle_df['hc_log'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['ho_log_ewm'+day] = futures_candle_df['ho_log'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['lc_log_ewm'+day] = futures_candle_df['lc_log'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['lo_log_ewm'+day] = futures_candle_df['lo_log'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_ewm'+day] = futures_candle_df['volume'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_24HR_ewm'+day] = futures_candle_df['volume_24HR'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_$_ewm'+day] = futures_candle_df['volume_$'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_24HR$_ewm'+day] = futures_candle_df['volume_24HR$'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "\n",
    "day = '7D'\n",
    "futures_candle_df['close_ewm'+day] = futures_candle_df['close'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['open_ewm'+day] = futures_candle_df['open'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['high_ewm'+day] = futures_candle_df['high'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['low_ewm'+day] = futures_candle_df['low'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['hl_log_sqr_ewm'+day] = futures_candle_df['hl_log_sqr'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['co_log_sqr_ewm'+day] = futures_candle_df['co_log_sqr'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['hc_log_ewm'+day] = futures_candle_df['hc_log'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['ho_log_ewm'+day] = futures_candle_df['ho_log'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['lc_log_ewm'+day] = futures_candle_df['lc_log'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['lo_log_ewm'+day] = futures_candle_df['lo_log'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_ewm'+day] = futures_candle_df['volume'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_24HR_ewm'+day] = futures_candle_df['volume_24HR'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_$_ewm'+day] = futures_candle_df['volume_$'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_24HR$_ewm'+day] = futures_candle_df['volume_24HR$'].ewm(halflife='3 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "\n",
    "\n",
    "\n",
    "day = '21D'\n",
    "futures_candle_df['close_ewm'+day] = futures_candle_df['close'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['open_ewm'+day] = futures_candle_df['open'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['high_ewm'+day] = futures_candle_df['high'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['low_ewm'+day] = futures_candle_df['low'].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['hl_log_sqr_ewm'+day] = futures_candle_df['hl_log_sqr'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['co_log_sqr_ewm'+day] = futures_candle_df['co_log_sqr'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['hc_log_ewm'+day] = futures_candle_df['hc_log'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['ho_log_ewm'+day] = futures_candle_df['ho_log'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['lc_log_ewm'+day] = futures_candle_df['lc_log'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['lo_log_ewm'+day] = futures_candle_df['lo_log'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_ewm'+day] = futures_candle_df['volume'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_24HR_ewm'+day] = futures_candle_df['volume_24HR'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_$_ewm'+day] = futures_candle_df['volume_$'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "futures_candle_df['volume_24HR$_ewm'+day] = futures_candle_df['volume_24HR$'].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c4b44e-d263-46fc-ad42-2f659b5e6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% make ewm % changes\n",
    "shifts = [1, 24]\n",
    "for col in futures_candle_df.columns:\n",
    "    if \"_ewm\" in col:\n",
    "        for s in shifts:\n",
    "            shift_df_temp = futures_candle_df.copy(deep=True).shift(s)\n",
    "            futures_candle_df = create_changePCT(futures_candle_df, shift_df_temp, col, str(s)+\"HR\")\n",
    "            \n",
    "            \n",
    "futures_candle_df.dropna(inplace=True)\n",
    "futures_candle_df.reset_index(drop = True, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6174eff9-25b2-4b60-bf6c-0be91fbc2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_windows = [1*24,3*24,5*24,7*24, 15*24, 30*24, 60*24]\n",
    "for x in vol_windows:\n",
    "    #make close2close\n",
    "    futures_candle_df['vol_c2c_'+str(x/24)+\"D\"] = (futures_candle_df['closeChg%24HR'].rolling(x).std()*((365)**.5))*100\n",
    "\n",
    "    \n",
    "    \n",
    "    #make parkinsonConsole 9\n",
    "    futures_candle_df['vol_park_'+str(x/24)+\"D\"] = (futures_candle_df['hl_log_sqr'].rolling(x).sum()*(1.0 / (4.0*(x)* np.log(2.0))))**.5\n",
    "    futures_candle_df['vol_park_'+str(x/24)+\"D\"] = (futures_candle_df['vol_park_'+str(x/24)+\"D\"]*((365*24)**.5))*100\n",
    "    \n",
    "    \n",
    "    \n",
    "    #make garman-klass\n",
    "    mult_one= 1/(2*x)\n",
    "    mult_two = (2*np.log(2)-1)/x\n",
    "    futures_candle_df['vol_garman_'+str(x/24)+\"D\"] = futures_candle_df['hl_log_sqr']-mult_two*futures_candle_df['co_log_sqr']\n",
    "    futures_candle_df['vol_garman_'+str(x/24)+\"D\"] = (mult_one*futures_candle_df['vol_garman_'+str(x/24)+\"D\"].rolling(x).sum())**.5\n",
    "    futures_candle_df['vol_garman_'+str(x/24)+\"D\"] = (futures_candle_df['vol_garman_'+str(x/24)+\"D\"]*((365*24)**.5))*100\n",
    "    #rogers-stachell\n",
    "    mult_one = 1/x\n",
    "    futures_candle_df['vol_rogers_'+str(x/24)+\"D\"] = (futures_candle_df['hc_log']*futures_candle_df['ho_log'])+ (futures_candle_df['lc_log']*futures_candle_df['lo_log'])\n",
    "    futures_candle_df['vol_rogers_'+str(x/24)+\"D\"] = (mult_one*futures_candle_df['vol_rogers_'+str(x/24)+\"D\"].rolling(x).sum())**.5\n",
    "    futures_candle_df['vol_rogers_'+str(x/24)+\"D\"] = (futures_candle_df['vol_rogers_'+str(x/24)+\"D\"]*((365*24)**.5))*100\n",
    "\n",
    "\n",
    "    #make EWM base don halflives\n",
    "    futures_candle_df['vol_c2c_'+str(x/24)+\"D\"+\"_ewm7D\"] = futures_candle_df['vol_c2c_'+str(x/24)+\"D\"].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "    futures_candle_df['vol_c2c_'+str(x/24)+\"D\"+\"_ewm21D\"] = futures_candle_df['vol_c2c_'+str(x/24)+\"D\"].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "    futures_candle_df['vol_park_'+str(x/24)+\"D\"+\"_ewm7D\"] = futures_candle_df['vol_park_'+str(x/24)+\"D\"].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "    futures_candle_df['vol_park_'+str(x/24)+\"D\"+\"_ewm21D\"] = futures_candle_df['vol_park_'+str(x/24)+\"D\"].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "    futures_candle_df['vol_garman_'+str(x/24)+\"D\"+\"_ewm7D\"] = futures_candle_df['vol_garman_'+str(x/24)+\"D\"].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "    futures_candle_df['vol_garman_'+str(x/24)+\"D\"+\"_ewm21D\"] = futures_candle_df['vol_garman_'+str(x/24)+\"D\"].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "    futures_candle_df['vol_rogers_'+str(x/24)+\"D\"+\"_ewm7D\"] = futures_candle_df['vol_rogers_'+str(x/24)+\"D\"].ewm(halflife='7 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "    futures_candle_df['vol_rogers_'+str(x/24)+\"D\"+\"_ewm21D\"] = futures_candle_df['vol_rogers_'+str(x/24)+\"D\"].ewm(halflife='21 days', times=pd.DatetimeIndex(futures_candle_df['dt'])).mean()\n",
    "#24hr and 1hr changes  \n",
    "shifts = [1, 24]\n",
    "for col in futures_candle_df.columns:\n",
    "    if \"vol_\" in col:\n",
    "        for s in shifts:\n",
    "            shift_df_temp = futures_candle_df.copy(deep=True).shift(s)\n",
    "            futures_candle_df = create_changePCT(futures_candle_df, shift_df_temp, col, str(s)+\"HR\")   \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3437e-c919-435d-9a2e-56327785c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%get pred\n",
    "futures_candle_df['closeChg%_forward24HR'] = futures_candle_df['closeChg%24HR'].shift(-24)\n",
    "futures_candle_df['closeChg%_forward1HR'] = futures_candle_df['closeChg%1HR'].shift(-1)\n",
    "#get up down or chop based on sdev\n",
    "std_24 = futures_candle_df['closeChg%_forward24HR'].std()\n",
    "std_1 = futures_candle_df['closeChg%_forward1HR'].std()\n",
    "for index, row in futures_candle_df.iterrows():\n",
    "    if abs(row['closeChg%_forward24HR'])>=  std_24:\n",
    "        if row['closeChg%_forward24HR'] > 0:\n",
    "            futures_candle_df.at[index,'UpDownPred24HR' ] =1\n",
    "        else:\n",
    "            futures_candle_df.at[index,'UpDownPred24HR' ] =-1\n",
    "    else:\n",
    "        futures_candle_df.at[index,'UpDownPred24HR' ] =0\n",
    "    if abs(row['closeChg%_forward1HR'])>=  std_1:\n",
    "        if row['closeChg%_forward1HR'] > 0:\n",
    "            futures_candle_df.at[index,'UpDownPred1HR' ] =1\n",
    "        else:\n",
    "            futures_candle_df.at[index,'UpDownPred1HR' ] =-1\n",
    "    else:\n",
    "        futures_candle_df.at[index,'UpDownPred1HR' ] =0\n",
    "\n",
    "\n",
    "\n",
    "futures_candle_df.dropna(inplace=True)\n",
    "futures_candle_df.reset_index(drop = True, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc19c436-c6c0-456d-bd48-dd58ce7f84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% classification 24hr\n",
    "start_class = datetime.now()\n",
    "from pycaret.classification import *\n",
    "#number_columns = 100/(len(futures_candle_df.columns))\n",
    "exp_clf24 = setup(futures_candle_df,target='UpDownPred24HR',\n",
    "        ignore_features=['dt', 'exchange', 'timestamp', 'instrument', 'closeChg%_forward1HR', 'closeChg%_forward24HR', 'UpDownPred1HR'],session_id=11,\n",
    "        profile=False,  use_gpu=True,  normalize = True,  remove_multicollinearity=True) \n",
    "end_setup_class= datetime.now()\n",
    "models_class = compare_models(turbo=True, n_select =4)\n",
    "model_df_class = pull()\n",
    "best_models_class = model_df_class .iloc[0:4]\n",
    "\n",
    "end_class = datetime.now()\n",
    "print('class_setup_config', (end_setup_class - start_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259762d8-859a-48fd-907b-3e5eaaab0611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
